<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8a7765b85f123e8a62aa3847141ca072",
  "translation_date": "2025-10-30T13:07:22+00:00",
  "source_file": "Module06/03.IntroduceMCP.md",
  "language_code": "da"
}
-->
# Afsnit 03 - Integration af Model Context Protocol (MCP)

## Introduktion til MCP (Model Context Protocol)

Model Context Protocol (MCP) er en open-source standard til at forbinde AI-applikationer med eksterne systemer. Ved hjælp af MCP kan AI-applikationer som Claude eller ChatGPT forbindes til datakilder (f.eks. lokale filer, databaser), værktøjer (f.eks. søgemaskiner, regnemaskiner) og arbejdsgange (f.eks. specialiserede prompts)—hvilket gør det muligt for dem at få adgang til vigtig information og udføre opgaver.

Tænk på MCP som en **USB-C-port for AI-applikationer**. Ligesom USB-C giver en standardiseret måde at forbinde elektroniske enheder på, giver MCP en standardiseret måde at forbinde AI-applikationer med eksterne systemer.

### Hvad kan MCP muliggøre?

MCP åbner op for kraftfulde funktioner for AI-applikationer:

- **Personlige AI-assistenter**: Agenter kan få adgang til din Google Kalender og Notion og fungere som en mere personlig AI-assistent
- **Avanceret kodegenerering**: Claude Code kan generere en hel webapp baseret på et Figma-design
- **Integration af virksomhedsdata**: Virksomhedschatbots kan forbinde til flere databaser på tværs af organisationen og give brugere mulighed for at analysere data via chat
- **Kreative arbejdsgange**: AI-modeller kan skabe 3D-designs i Blender og printe dem ud med en 3D-printer
- **Adgang til realtidsinformation**: Forbind til eksterne datakilder for opdateret information
- **Komplekse flertrinsoperationer**: Udfør sofistikerede arbejdsgange, der kombinerer flere værktøjer og systemer

### Hvorfor er MCP vigtigt?

MCP giver fordele på tværs af økosystemet:

**For udviklere**: MCP reducerer udviklingstid og kompleksitet ved opbygning eller integration med en AI-applikation eller agent.

**For AI-applikationer**: MCP giver adgang til et økosystem af datakilder, værktøjer og apps, som forbedrer funktionaliteten og brugeroplevelsen.

**For slutbrugere**: MCP resulterer i mere kapable AI-applikationer eller agenter, der kan få adgang til dine data og handle på dine vegne, når det er nødvendigt.

## Små sprogmodeller (SLMs) i MCP

Små sprogmodeller repræsenterer en effektiv tilgang til AI-implementering og tilbyder flere fordele:

### Fordele ved SLMs
- **Ressourceeffektivitet**: Lavere krav til beregningskraft
- **Hurtigere svartider**: Mindre forsinkelse for realtidsapplikationer  
- **Omkostningseffektivitet**: Minimale infrastrukturbehov
- **Privatliv**: Kan køre lokalt uden dataoverførsel
- **Tilpasning**: Nem at finjustere til specifikke domæner

### Hvorfor SLMs fungerer godt med MCP

SLMs kombineret med MCP skaber en kraftfuld kombination, hvor modellens ræsonnementsevner forstærkes af eksterne værktøjer, hvilket kompenserer for deres mindre parameterantal gennem forbedret funktionalitet.

## Python MCP SDK Oversigt

Python MCP SDK giver fundamentet for at bygge MCP-aktiverede applikationer. SDK'en inkluderer:

- **Klientbiblioteker**: Til at forbinde til MCP-servere
- **Serverframework**: Til at oprette brugerdefinerede MCP-servere
- **Protokolhåndterere**: Til at administrere kommunikation
- **Værktøjsintegration**: Til at udføre eksterne funktioner

## Praktisk implementering: Phi-4 MCP-klient

Lad os udforske en implementering i den virkelige verden ved hjælp af Microsofts Phi-4 mini-model integreret med MCP-funktioner.

### MCP Arkitektur Oversigt

MCP følger en **klient-server arkitektur**, hvor en MCP-vært (en AI-applikation som Claude Code eller Claude Desktop) etablerer forbindelser til en eller flere MCP-servere. MCP-værten opnår dette ved at oprette en MCP-klient for hver MCP-server.

#### Nøgleaktører

- **MCP-vært**: AI-applikationen, der koordinerer og administrerer en eller flere MCP-klienter
- **MCP-klient**: En komponent, der opretholder en forbindelse til en MCP-server og henter kontekst fra en MCP-server, som MCP-værten kan bruge
- **MCP-server**: Et program, der leverer kontekst til MCP-klienter

#### To-lags arkitektur

MCP består af to adskilte lag:

**Datalag**: Definerer den JSON-RPC-baserede protokol for klient-server kommunikation, herunder:
- Livscyklusstyring (initialisering af forbindelse, kapabilitetsforhandling)
- Kerneprimitiver (værktøjer, ressourcer, prompts)
- Klientfunktioner (sampling, elicitation, logging)
- Hjælpefunktioner (notifikationer, fremskridtssporing)

**Transportlag**: Definerer kommunikationsmekanismer og kanaler:
- **STDIO Transport**: Bruger standard input/output streams til lokale processer (optimal ydeevne, ingen netværksbelastning)
- **Streamable HTTP Transport**: Bruger HTTP POST med valgfri Server-Sent Events til fjernservere (understøtter standard HTTP-autentifikation)

```
┌─────────────────────────────────────┐
│           MCP Host                  │
│     (AI Application)                │
└─────────────────┬───────────────────┘
                  │
┌─────────────────┴───────────────────┐
│         MCP Client 1                │
│  ┌─────────────────────────────────┐ │
│  │        Data Layer               │ │
│  │  ├── Lifecycle Management       │ │
│  │  ├── Primitives (Tools/Resources)│ │
│  │  └── Notifications              │ │
│  └─────────────────────────────────┘ │
│  ┌─────────────────────────────────┐ │
│  │      Transport Layer           │ │
│  │  ├── STDIO Transport           │ │
│  │  └── HTTP Transport            │ │
│  └─────────────────────────────────┘ │
└─────────────────┬───────────────────┘
                  │
┌─────────────────┴───────────────────┐
│         MCP Server 1                │
│    (Local/Remote Context Provider)  │
└─────────────────────────────────────┘
```

### MCP Kerneprimitiver

MCP definerer primitivere, der specificerer typer af kontekstuel information, der kan deles med AI-applikationer, og rækkevidden af handlinger, der kan udføres.

#### Serverprimitiver

MCP definerer tre kerneprimitiver, som servere kan eksponere:

**Værktøjer**: Udførbare funktioner, som AI-applikationer kan kalde for at udføre handlinger
- Eksempler: filoperationer, API-kald, databaseforespørgsler
- Metoder: `tools/list`, `tools/call`
- Understøtter dynamisk opdagelse og udførelse

**Ressourcer**: Datakilder, der giver kontekstuel information til AI-applikationer
- Eksempler: filindhold, databaseposter, API-svar
- Metoder: `resources/list`, `resources/read`
- Muliggør adgang til strukturerede data

**Prompts**: Genanvendelige skabeloner, der hjælper med at strukturere interaktioner med sprogmodeller
- Eksempler: systemprompts, få-skud eksempler
- Metoder: `prompts/list`, `prompts/get`
- Standardiserer AI-interaktionsmønstre

#### Klientprimitiver

MCP definerer også primitivere, som klienter kan eksponere for at muliggøre rigere interaktioner:

**Sampling**: Tillader servere at anmode om sprogmodelkompletteringer fra klientens AI-applikation
- Metode: `sampling/complete`
- Muliggør modeluafhængig serverudvikling
- Giver adgang til værtens sprogmodel

**Elicitation**: Tillader servere at anmode om yderligere information fra brugere
- Metode: `elicitation/request`
- Muliggør brugerinteraktion og bekræftelse
- Understøtter dynamisk informationsindsamling

**Logging**: Gør det muligt for servere at sende logbeskeder til klienter
- Bruges til fejlfinding og overvågning
- Giver indsigt i serveroperationer

### MCP Protokollivscyklus

#### Initialisering og kapabilitetsforhandling

MCP er en tilstandsbaseret protokol, der kræver livscyklusstyring. Initialiseringsprocessen tjener flere kritiske formål:

1. **Protokolversionsforhandling**: Sikrer, at både klient og server bruger kompatible protokolversioner (f.eks. "2025-06-18")
2. **Kapabilitetsopdagelse**: Hver part erklærer understøttede funktioner og primitivere
3. **Identitetsudveksling**: Giver identifikations- og versionsinformation

```python
# Example initialization request
{
  "jsonrpc": "2.0",
  "id": 1,
  "method": "initialize",
  "params": {
    "protocolVersion": "2025-06-18",
    "capabilities": {
      "elicitation": {},  # Client supports user interaction
      "sampling": {}      # Client can provide LLM completions
    },
    "clientInfo": {
      "name": "edge-ai-client",
      "version": "1.0.0"
    }
  }
}
```

#### Værktøjsopdagelse og udførelse

Efter initialisering kan klienter opdage og udføre værktøjer:

```python
# Discover available tools
tools_response = await session.list_tools()

# Execute a tool
result = await session.call_tool(
    "weather_current",
    {
        "location": "San Francisco",
        "units": "imperial"
    }
)
```

#### Realtidsnotifikationer

MCP understøtter realtidsnotifikationer for dynamiske opdateringer:

```python
# Server sends notification when tools change
{
  "jsonrpc": "2.0",
  "method": "notifications/tools/list_changed"
}

# Client responds by refreshing tool list
await session.list_tools()  # Get updated tools
```

## Kom godt i gang: Trin-for-trin guide

### Trin 1: Opsætning af miljø

Installer nødvendige afhængigheder:
```bash
pip install fastmcp mcp-python-client openai requests pyautogui Pillow
```

### Trin 2: Grundlæggende konfiguration

Opsæt dine miljøvariabler:
```python
# System Configuration
SYSTEM_PROMPT = "You are an AI assistant with some tools."

# Ollama Configuration (Local)
OLLAMA_URL = "http://localhost:11434/api/chat"
OLLAMA_MODEL_ID = "phi4-mini:3.8b-fp16"

# vLLM Configuration (Server)
VLLM_URL = "http://localhost:8000/v1"
VLLM_MODEL_ID = "microsoft/Phi-4-mini-instruct"
```

### Trin 3: Kør din første MCP-klient

**Grundlæggende Ollama-opsætning:**
```bash
python ghmodel_mcp_demo.py
```

**Brug af vLLM-backend:**
```bash
python ghmodel_mcp_demo.py --env vllm
```

**Server-Sent Events-forbindelse:**
```bash
python ghmodel_mcp_demo.py --run sse
```

**Brugerdefineret MCP-server:**
```bash
python ghmodel_mcp_demo.py --server /path/to/server.py
```

### Trin 4: Programmerbar brug

```python
import asyncio
from ghmodel_mcp_demo import OllamaClient, Phi4MiniMCPClient

async def automated_interaction():
    # Configure MCP server parameters
    server_params = StdioServerParameters(
        command="npx",
        args=["@playwright/mcp@latest"],
        env=None,
    )
    
    # Create MCP client and process tools
    async with Phi4MiniMCPClient(server_params) as mcp_client:
        tools = await process_mcp_tools(mcp_client)
        llm_client = OllamaClient()
        
        # Generate response with tool capabilities
        response, messages = await llm_client.generate_response(
            "Help me automate a web task",
            tools
        )
        return response

# Execute the automation
result = asyncio.run(automated_interaction())
print(result)
```

## Avancerede funktioner

### Multi-backend support

Implementeringen understøtter både Ollama og vLLM backends, så du kan vælge baseret på dine behov:

- **Ollama**: Bedre til lokal udvikling og test
- **vLLM**: Optimeret til produktion og høj gennemstrømning

### Fleksible forbindelsesprotokoller

To forbindelsestilstande understøttes:

**STDIO Mode**: Direkte proceskommunikation
- Lavere forsinkelse
- Egnet til lokale værktøjer
- Enkel opsætning

**SSE Mode**: HTTP-baseret streaming
- Netværkskompatibel
- Bedre til distribuerede systemer
- Realtidsopdateringer

### Værktøjsintegrationsmuligheder

Systemet kan integreres med forskellige værktøjer:
- Webautomatisering (Playwright)
- Filoperationer
- API-interaktioner
- Systemkommandoer
- Brugerdefinerede funktioner

## Fejlhåndtering og bedste praksis

### Omfattende fejlhåndtering

Implementeringen inkluderer robust fejlhåndtering for:

**Forbindelsesfejl**:
- MCP-serverfejl
- Netværksudfald
- Forbindelsesproblemer

**Værktøjsudførelsesfejl**:
- Manglende værktøjer
- Parametervalidering
- Udførelsesfejl

**Responsbehandlingsfejl**:
- JSON-parsning
- Formatinkonsistenser
- LLM-responsanomalier

### Bedste praksis

1. **Ressourcestyring**: Brug asynkrone kontekststyrere
2. **Fejlhåndtering**: Implementer omfattende try-catch blokke
3. **Logging**: Aktiver passende logningsniveauer
4. **Sikkerhed**: Valider input og rens output
5. **Ydeevne**: Brug forbindelsespooling og caching

## Anvendelser i den virkelige verden

### Webautomatisering
```python
# Example: Automated web testing
async def web_automation_example():
    tools = await setup_playwright_tools()
    response = await llm_client.generate_response(
        "Navigate to example.com and take a screenshot",
        tools
    )
```

### Databehandling
```python
# Example: File analysis
async def data_processing_example():
    tools = await setup_file_tools()
    response = await llm_client.generate_response(
        "Analyze the CSV file and generate a summary report",
        tools
    )
```

### API-integration
```python
# Example: API interactions
async def api_integration_example():
    tools = await setup_api_tools()
    response = await llm_client.generate_response(
        "Fetch weather data and create a forecast summary",
        tools
    )
```

## Performanceoptimering

### Hukommelsesstyring
- Effektiv håndtering af beskedhistorik
- Korrekt oprydning af ressourcer
- Forbindelsespooling

### Netværksoptimering
- Asynkrone HTTP-operationer
- Konfigurerbare timeouts
- Smidig fejlgendannelse

### Samtidig behandling
- Ikke-blokerende I/O
- Parallel værktøjsudførelse
- Effektive asynkrone mønstre

## Sikkerhedsovervejelser

### Databeskyttelse
- Sikker håndtering af API-nøgler
- Inputvalidering
- Outputsanitering

### Netværkssikkerhed
- HTTPS-understøttelse
- Standardindstillinger for lokale endpoints
- Sikker tokenhåndtering

### Udførelsessikkerhed
- Filtrering af værktøjer
- Sandkassemiljøer
- Audit-logning

## MCP Økosystem og udvikling

### MCP Projektomfang

Model Context Protocol-økosystemet inkluderer flere nøglekomponenter:

- **[MCP Specifikation](https://modelcontextprotocol.io/specification/latest)**: Officiel specifikation, der beskriver implementeringskrav for klienter og servere
- **[MCP SDKs](https://modelcontextprotocol.io/docs/sdk)**: SDK'er for forskellige programmeringssprog, der implementerer MCP
- **MCP Udviklingsværktøjer**: Værktøjer til udvikling af MCP-servere og -klienter, inklusive [MCP Inspector](https://github.com/modelcontextprotocol/inspector)
- **[MCP Reference Server Implementeringer](https://github.com/modelcontextprotocol/servers)**: Referenceimplementeringer af MCP-servere

### Kom godt i gang med MCP-udvikling

For at begynde at bygge med MCP:

**Byg servere**: [Opret MCP-servere](https://modelcontextprotocol.io/docs/develop/build-server) for at eksponere dine data og værktøjer

**Byg klienter**: [Udvikl applikationer](https://modelcontextprotocol.io/docs/develop/build-client), der forbinder til MCP-servere

**Lær koncepter**: [Forstå de grundlæggende koncepter](https://modelcontextprotocol.io/docs/learn/architecture) og arkitekturen bag MCP

## Konklusion

SLMs integreret med MCP repræsenterer et paradigmeskift i udviklingen af AI-applikationer. Ved at kombinere effektiviteten af små modeller med kraften fra eksterne værktøjer kan udviklere skabe intelligente systemer, der både er ressourceeffektive og meget kapable.

Model Context Protocol giver en standardiseret måde at forbinde AI-applikationer med eksterne systemer, ligesom USB-C giver en universel forbindelsesstandard for elektroniske enheder. Denne standardisering muliggør:

- **Problemfri integration**: Forbind AI-modeller til forskellige datakilder og værktøjer
- **Økosystemvækst**: Byg én gang, brug på tværs af flere AI-applikationer
- **Forbedrede funktioner**: Forstærk SLMs med ekstern funktionalitet
- **Realtidsopdateringer**: Understøt dynamiske, responsive AI-applikationer

Vigtige pointer:
- MCP er en åben standard, der forbinder AI-applikationer og eksterne systemer
- Protokollen understøtter værktøjer, ressourcer og prompts som kerneprimitiver
- Realtidsnotifikationer muliggør dynamiske, responsive applikationer
- Korrekt livscyklusstyring og fejlhåndtering er afgørende for produktionsbrug
- Økosystemet tilbyder omfattende SDK'er og udviklingsværktøjer

## Referencer og yderligere læsning

### Officiel MCP Dokumentation

- **[Model Context Protocol Officielt Site](https://modelcontextprotocol.io/)** - Komplet dokumentation og specifikationer
- **[MCP Kom godt i gang Guide](https://modelcontextprotocol.io/docs/getting-started/intro)** - Introduktion og grundlæggende koncepter
- **[MCP Arkitektur Oversigt](https://modelcontextprotocol.io/docs/learn/architecture)** - Detaljeret teknisk arkitektur
- **[MCP Specifikation](https://modelcontextprotocol.io/specification/latest)** - Officiel protokolspecifikation
- **[MCP SDKs Dokumentation](https://modelcontextprotocol.io/docs/sdk)** - Sprog-specifikke SDK-guides

### Udviklingsressourcer

- **[MCP for begyndere](https://aka.ms/mcp-for-beginners)** - Omfattende begyndervejledning til Model Context Protocol
- **[MCP GitHub Organisation](https://github.com/modelcontextprotocol)** - Officielle repositories og eksempler
- **[MCP Server Repository](https://github.com/modelcontextprotocol/servers)** - Reference serverimplementeringer
- **[MCP Inspector](https://github.com/modelcontextprotocol/inspector)** - Udviklings- og fejlsøgningsværktøj
- **[Byg MCP Servere Guide](https://modelcontextprotocol.io/docs/develop/build-server)** - Serverudviklingsvejledning
- **[Byg MCP Klienter Guide](https://modelcontextprotocol.io/docs/develop/build-client)** - Klientudviklingsvejledning

### Små sprogmodeller og Edge AI

- **[Microsoft Phi Modeller](https://aka.ms/phicookbook)** - Phi-modelfamilien 
- **[Foundry Local Dokumentation](https://github.com/microsoft/Foundry-Local)** - Microsofts edge AI runtime
- **[Ollama Dokumentation](https://ollama.ai/docs)** - Platform til lokal LLM-implementering
- **[vLLM Dokumentation](https://docs.vllm.ai/)** - Højtydende LLM-servering

### Tekniske standarder og protokoller

- **[JSON-RPC 2.0 Specifikation](https://www.jsonrpc.org/)** - Underliggende RPC-protokol brugt af MCP
- **[JSON Schema](https://json-schema.org/)** - Standard for skemadefinition til MCP-værktøjer
- **[OpenAPI Specifikation](https://swagger.io/specification/)** - Standard for API-dokumentation
- **[Server-Sent Events (SSE)](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events)** - Webstandard for realtidsopdateringer

### Udvikling af AI-agenter

- **[Microsoft Agent Framework](https://github.com/microsoft/agent-framework)** - Produktionsklar udvikling af agenter
- **[LangChain Dokumentation](https://docs.langchain.com/)** - Framework til integration af agenter og værktøjer
- **[Semantic Kernel](https://learn.microsoft.com/en-us/semantic-kernel/)** - Microsofts SDK til AI-orkestrering

### Brancheanalyser og forskning

- **[Anthropics Model Context Protocol Announcement](https://www.anthropic.com/news/model-context-protocol)** - Oprindelig MCP-introduktion
- **[Small Language Models Survey](https://arxiv.org/abs/2410.20011)** - Akademisk undersøgelse af SLM-forskning
- **[Edge AI Markedsanalyse](https://www.marketsandmarkets.com/Market-Reports/edge-ai-software-market-74385617.html)** - Branchetrends og prognoser
- **[AI Agent Development Best Practices](https://arxiv.org/abs/2309.02427)** - Forskning i agentarkitekturer

Denne sektion giver fundamentet for at bygge dine egne MCP-applikationer drevet af SLM, hvilket åbner op for muligheder inden for automatisering, databehandling og integration af intelligente systemer.

## ➡️ Hvad er næste skridt

- [Modul 7. Edge AI eksempler](../Module07/README.md)

---

**Ansvarsfraskrivelse**:  
Dette dokument er blevet oversat ved hjælp af AI-oversættelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selvom vi bestræber os på nøjagtighed, skal det bemærkes, at automatiserede oversættelser kan indeholde fejl eller unøjagtigheder. Det originale dokument på dets oprindelige sprog bør betragtes som den autoritative kilde. For kritisk information anbefales professionel menneskelig oversættelse. Vi er ikke ansvarlige for eventuelle misforståelser eller fejltolkninger, der opstår som følge af brugen af denne oversættelse.