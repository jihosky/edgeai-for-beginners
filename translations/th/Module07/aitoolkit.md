<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "efb0e70d6e87d0795f4d381c3bc99074",
  "translation_date": "2025-10-21T07:15:59+00:00",
  "source_file": "Module07/aitoolkit.md",
  "language_code": "th"
}
-->
# AI Toolkit สำหรับ Visual Studio Code - คู่มือการพัฒนา Edge AI

## บทนำ

ยินดีต้อนรับสู่คู่มือฉบับสมบูรณ์สำหรับการใช้งาน AI Toolkit ใน Visual Studio Code เพื่อการพัฒนา Edge AI เมื่อปัญญาประดิษฐ์ก้าวออกจากการประมวลผลบนคลาวด์แบบรวมศูนย์ไปสู่การใช้งานบนอุปกรณ์ Edge ที่กระจายตัว นักพัฒนาจำเป็นต้องมีเครื่องมือที่ทรงพลังและครบวงจรที่สามารถจัดการกับความท้าทายเฉพาะของการใช้งาน Edge เช่น ข้อจำกัดด้านทรัพยากรและความต้องการในการทำงานแบบออฟไลน์

AI Toolkit สำหรับ Visual Studio Code ช่วยเติมเต็มช่องว่างนี้โดยการมอบสภาพแวดล้อมการพัฒนาที่สมบูรณ์แบบซึ่งออกแบบมาเพื่อสร้าง ทดสอบ และปรับปรุงแอปพลิเคชัน AI ที่ทำงานได้อย่างมีประสิทธิภาพบนอุปกรณ์ Edge ไม่ว่าคุณจะพัฒนาสำหรับเซ็นเซอร์ IoT อุปกรณ์มือถือ ระบบฝังตัว หรือเซิร์ฟเวอร์ Edge เครื่องมือนี้ช่วยให้กระบวนการพัฒนาทั้งหมดของคุณง่ายขึ้นภายในสภาพแวดล้อมที่คุ้นเคยของ VS Code

คู่มือนี้จะนำคุณผ่านแนวคิดสำคัญ เครื่องมือ และแนวปฏิบัติที่ดีที่สุดสำหรับการใช้ AI Toolkit ในโครงการ Edge AI ของคุณ ตั้งแต่การเลือกโมเดลเริ่มต้นไปจนถึงการใช้งานในระดับผลิต

## ภาพรวม

AI Toolkit สำหรับ Visual Studio Code เป็นส่วนขยายที่ทรงพลังที่ช่วยให้การพัฒนาเอเจนต์และการสร้างแอปพลิเคชัน AI เป็นไปอย่างราบรื่น เครื่องมือนี้มีความสามารถที่ครอบคลุมสำหรับการสำรวจ ประเมิน และใช้งานโมเดล AI จากผู้ให้บริการหลากหลาย เช่น Anthropic, OpenAI, GitHub, Google พร้อมทั้งรองรับการใช้งานโมเดลในเครื่องด้วย ONNX และ Ollama

สิ่งที่ทำให้ AI Toolkit โดดเด่นคือแนวทางที่ครอบคลุมตลอดวงจรการพัฒนา AI แตกต่างจากเครื่องมือพัฒนา AI แบบดั้งเดิมที่มุ่งเน้นเพียงบางส่วน AI Toolkit มอบสภาพแวดล้อมที่ครบวงจรซึ่งครอบคลุมการค้นหาโมเดล การทดลอง การพัฒนาเอเจนต์ การประเมิน และการใช้งาน ทั้งหมดนี้อยู่ในสภาพแวดล้อมที่คุ้นเคยของ VS Code

แพลตฟอร์มนี้ออกแบบมาเพื่อการสร้างต้นแบบอย่างรวดเร็วและการใช้งานในระดับผลิต ด้วยฟีเจอร์อย่างการสร้างคำสั่งเริ่มต้น ตัวช่วยเริ่มต้นที่รวดเร็ว การผสานรวมเครื่องมือ MCP (Model Context Protocol) อย่างไร้รอยต่อ และความสามารถในการประเมินที่ครอบคลุม สำหรับการพัฒนา Edge AI หมายความว่าคุณสามารถพัฒนา ทดสอบ และปรับปรุงแอปพลิเคชัน AI สำหรับสถานการณ์การใช้งาน Edge ได้อย่างมีประสิทธิภาพในขณะที่ยังคงรักษากระบวนการพัฒนาเต็มรูปแบบภายใน VS Code

## วัตถุประสงค์การเรียนรู้

เมื่อจบคู่มือนี้ คุณจะสามารถ:

### ความสามารถหลัก
- **ติดตั้งและกำหนดค่า** AI Toolkit สำหรับ Visual Studio Code เพื่อการพัฒนา Edge AI
- **นำทางและใช้งาน** อินเทอร์เฟซ AI Toolkit รวมถึง Model Catalog, Playground และ Agent Builder
- **เลือกและประเมิน** โมเดล AI ที่เหมาะสมสำหรับการใช้งาน Edge โดยพิจารณาจากประสิทธิภาพและข้อจำกัดด้านทรัพยากร
- **แปลงและปรับปรุง** โมเดลโดยใช้รูปแบบ ONNX และเทคนิคการลดขนาดสำหรับอุปกรณ์ Edge

### ทักษะการพัฒนา Edge AI
- **ออกแบบและพัฒนา** แอปพลิเคชัน Edge AI โดยใช้สภาพแวดล้อมการพัฒนาที่ครบวงจร
- **ทดสอบโมเดล** ในสภาพแวดล้อมที่คล้ายกับ Edge โดยใช้การอนุมานในเครื่องและการตรวจสอบทรัพยากร
- **สร้างและปรับแต่ง** เอเจนต์ AI ที่เหมาะสมสำหรับสถานการณ์การใช้งาน Edge
- **ประเมินประสิทธิภาพโมเดล** โดยใช้เมตริกที่เกี่ยวข้องกับการประมวลผล Edge (ความหน่วงเวลา การใช้หน่วยความจำ ความแม่นยำ)

### การปรับปรุงและการใช้งาน
- **ใช้เทคนิคการลดขนาดและการตัดแต่ง** เพื่อลดขนาดโมเดลในขณะที่ยังคงรักษาประสิทธิภาพที่ยอมรับได้
- **ปรับปรุงโมเดล** สำหรับแพลตฟอร์มฮาร์ดแวร์ Edge เฉพาะ เช่น CPU, GPU และ NPU
- **นำแนวปฏิบัติที่ดีที่สุด** สำหรับการพัฒนา Edge AI รวมถึงการจัดการทรัพยากรและกลยุทธ์สำรอง
- **เตรียมโมเดลและแอปพลิเคชัน** สำหรับการใช้งานในระดับผลิตบนอุปกรณ์ Edge

### แนวคิด Edge AI ขั้นสูง
- **ผสานรวมกับเฟรมเวิร์ก Edge AI** เช่น ONNX Runtime, Windows ML และ TensorFlow Lite
- **ใช้งานสถาปัตยกรรมหลายโมเดล** และสถานการณ์การเรียนรู้แบบกระจายสำหรับสภาพแวดล้อม Edge
- **แก้ไขปัญหา Edge AI ทั่วไป** เช่น ข้อจำกัดด้านหน่วยความจำ ความเร็วในการอนุมาน และความเข้ากันได้ของฮาร์ดแวร์
- **ออกแบบกลยุทธ์การตรวจสอบและบันทึก** สำหรับแอปพลิเคชัน Edge AI ในระดับผลิต

### การประยุกต์ใช้งานจริง
- **สร้างโซลูชัน Edge AI แบบครบวงจร** ตั้งแต่การเลือกโมเดลไปจนถึงการใช้งาน
- **แสดงความเชี่ยวชาญ** ในกระบวนการพัฒนาและเทคนิคการปรับปรุงที่เฉพาะเจาะจงสำหรับ Edge
- **นำแนวคิดที่เรียนรู้มาใช้** กับกรณีการใช้งาน Edge AI ในโลกจริง เช่น IoT, มือถือ และแอปพลิเคชันฝังตัว
- **ประเมินและเปรียบเทียบ** กลยุทธ์การใช้งาน Edge AI ต่าง ๆ และข้อดีข้อเสียของแต่ละกลยุทธ์

## ฟีเจอร์สำคัญสำหรับการพัฒนา Edge AI

### 1. Model Catalog และการค้นหา
- **รองรับผู้ให้บริการหลายราย**: เรียกดูและเข้าถึงโมเดล AI จาก Anthropic, OpenAI, GitHub, Google และผู้ให้บริการอื่น ๆ
- **การผสานรวมโมเดลในเครื่อง**: การค้นหาโมเดล ONNX และ Ollama สำหรับการใช้งาน Edge ที่ง่ายขึ้น
- **โมเดล GitHub**: การผสานรวมโดยตรงกับการโฮสต์โมเดลของ GitHub เพื่อการเข้าถึงที่ง่ายดาย
- **การเปรียบเทียบโมเดล**: เปรียบเทียบโมเดลแบบเคียงข้างกันเพื่อค้นหาสมดุลที่เหมาะสมสำหรับข้อจำกัดของอุปกรณ์ Edge

### 2. Interactive Playground
- **สภาพแวดล้อมการทดสอบแบบโต้ตอบ**: ทดลองความสามารถของโมเดลอย่างรวดเร็วในสภาพแวดล้อมที่ควบคุมได้
- **รองรับหลายรูปแบบ**: ทดสอบด้วยภาพ ข้อความ และอินพุตอื่น ๆ ที่พบในสถานการณ์ Edge
- **การทดลองแบบเรียลไทม์**: รับผลตอบกลับทันทีเกี่ยวกับการตอบสนองและประสิทธิภาพของโมเดล
- **การปรับพารามิเตอร์**: ปรับแต่งพารามิเตอร์โมเดลให้เหมาะสมกับข้อกำหนดการใช้งาน Edge

### 3. Prompt (Agent) Builder
- **การสร้างคำสั่งด้วยภาษาธรรมชาติ**: สร้างคำสั่งเริ่มต้นโดยใช้คำอธิบายภาษาธรรมชาติ
- **การปรับปรุงแบบวนซ้ำ**: ปรับปรุงคำสั่งตามการตอบสนองและประสิทธิภาพของโมเดล
- **การแบ่งงาน**: แบ่งงานที่ซับซ้อนด้วยการเชื่อมโยงคำสั่งและผลลัพธ์ที่มีโครงสร้าง
- **รองรับตัวแปร**: ใช้ตัวแปรในคำสั่งเพื่อพฤติกรรมเอเจนต์ที่เปลี่ยนแปลงได้
- **การสร้างโค้ดสำหรับการผลิต**: สร้างโค้ดพร้อมใช้งานสำหรับการพัฒนาแอปอย่างรวดเร็ว

### 4. Bulk Run และการประเมิน
- **การทดสอบหลายโมเดล**: รันคำสั่งหลายคำสั่งพร้อมกันในโมเดลที่เลือก
- **การทดสอบที่มีประสิทธิภาพในระดับใหญ่**: ทดสอบอินพุตและการกำหนดค่าต่าง ๆ ได้อย่างมีประสิทธิภาพ
- **กรณีทดสอบที่กำหนดเอง**: รันเอเจนต์ด้วยกรณีทดสอบเพื่อยืนยันการทำงาน
- **การเปรียบเทียบประสิทธิภาพ**: เปรียบเทียบผลลัพธ์ในโมเดลและการกำหนดค่าต่าง ๆ

### 5. การประเมินโมเดลด้วยชุดข้อมูล
- **เมตริกมาตรฐาน**: ทดสอบโมเดล AI โดยใช้ตัวประเมินในตัว (F1 score, ความเกี่ยวข้อง, ความคล้ายคลึง, ความสอดคล้อง)
- **ตัวประเมินที่กำหนดเอง**: สร้างเมตริกการประเมินของคุณเองสำหรับกรณีการใช้งานเฉพาะ
- **การผสานรวมชุดข้อมูล**: ทดสอบโมเดลกับชุดข้อมูลที่ครอบคลุม
- **การวัดประสิทธิภาพ**: วัดประสิทธิภาพโมเดลสำหรับการตัดสินใจใช้งาน Edge

### 6. ความสามารถในการปรับแต่ง
- **การปรับแต่งโมเดล**: ปรับแต่งโมเดลสำหรับกรณีการใช้งานและโดเมนเฉพาะ
- **การปรับให้เหมาะสมเฉพาะทาง**: ปรับโมเดลให้เหมาะสมกับข้อกำหนดและโดเมนเฉพาะ
- **การปรับปรุงสำหรับ Edge**: ปรับแต่งโมเดลโดยเฉพาะสำหรับข้อจำกัดการใช้งาน Edge
- **การฝึกอบรมเฉพาะโดเมน**: สร้างโมเดลที่ปรับแต่งสำหรับกรณีการใช้งาน Edge เฉพาะ

### 7. การผสานรวมเครื่องมือ MCP
- **การเชื่อมต่อเครื่องมือภายนอก**: เชื่อมต่อเอเจนต์กับเครื่องมือภายนอกผ่านเซิร์ฟเวอร์ Model Context Protocol
- **การดำเนินการในโลกจริง**: ทำให้เอเจนต์สามารถสอบถามฐานข้อมูล เข้าถึง API หรือดำเนินการตรรกะที่กำหนดเอง
- **เซิร์ฟเวอร์ MCP ที่มีอยู่**: ใช้เครื่องมือจากคำสั่ง (stdio) หรือ HTTP (server-sent event) protocols
- **การพัฒนา MCP ที่กำหนดเอง**: สร้างและตั้งค่าเซิร์ฟเวอร์ MCP ใหม่พร้อมการทดสอบใน Agent Builder

### 8. การพัฒนาและการทดสอบเอเจนต์
- **รองรับการเรียกฟังก์ชัน**: ทำให้เอเจนต์สามารถเรียกใช้ฟังก์ชันภายนอกได้แบบไดนามิก
- **การทดสอบการผสานรวมแบบเรียลไทม์**: ทดสอบการผสานรวมด้วยการรันแบบเรียลไทม์และการใช้เครื่องมือ
- **การจัดการเวอร์ชันเอเจนต์**: การควบคุมเวอร์ชันสำหรับเอเจนต์พร้อมความสามารถในการเปรียบเทียบผลลัพธ์การประเมิน
- **การดีบักและการติดตาม**: ความสามารถในการติดตามและดีบักในเครื่องสำหรับการพัฒนาเอเจนต์

## กระบวนการพัฒนา Edge AI

### เฟส 1: การค้นหาและการเลือกโมเดล
1. **สำรวจ Model Catalog**: ใช้ Model Catalog เพื่อค้นหาโมเดลที่เหมาะสมสำหรับการใช้งาน Edge
2. **เปรียบเทียบประสิทธิภาพ**: ประเมินโมเดลตามขนาด ความแม่นยำ และความเร็วในการอนุมาน
3. **ทดสอบในเครื่อง**: ใช้โมเดล Ollama หรือ ONNX เพื่อทดสอบในเครื่องก่อนการใช้งาน Edge
4. **ประเมินความต้องการทรัพยากร**: กำหนดความต้องการหน่วยความจำและการประมวลผลสำหรับอุปกรณ์ Edge เป้าหมาย

### เฟส 2: การปรับปรุงโมเดล
1. **แปลงเป็น ONNX**: แปลงโมเดลที่เลือกเป็นรูปแบบ ONNX เพื่อความเข้ากันได้กับ Edge
2. **ใช้การลดขนาด**: ลดขนาดโมเดลด้วยการลดขนาด INT8 หรือ INT4
3. **การปรับปรุงฮาร์ดแวร์**: ปรับปรุงสำหรับฮาร์ดแวร์ Edge เป้าหมาย (ARM, x86, ตัวเร่งเฉพาะทาง)
4. **การตรวจสอบประสิทธิภาพ**: ตรวจสอบว่าโมเดลที่ปรับปรุงแล้วยังคงรักษาความแม่นยำที่ยอมรับได้

### เฟส 3: การพัฒนาแอปพลิเคชัน
1. **การออกแบบเอเจนต์**: ใช้ Agent Builder เพื่อสร้างเอเจนต์ AI ที่เหมาะสมกับ Edge
2. **การออกแบบคำสั่ง**: พัฒนาคำสั่งที่ทำงานได้อย่างมีประสิทธิภาพกับโมเดล Edge ขนาดเล็ก
3. **การทดสอบการผสานรวม**: ทดสอบเอเจนต์ในสภาพแวดล้อม Edge จำลอง
4. **การสร้างโค้ด**: สร้างโค้ดสำหรับการผลิตที่เหมาะสมกับการใช้งาน Edge

### เฟส 4: การประเมินและการทดสอบ
1. **การประเมินแบบกลุ่ม**: ทดสอบการกำหนดค่าหลายแบบเพื่อค้นหาการตั้งค่า Edge ที่เหมาะสมที่สุด
2. **การวิเคราะห์ประสิทธิภาพ**: วิเคราะห์ความเร็วในการอนุมาน การใช้หน่วยความจำ และความแม่นยำ
3. **การจำลอง Edge**: ทดสอบในสภาพแวดล้อมที่คล้ายกับการใช้งาน Edge เป้าหมาย
4. **การทดสอบความเครียด**: ประเมินประสิทธิภาพภายใต้เงื่อนไขการโหลดต่าง ๆ

### เฟส 5: การเตรียมการใช้งาน
1. **การปรับปรุงขั้นสุดท้าย**: ใช้การปรับปรุงขั้นสุดท้ายตามผลการทดสอบ
2. **การบรรจุสำหรับการใช้งาน**: บรรจุโมเดลและโค้ดสำหรับการใช้งาน Edge
3. **การจัดทำเอกสาร**: จัดทำเอกสารข้อกำหนดและการกำหนดค่าการใช้งาน
4. **การตั้งค่าการตรวจสอบ**: เตรียมการตรวจสอบและบันทึกสำหรับการใช้งาน Edge

## กลุ่มเป้าหมายสำหรับการพัฒนา Edge AI

### นักพัฒนา Edge AI
- นักพัฒนาแอปพลิเคชันที่สร้างอุปกรณ์ Edge และโซลูชัน IoT ที่ขับเคลื่อนด้วย AI
- นักพัฒนาระบบฝังตัวที่ผสานรวมความสามารถ AI เข้ากับอุปกรณ์ที่มีข้อจำกัดด้านทรัพยากร
- นักพัฒนามือถือที่สร้างแอปพลิเคชัน AI บนอุปกรณ์สำหรับสมาร์ทโฟนและแท็บเล็ต

### วิศวกร Edge AI
- วิศวกร AI ที่ปรับปรุงโมเดลสำหรับการใช้งาน Edge และจัดการกระบวนการอนุมาน
- วิศวกร DevOps ที่ใช้งานและจัดการโมเดล AI ในโครงสร้างพื้นฐาน Edge ที่กระจายตัว
- วิศวกรประสิทธิภาพที่ปรับปรุงการทำงาน AI ให้เหมาะสมกับข้อจำกัดฮาร์ดแวร์ Edge

### นักวิจัยและผู้สอน
- นักวิจัย AI ที่พัฒนาโมเดลและอัลกอริทึมที่มีประสิทธิภาพสำหรับการประมวลผล Edge
- ผู้สอนที่สอนแนวคิด Edge AI และสาธิตเทคนิคการปรับปรุง
- นักเรียนที่เรียนรู้เกี่ยวกับความท้าทายและวิธีแก้ปัญหาในการใช้งาน Edge AI

## กรณีการใช้งาน Edge AI

### อุปกรณ์ IoT อัจฉริยะ
- **การจดจำภาพแบบเรียลไทม์**: ใช้งานโมเดลคอมพิวเตอร์วิชั่นบนกล้อง IoT และเซ็นเซอร์
- **การประมวลผลเสียง**: ใช้งานการจดจำเสียงและการประมวลผลภาษาธรรมชาติบนลำโพงอัจฉริยะ
- **การบำรุงรักษาเชิงคาดการณ์**: ใช้งานโมเด
2. สร้างคำแนะนำเริ่มต้นโดยใช้คำอธิบายภาษาธรรมชาติ  
3. ปรับปรุงและพัฒนาคำแนะนำตามผลลัพธ์ของโมเดล  
4. ผสานเครื่องมือ MCP เพื่อเพิ่มความสามารถของตัวแทน  

#### ขั้นตอนที่ 3: การทดสอบและการประเมินผล  
1. ใช้ **Bulk Run** เพื่อทดสอบคำแนะนำหลายรายการในโมเดลที่เลือก  
2. รันตัวแทนด้วยกรณีทดสอบเพื่อยืนยันการทำงาน  
3. ประเมินความถูกต้องและประสิทธิภาพโดยใช้เมตริกที่มีอยู่หรือกำหนดเอง  
4. เปรียบเทียบโมเดลและการตั้งค่าต่าง ๆ  

#### ขั้นตอนที่ 4: การปรับแต่งและการเพิ่มประสิทธิภาพ  
1. ปรับแต่งโมเดลสำหรับกรณีการใช้งานเฉพาะ  
2. ใช้การปรับแต่งเฉพาะด้าน  
3. เพิ่มประสิทธิภาพสำหรับข้อจำกัดการใช้งานในพื้นที่  
4. สร้างเวอร์ชันและเปรียบเทียบการตั้งค่าตัวแทนต่าง ๆ  

#### ขั้นตอนที่ 5: การเตรียมการสำหรับการใช้งาน  
1. สร้างโค้ดที่พร้อมใช้งานจริงโดยใช้ Agent Builder  
2. ตั้งค่าการเชื่อมต่อเซิร์ฟเวอร์ MCP สำหรับการใช้งานจริง  
3. เตรียมแพ็กเกจการใช้งานสำหรับอุปกรณ์ในพื้นที่  
4. กำหนดค่าการตรวจสอบและเมตริกการประเมินผล  

## ตัวอย่างสำหรับ AI Toolkit  

ลองใช้ตัวอย่างของเรา  
[ตัวอย่าง AI Toolkit](https://github.com/Azure-Samples/AI_Toolkit_Samples) ถูกออกแบบมาเพื่อช่วยนักพัฒนาและนักวิจัยสำรวจและนำโซลูชัน AI ไปใช้ได้อย่างมีประสิทธิภาพ  

ตัวอย่างของเราประกอบด้วย:  

โค้ดตัวอย่าง: ตัวอย่างที่สร้างไว้ล่วงหน้าเพื่อแสดงฟังก์ชันการทำงานของ AI เช่น การฝึกอบรม การใช้งาน หรือการผสานโมเดลเข้ากับแอปพลิเคชัน  
เอกสารประกอบ: คู่มือและบทแนะนำเพื่อช่วยให้ผู้ใช้เข้าใจคุณสมบัติของ AI Toolkit และวิธีการใช้งาน  

ข้อกำหนดเบื้องต้น  
- Visual Studio Code  
- AI Toolkit สำหรับ Visual Studio Code  
- GitHub Fine-grained personal access token (PAT)  
- Foundry Local  

## แนวปฏิบัติที่ดีที่สุดสำหรับการพัฒนา Edge AI  

### การเลือกโมเดล  
- **ข้อจำกัดด้านขนาด**: เลือกโมเดลที่เหมาะสมกับข้อจำกัดด้านหน่วยความจำของอุปกรณ์เป้าหมาย  
- **ความเร็วในการประมวลผล**: ให้ความสำคัญกับโมเดลที่มีความเร็วในการประมวลผลสูงสำหรับการใช้งานแบบเรียลไทม์  
- **การแลกเปลี่ยนความแม่นยำ**: ปรับสมดุลระหว่างความแม่นยำของโมเดลกับข้อจำกัดด้านทรัพยากร  
- **ความเข้ากันได้ของรูปแบบ**: เลือกใช้รูปแบบ ONNX หรือรูปแบบที่ปรับแต่งสำหรับฮาร์ดแวร์เพื่อการใช้งานในพื้นที่  

### เทคนิคการเพิ่มประสิทธิภาพ  
- **Quantization**: ใช้การลดขนาดโมเดลด้วย INT8 หรือ INT4 เพื่อเพิ่มความเร็ว  
- **Pruning**: ลบพารามิเตอร์ที่ไม่จำเป็นของโมเดลเพื่อลดความต้องการในการประมวลผล  
- **Knowledge Distillation**: สร้างโมเดลขนาดเล็กที่ยังคงประสิทธิภาพของโมเดลขนาดใหญ่  
- **การเร่งด้วยฮาร์ดแวร์**: ใช้ NPUs, GPUs หรืออุปกรณ์เร่งความเร็วเฉพาะเมื่อมี  

### ขั้นตอนการพัฒนา  
- **การทดสอบแบบวนซ้ำ**: ทดสอบบ่อยครั้งในสภาพแวดล้อมที่คล้ายกับการใช้งานในพื้นที่  
- **การตรวจสอบประสิทธิภาพ**: ตรวจสอบการใช้งานทรัพยากรและความเร็วในการประมวลผลอย่างต่อเนื่อง  
- **การควบคุมเวอร์ชัน**: ติดตามเวอร์ชันของโมเดลและการตั้งค่าการเพิ่มประสิทธิภาพ  
- **เอกสารประกอบ**: บันทึกการตัดสินใจในการเพิ่มประสิทธิภาพและการแลกเปลี่ยนประสิทธิภาพ  

### ข้อควรพิจารณาในการใช้งาน  
- **การตรวจสอบทรัพยากร**: ตรวจสอบการใช้งานหน่วยความจำ CPU และพลังงานในสภาพแวดล้อมจริง  
- **กลยุทธ์สำรอง**: ใช้กลไกสำรองสำหรับกรณีที่โมเดลล้มเหลว  
- **กลไกการอัปเดต**: วางแผนสำหรับการอัปเดตโมเดลและการจัดการเวอร์ชัน  
- **ความปลอดภัย**: ใช้มาตรการรักษาความปลอดภัยที่เหมาะสมสำหรับแอปพลิเคชัน Edge AI  

## การผสานรวมกับเฟรมเวิร์ก Edge AI  

### ONNX Runtime  
- **การใช้งานข้ามแพลตฟอร์ม**: ใช้โมเดล ONNX บนอุปกรณ์ในพื้นที่ที่หลากหลาย  
- **การเพิ่มประสิทธิภาพฮาร์ดแวร์**: ใช้การเพิ่มประสิทธิภาพเฉพาะฮาร์ดแวร์ของ ONNX Runtime  
- **รองรับมือถือ**: ใช้ ONNX Runtime Mobile สำหรับแอปพลิเคชันบนสมาร์ทโฟนและแท็บเล็ต  
- **การผสาน IoT**: ใช้งานบนอุปกรณ์ IoT ด้วยการกระจายที่เบาของ ONNX Runtime  

### Windows ML  
- **อุปกรณ์ Windows**: เพิ่มประสิทธิภาพสำหรับอุปกรณ์ Windows และ PC  
- **การเร่งด้วย NPU**: ใช้ Neural Processing Units บนอุปกรณ์ Windows  
- **DirectML**: ใช้ DirectML สำหรับการเร่ง GPU บนแพลตฟอร์ม Windows  
- **การผสาน UWP**: ผสานรวมกับแอปพลิเคชัน Universal Windows Platform  

### TensorFlow Lite  
- **การเพิ่มประสิทธิภาพมือถือ**: ใช้โมเดล TensorFlow Lite บนอุปกรณ์มือถือและอุปกรณ์ฝังตัว  
- **ตัวแทนฮาร์ดแวร์**: ใช้ตัวแทนฮาร์ดแวร์เฉพาะสำหรับการเร่งความเร็ว  
- **ไมโครคอนโทรลเลอร์**: ใช้งานบนไมโครคอนโทรลเลอร์ด้วย TensorFlow Lite Micro  
- **รองรับข้ามแพลตฟอร์ม**: ใช้งานบน Android, iOS และระบบ Linux ฝังตัว  

### Azure IoT Edge  
- **การผสานคลาวด์-เอดจ์**: ผสานการฝึกอบรมในคลาวด์กับการประมวลผลในพื้นที่  
- **การใช้งานโมดูล**: ใช้โมเดล AI เป็นโมดูล IoT Edge  
- **การจัดการอุปกรณ์**: จัดการอุปกรณ์ในพื้นที่และการอัปเดตโมเดลจากระยะไกล  
- **การวัดผล**: เก็บข้อมูลประสิทธิภาพและเมตริกโมเดลจากการใช้งานในพื้นที่  

## สถานการณ์ Edge AI ขั้นสูง  

### การใช้งานหลายโมเดล  
- **Model Ensembles**: ใช้โมเดลหลายตัวเพื่อเพิ่มความแม่นยำหรือความเสถียร  
- **A/B Testing**: ทดสอบโมเดลต่าง ๆ พร้อมกันบนอุปกรณ์ในพื้นที่  
- **การเลือกแบบไดนามิก**: เลือกโมเดลตามสภาพของอุปกรณ์ปัจจุบัน  
- **การแบ่งปันทรัพยากร**: เพิ่มประสิทธิภาพการใช้งานทรัพยากรระหว่างโมเดลที่ใช้งานหลายตัว  

### Federated Learning  
- **การฝึกอบรมแบบกระจาย**: ฝึกอบรมโมเดลบนอุปกรณ์ในพื้นที่หลายตัว  
- **การรักษาความเป็นส่วนตัว**: เก็บข้อมูลการฝึกอบรมไว้ในพื้นที่ในขณะที่แบ่งปันการปรับปรุงโมเดล  
- **การเรียนรู้ร่วมกัน**: ให้อุปกรณ์เรียนรู้จากประสบการณ์ร่วมกัน  
- **การประสานงานระหว่างเอดจ์-คลาวด์**: ประสานการเรียนรู้ระหว่างอุปกรณ์ในพื้นที่และโครงสร้างพื้นฐานคลาวด์  

### การประมวลผลแบบเรียลไทม์  
- **Stream Processing**: ประมวลผลข้อมูลแบบต่อเนื่องบนอุปกรณ์ในพื้นที่  
- **Low-latency Inference**: เพิ่มประสิทธิภาพสำหรับการประมวลผลที่มีความหน่วงต่ำ  
- **Batch Processing**: ประมวลผลข้อมูลเป็นชุดอย่างมีประสิทธิภาพบนอุปกรณ์ในพื้นที่  
- **Adaptive Processing**: ปรับการประมวลผลตามความสามารถของอุปกรณ์ปัจจุบัน  

## การแก้ไขปัญหาการพัฒนา Edge AI  

### ปัญหาทั่วไป  
- **ข้อจำกัดด้านหน่วยความจำ**: โมเดลมีขนาดใหญ่เกินไปสำหรับหน่วยความจำของอุปกรณ์เป้าหมาย  
- **ความเร็วในการประมวลผล**: การประมวลผลโมเดลช้าเกินไปสำหรับความต้องการแบบเรียลไทม์  
- **การลดความแม่นยำ**: การเพิ่มประสิทธิภาพลดความแม่นยำของโมเดลในระดับที่ไม่ยอมรับได้  
- **ความเข้ากันได้ของฮาร์ดแวร์**: โมเดลไม่เข้ากันกับฮาร์ดแวร์เป้าหมาย  

### กลยุทธ์การแก้ไขปัญหา  
- **การวิเคราะห์ประสิทธิภาพ**: ใช้ฟีเจอร์การติดตามของ AI Toolkit เพื่อระบุปัญหา  
- **การตรวจสอบทรัพยากร**: ตรวจสอบการใช้งานหน่วยความจำและ CPU ระหว่างการพัฒนา  
- **การทดสอบแบบเพิ่มทีละขั้น**: ทดสอบการเพิ่มประสิทธิภาพทีละขั้นตอนเพื่อแยกปัญหา  
- **การจำลองฮาร์ดแวร์**: ใช้เครื่องมือพัฒนาเพื่อจำลองฮาร์ดแวร์เป้าหมาย  

### วิธีแก้ไขการเพิ่มประสิทธิภาพ  
- **การลดขนาดเพิ่มเติม**: ใช้เทคนิคการลดขนาดที่เข้มข้นขึ้น  
- **สถาปัตยกรรมโมเดล**: พิจารณาสถาปัตยกรรมโมเดลที่แตกต่างกันซึ่งเหมาะสมกับการใช้งานในพื้นที่  
- **การเพิ่มประสิทธิภาพการเตรียมข้อมูล**: ปรับการเตรียมข้อมูลให้เหมาะสมกับข้อจำกัดในพื้นที่  
- **การเพิ่มประสิทธิภาพการประมวลผล**: ใช้การเพิ่มประสิทธิภาพการประมวลผลเฉพาะฮาร์ดแวร์  

## แหล่งข้อมูลและขั้นตอนถัดไป  

### เอกสารประกอบอย่างเป็นทางการ  
- [AI Toolkit Developer Documentation](https://aka.ms/AIToolkit/doc)  
- [Installation and Setup Guide](https://code.visualstudio.com/docs/intelligentapps/overview#_install-and-setup)  
- [VS Code Intelligent Apps Documentation](https://code.visualstudio.com/docs/intelligentapps)  
- [Model Context Protocol (MCP) Documentation](https://modelcontextprotocol.io/)  

### ชุมชนและการสนับสนุน  
- [AI Toolkit GitHub Repository](https://github.com/microsoft/vscode-ai-toolkit)  
- [GitHub Issues and Feature Requests](https://aka.ms/AIToolkit/feedback)  
- [Azure AI Foundry Discord Community](https://aka.ms/azureaifoundry/discord)  
- [VS Code Extension Marketplace](https://marketplace.visualstudio.com/items?itemName=ms-windows-ai-studio.windows-ai-studio)  

### แหล่งข้อมูลทางเทคนิค  
- [ONNX Runtime Documentation](https://onnxruntime.ai/)  
- [Ollama Documentation](https://ollama.ai/)  
- [Windows ML Documentation](https://docs.microsoft.com/en-us/windows/ai/)  
- [Azure AI Foundry Documentation](https://learn.microsoft.com/en-us/azure/ai-foundry/)  

### เส้นทางการเรียนรู้  
- [Edge AI Fundamentals Course](../Module01/README.md)  
- [Small Language Models Guide](../Module02/README.md)  
- [Edge Deployment Strategies](../Module03/README.md)  
- [Windows Edge AI Development](./windowdeveloper.md)  

### แหล่งข้อมูลเพิ่มเติม  
- **สถิติของ Repository**: 1.8k+ ดาว, 150+ forks, 18+ ผู้ร่วมพัฒนา  
- **ใบอนุญาต**: ใบอนุญาต MIT  
- **ความปลอดภัย**: ใช้นโยบายความปลอดภัยของ Microsoft  
- **การวัดผล**: เคารพการตั้งค่าการวัดผลของ VS Code  

## สรุป  

AI Toolkit สำหรับ Visual Studio Code เป็นแพลตฟอร์มที่ครอบคลุมสำหรับการพัฒนา AI สมัยใหม่ โดยมีความสามารถในการพัฒนาตัวแทนที่มีประโยชน์อย่างยิ่งสำหรับแอปพลิเคชัน Edge AI ด้วยแคตตาล็อกโมเดลที่หลากหลายซึ่งรองรับผู้ให้บริการอย่าง Anthropic, OpenAI, GitHub และ Google รวมถึงการประมวลผลในพื้นที่ผ่าน ONNX และ Ollama เครื่องมือนี้มอบความยืดหยุ่นที่จำเป็นสำหรับสถานการณ์การใช้งานในพื้นที่ที่หลากหลาย  

จุดแข็งของเครื่องมืออยู่ที่วิธีการแบบบูรณาการ—ตั้งแต่การค้นหาและทดลองโมเดลใน Playground ไปจนถึงการพัฒนาตัวแทนที่ซับซ้อนด้วย Prompt Builder ความสามารถในการประเมินผลที่ครอบคลุม และการผสานเครื่องมือ MCP อย่างไร้รอยต่อ สำหรับนักพัฒนา Edge AI นี่หมายถึงการสร้างต้นแบบและการทดสอบตัวแทน AI อย่างรวดเร็วก่อนการใช้งานในพื้นที่ พร้อมความสามารถในการปรับปรุงและเพิ่มประสิทธิภาพสำหรับสภาพแวดล้อมที่มีข้อจำกัดด้านทรัพยากร  

ข้อดีสำคัญสำหรับการพัฒนา Edge AI ได้แก่:  
- **การทดลองอย่างรวดเร็ว**: ทดสอบโมเดลและตัวแทนอย่างรวดเร็วก่อนการใช้งานในพื้นที่  
- **ความยืดหยุ่นหลายผู้ให้บริการ**: เข้าถึงโมเดลจากแหล่งต่าง ๆ เพื่อค้นหาโซลูชันที่เหมาะสม  
- **การพัฒนาในพื้นที่**: ทดสอบด้วย ONNX และ Ollama สำหรับการพัฒนาแบบออฟไลน์และการรักษาความเป็นส่วนตัว  
- **ความพร้อมใช้งานจริง**: สร้างโค้ดที่พร้อมใช้งานจริงและผสานรวมกับเครื่องมือภายนอกผ่าน MCP  
- **การประเมินผลที่ครอบคลุม**: ใช้เมตริกที่มีอยู่และกำหนดเองเพื่อยืนยันประสิทธิภาพ Edge AI  

ในขณะที่ AI ยังคงมุ่งสู่สถานการณ์การใช้งานในพื้นที่ AI Toolkit สำหรับ VS Code มอบสภาพแวดล้อมการพัฒนาและขั้นตอนการทำงานที่จำเป็นในการสร้าง ทดสอบ และเพิ่มประสิทธิภาพแอปพลิเคชันอัจฉริยะสำหรับสภาพแวดล้อมที่มีข้อจำกัดด้านทรัพยากร ไม่ว่าคุณจะพัฒนาโซลูชัน IoT แอปพลิเคชัน AI บนมือถือ หรือระบบอัจฉริยะฝังตัว เครื่องมือที่ครอบคลุมและขั้นตอนการทำงานแบบบูรณาการของ Toolkit รองรับวงจรการพัฒนา Edge AI ทั้งหมด  

ด้วยการพัฒนาอย่างต่อเนื่องและชุมชนที่มีความเคลื่อนไหว (1.8k+ ดาวใน GitHub) AI Toolkit ยังคงเป็นเครื่องมือที่ล้ำหน้าสำหรับนักพัฒนา AI สมัยใหม่ที่สร้างสรรค์สำหรับสถานการณ์การใช้งานในพื้นที่  

[Next Foundry Local](./foundrylocal.md)

---

**ข้อจำกัดความรับผิดชอบ**:  
เอกสารนี้ได้รับการแปลโดยใช้บริการแปลภาษา AI [Co-op Translator](https://github.com/Azure/co-op-translator) แม้ว่าเราจะพยายามให้การแปลมีความถูกต้อง แต่โปรดทราบว่าการแปลอัตโนมัติอาจมีข้อผิดพลาดหรือความไม่ถูกต้อง เอกสารต้นฉบับในภาษาดั้งเดิมควรถือเป็นแหล่งข้อมูลที่เชื่อถือได้ สำหรับข้อมูลที่สำคัญ ขอแนะนำให้ใช้บริการแปลภาษามืออาชีพ เราจะไม่รับผิดชอบต่อความเข้าใจผิดหรือการตีความผิดที่เกิดจากการใช้การแปลนี้