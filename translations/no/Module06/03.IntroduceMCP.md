<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8a7765b85f123e8a62aa3847141ca072",
  "translation_date": "2025-10-30T13:12:10+00:00",
  "source_file": "Module06/03.IntroduceMCP.md",
  "language_code": "no"
}
-->
# Seksjon 03 - Integrering av Model Context Protocol (MCP)

## Introduksjon til MCP (Model Context Protocol)

Model Context Protocol (MCP) er en åpen standard for å koble AI-applikasjoner til eksterne systemer. Ved å bruke MCP kan AI-applikasjoner som Claude eller ChatGPT koble seg til datakilder (f.eks. lokale filer, databaser), verktøy (f.eks. søkemotorer, kalkulatorer) og arbeidsflyter (f.eks. spesialiserte forespørsler)—som gjør det mulig for dem å få tilgang til viktig informasjon og utføre oppgaver.

Tenk på MCP som en **USB-C-port for AI-applikasjoner**. Akkurat som USB-C gir en standardisert måte å koble elektroniske enheter på, gir MCP en standardisert måte å koble AI-applikasjoner til eksterne systemer.

### Hva kan MCP muliggjøre?

MCP åpner for kraftige funksjoner for AI-applikasjoner:

- **Personlige AI-assistenter**: Agenter kan få tilgang til Google Kalender og Notion, og fungere som en mer personlig AI-assistent
- **Avansert kodegenerering**: Claude Code kan generere en hel webapplikasjon basert på et Figma-design
- **Integrering av bedriftsdata**: Bedriftschatboter kan koble seg til flere databaser i en organisasjon, og gi brukere mulighet til å analysere data via chat
- **Kreative arbeidsflyter**: AI-modeller kan lage 3D-design i Blender og skrive dem ut med en 3D-printer
- **Tilgang til sanntidsinformasjon**: Koble til eksterne datakilder for oppdatert informasjon
- **Komplekse flertrinnsoperasjoner**: Utføre sofistikerte arbeidsflyter som kombinerer flere verktøy og systemer

### Hvorfor er MCP viktig?

MCP gir fordeler på tvers av økosystemet:

**For utviklere**: MCP reduserer utviklingstid og kompleksitet når man bygger eller integrerer en AI-applikasjon eller agent.

**For AI-applikasjoner**: MCP gir tilgang til et økosystem av datakilder, verktøy og apper som forbedrer funksjonaliteten og brukeropplevelsen.

**For sluttbrukere**: MCP resulterer i mer kapable AI-applikasjoner eller agenter som kan få tilgang til dataene dine og utføre handlinger på dine vegne når det er nødvendig.

## Små språkmodeller (SLMs) i MCP

Små språkmodeller representerer en effektiv tilnærming til AI-distribusjon og tilbyr flere fordeler:

### Fordeler med SLMs
- **Ressurseffektivitet**: Lavere krav til datakraft
- **Raskere responstider**: Redusert ventetid for sanntidsapplikasjoner  
- **Kostnadseffektivitet**: Minimale infrastrukturbehov
- **Personvern**: Kan kjøre lokalt uten datatransmisjon
- **Tilpasning**: Enklere å finjustere for spesifikke domener

### Hvorfor SLMs fungerer godt med MCP

SLMs kombinert med MCP skaper en kraftig kombinasjon der modellens resonneringsevner forsterkes av eksterne verktøy, og kompenserer for deres mindre parameterantall gjennom utvidet funksjonalitet.

## Oversikt over Python MCP SDK

Python MCP SDK gir grunnlaget for å bygge MCP-aktiverte applikasjoner. SDK-en inkluderer:

- **Klientbiblioteker**: For å koble til MCP-servere
- **Serverrammeverk**: For å lage tilpassede MCP-servere
- **Protokollhåndterere**: For å administrere kommunikasjon
- **Verktøyintegrasjon**: For å utføre eksterne funksjoner

## Praktisk implementering: Phi-4 MCP-klient

La oss utforske en implementering i virkeligheten ved å bruke Microsofts Phi-4 mini-modell integrert med MCP-funksjoner.

### Oversikt over MCP-arkitektur

MCP følger en **klient-server-arkitektur** der en MCP-vert (en AI-applikasjon som Claude Code eller Claude Desktop) etablerer forbindelser til én eller flere MCP-servere. MCP-verten oppnår dette ved å opprette én MCP-klient for hver MCP-server.

#### Viktige deltakere

- **MCP-vert**: AI-applikasjonen som koordinerer og administrerer én eller flere MCP-klienter
- **MCP-klient**: En komponent som opprettholder en forbindelse til en MCP-server og henter kontekst fra MCP-serveren for MCP-verten å bruke
- **MCP-server**: Et program som gir kontekst til MCP-klienter

#### To-lags arkitektur

MCP består av to distinkte lag:

**Datalag**: Definerer den JSON-RPC-baserte protokollen for klient-server-kommunikasjon, inkludert:
- Livssyklusadministrasjon (initialisering av tilkobling, kapabilitetsforhandling)
- Kjerneprimitiver (verktøy, ressurser, forespørsler)
- Klientfunksjoner (sampling, innhenting, logging)
- Nyttige funksjoner (varsler, fremdriftssporing)

**Transportlag**: Definerer kommunikasjonsmekanismer og kanaler:
- **STDIO Transport**: Bruker standard inn-/utstrømmer for lokale prosesser (optimal ytelse, ingen nettverksbelastning)
- **Streamable HTTP Transport**: Bruker HTTP POST med valgfrie server-sent events for eksterne servere (støtter standard HTTP-autentisering)

```
┌─────────────────────────────────────┐
│           MCP Host                  │
│     (AI Application)                │
└─────────────────┬───────────────────┘
                  │
┌─────────────────┴───────────────────┐
│         MCP Client 1                │
│  ┌─────────────────────────────────┐ │
│  │        Data Layer               │ │
│  │  ├── Lifecycle Management       │ │
│  │  ├── Primitives (Tools/Resources)│ │
│  │  └── Notifications              │ │
│  └─────────────────────────────────┘ │
│  ┌─────────────────────────────────┐ │
│  │      Transport Layer           │ │
│  │  ├── STDIO Transport           │ │
│  │  └── HTTP Transport            │ │
│  └─────────────────────────────────┘ │
└─────────────────┬───────────────────┘
                  │
┌─────────────────┴───────────────────┐
│         MCP Server 1                │
│    (Local/Remote Context Provider)  │
└─────────────────────────────────────┘
```

### MCP Kjerneprimitiver

MCP definerer primitivene som spesifiserer typene kontekstuell informasjon som kan deles med AI-applikasjoner og rekkevidden av handlinger som kan utføres.

#### Serverprimitiver

MCP definerer tre kjerneprimitiver som servere kan eksponere:

**Verktøy**: Utførbare funksjoner som AI-applikasjoner kan påkalle for å utføre handlinger
- Eksempler: filoperasjoner, API-kall, databaseforespørsler
- Metoder: `tools/list`, `tools/call`
- Støtter dynamisk oppdagelse og utførelse

**Ressurser**: Datakilder som gir kontekstuell informasjon til AI-applikasjoner
- Eksempler: filinnhold, databaseposter, API-responser
- Metoder: `resources/list`, `resources/read`
- Muliggjør tilgang til strukturert data

**Forespørsler**: Gjenbrukbare maler som hjelper med å strukturere interaksjoner med språkmodeller
- Eksempler: systemforespørsler, få-eksempler
- Metoder: `prompts/list`, `prompts/get`
- Standardiserer AI-interaksjonsmønstre

#### Klientprimitiver

MCP definerer også primitivene som klienter kan eksponere for å muliggjøre rikere interaksjoner:

**Sampling**: Lar servere be om språkmodellfullføringer fra klientens AI-applikasjon
- Metode: `sampling/complete`
- Muliggjør modell-uavhengig serverutvikling
- Gir tilgang til vertens språkmodell

**Innhenting**: Lar servere be om tilleggsinformasjon fra brukere
- Metode: `elicitation/request`
- Muliggjør brukerinteraksjon og bekreftelse
- Støtter dynamisk informasjonsinnsamling

**Logging**: Lar servere sende loggmeldinger til klienter
- Brukes til feilsøking og overvåking
- Gir innsikt i serveroperasjoner

### MCP Protokollens livssyklus

#### Initialisering og kapabilitetsforhandling

MCP er en tilstandsbasert protokoll som krever livssyklusadministrasjon. Initialiseringsprosessen tjener flere kritiske formål:

1. **Protokollversjonsforhandling**: Sikrer at både klient og server bruker kompatible protokollversjoner (f.eks. "2025-06-18")
2. **Kapabilitetsoppdagelse**: Hver part erklærer støttede funksjoner og primitivene
3. **Identitetsutveksling**: Gir identifikasjons- og versjonsinformasjon

```python
# Example initialization request
{
  "jsonrpc": "2.0",
  "id": 1,
  "method": "initialize",
  "params": {
    "protocolVersion": "2025-06-18",
    "capabilities": {
      "elicitation": {},  # Client supports user interaction
      "sampling": {}      # Client can provide LLM completions
    },
    "clientInfo": {
      "name": "edge-ai-client",
      "version": "1.0.0"
    }
  }
}
```

#### Verktøyoppdagelse og utførelse

Etter initialisering kan klienter oppdage og utføre verktøy:

```python
# Discover available tools
tools_response = await session.list_tools()

# Execute a tool
result = await session.call_tool(
    "weather_current",
    {
        "location": "San Francisco",
        "units": "imperial"
    }
)
```

#### Sanntidsvarsler

MCP støtter sanntidsvarsler for dynamiske oppdateringer:

```python
# Server sends notification when tools change
{
  "jsonrpc": "2.0",
  "method": "notifications/tools/list_changed"
}

# Client responds by refreshing tool list
await session.list_tools()  # Get updated tools
```

## Komme i gang: Trinn-for-trinn-guide

### Trinn 1: Miljøoppsett

Installer nødvendige avhengigheter:
```bash
pip install fastmcp mcp-python-client openai requests pyautogui Pillow
```

### Trinn 2: Grunnleggende konfigurasjon

Sett opp miljøvariablene dine:
```python
# System Configuration
SYSTEM_PROMPT = "You are an AI assistant with some tools."

# Ollama Configuration (Local)
OLLAMA_URL = "http://localhost:11434/api/chat"
OLLAMA_MODEL_ID = "phi4-mini:3.8b-fp16"

# vLLM Configuration (Server)
VLLM_URL = "http://localhost:8000/v1"
VLLM_MODEL_ID = "microsoft/Phi-4-mini-instruct"
```

### Trinn 3: Kjøre din første MCP-klient

**Grunnleggende Ollama-oppsett:**
```bash
python ghmodel_mcp_demo.py
```

**Bruke vLLM-backend:**
```bash
python ghmodel_mcp_demo.py --env vllm
```

**Server-Sent Events-tilkobling:**
```bash
python ghmodel_mcp_demo.py --run sse
```

**Tilpasset MCP-server:**
```bash
python ghmodel_mcp_demo.py --server /path/to/server.py
```

### Trinn 4: Programmerbar bruk

```python
import asyncio
from ghmodel_mcp_demo import OllamaClient, Phi4MiniMCPClient

async def automated_interaction():
    # Configure MCP server parameters
    server_params = StdioServerParameters(
        command="npx",
        args=["@playwright/mcp@latest"],
        env=None,
    )
    
    # Create MCP client and process tools
    async with Phi4MiniMCPClient(server_params) as mcp_client:
        tools = await process_mcp_tools(mcp_client)
        llm_client = OllamaClient()
        
        # Generate response with tool capabilities
        response, messages = await llm_client.generate_response(
            "Help me automate a web task",
            tools
        )
        return response

# Execute the automation
result = asyncio.run(automated_interaction())
print(result)
```

## Avanserte funksjoner

### Støtte for flere backends

Implementeringen støtter både Ollama og vLLM-backends, slik at du kan velge basert på dine behov:

- **Ollama**: Bedre for lokal utvikling og testing
- **vLLM**: Optimalisert for produksjon og høy gjennomstrømning

### Fleksible tilkoblingsprotokoller

To tilkoblingsmoduser støttes:

**STDIO-modus**: Direkte prosesskommunikasjon
- Lavere ventetid
- Egnet for lokale verktøy
- Enkel oppsett

**SSE-modus**: HTTP-basert strømming
- Nettverkskapabel
- Bedre for distribuerte systemer
- Sanntidsoppdateringer

### Verktøyintegreringsmuligheter

Systemet kan integreres med ulike verktøy:
- Nettautomatisering (Playwright)
- Filoperasjoner
- API-interaksjoner
- Systemkommandoer
- Tilpassede funksjoner

## Feilhåndtering og beste praksis

### Omfattende feiladministrasjon

Implementeringen inkluderer robust feilhåndtering for:

**Tilkoblingsfeil:**
- MCP-serverfeil
- Nettverkstidsavbrudd
- Tilkoblingsproblemer

**Verktøyutførelsesfeil:**
- Manglende verktøy
- Parametervalidering
- Utførelsesfeil

**Responsbehandlingsfeil:**
- JSON-parsingproblemer
- Formatinkonsekvenser
- LLM-responsanomalier

### Beste praksis

1. **Ressursadministrasjon**: Bruk asynkrone kontekstadministratorer
2. **Feilhåndtering**: Implementer omfattende try-catch-blokker
3. **Logging**: Aktiver passende loggnivåer
4. **Sikkerhet**: Valider input og rens output
5. **Ytelse**: Bruk tilkoblingspooling og caching

## Virkelige applikasjoner

### Nettautomatisering
```python
# Example: Automated web testing
async def web_automation_example():
    tools = await setup_playwright_tools()
    response = await llm_client.generate_response(
        "Navigate to example.com and take a screenshot",
        tools
    )
```

### Databehandling
```python
# Example: File analysis
async def data_processing_example():
    tools = await setup_file_tools()
    response = await llm_client.generate_response(
        "Analyze the CSV file and generate a summary report",
        tools
    )
```

### API-integrasjon
```python
# Example: API interactions
async def api_integration_example():
    tools = await setup_api_tools()
    response = await llm_client.generate_response(
        "Fetch weather data and create a forecast summary",
        tools
    )
```

## Ytelsesoptimalisering

### Minnehåndtering
- Effektiv håndtering av meldingshistorikk
- Riktig ressursopprydding
- Tilkoblingspooling

### Nettverksoptimalisering
- Asynkrone HTTP-operasjoner
- Konfigurerbare tidsavbrudd
- Grasiøs feilgjenoppretting

### Samtidig behandling
- Ikke-blokkerende I/O
- Parallell verktøyutførelse
- Effektive asynkrone mønstre

## Sikkerhetsvurderinger

### Databeskyttelse
- Sikker administrasjon av API-nøkler
- Inputvalidering
- Outputsanitering

### Nettverkssikkerhet
- HTTPS-støtte
- Lokale endepunktstandarder
- Sikker tokenhåndtering

### Utførelsessikkerhet
- Verktøyfiltrering
- Sandkassemiljøer
- Revisorlogging

## MCP-økosystem og utvikling

### MCP Prosjektomfang

Model Context Protocol-økosystemet inkluderer flere nøkkelkomponenter:

- **[MCP-spesifikasjon](https://modelcontextprotocol.io/specification/latest)**: Offisiell spesifikasjon som beskriver implementeringskrav for klienter og servere
- **[MCP SDKs](https://modelcontextprotocol.io/docs/sdk)**: SDK-er for ulike programmeringsspråk som implementerer MCP
- **MCP Utviklingsverktøy**: Verktøy for utvikling av MCP-servere og klienter, inkludert [MCP Inspector](https://github.com/modelcontextprotocol/inspector)
- **[MCP Referanseserverimplementeringer](https://github.com/modelcontextprotocol/servers)**: Referanseimplementeringer av MCP-servere

### Komme i gang med MCP-utvikling

For å begynne å bygge med MCP:

**Bygg servere**: [Lag MCP-servere](https://modelcontextprotocol.io/docs/develop/build-server) for å eksponere dataene og verktøyene dine

**Bygg klienter**: [Utvikle applikasjoner](https://modelcontextprotocol.io/docs/develop/build-client) som kobler til MCP-servere

**Lær konsepter**: [Forstå kjernekonseptene](https://modelcontextprotocol.io/docs/learn/architecture) og arkitekturen til MCP

## Konklusjon

SLMs integrert med MCP representerer et paradigmeskifte i utviklingen av AI-applikasjoner. Ved å kombinere effektiviteten til små modeller med kraften til eksterne verktøy, kan utviklere lage intelligente systemer som både er ressursbesparende og svært kapable.

Model Context Protocol gir en standardisert måte å koble AI-applikasjoner til eksterne systemer, på samme måte som USB-C gir en universell tilkoblingsstandard for elektroniske enheter. Denne standardiseringen muliggjør:

- **Sømløs integrering**: Koble AI-modeller til ulike datakilder og verktøy
- **Økosystemvekst**: Bygg én gang, bruk på tvers av flere AI-applikasjoner
- **Utvidede funksjoner**: Forsterk SLMs med ekstern funksjonalitet
- **Sanntidsoppdateringer**: Støtt dynamiske, responsive AI-applikasjoner

Viktige punkter:
- MCP er en åpen standard som bygger bro mellom AI-applikasjoner og eksterne systemer
- Protokollen støtter verktøy, ressurser og forespørsler som kjerneprimitiver
- Sanntidsvarsler muliggjør dynamiske, responsive applikasjoner
- Riktig livssyklusadministrasjon og feilhåndtering er avgjørende for produksjonsbruk
- Økosystemet tilbyr omfattende SDK-er og utviklingsverktøy

## Referanser og videre lesing

### Offisiell MCP-dokumentasjon

- **[Model Context Protocol Offisiell Side](https://modelcontextprotocol.io/)** - Komplett dokumentasjon og spesifikasjoner
- **[MCP Komme i Gang Guide](https://modelcontextprotocol.io/docs/getting-started/intro)** - Introduksjon og kjernekonsepter
- **[MCP Arkitekturoversikt](https://modelcontextprotocol.io/docs/learn/architecture)** - Detaljert teknisk arkitektur
- **[MCP Spesifikasjon](https://modelcontextprotocol.io/specification/latest)** - Offisiell protokollspesifikasjon
- **[MCP SDKs Dokumentasjon](https://modelcontextprotocol.io/docs/sdk)** - Språkspesifikke SDK-guider

### Utviklingsressurser

- **[MCP for Nybegynnere](https://aka.ms/mcp-for-beginners)** - Omfattende nybegynnerguide til Model Context Protocol
- **[MCP GitHub Organisasjon](https://github.com/modelcontextprotocol)** - Offisielle repositorier og eksempler
- **[MCP Server Repository](https://github.com/modelcontextprotocol/servers)** - Referanseserverimplementeringer
- **[MCP Inspector](https://github.com/modelcontextprotocol/inspector)** - Utviklings- og feilsøkingsverktøy
- **[Bygg MCP Servere Guide](https://modelcontextprotocol.io/docs/develop/build-server)** - Serverutviklingstutorial
- **[Bygg MCP Klienter Guide](https://modelcontextprotocol.io/docs/develop/build-client)** - Klientutviklingstutorial

### Små språkmodeller og Edge AI

- **[Microsoft Phi-modeller](https://aka.ms/phicookbook)** - Phi-modellfamilien 
- **[Foundry Local Dokumentasjon](https://github.com/microsoft/Foundry-Local)** - Microsofts edge AI-runtime
- **[Ollama Dokumentasjon](https://ollama.ai/docs)** - Plattform for lokal LLM-distribusjon
- **[vLLM Dokumentasjon](https://docs.vllm.ai/)** - Høyytelses LLM-tjeneste

### Tekniske standarder og protokoller

- **[JSON-RPC 2.0 Spesifikasjon](https://www.jsonrpc.org/)** - Underliggende RPC-protokoll brukt av MCP
- **[JSON Schema](https://json-schema.org/)** - Standard for skjema-definisjon for MCP-verktøy
- **[OpenAPI Spesifikasjon](https://swagger.io/specification/)** - Standard for API-dokumentasjon
- **[Server-Sent Events (SSE)](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events)** - Webstandard for sanntidsoppdateringer

### Utvikling av AI-agenter

- **[Microsoft Agent Framework](https://github.com/microsoft/agent-framework)** - Produksjonsklar utvikling av agenter
- **[LangChain Dokumentasjon](https://docs.langchain.com/)** - Rammeverk for integrasjon av agenter og verktøy
- **[Semantic Kernel](https://learn.microsoft.com/en-us/semantic-kernel/)** - Microsofts SDK for AI-orkestrering

### Bransjerapporter og forskning

- **[Anthropics kunngjøring om Model Context Protocol](https://www.anthropic.com/news/model-context-protocol)** - Opprinnelig MCP-introduksjon
- **[Undersøkelse av små språkmodeller](https://arxiv.org/abs/2410.20011)** - Akademisk undersøkelse av SLM-forskning
- **[Analyse av Edge AI-markedet](https://www.marketsandmarkets.com/Market-Reports/edge-ai-software-market-74385617.html)** - Bransjetrender og prognoser
- **[Beste praksis for utvikling av AI-agenter](https://arxiv.org/abs/2309.02427)** - Forskning på agentarkitekturer

Denne seksjonen gir grunnlaget for å bygge dine egne MCP-applikasjoner drevet av SLM, og åpner opp muligheter for automatisering, databehandling og integrasjon av intelligente systemer.

## ➡️ Hva er neste

- [Modul 7. Edge AI-eksempler](../Module07/README.md)

---

**Ansvarsfraskrivelse**:  
Dette dokumentet er oversatt ved hjelp av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi streber etter nøyaktighet, vær oppmerksom på at automatiserte oversettelser kan inneholde feil eller unøyaktigheter. Det originale dokumentet på sitt opprinnelige språk bør anses som den autoritative kilden. For kritisk informasjon anbefales profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for misforståelser eller feiltolkninger som oppstår ved bruk av denne oversettelsen.