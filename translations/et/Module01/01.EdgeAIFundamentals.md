<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "be25052ac4c842765e7f6f7eb4d7dcc5",
  "translation_date": "2025-10-20T10:07:40+00:00",
  "source_file": "Module01/01.EdgeAIFundamentals.md",
  "language_code": "et"
}
-->
# 1. peatükk: EdgeAI põhialused

EdgeAI esindab tehisintellekti juurutamise paradigmat, mis toob AI võimekuse otse ääreseadmetesse, mitte ei tugine ainult pilvepõhisele töötlemisele. Oluline on mõista, kuidas EdgeAI võimaldab kohalikku AI töötlemist piiratud ressurssidega seadmetel, säilitades samal ajal mõistliku jõudluse ja lahendades väljakutseid nagu privaatsus, latentsus ja võrguühenduseta toimimine.

## Sissejuhatus

Selles õppetükis uurime EdgeAI-d ja selle põhikontseptsioone. Käsitleme traditsioonilist AI arvutusparadigmat, ääretöötluse väljakutseid, EdgeAI-d võimaldavaid võtmetehnoloogiaid ja praktilisi rakendusi erinevates tööstusharudes.

## Õppe-eesmärgid

Selle õppetüki lõpuks oskate:

- Mõista traditsioonilise pilvepõhise AI ja EdgeAI lähenemisviiside erinevusi.
- Tuvastada võtmetehnoloogiad, mis võimaldavad AI töötlemist ääreseadmetes.
- Tunnustada EdgeAI rakenduste eeliseid ja piiranguid.
- Rakendada EdgeAI teadmisi reaalsetes olukordades ja kasutusjuhtumites.

## Traditsioonilise AI arvutusparadigma mõistmine

Traditsiooniliselt tuginevad generatiivse tehisintellekti rakendused suure jõudlusega arvutustaristule, et käitada tõhusalt suuri keelemudeleid (LLM). Organisatsioonid juurutavad tavaliselt need mudelid GPU klastritele pilvekeskkonnas, kasutades nende võimekust API-liideste kaudu.

See tsentraliseeritud mudel toimib hästi paljude rakenduste puhul, kuid sellel on ääretöötluse stsenaariumides omased piirangud. Traditsiooniline lähenemine hõlmab kasutaja päringute saatmist kaugserveritesse, nende töötlemist võimsa riistvara abil ja tulemuste tagastamist interneti kaudu. Kuigi see meetod võimaldab juurdepääsu tipptasemel mudelitele, tekitab see sõltuvuse internetiühendusest, suurendab latentsust ja tõstatab privaatsuse küsimusi, kui tundlikke andmeid tuleb edastada välistele serveritele.

Traditsioonilise AI arvutusparadigma puhul tuleb mõista mõningaid põhikontseptsioone, nimelt:

- **☁️ Pilvepõhine töötlemine**: AI mudelid töötavad võimsal serveritaristul, millel on suured arvutusressursid.
- **🔌 API-põhine juurdepääs**: Rakendused kasutavad AI võimekust kaug-API-kõnede kaudu, mitte kohalikult.
- **🎛️ Tsentraliseeritud mudelihaldus**: Mudeleid hallatakse ja uuendatakse tsentraalselt, tagades järjepidevuse, kuid nõudes võrguühendust.
- **📈 Ressursside skaleeritavus**: Pilvetaristu saab dünaamiliselt skaleerida, et toime tulla erinevate arvutusnõudmistega.

## Ääretöötluse väljakutsed

Ääreseadmed, nagu sülearvutid, mobiiltelefonid ja asjade interneti (IoT) seadmed, näiteks Raspberry Pi ja NVIDIA Orin Nano, esitlevad unikaalseid arvutuspiiranguid. Need seadmed omavad tavaliselt piiratud töötlemisvõimsust, mälu ja energiavarusid võrreldes andmekeskuste taristuga.

Traditsiooniliste LLM-ide käitamine sellistel seadmetel on ajalooliselt olnud keeruline nende riistvarapiirangute tõttu. Kuid vajadus ääre-AI töötlemise järele on muutunud üha olulisemaks erinevates olukordades. Mõelge olukordadele, kus internetiühendus on ebausaldusväärne või puudub, näiteks kaugemates tööstuspiirkondades, transiidis olevates sõidukites või kehva võrguühendusega piirkondades. Lisaks võivad rakendused, mis nõuavad kõrgeid turvastandardeid, nagu meditsiiniseadmed, finantssüsteemid või valitsuse rakendused, vajada tundlike andmete kohalikku töötlemist privaatsuse ja vastavusnõuete säilitamiseks.

### Ääretöötluse põhilised piirangud

Ääretöötluskeskkonnad seisavad silmitsi mitmete põhiliste piirangutega, mida traditsioonilised pilvepõhised AI lahendused ei kohta:

- **Piiratud töötlemisvõimsus**: Ääreseadmetel on tavaliselt vähem CPU tuumasid ja madalamad taktsagedused võrreldes serveriklassi riistvaraga.
- **Mälupiirangud**: Saadaval olev RAM ja salvestusmaht on ääreseadmetes oluliselt väiksemad.
- **Energiapiirangud**: Aku toitel töötavad seadmed peavad tasakaalustama jõudlust ja energiatarbimist pikema tööaja tagamiseks.
- **Termohaldus**: Kompaktsed vormid piiravad jahutusvõimalusi, mõjutades koormuse all püsivat jõudlust.

## Mis on EdgeAI?

### Kontseptsioon: EdgeAI määratlus

EdgeAI viitab tehisintellekti algoritmide juurutamisele ja käitamisele otse ääreseadmetes—füüsilises riistvaras, mis asub võrgu "ääres", lähedal andmete genereerimisele ja kogumisele. Nende seadmete hulka kuuluvad nutitelefonid, IoT sensorid, nutikad kaamerad, autonoomsed sõidukid, kantavad seadmed ja tööstusseadmed. Erinevalt traditsioonilistest AI süsteemidest, mis tuginevad töötlemiseks pilveserveritele, toob EdgeAI intelligentsuse otse andmeallikani.

EdgeAI põhineb AI töötlemise detsentraliseerimisel, viies selle tsentraliseeritud andmekeskustest eemale ja jaotades selle laialdase digitaalse ökosüsteemi seadmete vahel. See esindab fundamentaalset arhitektuurilist muutust AI süsteemide kujundamises ja juurutamises.

EdgeAI peamised kontseptuaalsed tugisambad hõlmavad:

- **Lähedus töötlemisele**: Arvutused toimuvad füüsiliselt lähedal andmete päritolule.
- **Detsentraliseeritud intelligentsus**: Otsustusvõime jaotatakse mitme seadme vahel.
- **Andmete suveräänsus**: Informatsioon jääb kohaliku kontrolli alla, sageli ei lahku see seadmest.
- **Autonoomne toimimine**: Seadmed suudavad toimida intelligentselt ilma pideva ühenduvuseta.
- **Sisseehitatud AI**: Intelligentsus muutub igapäevaste seadmete lahutamatuks osaks.

### EdgeAI arhitektuuri visualiseerimine

```
┌─────────────────────────────────────────────────────────────────────┐
│                         TRADITIONAL AI ARCHITECTURE                 │
└─────────────────────────────────────────────────────────────────────┘
                                  │
┌──────────────┐   Data Transfer  ┌───────────────┐   API Response   ┌───────────┐
│ Edge Devices ├─────────────────>│ Cloud Servers │────────────────> │ End Users │
└──────────────┘                  └───────────────┘                  └───────────┘
     Data                         Model Inference                     Results
   Collection                     High Latency
                                  High Bandwidth
                                  Privacy Concerns
                               
┌─────────────────────────────────────────────────────────────────────┐
│                            EDGE AI ARCHITECTURE                     │
└─────────────────────────────────────────────────────────────────────┘
                                  │
┌────────────────────────────────────────────────────┐   Direct Response  ┌───────────┐
│              Edge Devices with Embedded AI         │───────────────────>│ End Users │
│  ┌─────────┐  ┌───────────────┐  ┌──────────────┐  │                    └───────────┘
│  │ Sensors │─>│ SLM Inference │─>│ Local Action │  │
│  └─────────┘  └───────────────┘  └──────────────┘  │
└────────────────────────────────────────────────────┘
     Data         Low Latency       Immediate
   Collection     Processing        Response
                  No Data Transfer
                  Enhanced Privacy
```

EdgeAI esindab tehisintellekti juurutamise paradigmat, mis toob AI võimekuse otse ääreseadmetesse, mitte ei tugine ainult pilvepõhisele töötlemisele. See lähenemine võimaldab AI mudeleid käitada kohapeal piiratud arvutusressurssidega seadmetel, pakkudes reaalajas järeldusvõimekust ilma pideva internetiühenduseta.

EdgeAI hõlmab mitmesuguseid tehnoloogiaid ja tehnikaid, mis on mõeldud AI mudelite tõhusamaks muutmiseks ja nende juurutamiseks piiratud ressurssidega seadmetel. Eesmärk on säilitada mõistlik jõudlus, vähendades oluliselt AI mudelite arvutus- ja mälunõudeid.

Vaatame peamisi lähenemisviise, mis võimaldavad EdgeAI rakendusi erinevat tüüpi seadmetes ja kasutusjuhtumites.

### EdgeAI põhialused

EdgeAI tugineb mitmele põhimõttele, mis eristavad seda traditsioonilisest pilvepõhisest AI-st:

- **Kohalik töötlemine**: AI järeldused tehakse otse ääreseadmes, ilma et oleks vaja välist ühenduvust.
- **Ressursside optimeerimine**: Mudeleid optimeeritakse spetsiaalselt sihtseadmete riistvarapiirangute jaoks.
- **Reaalajas jõudlus**: Töötlemine toimub minimaalse latentsusega ajakriitiliste rakenduste jaoks.
- **Privaatsus disainis**: Tundlikud andmed jäävad seadmesse, suurendades turvalisust ja vastavust.

## EdgeAI-d võimaldavad võtmetehnoloogiad

### Mudelite kvantiseerimine

Üks olulisemaid tehnikaid EdgeAI-s on mudelite kvantiseerimine. See protsess hõlmab mudeli parameetrite täpsuse vähendamist, tavaliselt 32-bitistest ujukomaarvudest 8-bitisteks täisarvudeks või isegi madalama täpsusega formaatideks. Kuigi see täpsuse vähendamine võib tunduda murettekitav, on uuringud näidanud, et paljud AI mudelid suudavad säilitada oma jõudluse isegi oluliselt vähendatud täpsusega.

Kvantiseerimine toimib, kaardistades ujukomaarvude vahemiku väiksemaks diskreetsete väärtuste kogumiks. Näiteks 32 bitti kasutamise asemel iga parameetri esindamiseks võib kvantiseerimine kasutada ainult 8 bitti, mis toob kaasa 4-kordse mälunõuete vähenemise ja sageli kiiremaks järelduste tegemiseks.

```python
# Example: PyTorch model quantization 
import torch

# Load a pre-trained model
model = torch.load('large_model.pth')

# Quantize the model to INT8
quantized_model = torch.quantization.quantize_dynamic(
    model,  # model to quantize
    {torch.nn.Linear, torch.nn.Conv2d},  # layers to quantize
    dtype=torch.qint8  # quantization data type
)

# Save the quantized model
torch.save(quantized_model, 'quantized_model.pth')

# Memory usage comparison
original_size = model.size()
quantized_size = quantized_model.size()
print(f"Memory reduction: {original_size / quantized_size:.2f}x")
```

Erinevad kvantiseerimistehnikad hõlmavad:

- **Post-treeningu kvantiseerimine (PTQ)**: Rakendatakse pärast mudeli treenimist, ilma et oleks vaja uuesti treenida.
- **Kvantiseerimisega teadlik treenimine (QAT)**: Kaasatakse kvantiseerimise mõjud treenimise ajal parema täpsuse saavutamiseks.
- **Dünaamiline kvantiseerimine**: Kvantiseerib kaalu int8-le, kuid arvutab aktivatsioonid dünaamiliselt.
- **Staatiline kvantiseerimine**: Eelnevalt arvutab kõik kvantiseerimisparameetrid nii kaaludele kui ka aktivatsioonidele.

EdgeAI juurutuste puhul sõltub sobiva kvantiseerimisstrateegia valik konkreetse mudeli arhitektuurist, jõudlusnõuetest ja sihtseadme riistvaravõimekusest.

### Mudelite tihendamine ja optimeerimine

Lisaks kvantiseerimisele aitavad mitmesugused tihendustehnikad vähendada mudeli suurust ja arvutusnõudeid. Nende hulka kuuluvad:

**Pügamine**: See tehnika eemaldab neuralvõrkudest mittevajalikud ühendused või neuronid. Tuues välja ja kõrvaldades parameetrid, mis mudeli jõudlusele vähe kaasa aitavad, võib pügamine oluliselt vähendada mudeli suurust, säilitades samal ajal täpsuse.

```python
# Example: Neural network pruning in TensorFlow
import tensorflow as tf
import tensorflow_model_optimization as tfmot

# Define the model
model = tf.keras.Sequential([
    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

# Apply pruning during training
pruning_schedule = tfmot.sparsity.keras.PolynomialDecay(
    initial_sparsity=0.0,
    final_sparsity=0.5,  # 50% of connections will be pruned
    begin_step=0,
    end_step=10000
)

pruned_model = tfmot.sparsity.keras.prune_low_magnitude(
    model, pruning_schedule=pruning_schedule
)

# Compile the pruned model
pruned_model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# Train the model while pruning
pruned_model.fit(x_train, y_train, epochs=10)

# Convert to a smaller model for deployment
final_model = tfmot.sparsity.keras.strip_pruning(pruned_model)
```

**Teadmiste destilleerimine**: See lähenemine hõlmab väiksema "õpilasmudeli" treenimist, et jäljendada suurema "õpetajamudeli" käitumist. Õpilasmudel õpib õpetaja väljundeid jäljendama, saavutades sageli sarnase jõudluse oluliselt väiksema parameetrite arvuga.

**Mudeli arhitektuuri optimeerimine**: Teadlased on välja töötanud spetsiaalsed arhitektuurid, mis on mõeldud spetsiaalselt äärejuurutamiseks, nagu MobileNets, EfficientNets ja muud kerged arhitektuurid, mis tasakaalustavad jõudlust ja arvutustõhusust.

### Väikesed keelemudelid (SLM)

EdgeAI-s on esile kerkinud trend väikeste keelemudelite (SLM) arendamisel. Need mudelid on algusest peale loodud kompaktseks ja tõhusaks, pakkudes samal ajal olulisi loomuliku keele võimekusi. SLM-id saavutavad selle läbi hoolikate arhitektuurivalikute, tõhusate treenimistehnikate ja keskendunud treenimise konkreetsetele domeenidele või ülesannetele.

Erinevalt traditsioonilistest lähenemistest, mis hõlmavad suurte mudelite tihendamist, treenitakse SLM-e sageli väiksemate andmekogumite ja optimeeritud arhitektuuridega, mis on spetsiaalselt mõeldud äärejuurutamiseks. See lähenemine võib anda mudeleid, mis on mitte ainult väiksemad, vaid ka tõhusamad konkreetsete kasutusjuhtumite jaoks.

## Riistvara kiirendus EdgeAI jaoks

Kaasaegsed ääreseadmed sisaldavad üha enam spetsiaalset riistvara, mis on mõeldud AI töökoormuste kiirendamiseks:

### Neuraaltöötlusüksused (NPUs)

NPUs on spetsiaalsed protsessorid, mis on mõeldud spetsiaalselt neuralvõrkude arvutuste jaoks. Need kiibid suudavad AI järeldusülesandeid täita palju tõhusamalt kui traditsioonilised CPU-d, sageli madalama energiatarbimisega. Paljud kaasaegsed nutitelefonid, sülearvutid ja IoT-seadmed sisaldavad nüüd NPUsid, et võimaldada seadmesisest AI töötlemist.

```csharp
// Example: Using Windows ML to target NPU acceleration in C#
using Microsoft.ML.OnnxRuntime;

// Create session options with NPU provider
var sessionOptions = new SessionOptions();
sessionOptions.AppendExecutionProvider_DmlExecutionProvider();  // DirectML for NPU

// Load the ONNX model
using var session = new InferenceSession("model.onnx", sessionOptions);

// Create input tensor
var inputTensor = new DenseTensor<float>(new[] { 1, 3, 224, 224 });  // Example input shape
var inputs = new List<NamedOnnxValue> { NamedOnnxValue.CreateFromTensor("input", inputTensor) };

// Run inference with NPU acceleration
using var results = session.Run(inputs);
var output = results.First().AsTensor<float>();

// Process output
Console.WriteLine($"Inference result: {output[0]}");
```

Seadmed, millel on NPUs, hõlmavad:

- **Apple**: A-seeria ja M-seeria kiibid Neural Engine'iga
- **Qualcomm**: Snapdragon protsessorid Hexagon DSP/NPU-ga
- **Samsung**: Exynos protsessorid NPU-ga
- **Intel**: Movidius VPU-d ja Habana Labs kiirendid
- **Microsoft**: Windows Copilot+ arvutid NPUsidega

### 🎮 GPU kiirendus

Kuigi ääreseadmetel ei pruugi olla andmekeskustes leiduvaid võimsaid GPU-sid, sisaldavad paljud siiski integreeritud või eraldiseisvaid GPU-sid, mis suudavad kiirendada AI töökoormusi. Kaasaegsed mobiilsed GPU-d ja integreeritud graafikaprotsessorid võivad pakkuda AI järeldusülesannete jaoks märkimisväärset jõudluse paranemist.

```python
# Example: Using TensorRT for GPU acceleration on edge devices
import tensorrt as trt
import numpy as np

# Create TensorRT logger and builder
TRT_LOGGER = trt.Logger(trt.Logger.WARNING)
builder = trt.Builder(TRT_LOGGER)
network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))
parser = trt.OnnxParser(network, TRT_LOGGER)

# Parse ONNX model
with open('model.onnx', 'rb') as model:
    parser.parse(model.read())

# Configure builder
config = builder.create_builder_config()
config.max_workspace_size = 1 << 28  # 256 MiB
config.set_flag(trt.BuilderFlag.FP16)  # Use FP16 precision for edge GPU

# Build and serialize engine
engine = builder.build_engine(network, config)
with open('model.trt', 'wb') as f:
    f.write(engine.serialize())
```

### CPU optimeerimine

Isegi ainult CPU-ga seadmed võivad EdgeAI-st kasu saada optimeeritud rakenduste kaudu. Kaasaegsed CPU-d sisaldavad spetsiaalseid juhiseid AI töökoormuste jaoks ning tarkvararaamistikud on välja töötatud, et maksimeerida CPU jõudlust AI järelduste tegemisel.

```bash
# Example: Using XNNPACK with TFLite for optimized CPU inference
# Compilation command with XNNPACK acceleration enabled

bazel build -c opt --copt=-O3 --copt=-march=native \
  tensorflow/lite/delegates/xnnpack:libxnnpack_delegate.so

# Convert TensorFlow model to TFLite with optimization
tflite_convert \
  --keras_model_file=model.h5 \
  --output_file=model.tflite \
  --inference_type=FLOAT \
  --experimental_new_converter \
  --experimental_new_quantizer
```

EdgeAI-ga töötavatele tarkvarainseneridele on kriitiline mõista, kuidas kasutada neid riistvara kiirendusvõimalusi, et optimeerida järelduste jõudlust ja energiatõhusust sihtseadmetes.

## EdgeAI eelised

### Privaatsus ja turvalisus

Üks EdgeAI suurimaid eeliseid on parem privaatsus ja turvalisus. Töötledes andmeid kohapeal seadmes, ei lahku tundlik teave kunagi kasutaja kontrolli alt. See on eriti oluline rakenduste puhul, mis töötlevad isikuandmeid, meditsiinilist teavet või konfidentsiaalset ärialast teavet.

### Vähenenud latentsus

EdgeAI kõrvaldab vajaduse saata andmeid kaugserveritesse töötlemiseks, vähendades oluliselt latentsust. See on kriitiline reaalajas rakenduste jaoks, nagu autonoomsed sõidukid, tööstusautomaatika või interaktiivsed rakendused, kus on vaja koheseid vastuseid.

### Võrguühenduseta võimekus

EdgeAI võimaldab AI funktsionaalsust isegi siis, kui internetiühendus puudub. See on väärtuslik rakenduste jaoks kaugemates piirkondades, reisimise ajal või olukordades, kus võrgu usaldusväärsus on probleem.

### Kulutõhusus

Vähendades sõltuvust pilvepõhistest AI teenustest, võib EdgeAI aidata vähendada tegevuskulusid, eriti rakenduste puhul, millel on suur kasutusmaht. Organisatsioonid saavad vältida pidevaid API kulusid ja vähendada ribalaiuse nõudeid.

### Skaleeritavus

EdgeAI jaotab arvutuskoormuse ääreseadmete vahel, mitte ei tsentraliseeri seda andmekeskustes. See võib aidata vähendada taristukulusid ja parandada kogu süsteemi skaleeritavust.

## EdgeAI rakendused

### Nutiseadmed ja IoT

EdgeAI toetab paljusid nutiseadmete funktsioone, alates häälassistentidest, mis suudavad käske kohapeal töödelda, kuni nutikate kaamerateni, mis suudavad tuvastada objekte ja inimesi ilma videot pilve saatmata. IoT-seadmed kasutavad EdgeAI-d ennustava hoolduse, keskkonnaseire ja automatiseeritud otsuste tegemise jaoks.

### Mobiilirakendused

Nutitelefonid ja tahvelarvutid kasutavad EdgeAI-d mitmesuguste funktsioonide jaoks, sealhulgas fotot
- [02: EdgeAI Rakendused](02.RealWorldCaseStudies.md)

---

**Lahtiütlus**:  
See dokument on tõlgitud AI tõlketeenuse [Co-op Translator](https://github.com/Azure/co-op-translator) abil. Kuigi püüame tagada täpsust, palume arvestada, et automaatsed tõlked võivad sisaldada vigu või ebatäpsusi. Algne dokument selle algses keeles tuleks pidada autoriteetseks allikaks. Olulise teabe puhul soovitame kasutada professionaalset inimtõlget. Me ei vastuta arusaamatuste või valesti tõlgenduste eest, mis võivad tekkida selle tõlke kasutamise tõttu.