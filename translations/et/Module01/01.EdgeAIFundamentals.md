<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "76b134be93f45283a2df8f8a93717d06",
  "translation_date": "2025-10-17T10:26:28+00:00",
  "source_file": "Module01/01.EdgeAIFundamentals.md",
  "language_code": "et"
}
-->
# 1. peatükk: EdgeAI põhialused

EdgeAI esindab paradigmat, kus tehisintellekti rakendamine toimub otse servaseadmetes, mitte ainult pilvepõhise töötlemise kaudu. Oluline on mõista, kuidas EdgeAI võimaldab kohalikku tehisintellekti töötlemist piiratud ressurssidega seadmetes, säilitades samal ajal mõistliku jõudluse ja lahendades privaatsuse, latentsuse ja võrguühenduseta töötamisega seotud väljakutseid.

## Sissejuhatus

Selles õppetükis uurime EdgeAI-d ja selle põhikontseptsioone. Käsitleme traditsioonilist tehisintellekti arvutusparadigmat, servaarvutuse väljakutseid, EdgeAI-d võimaldavaid võtmetehnoloogiaid ja praktilisi rakendusi erinevates tööstusharudes.

## Õpieesmärgid

Selle õppetüki lõpuks suudad:

- Mõista erinevust traditsioonilise pilvepõhise tehisintellekti ja EdgeAI lähenemisviiside vahel.
- Tuvastada võtmetehnoloogiad, mis võimaldavad tehisintellekti töötlemist servaseadmetes.
- Tunnustada EdgeAI rakenduste eeliseid ja piiranguid.
- Rakendada EdgeAI teadmisi reaalses maailmas ja kasutusjuhtumites.

## Traditsioonilise tehisintellekti arvutusparadigma mõistmine

Traditsiooniliselt tuginevad generatiivse tehisintellekti rakendused suure jõudlusega arvutustaristule, et käitada suuri keelemudeleid (LLM) tõhusalt. Organisatsioonid paigutavad tavaliselt need mudelid GPU klastritesse pilvekeskkonnas, kasutades nende võimalusi API-liideste kaudu.

See tsentraliseeritud mudel töötab hästi paljude rakenduste puhul, kuid sellel on servaarvutuse stsenaariumides kaasasündinud piirangud. Traditsiooniline lähenemine hõlmab kasutaja päringute saatmist kaugserveritesse, nende töötlemist võimsa riistvara abil ja tulemuste tagastamist interneti kaudu. Kuigi see meetod pakub juurdepääsu tipptasemel mudelitele, tekitab see sõltuvusi internetiühendusest, toob kaasa latentsuse probleeme ja tõstatab privaatsuse küsimusi, kui tundlikke andmeid tuleb edastada välistele serveritele.

Traditsioonilise tehisintellekti arvutusparadigma puhul tuleb mõista mõningaid põhikontseptsioone, nimelt:

- **☁️ Pilvepõhine töötlemine**: Tehisintellekti mudelid töötavad võimsal serveritaristul, millel on suured arvutusressursid.
- **🔌 API-põhine juurdepääs**: Rakendused kasutavad tehisintellekti võimalusi kaug-API-kõnede kaudu, mitte kohalikult töötlemiselt.
- **🎛️ Tsentraliseeritud mudelite haldamine**: Mudelid hoitakse ja uuendatakse tsentraalselt, tagades järjepidevuse, kuid nõudes võrguühendust.
- **📈 Ressursside skaleeritavus**: Pilvetaristu saab dünaamiliselt kohanduda erinevate arvutusnõudmistega.

## Servaarvutuse väljakutsed

Servaseadmed, nagu sülearvutid, mobiiltelefonid ja asjade interneti (IoT) seadmed, näiteks Raspberry Pi ja NVIDIA Orin Nano, esindavad unikaalseid arvutuslikke piiranguid. Nendel seadmetel on tavaliselt piiratud töötlemisvõimsus, mälu ja energiavarud võrreldes andmekeskuste taristuga.

Traditsiooniliste LLM-ide käitamine sellistel seadmetel on ajalooliselt olnud keeruline nende riistvaraliste piirangute tõttu. Kuid servatehisintellekti töötlemise vajadus on muutunud üha olulisemaks erinevates olukordades. Mõelge olukordadele, kus internetiühendus on ebausaldusväärne või puudub, näiteks kaugetes tööstuskohtades, transiidis olevates sõidukites või piirkondades, kus võrguühendus on kehv. Lisaks võivad rakendused, mis nõuavad kõrgeid turvastandardeid, nagu meditsiiniseadmed, finantssüsteemid või valitsuse rakendused, vajada tundlike andmete kohalikku töötlemist, et säilitada privaatsus ja vastavus nõuetele.

### Servaarvutuse põhilised piirangud

Servaarvutuse keskkonnad seisavad silmitsi mitmete põhiliste piirangutega, mida traditsioonilised pilvepõhised tehisintellekti lahendused ei kohta:

- **Piiratud töötlemisvõimsus**: Servaseadmetel on tavaliselt vähem CPU-tuumasid ja madalamad taktsagedused võrreldes serveriklassi riistvaraga.
- **Mälu piirangud**: Saadaval olev RAM ja salvestusmaht on servaseadmetes oluliselt väiksemad.
- **Energiapiirangud**: Akutoitel seadmed peavad tasakaalustama jõudlust ja energiatarbimist pikema tööaja tagamiseks.
- **Termiline haldamine**: Kompaktne vormifaktor piirab jahutusvõimalusi, mõjutades pidevat jõudlust koormuse all.

## Mis on EdgeAI?

### Kontseptsioon: EdgeAI määratlus

EdgeAI viitab tehisintellekti algoritmide paigutamisele ja käitamisele otse servaseadmetes—füüsilises riistvaras, mis asub võrgu "servas", lähedal andmete genereerimisele ja kogumisele. Need seadmed hõlmavad nutitelefone, IoT-andureid, nutikaameraid, autonoomseid sõidukeid, kantavaid seadmeid ja tööstusseadmeid. Erinevalt traditsioonilistest tehisintellekti süsteemidest, mis tuginevad töötlemiseks pilveserveritele, toob EdgeAI intelligentsuse otse andmeallikale.

EdgeAI keskmes on tehisintellekti töötlemise detsentraliseerimine, viies selle tsentraliseeritud andmekeskustest eemale ja jaotades selle üle ulatusliku seadmete võrgu, mis moodustab meie digitaalse ökosüsteemi. See esindab fundamentaalset arhitektuurilist muutust tehisintellekti süsteemide kujundamisel ja rakendamisel.

EdgeAI võtmekontseptuaalsed sambad hõlmavad:

- **Lähedane töötlemine**: Arvutused toimuvad füüsiliselt lähedal andmete päritolule.
- **Detsentraliseeritud intelligentsus**: Otsustusvõime jaotatakse mitme seadme vahel.
- **Andmete suveräänsus**: Informatsioon jääb kohaliku kontrolli alla, sageli ei lahku seadmest.
- **Autonoomne toimimine**: Seadmed suudavad toimida intelligentselt ilma pideva ühenduvuseta.
- **Sisseehitatud tehisintellekt**: Intelligentsus muutub igapäevaste seadmete lahutamatuks osaks.

### EdgeAI arhitektuuri visualiseerimine

```
┌─────────────────────────────────────────────────────────────────────┐
│                         TRADITIONAL AI ARCHITECTURE                 │
└─────────────────────────────────────────────────────────────────────┘
                                  │
┌──────────────┐   Data Transfer  ┌───────────────┐   API Response   ┌───────────┐
│ Edge Devices ├─────────────────>│ Cloud Servers │────────────────> │ End Users │
└──────────────┘                  └───────────────┘                  └───────────┘
     Data                         Model Inference                     Results
   Collection                     High Latency
                                  High Bandwidth
                                  Privacy Concerns
                               
┌─────────────────────────────────────────────────────────────────────┐
│                            EDGE AI ARCHITECTURE                     │
└─────────────────────────────────────────────────────────────────────┘
                                  │
┌────────────────────────────────────────────────────┐   Direct Response  ┌───────────┐
│              Edge Devices with Embedded AI         │───────────────────>│ End Users │
│  ┌─────────┐  ┌───────────────┐  ┌──────────────┐  │                    └───────────┘
│  │ Sensors │─>│ SLM Inference │─>│ Local Action │  │
│  └─────────┘  └───────────────┘  └──────────────┘  │
└────────────────────────────────────────────────────┘
     Data         Low Latency       Immediate
   Collection     Processing        Response
                  No Data Transfer
                  Enhanced Privacy
```

EdgeAI esindab paradigmat, kus tehisintellekti rakendamine toimub otse servaseadmetes, mitte ainult pilvepõhise töötlemise kaudu. See lähenemine võimaldab tehisintellekti mudeleid käitada kohapeal seadmetes, millel on piiratud arvutusressursid, pakkudes reaalajas järeldusvõimekust ilma pideva internetiühenduseta.

EdgeAI hõlmab mitmesuguseid tehnoloogiaid ja tehnikaid, mis on mõeldud tehisintellekti mudelite tõhusamaks muutmiseks ja nende sobivaks paigutamiseks piiratud ressurssidega seadmetesse. Eesmärk on säilitada mõistlik jõudlus, vähendades oluliselt tehisintellekti mudelite arvutus- ja mälunõudeid.

Vaatame põhilisi lähenemisviise, mis võimaldavad EdgeAI rakendusi erinevat tüüpi seadmetes ja kasutusjuhtumites.

### EdgeAI põhialused

EdgeAI tugineb mitmele põhimõttele, mis eristavad seda traditsioonilisest pilvepõhisest tehisintellektist:

- **Kohalik töötlemine**: Tehisintellekti järeldused tehakse otse servaseadmes ilma välise ühenduvuseta.
- **Ressursside optimeerimine**: Mudelid on optimeeritud spetsiaalselt sihtseadmete riistvaraliste piirangute jaoks.
- **Reaalajas jõudlus**: Töötlemine toimub minimaalse latentsusega ajakriitiliste rakenduste jaoks.
- **Privaatsus disainis**: Tundlikud andmed jäävad seadmesse, suurendades turvalisust ja vastavust.

## EdgeAI-d võimaldavad võtmetehnoloogiad

### Mudelite kvantiseerimine

Üks olulisemaid tehnikaid EdgeAI-s on mudelite kvantiseerimine. See protsess hõlmab mudeli parameetrite täpsuse vähendamist, tavaliselt 32-bitistest ujukomaarvudest 8-bitisteks täisarvudeks või isegi madalama täpsusega formaatideks. Kuigi see täpsuse vähendamine võib tunduda murettekitav, on uuringud näidanud, et paljud tehisintellekti mudelid suudavad säilitada oma jõudluse isegi oluliselt vähendatud täpsusega.

Kvantiseerimine töötab, kaardistades ujukomaarvude vahemiku väiksemale diskreetsete väärtuste kogumile. Näiteks 32 bitti iga parameetri esindamiseks kasutamise asemel võib kvantiseerimine kasutada ainult 8 bitti, mis toob kaasa 4-kordse mälunõuete vähenemise ja sageli kiiremad järeldusajad.

```python
# Example: PyTorch model quantization 
import torch

# Load a pre-trained model
model = torch.load('large_model.pth')

# Quantize the model to INT8
quantized_model = torch.quantization.quantize_dynamic(
    model,  # model to quantize
    {torch.nn.Linear, torch.nn.Conv2d},  # layers to quantize
    dtype=torch.qint8  # quantization data type
)

# Save the quantized model
torch.save(quantized_model, 'quantized_model.pth')

# Memory usage comparison
original_size = model.size()
quantized_size = quantized_model.size()
print(f"Memory reduction: {original_size / quantized_size:.2f}x")
```

Erinevad kvantiseerimistehnikad hõlmavad:

- **Järeltreeningu kvantiseerimine (PTQ)**: Rakendatakse pärast mudeli treenimist ilma uuesti treenimist vajamata.
- **Kvantiseerimisest teadlik treenimine (QAT)**: Hõlmab kvantiseerimise mõju treenimise ajal parema täpsuse saavutamiseks.
- **Dünaamiline kvantiseerimine**: Kvantiseerib kaalud int8-ks, kuid arvutab aktivatsioonid dünaamiliselt.
- **Staatiline kvantiseerimine**: Eelnevalt arvutab kõik kvantiseerimisparameetrid nii kaaludele kui aktivatsioonidele.

EdgeAI rakenduste puhul sõltub sobiva kvantiseerimisstrateegia valik konkreetse mudeli arhitektuurist, jõudlusnõuetest ja sihtseadme riistvaralistest võimalustest.

### Mudelite tihendamine ja optimeerimine

Lisaks kvantiseerimisele aitavad erinevad tihendustehnikad vähendada mudeli suurust ja arvutusnõudeid. Need hõlmavad:

**Pügamine**: See tehnika eemaldab neuralvõrkudest mittevajalikud ühendused või neuronid. Identifitseerides ja kõrvaldades parameetrid, mis mudeli jõudlusele vähe kaasa aitavad, võib pügamine oluliselt vähendada mudeli suurust, säilitades samal ajal täpsuse.

```python
# Example: Neural network pruning in TensorFlow
import tensorflow as tf
import tensorflow_model_optimization as tfmot

# Define the model
model = tf.keras.Sequential([
    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

# Apply pruning during training
pruning_schedule = tfmot.sparsity.keras.PolynomialDecay(
    initial_sparsity=0.0,
    final_sparsity=0.5,  # 50% of connections will be pruned
    begin_step=0,
    end_step=10000
)

pruned_model = tfmot.sparsity.keras.prune_low_magnitude(
    model, pruning_schedule=pruning_schedule
)

# Compile the pruned model
pruned_model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# Train the model while pruning
pruned_model.fit(x_train, y_train, epochs=10)

# Convert to a smaller model for deployment
final_model = tfmot.sparsity.keras.strip_pruning(pruned_model)
```

**Teadmiste destilleerimine**: See lähenemine hõlmab väiksema "õpilasmudeli" treenimist, et jäljendada suurema "õpetajamudeli" käitumist. Õpilasmudel õpib õpetaja väljundeid ligikaudselt jäljendama, saavutades sageli sarnase jõudluse oluliselt väiksema parameetrite arvuga.

**Mudeli arhitektuuri optimeerimine**: Teadlased on välja töötanud spetsiaalsed arhitektuurid, mis on mõeldud spetsiaalselt servaseadmetes kasutamiseks, nagu MobileNets, EfficientNets ja muud kerged arhitektuurid, mis tasakaalustavad jõudlust ja arvutustõhusust.

### Väikesed keelemudelid (SLM)

EdgeAI-s on esile kerkinud trend väikeste keelemudelite (SLM) arendamisel. Need mudelid on algusest peale loodud kompaktseks ja tõhusaks, pakkudes samal ajal olulisi loomuliku keele võimalusi. SLM-id saavutavad selle läbi hoolikate arhitektuurivalikute, tõhusate treenimistehnikate ja keskendunud treenimise konkreetsetele domeenidele või ülesannetele.

Erinevalt traditsioonilistest lähenemistest, mis hõlmavad suurte mudelite tihendamist, treenitakse SLM-e sageli väiksemate andmekogumite ja optimeeritud arhitektuuridega, mis on spetsiaalselt mõeldud servaseadmetes kasutamiseks. See lähenemine võib tulemuseks anda mudelid, mis on mitte ainult väiksemad, vaid ka tõhusamad konkreetsete kasutusjuhtumite jaoks.

## Riistvarakiirendus EdgeAI jaoks

Kaasaegsed servaseadmed sisaldavad üha enam spetsiaalset riistvara, mis on mõeldud tehisintellekti töökoormuste kiirendamiseks:

### Neuraaltöötlusüksused (NPU-d)

NPU-d on spetsiaalsed protsessorid, mis on mõeldud spetsiaalselt neuralvõrkude arvutuste jaoks. Need kiibid suudavad tehisintellekti järeldusülesandeid täita palju tõhusamalt kui traditsioonilised CPU-d, sageli madalama energiatarbimisega. Paljud kaasaegsed nutitelefonid, sülearvutid ja IoT-seadmed sisaldavad nüüd NPU-sid, et võimaldada seadmesisest tehisintellekti töötlemist.

```csharp
// Example: Using Windows ML to target NPU acceleration in C#
using Microsoft.ML.OnnxRuntime;

// Create session options with NPU provider
var sessionOptions = new SessionOptions();
sessionOptions.AppendExecutionProvider_DmlExecutionProvider();  // DirectML for NPU

// Load the ONNX model
using var session = new InferenceSession("model.onnx", sessionOptions);

// Create input tensor
var inputTensor = new DenseTensor<float>(new[] { 1, 3, 224, 224 });  // Example input shape
var inputs = new List<NamedOnnxValue> { NamedOnnxValue.CreateFromTensor("input", inputTensor) };

// Run inference with NPU acceleration
using var results = session.Run(inputs);
var output = results.First().AsTensor<float>();

// Process output
Console.WriteLine($"Inference result: {output[0]}");
```

Seadmed NPU-dega hõlmavad:

- **Apple**: A-seeria ja M-seeria kiibid Neural Engine'iga
- **Qualcomm**: Snapdragon protsessorid Hexagon DSP/NPU-ga
- **Samsung**: Exynos protsessorid NPU-ga
- **Intel**: Movidius VPU-d ja Habana Labs kiirendid
- **Microsoft**: Windows Copilot+ arvutid NPU-dega

### 🎮 GPU kiirendus

Kuigi servaseadmetes ei pruugi olla andmekeskustes leiduvaid võimsaid GPU-sid, sisaldavad paljud siiski integreeritud või eraldiseisvaid GPU-sid, mis suudavad tehisintellekti töökoormusi kiirendada. Kaasaegsed mobiilsed GPU-d ja integreeritud graafikaprotsessorid võivad pakkuda märkimisväärseid jõudluse parandusi tehisintellekti järeldusülesannete jaoks.

```python
# Example: Using TensorRT for GPU acceleration on edge devices
import tensorrt as trt
import numpy as np

# Create TensorRT logger and builder
TRT_LOGGER = trt.Logger(trt.Logger.WARNING)
builder = trt.Builder(TRT_LOGGER)
network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))
parser = trt.OnnxParser(network, TRT_LOGGER)

# Parse ONNX model
with open('model.onnx', 'rb') as model:
    parser.parse(model.read())

# Configure builder
config = builder.create_builder_config()
config.max_workspace_size = 1 << 28  # 256 MiB
config.set_flag(trt.BuilderFlag.FP16)  # Use FP16 precision for edge GPU

# Build and serialize engine
engine = builder.build_engine(network, config)
with open('model.trt', 'wb') as f:
    f.write(engine.serialize())
```

### CPU optimeerimine

Isegi ainult CPU-ga seadmed võivad EdgeAI-st kasu saada optimeeritud rakenduste kaudu. Kaasaegsed CPU-d sisaldavad spetsiaalseid juhiseid tehisintellekti töökoormuste jaoks ning tarkvararaamistikud on välja töötatud, et maksimeerida CPU jõudlust tehisintellekti järelduste jaoks.

```bash
# Example: Using XNNPACK with TFLite for optimized CPU inference
# Compilation command with XNNPACK acceleration enabled

bazel build -c opt --copt=-O3 --copt=-march=native \
  tensorflow/lite/delegates/xnnpack:libxnnpack_delegate.so

# Convert TensorFlow model to TFLite with optimization
tflite_convert \
  --keras_model_file=model.h5 \
  --output_file=model.tflite \
  --inference_type=FLOAT \
  --experimental_new_converter \
  --experimental_new_quantizer
```

EdgeAI-ga töötavate tarkvarainseneride jaoks on kriitiline mõista, kuidas kasutada neid riistvarakiirenduse võimalusi, et optimeerida järelduste jõudlust ja energiatõhusust sihtseadmetes.

## EdgeAI eelised

### Privaatsus ja turvalisus

Üks EdgeAI suurimaid eeliseid on paranenud privaatsus ja turvalisus. Töötlemine toimub kohapeal seadmes, mistõttu tundlik teave ei lahku kunagi kasutaja kontrolli alt. See on eriti oluline rakenduste puhul, mis käsitlevad isikuandmeid, meditsiinilist teavet või konfidentsiaalset ärialast teavet.

### Vähendatud latentsus

EdgeAI kõrvaldab vajaduse saata andmeid kaugserveritesse töötlemiseks, vähendades oluliselt latentsust. See on kriitiline reaalajas rakenduste jaoks, nagu autonoomsed sõidukid, tööstusautomaatika või interaktiivsed rakendused, kus on vaja koheseid vastuseid.

### Võrguühenduseta võimekus

EdgeAI võimaldab tehisintellekti funktsionaalsust isegi siis, kui internetiühendus puudub. See on väärtuslik rakenduste jaoks kaugetes asukohtades, reisimise ajal või olukordades, kus võrgu usaldusväärsus on probleem.

### Kulutõhusus

Vähendades sõltuvust pilvepõhistest tehisintellekti teenustest, võib EdgeAI aidata vähendada tegevuskulusid, eriti rakenduste puhul, millel on suur kasutusmaht. Organisatsioonid saavad vältida pidevaid API-kulusid ja vähendada ribalaiuse nõudeid.

### Skaleeritavus

EdgeAI jaotab arvutuskoormuse servaseadmete vahel, mitte ei tsentraliseeri seda andmekeskustes. See võib aidata vähendada taristukulusid ja parandada kogu süsteemi skaleeritavust.

## EdgeAI rakendused

### Nutiseadmed ja IoT

EdgeAI toetab paljusid nutiseadmete funktsioone, alates häälassistentidest, mis suudavad käske kohapeal töödel
- [02: EdgeAI Rakendused](02.RealWorldCaseStudies.md)

---

**Lahtiütlus**:  
See dokument on tõlgitud AI tõlketeenuse [Co-op Translator](https://github.com/Azure/co-op-translator) abil. Kuigi püüame tagada täpsust, palume arvestada, et automaatsed tõlked võivad sisaldada vigu või ebatäpsusi. Algne dokument selle algses keeles tuleks pidada autoriteetseks allikaks. Olulise teabe puhul soovitame kasutada professionaalset inimtõlget. Me ei vastuta arusaamatuste või valesti tõlgenduste eest, mis võivad tekkida selle tõlke kasutamise tõttu.