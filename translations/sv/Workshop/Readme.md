<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8b994c57f1207012e4d7f58b7c0d1ae7",
  "translation_date": "2025-10-17T09:44:15+00:00",
  "source_file": "Workshop/Readme.md",
  "language_code": "sv"
}
-->
# EdgeAI f√∂r Nyb√∂rjare - Workshop

> **Praktisk inl√§rningsv√§g f√∂r att bygga produktionsklara Edge AI-applikationer**
>
> Bem√§stra lokal AI-distribution med Microsoft Foundry Local, fr√•n f√∂rsta chattkomplettering till multi-agent orkestrering i 6 progressiva sessioner.

---

## üéØ Introduktion

V√§lkommen till **EdgeAI f√∂r Nyb√∂rjare Workshop** - din praktiska guide till att bygga intelligenta applikationer som k√∂rs helt p√• lokal h√•rdvara. Denna workshop omvandlar teoretiska Edge AI-koncept till verkliga f√§rdigheter genom stegvis utmanande √∂vningar med Microsoft Foundry Local och Small Language Models (SLMs).

### Varf√∂r denna workshop?

**Edge AI-revolutionen √§r h√§r**

Organisationer v√§rlden √∂ver skiftar fr√•n molnbaserad AI till edge computing av tre viktiga sk√§l:

1. **Integritet & Efterlevnad** - Bearbeta k√§nslig data lokalt utan att skicka till molnet (HIPAA, GDPR, finansiella regler)
2. **Prestanda** - Eliminera n√§tverksf√∂rdr√∂jning (50-500ms lokalt j√§mf√∂rt med 500-2000ms molnresor)
3. **Kostnadskontroll** - Ta bort kostnader per token f√∂r API och skala utan molnkostnader

**Men Edge AI √§r annorlunda**

Att k√∂ra AI lokalt kr√§ver nya f√§rdigheter:
- Modellval och optimering f√∂r resursbegr√§nsningar
- Hantering av lokala tj√§nster och h√•rdvaruacceleration
- Prompt engineering f√∂r mindre modeller
- Produktionsdistributionsm√∂nster f√∂r edge-enheter

**Denna workshop ger dig dessa f√§rdigheter**

Under 6 fokuserade sessioner (~3 timmar totalt) g√•r du fr√•n "Hello World" till att distribuera produktionsklara multi-agent system - allt k√∂rs lokalt p√• din dator.

---

## üìö L√§randem√•l

Genom att slutf√∂ra denna workshop kommer du att kunna:

### K√§rnkompetenser
1. **Distribuera och hantera lokala AI-tj√§nster**
   - Installera och konfigurera Microsoft Foundry Local
   - V√§lja l√§mpliga modeller f√∂r edge-distribution
   - Hantera modellens livscykel (nedladdning, laddning, cache)
   - √ñvervaka resursanv√§ndning och optimera prestanda

2. **Bygga AI-drivna applikationer**
   - Implementera OpenAI-kompatibla chattkompletteringar lokalt
   - Designa effektiva prompts f√∂r Small Language Models
   - Hantera str√∂mmande svar f√∂r b√§ttre anv√§ndarupplevelse
   - Integrera lokala modeller i befintliga applikationer

3. **Skapa RAG-system (Retrieval Augmented Generation)**
   - Bygga semantisk s√∂kning med embeddings
   - Grunda LLM-svar i dom√§nspecifik kunskap
   - Utv√§rdera RAG-kvalitet med branschstandardm√•tt
   - Skala fr√•n prototyp till produktion

4. **Optimera modellprestanda**
   - Benchmarka flera modeller f√∂r ditt anv√§ndningsomr√•de
   - M√§ta latens, genomstr√∂mning och tid f√∂r f√∂rsta token
   - V√§lja optimala modeller baserat p√• hastighet/kvalitet
   - J√§mf√∂ra SLM vs LLM avv√§gningar i verkliga scenarier

5. **Orkestrera multi-agent system**
   - Designa specialiserade agenter f√∂r olika uppgifter
   - Implementera agentminne och kontexthantering
   - Koordinera agenter i komplexa arbetsfl√∂den
   - Rutta f√∂rfr√•gningar intelligent mellan flera modeller

6. **Distribuera produktionsklara l√∂sningar**
   - Implementera felhantering och √•terf√∂rs√∂kslogik
   - √ñvervaka tokenanv√§ndning och systemresurser
   - Bygga skalbara arkitekturer med model-as-tools-m√∂nster
   - Planera migrationsv√§gar fr√•n edge till hybrid (edge + moln)

---

## üéì L√§randeresultat

### Vad du kommer att bygga

I slutet av denna workshop kommer du ha skapat:

| Session | Leverabel | Demonstrerade f√§rdigheter |
|---------|-----------|---------------------------|
| **1** | Chattapplikation med str√∂mning | Tj√§nstinstallation, grundl√§ggande kompletteringar, str√∂mmande UX |
| **2** | RAG-system med utv√§rdering | Embeddings, semantisk s√∂kning, kvalitetsm√•tt |
| **3** | Benchmarking-svit f√∂r flera modeller | Prestandam√§tning, modellj√§mf√∂relse |
| **4** | SLM vs LLM-j√§mf√∂relse | Avv√§gningsanalys, optimeringsstrategier |
| **5** | Multi-agent orkestrator | Agentdesign, minneshantering, koordinering |
| **6** | Intelligent routningssystem | Intent-detektion, modellval, skalbarhet |

### Kompetensmatris

| F√§rdighetsniv√• | Session 1-2 | Session 3-4 | Session 5-6 |
|----------------|-------------|-------------|-------------|
| **Nyb√∂rjare** | ‚úÖ Installation & grunder | ‚ö†Ô∏è Utmanande | ‚ùå F√∂r avancerat |
| **Mellanliggande** | ‚úÖ Snabb genomg√•ng | ‚úÖ K√§rninl√§rning | ‚ö†Ô∏è Utmanande m√•l |
| **Avancerad** | ‚úÖ Enkel genomg√•ng | ‚úÖ F√∂rfining | ‚úÖ Produktionsm√∂nster |

### Karri√§rklara f√§rdigheter

**Efter denna workshop kommer du vara redo att:**

‚úÖ **Bygga integritetsfokuserade applikationer**
- H√§lsoappar som hanterar PHI/PII lokalt
- Finansiella tj√§nster med efterlevnadskrav
- Statliga system med krav p√• datasuver√§nitet

‚úÖ **Optimera f√∂r edge-milj√∂er**
- IoT-enheter med begr√§nsade resurser
- Offline-f√∂rst mobilapplikationer
- L√•g-latens realtidssystem

‚úÖ **Designa intelligenta arkitekturer**
- Multi-agent system f√∂r komplexa arbetsfl√∂den
- Hybrid edge-moln distributioner
- Kostnadsoptimerad AI-infrastruktur

‚úÖ **Leda Edge AI-initiativ**
- Utv√§rdera Edge AI:s genomf√∂rbarhet f√∂r projekt
- V√§lja l√§mpliga modeller och ramverk
- Designa skalbara lokala AI-l√∂sningar

---

## üó∫Ô∏è Workshopstruktur

### Session√∂versikt (6 sessioner √ó 30 minuter = 3 timmar)

| Session | √Ñmne | Fokus | Varaktighet |
|---------|-------|-------|-------------|
| **1** | Kom ig√•ng med Foundry Local | Installera, validera, f√∂rsta kompletteringar | 30 min |
| **2** | Bygga AI-l√∂sningar med RAG | Prompt engineering, embeddings, utv√§rdering | 30 min |
| **3** | √ñppna k√§llkod-modeller | Modelluppt√§ckt, benchmarking, val | 30 min |
| **4** | Avancerade modeller | SLM vs LLM, optimering, ramverk | 30 min |
| **5** | AI-drivna agenter | Agentdesign, orkestrering, minne | 30 min |
| **6** | Modeller som verktyg | Routing, kedjning, skalningsstrategier | 30 min |

---

## üöÄ Snabbstart

### F√∂ruts√§ttningar

**Systemkrav:**
- **OS**: Windows 10/11, macOS 11+ eller Linux (Ubuntu 20.04+)
- **RAM**: Minst 8GB, rekommenderat 16GB+
- **Lagring**: Minst 10GB ledigt utrymme f√∂r modeller
- **CPU**: Modern processor med AVX2-st√∂d
- **GPU** (valfritt): CUDA-kompatibel eller Qualcomm NPU f√∂r acceleration

**Programvarukrav:**
- **Python 3.8+** ([Ladda ner](https://www.python.org/downloads/))
- **Microsoft Foundry Local** ([Installationsguide](../../../Workshop))
- **Git** ([Ladda ner](https://git-scm.com/downloads))
- **Visual Studio Code** (rekommenderas) ([Ladda ner](https://code.visualstudio.com/))

### Installation i 3 steg

#### 1. Installera Foundry Local

**Windows:**
```powershell
winget install Microsoft.FoundryLocal
```

**macOS:**
```bash
brew tap microsoft/foundrylocal
brew install foundrylocal
```

**Verifiera installationen:**
```bash
foundry --version
foundry service status
```

**Se till att Azure AI Foundry Local k√∂rs med en fast port**

```bash
# Set FoundryLocal to use port 58123 (default)
foundry service set --port 58123 --show

# Or use a different port
foundry service set --port 58000 --show
```

**Verifiera att det fungerar:**
```bash
# Check service status
foundry service status

# Test the endpoint
curl http://127.0.0.1:58123/v1/models
```
**Hitta tillg√§ngliga modeller**
F√∂r att se vilka modeller som √§r tillg√§ngliga i din Foundry Local-instans kan du fr√•ga modellens slutpunkt:

```bash
# cmd/bash/powershell
foundry model list
```

Anv√§nd webbslutpunkt 

```bash
# Windows PowerShell
powershell -Command "Invoke-RestMethod -Uri 'http://127.0.0.1:58123/v1/models' -Method Get"

# Or using curl (if available)
curl http://127.0.0.1:58123/v1/models
```

#### 2. Klona repository & installera beroenden

```bash
# Clone repository
git clone https://github.com/microsoft/edgeai-for-beginners.git
cd edgeai-for-beginners/Workshop

# Create virtual environment
python -m venv .venv

# Activate virtual environment
# Windows:
.\.venv\Scripts\activate
# macOS/Linux:
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

#### 3. K√∂r ditt f√∂rsta exempel

```bash
# Start Foundry Local and load a model
foundry model run phi-4-mini

# Run the chat bootstrap sample
cd samples/session01
python chat_bootstrap.py "What is edge AI?"
```

**‚úÖ Lyckat!** Du b√∂r se ett str√∂mmande svar om edge AI.

---

## üì¶ Workshopresurser

### Python-exempel

Progressiva praktiska exempel som demonstrerar varje koncept:

| Session | Exempel | Beskrivning | K√∂rtid |
|---------|---------|-------------|--------|
| 1 | [`chat_bootstrap.py`](../../../Workshop/samples/session01/chat_bootstrap.py) | Grundl√§ggande & str√∂mmande chatt | ~30s |
| 2 | [`rag_pipeline.py`](../../../Workshop/samples/session02/rag_pipeline.py) | RAG med embeddings | ~45s |
| 2 | [`rag_eval_ragas.py`](../../../Workshop/samples/session02/rag_eval_ragas.py) | Utv√§rdering av RAG-kvalitet | ~60s |
| 3 | [`benchmark_oss_models.py`](../../../Workshop/samples/session03/benchmark_oss_models.py) | Benchmarking av flera modeller | ~2-3m |
| 4 | [`model_compare.py`](../../../Workshop/samples/session04/model_compare.py) | SLM vs LLM-j√§mf√∂relse | ~45s |
| 5 | [`agents_orchestrator.py`](../../../Workshop/samples/session05/agents_orchestrator.py) | Multi-agent system | ~60s |
| 6 | [`models_router.py`](../../../Workshop/samples/session06/models_router.py) | Intent-baserad routing | ~45s |
| 6 | [`models_pipeline.py`](../../../Workshop/samples/session06/models_pipeline.py) | Multi-stegs pipeline | ~60s |

### Jupyter Notebooks

Interaktiv utforskning med f√∂rklaringar och visualiseringar:

| Session | Notebook | Beskrivning | Sv√•righetsgrad |
|---------|----------|-------------|----------------|
| 1 | [`session01_chat_bootstrap.ipynb`](./notebooks/session01_chat_bootstrap.ipynb) | Chattgrunder & str√∂mning | ‚≠ê Nyb√∂rjare |
| 2 | [`session02_rag_pipeline.ipynb`](./notebooks/session02_rag_pipeline.ipynb) | Bygg RAG-system | ‚≠ê‚≠ê Mellanliggande |
| 2 | [`session02_rag_eval_ragas.ipynb`](./notebooks/session02_rag_eval_ragas.ipynb) | Utv√§rdera RAG-kvalitet | ‚≠ê‚≠ê Mellanliggande |
| 3 | [`session03_benchmark_oss_models.ipynb`](./notebooks/session03_benchmark_oss_models.ipynb) | Modellbenchmarking | ‚≠ê‚≠ê Mellanliggande |
| 4 | [`session04_model_compare.ipynb`](./notebooks/session04_model_compare.ipynb) | Modellj√§mf√∂relse | ‚≠ê‚≠ê Mellanliggande |
| 5 | [`session05_agents_orchestrator.ipynb`](./notebooks/session05_agents_orchestrator.ipynb) | Agentorkestrering | ‚≠ê‚≠ê‚≠ê Avancerad |
| 6 | [`session06_models_router.ipynb`](./notebooks/session06_models_router.ipynb) | Intent-routing | ‚≠ê‚≠ê‚≠ê Avancerad |
| 6 | [`session06_models_pipeline.ipynb`](./notebooks/session06_models_pipeline.ipynb) | Pipeline-orkestrering | ‚≠ê‚≠ê‚≠ê Avancerad |

### Dokumentation

Omfattande guider och referenser:

| Dokument | Beskrivning | Anv√§nd n√§r |
|----------|-------------|------------|
| [QUICK_START.md](./QUICK_START.md) | Snabbstartsguide | B√∂rjar fr√•n b√∂rjan |
| [QUICK_REFERENCE.md](./QUICK_REFERENCE.md) | Kommando- & API-snabbguide | Beh√∂ver snabba svar |
| [FOUNDRY_SDK_QUICKREF.md](./FOUNDRY_SDK_QUICKREF.md) | SDK-m√∂nster & exempel | Skriver kod |
| [ENV_CONFIGURATION.md](./ENV_CONFIGURATION.md) | Guide f√∂r milj√∂variabler | Konfigurerar exempel |
| [SAMPLES_UPDATE_SUMMARY.md](./SAMPLES_UPDATE_SUMMARY.md) | Senaste f√∂rb√§ttringar av exempel | F√∂rst√• f√∂r√§ndringar |
| [SDK_MIGRATION_NOTES.md](./SDK_MIGRATION_NOTES.md) | Migrationsguide | Uppgraderar kod |
| [notebooks/TROUBLESHOOTING.md](./notebooks/TROUBLESHOOTING.md) | Vanliga problem & l√∂sningar | Fels√∂ker problem |

---

## üéì Rekommendationer f√∂r l√§randebana

### F√∂r nyb√∂rjare (3-4 timmar)
1. ‚úÖ Session 1: Kom ig√•ng (fokus p√• installation och grundl√§ggande chatt)
2. ‚úÖ Session 2: RAG-grunder (hoppa √∂ver utv√§rdering till en b√∂rjan)
3. ‚úÖ Session 3: Enkel benchmarking (endast 2 modeller)
4. ‚è≠Ô∏è Hoppa √∂ver sessionerna 4-6 f√∂r tillf√§llet
5. üîÑ √Öterv√§nd till sessionerna 4-6 efter att ha byggt f√∂rsta applikationen

### F√∂r mellanliggande utvecklare (3 timmar)
1. ‚ö° Session 1: Snabb installationsvalidering
2. ‚úÖ Session 2: Komplett RAG-pipeline med utv√§rdering
3. ‚úÖ Session 3: Fullst√§ndig benchmarking-svit
4. ‚úÖ Session 4: Modelloptimering
5. ‚úÖ Sessionerna 5-6: Fokus p√• arkitekturm√∂nster

### F√∂r avancerade ut√∂vare (2-3 timmar)
1. ‚ö° Sessionerna 1-3: Snabb genomg√•ng och validering
2. ‚úÖ Session 4: F√∂rdjupning i optimering
3. ‚úÖ Session 5: Multi-agent arkitektur
4. ‚úÖ Session 6: Produktionsm√∂nster och skalning
5. üöÄ Ut√∂ka: Bygg anpassad routningslogik och hybriddistributioner

---

## Workshop Session Pack (Fokuserade 30-minuters labb)

Om du f√∂ljer det komprimerade 6-sessioners workshopformatet, anv√§nd dessa dedikerade guider (varje guide motsvarar och kompletterar de bredare modul-dokumenten ovan):

| Workshop Session | Guide | K√§rnfokus |
|------------------|-------|-----------|
| 1 | [Session01-GettingStartedFoundryLocal](./Session01-GettingStartedFoundryLocal.md) | Installera, validera, k√∂r phi & GPT-OSS-20B, acceleration |
| 2 | [Session02-BuildAISolutionsRAG](./Session02-BuildAISolutionsRAG.md) | Prompt engineering, RAG-m√∂nster, CSV & dokumentgrundning, migration |
| 3 | [Session03-OpenSourceModels](./Session03-OpenSourceModels.md) | Hugging Face-integration, benchmarking, modellval |
| 4 | [Session04-CuttingEdgeModels](./Session04-CuttingEdgeModels.md) | SLM vs LLM, WebGPU, Chainlit RAG, ONNX-acceleration |
| 5 | [Session05-AIPoweredAgents](./Session05-AIPoweredAgents.md) | Agentroller, minne, verktyg, orkestrering |
| 6 | [Session06-ModelsAsTools](./Session06-ModelsAsTools.md) | Routing, kedjning, skalning till Azure |

Varje sessionsfil inneh√•ller: sammanfattning, l√§randem√•l, 30-minuters demo, startprojekt, valideringschecklista, fels√∂kning och referenser till den officiella Foundry Local Python SDK.

### Exempelskript

Installera workshopberoenden (Windows):

```powershell
cd Workshop
py -m venv .venv
.\.venv\Scripts\activate
pip install -r requirements.txt
```

macOS / Linux:

```bash
cd Workshop
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

Om Foundry Local-tj√§nsten k√∂rs p√• en annan (Windows) dator eller VM fr√•n macOS, exportera endpointen:

```bash
export FOUNDRY_LOCAL_ENDPOINT=http://<windows-host>:5273/v1
```

| Session | Skript | Beskrivning |
|---------|--------|-------------|
| 1 | `samples/session01/chat_bootstrap.py` | Starta tj√§nst & streamingchatt |
| 2 | `samples/session02/rag_pipeline.py` | Minimal RAG (in-memory embeddings) |
|   | `samples/session02/rag_eval_ragas.py` | RAG-utv√§rdering med ragas-m√•tt |
| 3 | `samples/session03/benchmark_oss_models.py` | Latens- och genomstr√∂mningsbenchmark f√∂r flera modeller |
| 4 | `samples/session04/model_compare.py` | J√§mf√∂relse mellan SLM och LLM (latens & exempelutdata) |
| 5 | `samples/session05/agents_orchestrator.py` | Tv√•-agenters forsknings- och redigeringspipeline |
| 6 | `samples/session06/models_router.py` | Intentbaserad routingdemo |
|   | `samples/session06/models_pipeline.py` | Flerstegsplanering/utf√∂rande/f√∂rfiningskedja |

### Milj√∂variabler (Gemensamma f√∂r alla exempel)

| Variabel | Syfte | Exempel |
|----------|-------|---------|
| `FOUNDRY_LOCAL_ALIAS` | Standardalias f√∂r enskild modell f√∂r grundl√§ggande exempel | `phi-4-mini` |
| `SLM_ALIAS` / `LLM_ALIAS` | Explicit SLM kontra st√∂rre modell f√∂r j√§mf√∂relse | `phi-4-mini` / `gpt-oss-20b` |
| `BENCH_MODELS` | Kommalista med alias att benchmarka | `qwen2.5-0.5b,gemma-2-2b,mistral-7b` |
| `BENCH_ROUNDS` | Antal benchmarkupprepningar per modell | `3` |
| `BENCH_PROMPT` | Prompt som anv√§nds vid benchmark | `Explain retrieval augmented generation briefly.` |
| `EMBED_MODEL` | Sentence-transformers embedding-modell | `sentence-transformers/all-MiniLM-L6-v2` |
| `RAG_QUESTION` | √Ösidos√§tt testfr√•ga f√∂r RAG-pipeline | `Why use RAG with local inference?` |
| `AGENT_QUESTION` | √Ösidos√§tt fr√•ga f√∂r agentpipeline | `Explain why edge AI matters for compliance.` |
| `AGENT_MODEL_PRIMARY` | Modellalias f√∂r forskningsagent | `phi-4-mini` |
| `AGENT_MODEL_EDITOR` | Modellalias f√∂r redigeringsagent (kan skilja sig) | `gpt-oss-20b` |
| `SHOW_USAGE` | N√§r `1`, skriver ut tokenanv√§ndning per completion | `1` |
| `RETRY_ON_FAIL` | N√§r `1`, f√∂rs√∂k igen vid tillf√§lliga chattfel | `1` |
| `RETRY_BACKOFF` | Sekunder att v√§nta innan nytt f√∂rs√∂k | `1.0` |

Om en variabel inte √§r inst√§lld, faller skripten tillbaka p√• rimliga standardv√§rden. F√∂r demos med en enda modell beh√∂ver du vanligtvis bara `FOUNDRY_LOCAL_ALIAS`.

### Hj√§lpmodul

Alla exempel delar nu en hj√§lpfunktion `samples/workshop_utils.py` som tillhandah√•ller:

* Cachad `FoundryLocalManager` + OpenAI-klientskapande
* `chat_once()`-hj√§lpare med valfri retry + anv√§ndningsutskrift
* Enkel tokenanv√§ndningsrapportering (aktivera via `SHOW_USAGE=1`)

Detta minskar duplicering och lyfter fram b√§sta praxis f√∂r effektiv lokal modellorkestrering.

## Valfria f√∂rb√§ttringar (√ñver sessionsgr√§nser)

| Tema | F√∂rb√§ttring | Sessioner | Milj√∂ / V√§xling |
|------|-------------|-----------|-----------------|
| Determinism | Fast temperatur + stabila promptupps√§ttningar | 1‚Äì6 | St√§ll in `temperature=0`, `top_p=1` |
| Synlighet f√∂r tokenanv√§ndning | Konsekvent kostnads-/effektivitetsundervisning | 1‚Äì6 | `SHOW_USAGE=1` |
| Streaming av f√∂rsta token | Upplevd latensm√§tning | 1,3,4,6 | `BENCH_STREAM=1` (benchmark) |
| √Öterh√§mtningsf√∂rm√•ga vid fel | Hanterar tillf√§lliga kallstartsfel | Alla | `RETRY_ON_FAIL=1` + `RETRY_BACKOFF` |
| Multi-modellagenter | Heterogen rollspecialisering | 5 | `AGENT_MODEL_PRIMARY`, `AGENT_MODEL_EDITOR` |
| Adaptiv routing | Intent + kostnadsheuristik | 6 | Ut√∂ka router med eskaleringslogik |
| Vektorminne | L√•ngsiktig semantisk √•terkallelse | 2,5,6 | Integrera FAISS/Chroma embedding index |
| Sp√•rningsexport | Revision & utv√§rdering | 2,5,6 | L√§gg till JSON-linjer per steg |
| Kvalitetsrubriker | Kvalitativ sp√•rning | 3‚Äì6 | Sekund√§ra bed√∂mningsprompter |
| Snabbtester | Snabb validering f√∂re workshop | Alla | `python Workshop/tests/smoke.py` |

### Deterministisk snabbstart

```powershell
set FOUNDRY_LOCAL_ALIAS=phi-4-mini
set SHOW_USAGE=1
python Workshop\tests\smoke.py
```

F√∂rv√§nta dig stabila tokenantal √∂ver upprepade identiska inmatningar.

### RAG-utv√§rdering (Session 2)

Anv√§nd `rag_eval_ragas.py` f√∂r att ber√§kna svarens relevans, trov√§rdighet och kontextprecision p√• en liten syntetisk dataset:

```powershell
python samples/session02/rag_eval_ragas.py
```

Ut√∂ka genom att tillhandah√•lla en st√∂rre JSONL med fr√•gor, kontexter och sanningar, och konvertera sedan till en Hugging Face `Dataset`.

## CLI-kommandon: Noggrannhetsbilaga

Workshopen anv√§nder medvetet endast aktuellt dokumenterade / stabila Foundry Local CLI-kommandon.

### Refererade stabila kommandon

| Kategori | Kommando | Syfte |
|----------|----------|-------|
| K√§rna | `foundry --version` | Visa installerad version |
| K√§rna | `foundry init` | Initiera konfiguration |
| Tj√§nst | `foundry service start` | Starta lokal tj√§nst (om inte automatiskt) |
| Tj√§nst | `foundry status` | Visa tj√§nstens status |
| Modeller | `foundry model list` | Lista katalog / tillg√§ngliga modeller |
| Modeller | `foundry model download <alias>` | Ladda ner modellvikter till cache |
| Modeller | `foundry model run <alias>` | Starta (ladda) en modell lokalt; kombinera med `--prompt` f√∂r enstaka k√∂rning |
| Modeller | `foundry model unload <alias>` / `foundry model stop <alias>` | Ladda ur en modell fr√•n minnet (om st√∂ds) |
| Cache | `foundry cache list` | Lista cachade (nedladdade) modeller |
| System | `foundry system info` | √ñgonblicksbild av h√•rdvara & accelerationskapacitet |
| System | `foundry system gpu-info` | Diagnostisk information om GPU |
| Konfiguration | `foundry config list` | Visa aktuella konfigurationsv√§rden |
| Konfiguration | `foundry config set <key> <value>` | Uppdatera konfiguration |

### Enstaka promptm√∂nster

Ist√§llet f√∂r ett f√∂r√•ldrat `model chat`-underkommando, anv√§nd:

```powershell
foundry model run <alias> --prompt "Your question here"
```

Detta utf√∂r en enstaka prompt/svar-cykel och avslutar sedan.

### Borttagna / Undvikna m√∂nster

| F√∂r√•ldrade / Odokumenterade | Ers√§ttning / V√§gledning |
|-----------------------------|-------------------------|
| `foundry model chat <model> "..."` | `foundry model run <model> --prompt "..."` |
| `foundry model list --running` | Anv√§nd vanlig `foundry model list` + senaste aktivitet / loggar |
| `foundry model list --cached` | `foundry cache list` |
| `foundry model stats <model>` | Anv√§nd benchmark-Python-skript + OS-verktyg (Task Manager / `nvidia-smi`) |
| `foundry model benchmark ...` | `samples/session03/benchmark_oss_models.py` |

### Benchmarking & Telemetri

- Latens, p95, tokens/sek: `samples/session03/benchmark_oss_models.py`
- F√∂rsta-token-latens (streaming): st√§ll in `BENCH_STREAM=1`
- Resursanv√§ndning: OS-√∂vervakare (Task Manager, Activity Monitor, `nvidia-smi`) + `foundry system info`.

N√§r nya CLI-telemetrikommandon stabiliseras uppstr√∂ms kan de integreras med minimala √§ndringar i sessionsmarkdowns.

### Automatiserad linter

En automatiserad linter f√∂rhindrar √•terinf√∂rande av f√∂r√•ldrade CLI-m√∂nster inom kodblock i markdownfiler:

Skript: `Workshop/scripts/lint_markdown_cli.py`

F√∂r√•ldrade m√∂nster blockeras inom kodblock.

Rekommenderade ers√§ttningar:
| F√∂r√•ldrade | Ers√§ttning |
|------------|-----------|
| `foundry model chat <a> "..."` | `foundry model run <a> --prompt "..."` |
| `model list --running` | `model list` |
| `model list --cached` | `cache list` |
| `model stats` | Benchmark-skript + systemverktyg |
| `model benchmark` | `samples/session03/benchmark_oss_models.py` |
| `model list --available` | `model list` |

K√∂r lokalt:
```powershell
python Workshop\scripts\lint_markdown_cli.py --verbose
```

GitHub Action: `.github/workflows/markdown-cli-lint.yml` k√∂rs vid varje push & PR.

Valfri pre-commit hook:
```bash
echo "python Workshop/scripts/lint_markdown_cli.py" > .git/hooks/pre-commit
chmod +x .git/hooks/pre-commit
```

## Snabb CLI ‚Üí SDK-migrationstabell

| Uppgift | CLI One-Liner | SDK (Python) Motsvarighet | Noteringar |
|---------|---------------|--------------------------|------------|
| K√∂r en modell en g√•ng (prompt) | `foundry model run phi-4-mini --prompt "Hello"` | `manager=FoundryLocalManager("phi-4-mini"); client=OpenAI(base_url=manager.endpoint, api_key=manager.api_key or "not-needed"); client.chat.completions.create(model=manager.get_model_info("phi-4-mini").id, messages=[{"role":"user","content":"Hello"}])` | SDK startar tj√§nst & caching automatiskt |
| Ladda ner (cache) modell | `foundry model download qwen2.5-0.5b` | `FoundryLocalManager("qwen2.5-0.5b")  # triggers download/load` | Manager v√§ljer b√§sta variant om aliaset mappar till flera versioner |
| Lista katalog | `foundry model list` | `# anv√§nd manager f√∂r varje alias eller beh√•ll k√§nd lista` | CLI aggregerar; SDK f√∂r n√§rvarande per-alias-instansiering |
| Lista cachade modeller | `foundry cache list` | `manager.list_cached_models()` | Efter manager-initiering (valfritt alias) |
| Aktivera GPU-acceleration | `foundry config set compute.onnx.enable_gpu true` | `# CLI-√•tg√§rd; SDK antar att konfiguration redan √§r till√§mpad` | Konfiguration √§r en extern sidoeffekt |
| H√§mta endpoint-URL | (implicit) | `manager.endpoint` | Anv√§nds f√∂r att skapa OpenAI-kompatibel klient |
| V√§rma upp en modell | `foundry model run <alias>` f√∂ljt av f√∂rsta prompt | `chat_once(alias, messages=[...])` (hj√§lpfunktion) | Hj√§lpfunktioner hanterar initial kall latensuppv√§rmning |
| M√§ta latens | `python benchmark_oss_models.py` | `import benchmark_oss_models` (eller nytt exportskript) | F√∂redra skript f√∂r konsekventa m√•tt |
| Stoppa / ladda ur modell | `foundry model unload <alias>` | (Ej exponerat ‚Äì starta om tj√§nst / process) | Vanligtvis inte n√∂dv√§ndigt f√∂r workshopfl√∂de |
| H√§mta tokenanv√§ndning | (visa output) | `resp.usage.total_tokens` | Tillhandah√•lls om backend returnerar anv√§ndningsobjekt |

## Benchmark Markdown-export

Anv√§nd skriptet `Workshop/scripts/export_benchmark_markdown.py` f√∂r att k√∂ra en ny benchmark (samma logik som `samples/session03/benchmark_oss_models.py`) och generera en GitHub-v√§nlig Markdown-tabell plus r√• JSON.

### Exempel

```powershell
python Workshop\scripts\export_benchmark_markdown.py --models "qwen2.5-0.5b,gemma-2-2b,mistral-7b" --prompt "Explain retrieval augmented generation briefly." --rounds 3 --output benchmark_report.md
```

Genererade filer:
| Fil | Inneh√•ll |
|-----|----------|
| `benchmark_report.md` | Markdown-tabell + tolkningshj√§lp |
| `benchmark_report.json` | R√• m√•ttarray (f√∂r j√§mf√∂relse / trendsp√•rning) |

St√§ll in `BENCH_STREAM=1` i milj√∂n f√∂r att inkludera f√∂rsta-token-latens om det st√∂ds.

---

**Ansvarsfriskrivning**:  
Detta dokument har √∂versatts med hj√§lp av AI-√∂vers√§ttningstj√§nsten [Co-op Translator](https://github.com/Azure/co-op-translator). √Ñven om vi str√§var efter noggrannhet, b√∂r det noteras att automatiserade √∂vers√§ttningar kan inneh√•lla fel eller felaktigheter. Det ursprungliga dokumentet p√• dess ursprungliga spr√•k b√∂r betraktas som den auktoritativa k√§llan. F√∂r kritisk information rekommenderas professionell m√§nsklig √∂vers√§ttning. Vi ansvarar inte f√∂r eventuella missf√∂rst√•nd eller feltolkningar som uppst√•r vid anv√§ndning av denna √∂vers√§ttning.