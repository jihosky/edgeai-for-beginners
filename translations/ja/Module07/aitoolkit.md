<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "efb0e70d6e87d0795f4d381c3bc99074",
  "translation_date": "2025-10-21T06:57:19+00:00",
  "source_file": "Module07/aitoolkit.md",
  "language_code": "ja"
}
-->
# Visual Studio Code用AIツールキット - エッジAI開発ガイド

## はじめに

Visual Studio Code用AIツールキットを使用したエッジAI開発の包括的なガイドへようこそ。人工知能が集中型クラウドコンピューティングから分散型エッジデバイスへと移行する中で、開発者はリソース制約やオフライン動作要件など、エッジ展開の独自の課題に対応できる強力で統合されたツールを必要としています。

Visual Studio Code用AIツールキットは、エッジデバイス上で効率的に動作するAIアプリケーションを構築、テスト、最適化するために特別に設計された完全な開発環境を提供することで、このギャップを埋めます。IoTセンサー、モバイルデバイス、組み込みシステム、エッジサーバー向けの開発を行う場合でも、このツールキットはお馴染みのVS Code環境内で開発ワークフロー全体を効率化します。

このガイドでは、AIツールキットを活用してエッジAIプロジェクトを進めるための基本的な概念、ツール、ベストプラクティスを、初期のモデル選択から本番展開まで詳しく説明します。

## 概要

Visual Studio Code用AIツールキットは、エージェント開発とAIアプリケーション作成を効率化する強力な拡張機能です。このツールキットは、Anthropic、OpenAI、GitHub、Googleなどの幅広いプロバイダーからAIモデルを探索、評価、展開するための包括的な機能を提供し、ONNXやOllamaを使用したローカルモデル実行をサポートします。

AIツールキットの特徴は、AI開発ライフサイクル全体を包括的にサポートする点です。従来のAI開発ツールが単一の側面に焦点を当てるのに対し、AIツールキットはモデルの発見、実験、エージェント開発、評価、展開を統合した環境を提供します。

このプラットフォームは、プロトタイピングから本番展開まで迅速に対応できるよう設計されており、プロンプト生成、クイックスタート、シームレスなMCP（Model Context Protocol）ツール統合、広範な評価機能などの特徴を備えています。エッジAI開発においては、VS Code内で完全な開発ワークフローを維持しながら、効率的にAIアプリケーションを開発、テスト、最適化できます。

## 学習目標

このガイドを終える頃には、以下のことができるようになります：

### 基本スキル
- Visual Studio Code用AIツールキットをエッジAI開発ワークフローに**インストールおよび設定**する
- AIツールキットのインターフェース（Model Catalog、Playground、Agent Builderなど）を**操作および活用**する
- パフォーマンスやリソース制約に基づいてエッジ展開に適したAIモデルを**選択および評価**する
- ONNX形式や量子化技術を使用してモデルを**変換および最適化**する

### エッジAI開発スキル
- 統合開発環境を使用してエッジAIアプリケーションを**設計および実装**する
- ローカル推論やリソースモニタリングを使用してエッジに近い条件でモデルを**テスト**する
- エッジ展開シナリオに最適化されたAIエージェントを**作成およびカスタマイズ**する
- エッジコンピューティングに関連する指標（レイテンシ、メモリ使用量、精度）を使用してモデルの**パフォーマンスを評価**する

### 最適化と展開
- モデルサイズを削減しつつ許容可能なパフォーマンスを維持するために**量子化と剪定**技術を適用する
- CPU、GPU、NPUアクセラレーションを含む特定のエッジハードウェアプラットフォーム向けにモデルを**最適化**する
- リソース管理やフォールバック戦略を含むエッジAI開発の**ベストプラクティスを実装**する
- エッジデバイス上での本番展開に向けてモデルやアプリケーションを**準備**する

### 高度なエッジAI概念
- ONNX Runtime、Windows ML、TensorFlow LiteなどのエッジAIフレームワークと**統合**する
- エッジ環境向けのマルチモデルアーキテクチャやフェデレーション学習シナリオを**実装**する
- メモリ制約、推論速度、ハードウェア互換性などの一般的なエッジAI問題を**トラブルシューティング**する
- 本番環境でのエッジAIアプリケーション向けの**モニタリングおよびログ戦略を設計**する

### 実践的な応用
- モデル選択から展開までの**エンドツーエンドのエッジAIソリューションを構築**する
- エッジ特有の開発ワークフローや最適化技術に関する**熟練度を示す**
- IoT、モバイル、組み込みアプリケーションを含む実際のエッジAIユースケースに**学んだ概念を適用**する
- 異なるエッジAI展開戦略とそのトレードオフを**評価および比較**する

## エッジAI開発のための主要機能

### 1. モデルカタログと探索
- **マルチプロバイダーサポート**: Anthropic、OpenAI、GitHub、GoogleなどのプロバイダーからAIモデルを閲覧およびアクセス
- **ローカルモデル統合**: エッジ展開向けのONNXおよびOllamaモデルの簡易探索
- **GitHubモデル**: GitHubのモデルホスティングとの直接統合で効率的なアクセス
- **モデル比較**: エッジデバイスの制約に最適なバランスを見つけるためのモデルの並列比較

### 2. インタラクティブプレイグラウンド
- **インタラクティブなテスト環境**: 制御された環境でモデルの機能を迅速に実験
- **マルチモーダルサポート**: エッジシナリオで一般的な画像、テキストなどの入力をテスト
- **リアルタイム実験**: モデルの応答とパフォーマンスに関する即時フィードバック
- **パラメータ最適化**: エッジ展開要件に合わせたモデルパラメータの微調整

### 3. プロンプト（エージェント）ビルダー
- **自然言語生成**: 自然言語記述を使用してスタータープロンプトを生成
- **反復的な改良**: モデルの応答とパフォーマンスに基づいてプロンプトを改善
- **タスク分解**: プロンプトチェーンや構造化出力を使用して複雑なタスクを分解
- **変数サポート**: 動的なエージェント動作のためにプロンプトに変数を使用
- **本番コード生成**: 本番対応のコードを生成して迅速なアプリ開発を実現

### 4. 一括実行と評価
- **マルチモデルテスト**: 選択したモデル間で複数のプロンプトを同時に実行
- **効率的なスケールでのテスト**: 様々な入力と構成を効率的にテスト
- **カスタムテストケース**: エージェントをテストケースで実行して機能を検証
- **パフォーマンス比較**: 異なるモデルと構成間で結果を比較

### 5. データセットを使用したモデル評価
- **標準指標**: 組み込み評価ツール（F1スコア、関連性、類似性、一貫性）を使用してAIモデルをテスト
- **カスタム評価ツール**: 特定のユースケース向けに独自の評価指標を作成
- **データセット統合**: 包括的なデータセットに対してモデルをテスト
- **パフォーマンス測定**: エッジ展開の意思決定のためにモデルのパフォーマンスを定量化

### 6. ファインチューニング機能
- **モデルカスタマイズ**: 特定のユースケースやドメイン向けにモデルをカスタマイズ
- **専門的な適応**: 特定のドメインや要件にモデルを適応
- **エッジ最適化**: エッジ展開の制約に特化したモデルをファインチューニング
- **ドメイン特化型トレーニング**: 特定のエッジユースケースに合わせたモデルを作成

### 7. MCPツール統合
- **外部ツールとの接続**: Model Context Protocolサーバーを通じてエージェントを外部ツールに接続
- **実世界のアクション**: エージェントがデータベースをクエリしたり、APIにアクセスしたり、カスタムロジックを実行したりする機能を有効化
- **既存のMCPサーバー**: コマンド（stdio）またはHTTP（サーバー送信イベント）プロトコルからツールを使用
- **カスタムMCP開発**: Agent Builderでテストしながら新しいMCPサーバーを構築およびスキャフォールド

### 8. エージェント開発とテスト
- **関数呼び出しサポート**: エージェントが外部関数を動的に呼び出す機能を有効化
- **リアルタイム統合テスト**: 実行中の統合とツール使用をリアルタイムでテスト
- **エージェントのバージョン管理**: 評価結果の比較機能を備えたエージェントのバージョン管理
- **デバッグとトレース**: エージェント開発のためのローカルトレースとデバッグ機能

## エッジAI開発ワークフロー

### フェーズ1: モデルの探索と選択
1. **モデルカタログを探索**: モデルカタログを使用してエッジ展開に適したモデルを見つける
2. **パフォーマンスを比較**: サイズ、精度、推論速度に基づいてモデルを評価
3. **ローカルでテスト**: エッジ展開前にOllamaまたはONNXモデルを使用してローカルでテスト
4. **リソース要件を評価**: 対象のエッジデバイスに必要なメモリと計算能力を判断

### フェーズ2: モデルの最適化
1. **ONNXに変換**: 選択したモデルをエッジ互換性のためにONNX形式に変換
2. **量子化を適用**: INT8またはINT4量子化を通じてモデルサイズを削減
3. **ハードウェア最適化**: 対象のエッジハードウェア（ARM、x86、専用アクセラレータ）向けに最適化
4. **パフォーマンス検証**: 最適化されたモデルが許容可能な精度を維持していることを確認

### フェーズ3: アプリケーション開発
1. **エージェント設計**: Agent Builderを使用してエッジ最適化されたAIエージェントを作成
2. **プロンプトエンジニアリング**: 小型のエッジモデルで効果的に機能するプロンプトを開発
3. **統合テスト**: シミュレーションされたエッジ条件でエージェントをテスト
4. **コード生成**: エッジ展開に最適化された本番コードを生成

### フェーズ4: 評価とテスト
1. **バッチ評価**: 複数の構成をテストして最適なエッジ設定を見つける
2. **パフォーマンスプロファイリング**: 推論速度、メモリ使用量、精度を分析
3. **エッジシミュレーション**: 対象のエッジ展開環境に類似した条件でテスト
4. **ストレステスト**: 様々な負荷条件下でのパフォーマンスを評価

### フェーズ5: 展開準備
1. **最終的な最適化**: テスト結果に基づいて最終的な最適化を適用
2. **展開パッケージ化**: モデルとコードをエッジ展開用にパッケージ化
3. **ドキュメント作成**: 展開要件と構成を文書化
4. **モニタリング設定**: エッジ展開のためのモニタリングとログを準備

## エッジAI開発の対象者

### エッジAI開発者
- AI搭載エッジデバイスやIoTソリューションを構築するアプリケーション開発者
- リソース制約のあるデバイスにAI機能を統合する組み込みシステム開発者
- スマートフォンやタブレット向けのオンデバイスAIアプリケーションを作成するモバイル開発者

### エッジAIエンジニア
- エッジ展開向けにモデルを最適化し、推論パイプラインを管理するAIエンジニア
- 分散型エッジインフラストラクチャ全体でAIモデルを展開および管理するDevOpsエンジニア
- エッジハードウェアの制約に合わせてAIワークロードを最適化するパフォーマンスエンジニア

### 研究者と教育者
- エッジコンピューティング向けの効率的なモデルやアルゴリズムを開発するAI研究者
- エッジAIの概念を教え、最適化技術を実演する教育者
- エッジAI展開の課題と解決策を学ぶ学生

## エッジAIユースケース

### スマートIoTデバイス
- **リアルタイム画像認識**: IoTカメラやセンサーにコンピュータビジョンモデルを展開
- **音声処理**: スマートスピーカーで音声認識や自然言語処理を実装
- **予測保守**: 産業用エッジデバイスで異常検知モデルを実行
- **環境モニタリング**: 環境アプリケーション向けにセンサーデータ分析モデルを展開

### モバイルおよび組み込みアプリケーション
- **オンデバイス翻訳**: オフラインで動作する言語翻訳モデルを実装
- **拡張現実**: ARアプリケーション向けにリアルタイムの物体認識と追跡を展開
- **健康モニタリング**: ウェアラブルデバイスや医療機器で健康分析モデルを実行
- **自律システム**: ドローン、ロボット、車両向けの意思決定モデルを実装

### エッジコンピューティングインフラストラクチャ
- **エッジデータセンター**: 低レイテンシアプリケーション向けにエッジデータセンターでAIモデルを展開
- **CDN統合**: コンテンツ配信ネットワークにAI処理機能を統合
- **5Gエッジ**: 5Gエッジコンピューティングを活用したAI対応アプリケーション
- **フォグコンピューティング**: フォグコンピューティング環境でAI処理を実装

## インストールとセットアップ

### 拡張機能のインストール
Visual Studio Code MarketplaceからAIツールキット拡張機能を直接インストールします：

**拡張機能ID**: `ms-windows-ai-studio.windows-ai-studio`

**インストール方法**:
1. **VS Code Marketplace**: Extensionsビューで「AI Toolkit」を検索
2. 自然言語の説明を使用してスタータープロンプトを生成する  
3. モデルの応答に基づいてプロンプトを反復し、改善する  
4. MCPツールを統合してエージェントの能力を強化する  

#### ステップ3: テストと評価  
1. **Bulk Run**を使用して、選択したモデルで複数のプロンプトをテストする  
2. テストケースを使用してエージェントの機能を検証する  
3. 組み込みまたはカスタムメトリクスを使用して精度とパフォーマンスを評価する  
4. 異なるモデルや構成を比較する  

#### ステップ4: 微調整と最適化  
1. 特定のエッジユースケースに合わせてモデルをカスタマイズする  
2. ドメイン固有の微調整を適用する  
3. エッジ展開の制約に合わせて最適化する  
4. 異なるエージェント構成をバージョン管理し、比較する  

#### ステップ5: 展開準備  
1. Agent Builderを使用して本番環境向けのコードを生成する  
2. 本番環境で使用するためにMCPサーバー接続を設定する  
3. エッジデバイス向けの展開パッケージを準備する  
4. 監視と評価メトリクスを設定する  

## AI Toolkitのサンプル  

サンプルを試してみよう  
[AI Toolkitのサンプル](https://github.com/Azure-Samples/AI_Toolkit_Samples)は、開発者や研究者がAIソリューションを効果的に探索・実装するために設計されています。  

サンプルには以下が含まれます:  

サンプルコード: トレーニング、展開、またはアプリケーションへのモデル統合など、AI機能を示す事前構築された例  
ドキュメント: AI Toolkitの機能とその使用方法を理解するためのガイドやチュートリアル  

必要条件  

- Visual Studio Code  
- Visual Studio Code用AI Toolkit  
- GitHubの詳細な個人アクセストークン（PAT）  
- Foundry Local  

## エッジAI開発のベストプラクティス  

### モデル選択  
- **サイズ制約**: ターゲットデバイスのメモリ制限内に収まるモデルを選択する  
- **推論速度**: リアルタイムアプリケーション向けに高速推論モデルを優先する  
- **精度のトレードオフ**: モデルの精度とリソース制約のバランスを取る  
- **形式の互換性**: エッジ展開にはONNXやハードウェア最適化形式を推奨  

### 最適化技術  
- **量子化**: INT8またはINT4量子化を使用してモデルサイズを縮小し、速度を向上させる  
- **プルーニング**: 不要なモデルパラメータを削除して計算要件を削減する  
- **知識蒸留**: 大きなモデルの性能を維持しつつ小さなモデルを作成する  
- **ハードウェアアクセラレーション**: NPU、GPU、または専用アクセラレータを活用する  

### 開発ワークフロー  
- **反復テスト**: 開発中にエッジに近い条件で頻繁にテストする  
- **パフォーマンス監視**: リソース使用量と推論速度を継続的に監視する  
- **バージョン管理**: モデルのバージョンと最適化設定を追跡する  
- **ドキュメント化**: すべての最適化決定とパフォーマンスのトレードオフを記録する  

### 展開の考慮事項  
- **リソース監視**: 本番環境でメモリ、CPU、電力使用量を監視する  
- **フォールバック戦略**: モデルの失敗に備えたフォールバックメカニズムを実装する  
- **更新メカニズム**: モデルの更新とバージョン管理を計画する  
- **セキュリティ**: エッジAIアプリケーションに適切なセキュリティ対策を実施する  

## エッジAIフレームワークとの統合  

### ONNX Runtime  
- **クロスプラットフォーム展開**: 異なるエッジプラットフォームでONNXモデルを展開する  
- **ハードウェア最適化**: ONNX Runtimeのハードウェア固有の最適化を活用する  
- **モバイル対応**: スマートフォンやタブレットアプリケーション向けにONNX Runtime Mobileを使用する  
- **IoT統合**: ONNX Runtimeの軽量ディストリビューションを使用してIoTデバイスに展開する  

### Windows ML  
- **Windowsデバイス**: WindowsベースのエッジデバイスやPC向けに最適化する  
- **NPUアクセラレーション**: WindowsデバイスのNeural Processing Unitを活用する  
- **DirectML**: WindowsプラットフォームでGPUアクセラレーションにDirectMLを使用する  
- **UWP統合**: Universal Windows Platformアプリケーションと統合する  

### TensorFlow Lite  
- **モバイル最適化**: モバイルや組み込みデバイスでTensorFlow Liteモデルを展開する  
- **ハードウェアデリゲート**: 専用ハードウェアデリゲートを使用してアクセラレーションする  
- **マイクロコントローラー**: TensorFlow Lite Microを使用してマイクロコントローラーに展開する  
- **クロスプラットフォーム対応**: Android、iOS、組み込みLinuxシステムで展開する  

### Azure IoT Edge  
- **クラウド-エッジハイブリッド**: クラウドトレーニングとエッジ推論を組み合わせる  
- **モジュール展開**: AIモデルをIoT Edgeモジュールとして展開する  
- **デバイス管理**: エッジデバイスとモデル更新をリモートで管理する  
- **テレメトリ**: エッジ展開からパフォーマンスデータとモデルメトリクスを収集する  

## 高度なエッジAIシナリオ  

### マルチモデル展開  
- **モデルアンサンブル**: 精度向上や冗長性のために複数モデルを展開する  
- **A/Bテスト**: エッジデバイスで異なるモデルを同時にテストする  
- **動的選択**: 現在のデバイス状況に基づいてモデルを選択する  
- **リソース共有**: 複数の展開モデル間でリソース使用を最適化する  

### フェデレーテッドラーニング  
- **分散トレーニング**: 複数のエッジデバイスでモデルをトレーニングする  
- **プライバシー保護**: トレーニングデータをローカルに保持しながらモデル改善を共有する  
- **協調学習**: デバイスが集団的な経験から学習できるようにする  
- **エッジ-クラウド連携**: エッジデバイスとクラウドインフラ間で学習を調整する  

### リアルタイム処理  
- **ストリーム処理**: エッジデバイスで連続データストリームを処理する  
- **低遅延推論**: 推論遅延を最小化するよう最適化する  
- **バッチ処理**: エッジデバイスでデータバッチを効率的に処理する  
- **適応処理**: 現在のデバイス能力に基づいて処理を調整する  

## エッジAI開発のトラブルシューティング  

### よくある問題  
- **メモリ制約**: モデルがターゲットデバイスのメモリに収まらない  
- **推論速度**: モデル推論がリアルタイム要件に対して遅すぎる  
- **精度低下**: 最適化によりモデル精度が許容範囲を超えて低下する  
- **ハードウェア互換性**: モデルがターゲットハードウェアと互換性がない  

### デバッグ戦略  
- **パフォーマンスプロファイリング**: AI Toolkitのトレース機能を使用してボトルネックを特定する  
- **リソース監視**: 開発中にメモリとCPU使用量を監視する  
- **段階的テスト**: 最適化を段階的にテストして問題を特定する  
- **ハードウェアシミュレーション**: 開発ツールを使用してターゲットハードウェアをシミュレーションする  

### 最適化ソリューション  
- **さらなる量子化**: より積極的な量子化技術を適用する  
- **モデルアーキテクチャ**: エッジ向けに最適化された異なるモデルアーキテクチャを検討する  
- **前処理の最適化**: エッジ制約に合わせてデータ前処理を最適化する  
- **推論の最適化**: ハードウェア固有の推論最適化を使用する  

## リソースと次のステップ  

### 公式ドキュメント  
- [AI Toolkit開発者向けドキュメント](https://aka.ms/AIToolkit/doc)  
- [インストールとセットアップガイド](https://code.visualstudio.com/docs/intelligentapps/overview#_install-and-setup)  
- [VS Codeインテリジェントアプリドキュメント](https://code.visualstudio.com/docs/intelligentapps)  
- [Model Context Protocol (MCP) ドキュメント](https://modelcontextprotocol.io/)  

### コミュニティとサポート  
- [AI Toolkit GitHubリポジトリ](https://github.com/microsoft/vscode-ai-toolkit)  
- [GitHubの問題と機能リクエスト](https://aka.ms/AIToolkit/feedback)  
- [Azure AI Foundry Discordコミュニティ](https://aka.ms/azureaifoundry/discord)  
- [VS Code拡張機能マーケットプレイス](https://marketplace.visualstudio.com/items?itemName=ms-windows-ai-studio.windows-ai-studio)  

### 技術リソース  
- [ONNX Runtimeドキュメント](https://onnxruntime.ai/)  
- [Ollamaドキュメント](https://ollama.ai/)  
- [Windows MLドキュメント](https://docs.microsoft.com/en-us/windows/ai/)  
- [Azure AI Foundryドキュメント](https://learn.microsoft.com/en-us/azure/ai-foundry/)  

### 学習パス  
- [エッジAI基礎コース](../Module01/README.md)  
- [小型言語モデルガイド](../Module02/README.md)  
- [エッジ展開戦略](../Module03/README.md)  
- [WindowsエッジAI開発](./windowdeveloper.md)  

### 追加リソース  
- **リポジトリ統計**: 1.8k+スター、150+フォーク、18+コントリビューター  
- **ライセンス**: MITライセンス  
- **セキュリティ**: Microsoftのセキュリティポリシーが適用される  
- **テレメトリ**: VS Codeのテレメトリ設定を尊重  

## 結論  

Visual Studio Code用AI Toolkitは、エッジAIアプリケーションに特に価値のある、モダンなAI開発のための包括的なプラットフォームを提供します。Anthropic、OpenAI、GitHub、Googleなどのプロバイダーをサポートする広範なモデルカタログと、ONNXやOllamaを使用したローカル実行を組み合わせることで、多様なエッジ展開シナリオに必要な柔軟性を提供します。  

このツールキットの強みは統合されたアプローチにあります。Playgroundでのモデル探索と実験から、Prompt Builderを使用した高度なエージェント開発、包括的な評価機能、そしてシームレスなMCPツール統合まで、エッジAI開発者にとって、エージェントのプロトタイプ作成とテストを迅速に行い、リソース制約のある環境に最適化する能力を提供します。  

エッジAI開発における主な利点は以下の通りです:  
- **迅速な実験**: エッジ展開にコミットする前にモデルとエージェントを迅速にテスト  
- **マルチプロバイダの柔軟性**: 最適なエッジソリューションを見つけるためにさまざまなソースからモデルにアクセス  
- **ローカル開発**: オフラインおよびプライバシー保護のためにONNXとOllamaでテスト  
- **本番対応**: 本番環境向けのコードを生成し、MCPを介して外部ツールと統合  
- **包括的な評価**: 組み込みおよびカスタムメトリクスを使用してエッジAIのパフォーマンスを検証  

AIがエッジ展開シナリオに向かう中で、VS Code用AI Toolkitは、リソース制約のある環境向けのインテリジェントアプリケーションを構築、テスト、最適化するために必要な開発環境とワークフローを提供します。IoTソリューション、モバイルAIアプリケーション、組み込みインテリジェンスシステムを開発する際、このツールキットの包括的な機能セットと統合されたワークフローは、エッジAI開発ライフサイクル全体をサポートします。  

継続的な開発と活発なコミュニティ（1.8k+ GitHubスター）により、AI Toolkitはエッジ展開シナリオを構築するモダンなAI開発者のニーズに応えるために進化し続けています。  

[次のFoundry Local](./foundrylocal.md)  

---

**免責事項**:  
この文書はAI翻訳サービス[Co-op Translator](https://github.com/Azure/co-op-translator)を使用して翻訳されています。正確性を追求しておりますが、自動翻訳には誤りや不正確な部分が含まれる可能性があります。元の言語で記載された文書を正式な情報源としてお考えください。重要な情報については、専門の人間による翻訳を推奨します。この翻訳の使用に起因する誤解や誤解について、当社は責任を負いません。