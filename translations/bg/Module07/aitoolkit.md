<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "efb0e70d6e87d0795f4d381c3bc99074",
  "translation_date": "2025-10-21T07:35:34+00:00",
  "source_file": "Module07/aitoolkit.md",
  "language_code": "bg"
}
-->
# AI Toolkit за Visual Studio Code - Ръководство за разработка на Edge AI

## Въведение

Добре дошли в подробното ръководство за използване на AI Toolkit за Visual Studio Code в разработката на Edge AI. С развитието на изкуствения интелект от централизирани облачни изчисления към разпределени крайни устройства, разработчиците се нуждаят от мощни, интегрирани инструменти, които да се справят с уникалните предизвикателства на крайното внедряване - от ограниченията на ресурсите до изискванията за работа офлайн.

AI Toolkit за Visual Studio Code запълва тази празнина, като предоставя цялостна среда за разработка, специално създадена за изграждане, тестване и оптимизиране на AI приложения, които работят ефективно на крайни устройства. Независимо дали разработвате за IoT сензори, мобилни устройства, вградени системи или крайни сървъри, този инструментариум опростява целия процес на разработка в познатата среда на VS Code.

Това ръководство ще ви запознае с основните концепции, инструменти и най-добри практики за използване на AI Toolkit във вашите Edge AI проекти - от избора на модел до внедряването в производство.

## Общ преглед

AI Toolkit за Visual Studio Code е мощно разширение, което опростява разработката на агенти и създаването на AI приложения. Инструментариумът предоставя цялостни възможности за изследване, оценка и внедряване на AI модели от широк кръг доставчици - включително Anthropic, OpenAI, GitHub, Google - като същевременно поддържа локално изпълнение на модели чрез ONNX и Ollama.

Това, което отличава AI Toolkit, е неговият цялостен подход към целия жизнен цикъл на AI разработката. За разлика от традиционните инструменти за разработка на AI, които се фокусират върху отделни аспекти, AI Toolkit предоставя интегрирана среда, която обхваща откриване на модели, експериментиране, разработка на агенти, оценка и внедряване - всичко това в познатата среда на VS Code.

Платформата е специално проектирана за бързо прототипиране и внедряване в производство, с функции като генериране на подсказки, бързи стартери, безпроблемни интеграции с MCP (Model Context Protocol) инструменти и обширни възможности за оценка. За разработката на Edge AI това означава, че можете ефективно да разработвате, тествате и оптимизирате AI приложения за крайни сценарии на внедряване, като същевременно поддържате целия процес на разработка в рамките на VS Code.

## Цели на обучението

До края на това ръководство ще можете:

### Основни компетенции
- **Инсталиране и конфигуриране** на AI Toolkit за Visual Studio Code за работни потоци на Edge AI разработка
- **Навигация и използване** на интерфейса на AI Toolkit, включително Model Catalog, Playground и Agent Builder
- **Избор и оценка** на AI модели, подходящи за крайно внедряване, въз основа на производителност и ограничения на ресурсите
- **Конвертиране и оптимизиране** на модели с помощта на ONNX формат и техники за квантизация за крайни устройства

### Умения за разработка на Edge AI
- **Проектиране и внедряване** на Edge AI приложения с помощта на интегрираната среда за разработка
- **Тестване на модели** в условия, подобни на крайни, с локално извеждане и мониторинг на ресурсите
- **Създаване и персонализиране** на AI агенти, оптимизирани за крайни сценарии на внедряване
- **Оценка на производителността на моделите** с помощта на метрики, релевантни за крайни изчисления (латентност, използване на памет, точност)

### Оптимизация и внедряване
- **Прилагане на техники за квантизация и подрязване** за намаляване на размера на модела, като същевременно се поддържа приемлива производителност
- **Оптимизиране на модели** за специфични крайни хардуерни платформи, включително ускорение на CPU, GPU и NPU
- **Прилагане на най-добри практики** за разработка на Edge AI, включително управление на ресурсите и стратегии за резервиране
- **Подготовка на модели и приложения** за внедряване в производство на крайни устройства

### Разширени концепции за Edge AI
- **Интеграция с крайни AI рамки** като ONNX Runtime, Windows ML и TensorFlow Lite
- **Внедряване на многомоделни архитектури** и сценарии за федеративно обучение за крайни среди
- **Отстраняване на често срещани проблеми с Edge AI** като ограничения на паметта, скорост на извеждане и съвместимост на хардуера
- **Проектиране на стратегии за мониторинг и логване** за Edge AI приложения в производство

### Практическо приложение
- **Създаване на цялостни Edge AI решения** от избора на модел до внедряването
- **Демонстриране на умения** в специфични за крайни устройства работни потоци за разработка и техники за оптимизация
- **Прилагане на научените концепции** към реални случаи на употреба на Edge AI, включително IoT, мобилни и вградени приложения
- **Оценка и сравнение** на различни стратегии за внедряване на Edge AI и техните компромиси

## Основни функции за разработка на Edge AI

### 1. Каталог на модели и откриване
- **Поддръжка на множество доставчици**: Преглеждайте и достъпвайте AI модели от Anthropic, OpenAI, GitHub, Google и други доставчици
- **Интеграция на локални модели**: Оптимизирано откриване на ONNX и Ollama модели за крайно внедряване
- **GitHub модели**: Директна интеграция с хостинг на модели в GitHub за опростен достъп
- **Сравнение на модели**: Сравнявайте модели един до друг, за да намерите оптималния баланс за ограниченията на крайни устройства

### 2. Интерактивна площадка
- **Интерактивна тестова среда**: Бързо експериментиране с възможностите на модела в контролирана среда
- **Поддръжка на мултимодалност**: Тестване с изображения, текст и други входове, типични за крайни сценарии
- **Експериментиране в реално време**: Незабавна обратна връзка за отговорите и производителността на модела
- **Оптимизация на параметри**: Фина настройка на параметрите на модела за изискванията на крайното внедряване

### 3. Създател на подсказки (Agent Builder)
- **Генериране на естествен език**: Генерирайте начални подсказки с помощта на описания на естествен език
- **Итеративно усъвършенстване**: Подобрете подсказките въз основа на отговорите и производителността на модела
- **Разбиване на задачи**: Разделете сложни задачи с верига от подсказки и структурирани изходи
- **Поддръжка на променливи**: Използвайте променливи в подсказките за динамично поведение на агента
- **Генериране на продукционен код**: Създавайте готов за производство код за бързо разработване на приложения

### 4. Масово изпълнение и оценка
- **Тестване на множество модели**: Изпълнявайте множество подсказки върху избрани модели едновременно
- **Ефективно тестване в мащаб**: Тестване на различни входове и конфигурации ефективно
- **Персонализирани тестови случаи**: Изпълнявайте агенти с тестови случаи за валидиране на функционалността
- **Сравнение на производителността**: Сравнявайте резултати между различни модели и конфигурации

### 5. Оценка на модели с набори от данни
- **Стандартни метрики**: Тестване на AI модели с вградени оценители (F1 резултат, релевантност, сходство, съгласуваност)
- **Персонализирани оценители**: Създавайте свои собствени метрики за оценка за специфични случаи на употреба
- **Интеграция на набори от данни**: Тестване на модели срещу обширни набори от данни
- **Измерване на производителността**: Квантифициране на производителността на модела за решения за крайно внедряване

### 6. Възможности за фина настройка
- **Персонализиране на модели**: Персонализирайте модели за специфични случаи на употреба и домейни
- **Специализирана адаптация**: Адаптирайте модели към специализирани домейни и изисквания
- **Оптимизация за крайни устройства**: Фина настройка на модели, специално за ограниченията на крайното внедряване
- **Обучение за специфични домейни**: Създавайте модели, пригодени за специфични крайни случаи на употреба

### 7. Интеграция с MCP инструменти
- **Свързване с външни инструменти**: Свързвайте агенти с външни инструменти чрез сървъри на Model Context Protocol
- **Действия в реалния свят**: Позволете на агентите да правят заявки към бази данни, да достъпват API или да изпълняват персонализирана логика
- **Съществуващи MCP сървъри**: Използвайте инструменти от команден ред (stdio) или HTTP (събития, изпратени от сървър)
- **Разработка на персонализирани MCP**: Създавайте и изграждайте нови MCP сървъри с тестване в Agent Builder

### 8. Разработка и тестване на агенти
- **Поддръжка на извикване на функции**: Позволете на агентите да извикват външни функции динамично
- **Тестване на интеграция в реално време**: Тестване на интеграции с изпълнения в реално време и използване на инструменти
- **Версиониране на агенти**: Контрол на версиите за агенти със способности за сравнение на резултати от оценка
- **Дебъгване и проследяване**: Локално проследяване и дебъгване за разработка на агенти

## Работен поток за разработка на Edge AI

### Фаза 1: Откриване и избор на модели
1. **Изследвайте каталога на модели**: Използвайте каталога на модели, за да намерите модели, подходящи за крайно внедряване
2. **Сравнете производителността**: Оценете модели въз основа на размер, точност и скорост на извеждане
3. **Тествайте локално**: Използвайте Ollama или ONNX модели за локално тестване преди крайно внедряване
4. **Оценете изискванията за ресурси**: Определете нуждите от памет и изчислителни ресурси за целевите крайни устройства

### Фаза 2: Оптимизация на модели
1. **Конвертиране в ONNX**: Конвертирайте избраните модели в ONNX формат за съвместимост с крайни устройства
2. **Прилагане на квантизация**: Намалете размера на модела чрез квантизация INT8 или INT4
3. **Оптимизация на хардуера**: Оптимизирайте за целевия крайен хардуер (ARM, x86, специализирани ускорители)
4. **Валидиране на производителността**: Уверете се, че оптимизираните модели поддържат приемлива точност

### Фаза 3: Разработка на приложения
1. **Проектиране на агенти**: Използвайте Agent Builder за създаване на AI агенти, оптимизирани за крайни устройства
2. **Инженеринг на подсказки**: Разработете подсказки, които работят ефективно с по-малки крайни модели
3. **Тестване на интеграция**: Тестване на агенти в симулирани крайни условия
4. **Генериране на код**: Създавайте продукционен код, оптимизиран за крайно внедряване

### Фаза 4: Оценка и тестване
1. **Масова оценка**: Тестване на множество конфигурации за намиране на оптимални крайни настройки
2. **Профилиране на производителността**: Анализиране на скоростта на извеждане, използването на памет и точността
3. **Симулация на крайни условия**: Тестване в условия, подобни на целевата крайна среда за внедряване
4. **Стрес тестове**: Оценка на производителността при различни условия на натоварване

### Фаза 5: Подготовка за внедряване
1. **Окончателна оптимизация**: Прилагане на окончателни оптимизации въз основа на резултатите от тестването
2. **Опаковане за внедряване**: Опаковане на модели и код за крайно внедряване
3. **Документация**: Документиране на изискванията за внедряване и конфигурация
4. **Настройка на мониторинг**: Подготовка на мониторинг и логване за крайно внедряване

## Целева аудитория за разработка на Edge AI

### Разработчици на Edge AI
- Разработчици на приложения, които изграждат AI-задвижвани крайни устройства и IoT решения
- Разработчици на вградени системи, които интегрират AI възможности в устройства с ограничени ресурси
- Мобилни разработчици, които създават AI приложения за смартфони и таблети

### Инженери на Edge AI
- AI инженери, които оптимизират модели за крайно внедряване и управляват тръбопроводи за извеждане
- DevOps инженери, които внедряват и управляват AI модели в разпределена крайна инфраструктура
- Инженери по производителност, които оптимизират AI натоварвания за ограниченията на крайния хардуер

### Изследователи и преподаватели
- AI изследователи, които разработват ефективни модели и алгоритми за крайни изчисления
- Преподаватели, които обучават концепции за Edge AI и демонстрират техники за оптимизация
- Студенти, които изучават предизвикателствата и решенията при внедряване на Edge AI

## Приложения на Edge AI

### Умни IoT устройства
- **Разпознаване на изображения в реално време**: Внедряване на модели за компютърно зрение на IoT камери и сензори
- **Обработка на глас**: Изпълнение на модели за разпознаване на реч и обработка на естествен език на умни говорители
- **Предиктивна поддръжка**: Изпълнение на модели за откриване на аномалии на индустриални крайни устройства
- **Мониторинг на околната среда**: Внедряване на модели за анализ на данни от сензори за екологични приложения

### Мобилни и вградени приложения
- **Превод на устройството**: Внедряване на модели за превод на езици, които работят офлайн
- **Добавена реалност**: Внедряване на разпознаване на обекти в реално време и проследяване за AR приложения
- **Мониторинг на здравето**: Изпълнение на модели за анализ на здравето на носими устройства и медицинско оборудване
- **Автономни системи**: Внедряване на модели за вземане на решения за дронове, роботи и превозни средства

### Инфраструктура за крайни изчисления
- **Крайни центрове за данни**: Внедряване на AI модели в крайни центрове за данни за приложения с ниска латентност
- **Интеграция с CDN**: Интегриране на AI възможности за обработка в мрежи за доставка на съдържание
- **5G Edge**: Използване на крайни изчисления с 5G за AI-задвижвани приложения
- **Fog Computing**: Внедряване на AI обработка в среди за fog computing

## Инсталация и настройка

### Инсталиране на разширението
Инсталирайте разширението AI Toolkit директно от Visual Studio Code Marketplace:

**
2. Генериране на начални подканващи текстове чрез описания на естествен език  
3. Итерация и усъвършенстване на подканващите текстове въз основа на отговорите на модела  
4. Интегриране на MCP инструменти за подобрени възможности на агентите  

#### Стъпка 3: Тестване и оценка  
1. Използвайте **Bulk Run**, за да тествате множество подканващи текстове на избрани модели  
2. Стартирайте агенти с тестови случаи за валидиране на функционалността  
3. Оценете точността и производителността, използвайки вградени или персонализирани метрики  
4. Сравнете различни модели и конфигурации  

#### Стъпка 4: Фина настройка и оптимизация  
1. Персонализирайте модели за специфични крайни случаи на употреба  
2. Приложете фина настройка, специфична за домейна  
3. Оптимизирайте за ограниченията на разгръщане на крайни устройства  
4. Версионирайте и сравнете различни конфигурации на агенти  

#### Стъпка 5: Подготовка за разгръщане  
1. Генерирайте готов код за производство, използвайки Agent Builder  
2. Настройте връзки към MCP сървъри за производствена употреба  
3. Подгответе пакети за разгръщане за крайни устройства  
4. Конфигурирайте метрики за мониторинг и оценка  

## Примери за AI Toolkit  

Опитайте нашите примери  
[Примерите за AI Toolkit](https://github.com/Azure-Samples/AI_Toolkit_Samples) са създадени, за да помогнат на разработчиците и изследователите да изследват и внедряват AI решения ефективно.  

Нашите примери включват:  

Примерен код: Готови примери, които демонстрират AI функционалности, като обучение, разгръщане или интегриране на модели в приложения.  
Документация: Ръководства и уроци, които помагат на потребителите да разберат функциите на AI Toolkit и как да ги използват.  
Предпоставки  

- Visual Studio Code  
- AI Toolkit за Visual Studio Code  
- GitHub персонален достъп токен (PAT)  
- Foundry Local  

## Най-добри практики за разработка на Edge AI  

### Избор на модел  
- **Ограничения на размера**: Изберете модели, които се вписват в ограниченията на паметта на целевите устройства  
- **Скорост на извод**: Приоритизирайте модели с бърза скорост на извод за приложения в реално време  
- **Търговия с точност**: Балансирайте точността на модела с ограниченията на ресурсите  
- **Съвместимост на формата**: Предпочитайте ONNX или формати, оптимизирани за хардуер, за разгръщане на крайни устройства  

### Техники за оптимизация  
- **Квантизация**: Използвайте INT8 или INT4 квантизация за намаляване на размера на модела и подобряване на скоростта  
- **Подрязване**: Премахнете ненужните параметри на модела, за да намалите изискванията за изчисления  
- **Дистилация на знания**: Създайте по-малки модели, които запазват производителността на по-големите  
- **Хардуерно ускорение**: Използвайте NPUs, GPUs или специализирани ускорители, когато са налични  

### Работен процес на разработка  
- **Итеративно тестване**: Тествайте често в условия, подобни на тези на крайни устройства по време на разработката  
- **Мониторинг на производителността**: Непрекъснато следете използването на ресурси и скоростта на извод  
- **Контрол на версиите**: Проследявайте версиите на модела и настройките за оптимизация  
- **Документация**: Документирайте всички решения за оптимизация и компромиси в производителността  

### Съображения за разгръщане  
- **Мониторинг на ресурсите**: Следете паметта, CPU и консумацията на енергия в производството  
- **Стратегии за резервиране**: Внедрете механизми за резервиране при отказ на модела  
- **Механизми за актуализация**: Планирайте актуализации на модела и управление на версиите  
- **Сигурност**: Внедрете подходящи мерки за сигурност за приложенията на Edge AI  

## Интеграция с рамки за Edge AI  

### ONNX Runtime  
- **Разгръщане на различни платформи**: Разгръщайте ONNX модели на различни крайни платформи  
- **Оптимизация за хардуер**: Използвайте хардуерно-специфичните оптимизации на ONNX Runtime  
- **Поддръжка за мобилни устройства**: Използвайте ONNX Runtime Mobile за приложения на смартфони и таблети  
- **Интеграция с IoT**: Разгръщайте на IoT устройства, използвайки леките дистрибуции на ONNX Runtime  

### Windows ML  
- **Windows устройства**: Оптимизирайте за крайни устройства и компютри с Windows  
- **Ускорение с NPU**: Използвайте Neural Processing Units на Windows устройства  
- **DirectML**: Използвайте DirectML за GPU ускорение на Windows платформи  
- **Интеграция с UWP**: Интегрирайте с приложения на Universal Windows Platform  

### TensorFlow Lite  
- **Оптимизация за мобилни устройства**: Разгръщайте TensorFlow Lite модели на мобилни и вградени устройства  
- **Хардуерни делегати**: Използвайте специализирани хардуерни делегати за ускорение  
- **Микроконтролери**: Разгръщайте на микроконтролери, използвайки TensorFlow Lite Micro  
- **Поддръжка на различни платформи**: Разгръщайте на Android, iOS и вградени Linux системи  

### Azure IoT Edge  
- **Хибрид облак-край**: Комбинирайте обучение в облака с извод на крайни устройства  
- **Разгръщане на модули**: Разгръщайте AI модели като IoT Edge модули  
- **Управление на устройства**: Управлявайте крайни устройства и актуализации на модели дистанционно  
- **Телеметрия**: Събирайте данни за производителността и метрики на моделите от крайни разгръщания  

## Напреднали сценарии за Edge AI  

### Разгръщане на множество модели  
- **Екипи от модели**: Разгръщайте множество модели за подобрена точност или резервираност  
- **A/B тестване**: Тествайте различни модели едновременно на крайни устройства  
- **Динамичен избор**: Избирайте модели въз основа на текущите условия на устройството  
- **Споделяне на ресурси**: Оптимизирайте използването на ресурси между множество разположени модели  

### Федеративно обучение  
- **Разпределено обучение**: Обучавайте модели на множество крайни устройства  
- **Запазване на поверителността**: Запазете обучителните данни локално, като споделяте подобренията на модела  
- **Съвместно обучение**: Позволете на устройствата да се учат от колективния опит  
- **Координация край-облак**: Координирайте обучението между крайни устройства и облачна инфраструктура  

### Обработка в реално време  
- **Обработка на потоци**: Обработвайте непрекъснати потоци от данни на крайни устройства  
- **Извод с ниска латентност**: Оптимизирайте за минимална латентност на извода  
- **Партидна обработка**: Ефективно обработвайте партиди от данни на крайни устройства  
- **Адаптивна обработка**: Настройте обработката според текущите възможности на устройството  

## Отстраняване на проблеми при разработка на Edge AI  

### Чести проблеми  
- **Ограничения на паметта**: Моделът е твърде голям за паметта на целевото устройство  
- **Скорост на извод**: Изводът на модела е твърде бавен за изискванията в реално време  
- **Деградация на точността**: Оптимизацията намалява точността на модела неприемливо  
- **Съвместимост с хардуер**: Моделът не е съвместим с целевия хардуер  

### Стратегии за дебъгване  
- **Профилиране на производителността**: Използвайте функциите за проследяване на AI Toolkit, за да идентифицирате тесни места  
- **Мониторинг на ресурсите**: Следете паметта и CPU използването по време на разработката  
- **Инкрементално тестване**: Тествайте оптимизациите инкрементално, за да изолирате проблемите  
- **Симулация на хардуер**: Използвайте инструменти за разработка, за да симулирате целевия хардуер  

### Решения за оптимизация  
- **Допълнителна квантизация**: Приложете по-агресивни техники за квантизация  
- **Архитектура на модела**: Обмислете различни архитектури на модели, оптимизирани за крайни устройства  
- **Оптимизация на предварителната обработка**: Оптимизирайте предварителната обработка на данни за ограниченията на крайни устройства  
- **Оптимизация на извода**: Използвайте хардуерно-специфични оптимизации за извод  

## Ресурси и следващи стъпки  

### Официална документация  
- [Документация за разработчици на AI Toolkit](https://aka.ms/AIToolkit/doc)  
- [Ръководство за инсталация и настройка](https://code.visualstudio.com/docs/intelligentapps/overview#_install-and-setup)  
- [Документация за интелигентни приложения на VS Code](https://code.visualstudio.com/docs/intelligentapps)  
- [Документация за Model Context Protocol (MCP)](https://modelcontextprotocol.io/)  

### Общност и поддръжка  
- [GitHub хранилище на AI Toolkit](https://github.com/microsoft/vscode-ai-toolkit)  
- [GitHub въпроси и заявки за функции](https://aka.ms/AIToolkit/feedback)  
- [Discord общност на Azure AI Foundry](https://aka.ms/azureaifoundry/discord)  
- [Пазар за разширения на VS Code](https://marketplace.visualstudio.com/items?itemName=ms-windows-ai-studio.windows-ai-studio)  

### Технически ресурси  
- [Документация за ONNX Runtime](https://onnxruntime.ai/)  
- [Документация за Ollama](https://ollama.ai/)  
- [Документация за Windows ML](https://docs.microsoft.com/en-us/windows/ai/)  
- [Документация за Azure AI Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/)  

### Пътища за обучение  
- [Курс за основи на Edge AI](../Module01/README.md)  
- [Ръководство за малки езикови модели](../Module02/README.md)  
- [Стратегии за разгръщане на крайни устройства](../Module03/README.md)  
- [Разработка на Windows Edge AI](./windowdeveloper.md)  

### Допълнителни ресурси  
- **Статистика на хранилището**: 1.8k+ звезди, 150+ форкове, 18+ сътрудници  
- **Лиценз**: MIT License  
- **Сигурност**: Прилагат се политики за сигурност на Microsoft  
- **Телеметрия**: Уважава настройките за телеметрия на VS Code  

## Заключение  

AI Toolkit за Visual Studio Code представлява цялостна платформа за модерна AI разработка, предоставяща усъвършенствани възможности за разработка на агенти, които са особено ценни за приложения на Edge AI. С обширния си каталог от модели, поддържащ доставчици като Anthropic, OpenAI, GitHub и Google, комбиниран с локално изпълнение чрез ONNX и Ollama, инструментариумът предлага необходимата гъвкавост за разнообразни сценарии на разгръщане на крайни устройства.  

Силата на инструментариума се крие в интегрирания му подход—от откриване и експериментиране с модели в Playground до сложна разработка на агенти с Prompt Builder, цялостни възможности за оценка и безпроблемна интеграция на MCP инструменти. За разработчиците на Edge AI това означава бързо прототипиране и тестване на AI агенти преди разгръщане на крайни устройства, с възможност за бърза итерация и оптимизация за среди с ограничени ресурси.  

Ключови предимства за разработка на Edge AI включват:  
- **Бързо експериментиране**: Бързо тестване на модели и агенти преди ангажиране към разгръщане на крайни устройства  
- **Гъвкавост на множество доставчици**: Достъп до модели от различни източници за намиране на оптимални решения за крайни устройства  
- **Локална разработка**: Тестване с ONNX и Ollama за офлайн и поверителна разработка  
- **Готовност за производство**: Генериране на готов код за производство и интеграция с външни инструменти чрез MCP  
- **Цялостна оценка**: Използване на вградени и персонализирани метрики за валидиране на производителността на Edge AI  

Докато AI продължава да се насочва към сценарии за разгръщане на крайни устройства, AI Toolkit за VS Code предоставя средата за разработка и работния процес, необходими за изграждане, тестване и оптимизация на интелигентни приложения за среди с ограничени ресурси. Независимо дали разработвате IoT решения, мобилни AI приложения или вградени интелигентни системи, обширният набор от функции и интегриран работен процес на инструментариума подкрепят целия жизнен цикъл на разработката на Edge AI.  

С непрекъснато развитие и активна общност (1.8k+ звезди в GitHub), AI Toolkit остава в авангарда на инструментите за AI разработка, като непрекъснато се адаптира към нуждите на съвременните AI разработчици, които изграждат за сценарии на разгръщане на крайни устройства.  

[Следва Foundry Local](./foundrylocal.md)

---

**Отказ от отговорност**:  
Този документ е преведен с помощта на AI услуга за превод [Co-op Translator](https://github.com/Azure/co-op-translator). Въпреки че се стремим към точност, моля, имайте предвид, че автоматизираните преводи може да съдържат грешки или неточности. Оригиналният документ на неговия роден език трябва да се счита за авторитетен източник. За критична информация се препоръчва професионален човешки превод. Ние не носим отговорност за каквито и да е недоразумения или погрешни интерпретации, произтичащи от използването на този превод.