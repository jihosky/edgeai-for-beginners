<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "76b134be93f45283a2df8f8a93717d06",
  "translation_date": "2025-10-17T10:16:08+00:00",
  "source_file": "Module01/01.EdgeAIFundamentals.md",
  "language_code": "sl"
}
-->
# Poglavje 1: Osnove EdgeAI

EdgeAI predstavlja spremembo paradigme pri uvajanju umetne inteligence, saj prinaša zmogljivosti AI neposredno na robne naprave, namesto da bi se zanašali izključno na obdelavo v oblaku. Pomembno je razumeti, kako EdgeAI omogoča lokalno obdelavo AI na napravah z omejenimi viri, hkrati pa ohranja sprejemljivo zmogljivost in se spopada z izzivi, kot so zasebnost, zakasnitve in delovanje brez povezave.

## Uvod

V tej lekciji bomo raziskali EdgeAI in njegove temeljne koncepte. Pokrili bomo tradicionalno paradigmo računalništva AI, izzive robnega računalništva, ključne tehnologije, ki omogočajo EdgeAI, ter praktične aplikacije v različnih industrijah.

## Cilji učenja

Do konca te lekcije boste lahko:

- Razumeli razliko med tradicionalnim pristopom AI, ki temelji na oblaku, in pristopom EdgeAI.
- Prepoznali ključne tehnologije, ki omogočajo obdelavo AI na robnih napravah.
- Prepoznali prednosti in omejitve implementacij EdgeAI.
- Uporabili znanje o EdgeAI v resničnih scenarijih in primerih uporabe.

## Razumevanje tradicionalne paradigme računalništva AI

Tradicionalno se aplikacije generativne AI zanašajo na infrastrukturo za visoko zmogljivo računalništvo, da učinkovito izvajajo velike jezikovne modele (LLM). Organizacije običajno uvajajo te modele na GPU grozdih v oblačnih okoljih, dostopajo pa do njihovih zmogljivosti prek API vmesnikov.

Ta centraliziran model dobro deluje za številne aplikacije, vendar ima prirojene omejitve pri scenarijih robnega računalništva. Tradicionalni pristop vključuje pošiljanje uporabniških poizvedb na oddaljene strežnike, njihovo obdelavo z zmogljivo strojno opremo in vračanje rezultatov prek interneta. Čeprav ta metoda omogoča dostop do najsodobnejših modelov, ustvarja odvisnosti od internetne povezljivosti, uvaja zakasnitve in odpira vprašanja zasebnosti, ko je treba občutljive podatke prenesti na zunanje strežnike.

Nekateri ključni koncepti, ki jih moramo razumeti pri delu s tradicionalnimi paradigmi računalništva AI, vključujejo:

- **☁️ Obdelava v oblaku**: AI modeli se izvajajo na zmogljivi strežniški infrastrukturi z visokimi računalniškimi viri.
- **🔌 Dostop prek API**: Aplikacije dostopajo do zmogljivosti AI prek oddaljenih API klicev, namesto lokalne obdelave.
- **🎛️ Centralizirano upravljanje modelov**: Modeli se vzdržujejo in posodabljajo centralno, kar zagotavlja doslednost, vendar zahteva omrežno povezljivost.
- **📈 Skalabilnost virov**: Infrastruktura v oblaku se lahko dinamično prilagaja za obvladovanje različnih računalniških zahtev.

## Izzivi robnega računalništva

Robne naprave, kot so prenosniki, mobilni telefoni in naprave interneta stvari (IoT), kot sta Raspberry Pi in NVIDIA Orin Nano, predstavljajo edinstvene omejitve pri računalniških zmogljivostih. Te naprave imajo običajno omejeno procesorsko moč, pomnilnik in energetske vire v primerjavi z infrastrukturo podatkovnih centrov.

Zagon tradicionalnih LLM na takšnih napravah je bil zgodovinsko težaven zaradi teh strojnih omejitev. Vendar pa je potreba po obdelavi AI na robu postala vse bolj pomembna v različnih scenarijih. Pomislite na situacije, kjer je internetna povezljivost nezanesljiva ali nedostopna, kot so oddaljena industrijska območja, vozila med prevozom ali območja s slabo omrežno pokritostjo. Poleg tega aplikacije, ki zahtevajo visoke varnostne standarde, kot so medicinske naprave, finančni sistemi ali vladne aplikacije, morda potrebujejo lokalno obdelavo občutljivih podatkov za ohranjanje zasebnosti in skladnosti.

### Ključne omejitve robnega računalništva

Okolja robnega računalništva se soočajo z več temeljnimi omejitvami, ki jih tradicionalne rešitve AI, ki temeljijo na oblaku, ne srečujejo:

- **Omejena procesorska moč**: Robne naprave imajo običajno manj procesorskih jeder in nižje frekvence kot strežniška strojna oprema.
- **Omejitve pomnilnika**: Razpoložljiva RAM in kapaciteta shranjevanja sta na robnih napravah bistveno zmanjšani.
- **Omejitve energije**: Naprave na baterijski pogon morajo uravnotežiti zmogljivost z energetsko porabo za daljše delovanje.
- **Toplotno upravljanje**: Kompaktne oblike omejujejo zmogljivosti hlajenja, kar vpliva na trajno zmogljivost pod obremenitvijo.

## Kaj je EdgeAI?

### Koncept: Definicija EdgeAI

EdgeAI se nanaša na uvajanje in izvajanje algoritmov umetne inteligence neposredno na robnih napravah—fizični strojni opremi, ki obstaja na "robovih" omrežja, blizu mesta, kjer se podatki ustvarjajo in zbirajo. Te naprave vključujejo pametne telefone, IoT senzorje, pametne kamere, avtonomna vozila, nosljive naprave in industrijsko opremo. Za razliko od tradicionalnih sistemov AI, ki se zanašajo na oblačne strežnike za obdelavo, EdgeAI prinaša inteligenco neposredno na vir podatkov.

V svojem bistvu EdgeAI decentralizira obdelavo AI, jo premika stran od centraliziranih podatkovnih centrov in jo razporeja po obsežnem omrežju naprav, ki sestavljajo naš digitalni ekosistem. To predstavlja temeljno arhitekturno spremembo v načinu oblikovanja in uvajanja sistemov AI.

Ključni konceptualni stebri EdgeAI vključujejo:

- **Obdelava v bližini**: Računanje poteka fizično blizu mesta, kjer podatki nastajajo.
- **Decentralizirana inteligenca**: Zmožnosti odločanja so razporejene med več napravami.
- **Suverenost podatkov**: Informacije ostajajo pod lokalnim nadzorom in pogosto nikoli ne zapustijo naprave.
- **Avtonomno delovanje**: Naprave lahko delujejo inteligentno brez stalne povezljivosti.
- **Vgrajena AI**: Inteligenca postane intrinzična zmogljivost vsakodnevnih naprav.

### Vizualizacija arhitekture EdgeAI

```
┌─────────────────────────────────────────────────────────────────────┐
│                         TRADITIONAL AI ARCHITECTURE                 │
└─────────────────────────────────────────────────────────────────────┘
                                  │
┌──────────────┐   Data Transfer  ┌───────────────┐   API Response   ┌───────────┐
│ Edge Devices ├─────────────────>│ Cloud Servers │────────────────> │ End Users │
└──────────────┘                  └───────────────┘                  └───────────┘
     Data                         Model Inference                     Results
   Collection                     High Latency
                                  High Bandwidth
                                  Privacy Concerns
                               
┌─────────────────────────────────────────────────────────────────────┐
│                            EDGE AI ARCHITECTURE                     │
└─────────────────────────────────────────────────────────────────────┘
                                  │
┌────────────────────────────────────────────────────┐   Direct Response  ┌───────────┐
│              Edge Devices with Embedded AI         │───────────────────>│ End Users │
│  ┌─────────┐  ┌───────────────┐  ┌──────────────┐  │                    └───────────┘
│  │ Sensors │─>│ SLM Inference │─>│ Local Action │  │
│  └─────────┘  └───────────────┘  └──────────────┘  │
└────────────────────────────────────────────────────┘
     Data         Low Latency       Immediate
   Collection     Processing        Response
                  No Data Transfer
                  Enhanced Privacy
```

EdgeAI predstavlja spremembo paradigme pri uvajanju umetne inteligence, saj prinaša zmogljivosti AI neposredno na robne naprave, namesto da bi se zanašali izključno na obdelavo v oblaku. Ta pristop omogoča izvajanje AI modelov lokalno na napravah z omejenimi računalniškimi viri, kar zagotavlja zmogljivosti sklepanja v realnem času brez potrebe po stalni internetni povezljivosti.

EdgeAI vključuje različne tehnologije in tehnike, zasnovane za izboljšanje učinkovitosti AI modelov in njihovo primernost za uvajanje na napravah z omejenimi viri. Cilj je ohraniti sprejemljivo zmogljivost, hkrati pa bistveno zmanjšati računalniške in pomnilniške zahteve AI modelov.

Poglejmo temeljne pristope, ki omogočajo implementacije EdgeAI na različnih vrstah naprav in primerih uporabe.

### Temeljna načela EdgeAI

EdgeAI temelji na več osnovnih načelih, ki ga razlikujejo od tradicionalnega AI, ki temelji na oblaku:

- **Lokalna obdelava**: Sklepanje AI poteka neposredno na robni napravi brez potrebe po zunanji povezljivosti.
- **Optimizacija virov**: Modeli so posebej optimizirani za strojne omejitve ciljnih naprav.
- **Zmogljivost v realnem času**: Obdelava poteka z minimalno zakasnitvijo za časovno občutljive aplikacije.
- **Zasebnost po zasnovi**: Občutljivi podatki ostajajo na napravi, kar povečuje varnost in skladnost.

## Ključne tehnologije, ki omogočajo EdgeAI

### Kvantizacija modelov

Ena najpomembnejših tehnik v EdgeAI je kvantizacija modelov. Ta proces vključuje zmanjšanje natančnosti parametrov modela, običajno iz 32-bitnih plavajočih števil na 8-bitna cela števila ali celo nižje natančnostne formate. Čeprav se to zmanjšanje natančnosti morda zdi zaskrbljujoče, raziskave kažejo, da lahko številni AI modeli ohranijo svojo zmogljivost tudi ob znatno zmanjšani natančnosti.

Kvantizacija deluje tako, da preslika obseg vrednosti plavajočih števil na manjši nabor diskretnih vrednosti. Na primer, namesto da bi za predstavitev vsakega parametra uporabili 32 bitov, kvantizacija morda uporabi le 8 bitov, kar vodi do 4-kratnega zmanjšanja zahtev po pomnilniku in pogosto do hitrejših časov sklepanja.

```python
# Example: PyTorch model quantization 
import torch

# Load a pre-trained model
model = torch.load('large_model.pth')

# Quantize the model to INT8
quantized_model = torch.quantization.quantize_dynamic(
    model,  # model to quantize
    {torch.nn.Linear, torch.nn.Conv2d},  # layers to quantize
    dtype=torch.qint8  # quantization data type
)

# Save the quantized model
torch.save(quantized_model, 'quantized_model.pth')

# Memory usage comparison
original_size = model.size()
quantized_size = quantized_model.size()
print(f"Memory reduction: {original_size / quantized_size:.2f}x")
```

Različne tehnike kvantizacije vključujejo:

- **Post-trening kvantizacija (PTQ)**: Uporablja se po treningu modela brez potrebe po ponovnem treningu.
- **Kvantizacija zavedna treninga (QAT)**: Vključuje učinke kvantizacije med treningom za boljšo natančnost.
- **Dinamična kvantizacija**: Kvantizira uteži na int8, vendar dinamično izračunava aktivacije.
- **Statična kvantizacija**: Vnaprej izračuna vse parametre kvantizacije za uteži in aktivacije.

Za uvajanje EdgeAI je izbira ustrezne strategije kvantizacije odvisna od specifične arhitekture modela, zahtev glede zmogljivosti in strojnih zmogljivosti ciljnih naprav.

### Kompresija in optimizacija modelov

Poleg kvantizacije različne tehnike kompresije pomagajo zmanjšati velikost modela in računalniške zahteve. Te vključujejo:

**Obrezovanje**: Ta tehnika odstrani nepotrebne povezave ali nevrone iz nevronskih mrež. Z identifikacijo in odpravo parametrov, ki malo prispevajo k zmogljivosti modela, lahko obrezovanje znatno zmanjša velikost modela, hkrati pa ohranja natančnost.

```python
# Example: Neural network pruning in TensorFlow
import tensorflow as tf
import tensorflow_model_optimization as tfmot

# Define the model
model = tf.keras.Sequential([
    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

# Apply pruning during training
pruning_schedule = tfmot.sparsity.keras.PolynomialDecay(
    initial_sparsity=0.0,
    final_sparsity=0.5,  # 50% of connections will be pruned
    begin_step=0,
    end_step=10000
)

pruned_model = tfmot.sparsity.keras.prune_low_magnitude(
    model, pruning_schedule=pruning_schedule
)

# Compile the pruned model
pruned_model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# Train the model while pruning
pruned_model.fit(x_train, y_train, epochs=10)

# Convert to a smaller model for deployment
final_model = tfmot.sparsity.keras.strip_pruning(pruned_model)
```

**Destilacija znanja**: Ta pristop vključuje trening manjšega "študentskega" modela, da posnema vedenje večjega "učiteljskega" modela. Študentski model se nauči približati učiteljeve izhode, pogosto doseže podobno zmogljivost z bistveno manj parametri.

**Optimizacija arhitekture modela**: Raziskovalci so razvili specializirane arhitekture, zasnovane posebej za robno uvajanje, kot so MobileNets, EfficientNets in druge lahke arhitekture, ki uravnotežijo zmogljivost z računalniško učinkovitostjo.

### Majhni jezikovni modeli (SLM)

Naraščajoči trend v EdgeAI je razvoj majhnih jezikovnih modelov (SLM). Ti modeli so zasnovani od začetka, da so kompaktni in učinkoviti, hkrati pa še vedno zagotavljajo smiselne zmogljivosti naravnega jezika. SLM dosežejo to z natančno izbiro arhitekture, učinkovitimi tehnikami treninga in osredotočenim treningom na specifične domene ali naloge.

Za razliko od tradicionalnih pristopov, ki vključujejo kompresijo velikih modelov, so SLM pogosto trenirani z manjšimi nabori podatkov in optimiziranimi arhitekturami, posebej zasnovanimi za robno uvajanje. Ta pristop lahko vodi do modelov, ki niso le manjši, ampak tudi bolj učinkoviti za specifične primere uporabe.

## Strojna pospešitev za EdgeAI

Sodobne robne naprave vse pogosteje vključujejo specializirano strojno opremo, zasnovano za pospeševanje AI delovnih obremenitev:

### Nevronske procesne enote (NPU)

NPU so specializirani procesorji, zasnovani posebej za nevronske mrežne izračune. Ti čipi lahko izvajajo naloge sklepanja AI veliko bolj učinkovito kot tradicionalni CPU, pogosto z nižjo porabo energije. Številni sodobni pametni telefoni, prenosniki in IoT naprave zdaj vključujejo NPU za omogočanje obdelave AI na napravi.

```csharp
// Example: Using Windows ML to target NPU acceleration in C#
using Microsoft.ML.OnnxRuntime;

// Create session options with NPU provider
var sessionOptions = new SessionOptions();
sessionOptions.AppendExecutionProvider_DmlExecutionProvider();  // DirectML for NPU

// Load the ONNX model
using var session = new InferenceSession("model.onnx", sessionOptions);

// Create input tensor
var inputTensor = new DenseTensor<float>(new[] { 1, 3, 224, 224 });  // Example input shape
var inputs = new List<NamedOnnxValue> { NamedOnnxValue.CreateFromTensor("input", inputTensor) };

// Run inference with NPU acceleration
using var results = session.Run(inputs);
var output = results.First().AsTensor<float>();

// Process output
Console.WriteLine($"Inference result: {output[0]}");
```

Naprave z NPU vključujejo:

- **Apple**: Čipi serije A in M z Neural Engine
- **Qualcomm**: Procesorji Snapdragon s Hexagon DSP/NPU
- **Samsung**: Procesorji Exynos z NPU
- **Intel**: Movidius VPU in pospeševalniki Habana Labs
- **Microsoft**: Windows Copilot+ računalniki z NPU

### 🎮 Pospeševanje z GPU

Čeprav robne naprave morda nimajo zmogljivih GPU, ki jih najdemo v podatkovnih centrih, mnoge še vedno vključujejo integrirane ali diskretne GPU, ki lahko pospešijo AI delovne obremenitve. Sodobni mobilni GPU in integrirani grafični procesorji lahko zagotovijo pomembne izboljšave zmogljivosti za naloge sklepanja AI.

```python
# Example: Using TensorRT for GPU acceleration on edge devices
import tensorrt as trt
import numpy as np

# Create TensorRT logger and builder
TRT_LOGGER = trt.Logger(trt.Logger.WARNING)
builder = trt.Builder(TRT_LOGGER)
network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))
parser = trt.OnnxParser(network, TRT_LOGGER)

# Parse ONNX model
with open('model.onnx', 'rb') as model:
    parser.parse(model.read())

# Configure builder
config = builder.create_builder_config()
config.max_workspace_size = 1 << 28  # 256 MiB
config.set_flag(trt.BuilderFlag.FP16)  # Use FP16 precision for edge GPU

# Build and serialize engine
engine = builder.build_engine(network, config)
with open('model.trt', 'wb') as f:
    f.write(engine.serialize())
```

### Optimizacija CPU

Tudi naprave, ki imajo samo CPU, lahko izkoristijo EdgeAI prek optimiziranih implementacij. Sodobni CPU vključujejo specializirana navodila za AI delovne obremenitve, programski okviri pa so bili razviti za maksimalno zmogljivost CPU pri sklepanju AI.

```bash
# Example: Using XNNPACK with TFLite for optimized CPU inference
# Compilation command with XNNPACK acceleration enabled

bazel build -c opt --copt=-O3 --copt=-march=native \
  tensorflow/lite/delegates/xnnpack:libxnnpack_delegate.so

# Convert TensorFlow model to TFLite with optimization
tflite_convert \
  --keras_model_file=model.h5 \
  --output_file=model.tflite \
  --inference_type=FLOAT \
  --experimental_new_converter \
  --experimental_new_quantizer
```

Za programske inženirje, ki delajo z EdgeAI, je razumevanje, kako izkoristiti te možnosti strojne pospešitve, ključnega pomena za optimizacijo zmogljivosti sklepanja in energetske učinkovitosti na ciljnih napravah.

## Prednosti EdgeAI

### Zasebnost in varnost

Ena najpomembnejših prednosti EdgeAI je izboljšana zasebnost in varnost. Z obdelavo podatkov lokalno na napravi občutljive informacije nikoli ne zapustijo nadzora uporabnika. To je še posebej pomembno za aplikacije, ki obravnavajo osebne podatke, medicinske informacije ali zaupne poslovne podatke.

### Zmanjšana zakasnitev

EdgeAI odpravlja potrebo po pošiljanju podatkov na oddaljene strežnike za obdelavo, kar bistveno zmanjšuje zakasnitev. To je ključno za aplikacije v realnem času, kot so avtonomna vozila, industrijska avtomatizacija ali interaktivne aplikacije, kjer so potrebni takojšnji odzivi.

### Zmožnost delovanja brez povezave

EdgeAI omogoča funkcionalnost AI tudi takrat, ko internetna povezljivost ni na voljo. To je dragoceno za aplikacije na oddaljenih lokacijah, med potovanjem ali v situacijah, kjer je zanesljivost omrežja vprašljiva.

### Stroškovna učinkovitost

Z zmanjšanjem odvisnosti od storitev AI, ki temeljijo na oblaku, lahko EdgeAI pomaga zmanjšati operativne stroške, zlasti za aplikacije z velikimi količinami uporabe. Organizacije se lahko izognejo stalnim stroškom API in zmanjšajo zahteve po pasovni širini.

### Skalabilnost

EdgeAI porazdeli računalniško obremenitev med robne naprave, namesto da bi jo centraliziral v podatkovnih centrih. To lahko pomaga zmanjšati stroške infrastrukture in izboljšati splošno skalabilnost sistema.

## Aplikacije EdgeAI

### Pametne naprave in IoT

EdgeAI poganja številne funkcije pametnih naprav, od glasovnih asistentov, ki lahko lokalno obdelajo ukaze, do pametnih kamer, ki lahko prepoznajo predmete in ljudi brez pošiljanja videa v oblak. IoT naprave uporabljajo EdgeAI za prediktivno vzdrževanje, spremljanje okolja in avtomatizirano odločanje.

### Mobilne aplikacije

Pametni telefoni in tablični računalniki uporabljajo EdgeAI za različne funkcije, vključno z izboljšanjem fotografij, prevajanjem v realnem času, razširjeno resničnostjo in prilagojenimi priporočili. Te aplikacije koristijo nizko zakasnitev in prednosti zasebnosti lokalne obdelave.

### Industrijske aplikacije

Proizvodna in industrijska okolja uporabljajo EdgeAI za nadzor kakovosti, prediktivno vzdrževanje in optimizacijo procesov. Te aplikacije pogosto zahtevajo obdelavo v realnem času in lahko delujejo v okoljih z omejeno povezljivostjo.

### Zdravstvo

Medicinske napr
- [02: EdgeAI Aplikacije](02.RealWorldCaseStudies.md)

---

**Omejitev odgovornosti**:  
Ta dokument je bil preveden z uporabo storitve za prevajanje AI [Co-op Translator](https://github.com/Azure/co-op-translator). Čeprav si prizadevamo za natančnost, vas prosimo, da upoštevate, da lahko avtomatizirani prevodi vsebujejo napake ali netočnosti. Izvirni dokument v njegovem maternem jeziku naj se šteje za avtoritativni vir. Za ključne informacije priporočamo profesionalni človeški prevod. Ne odgovarjamo za morebitne nesporazume ali napačne razlage, ki izhajajo iz uporabe tega prevoda.