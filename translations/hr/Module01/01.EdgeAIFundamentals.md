<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "76b134be93f45283a2df8f8a93717d06",
  "translation_date": "2025-10-17T10:14:12+00:00",
  "source_file": "Module01/01.EdgeAIFundamentals.md",
  "language_code": "hr"
}
-->
# Poglavlje 1: Osnove EdgeAI-a

EdgeAI predstavlja promjenu paradigme u primjeni umjetne inteligencije, donoseći AI mogućnosti izravno na rubne uređaje umjesto oslanjanja isključivo na obradu u oblaku. Važno je razumjeti kako EdgeAI omogućuje lokalnu obradu AI-a na uređajima s ograničenim resursima, dok istovremeno održava razumnu izvedbu i rješava izazove poput privatnosti, kašnjenja i offline mogućnosti.

## Uvod

U ovoj lekciji istražit ćemo EdgeAI i njegove osnovne koncepte. Pokrit ćemo tradicionalni AI računalni model, izazove rubnog računalstva, ključne tehnologije koje omogućuju EdgeAI te praktične primjene u raznim industrijama.

## Ciljevi učenja

Na kraju ove lekcije moći ćete:

- Razumjeti razliku između tradicionalnog AI-a temeljenog na oblaku i EdgeAI pristupa.
- Identificirati ključne tehnologije koje omogućuju AI obradu na rubnim uređajima.
- Prepoznati prednosti i ograničenja EdgeAI implementacija.
- Primijeniti znanje o EdgeAI-u na stvarne scenarije i primjere.

## Razumijevanje tradicionalnog AI računalnog modela

Tradicionalno, generativne AI aplikacije oslanjaju se na infrastrukturu visokih performansi za učinkovito pokretanje velikih jezičnih modela (LLM-ova). Organizacije obično implementiraju ove modele na GPU klasterima u oblaku, pristupajući njihovim mogućnostima putem API sučelja.

Ovaj centralizirani model dobro funkcionira za mnoge aplikacije, ali ima inherentna ograničenja u scenarijima rubnog računalstva. Konvencionalni pristup uključuje slanje korisničkih upita na udaljene servere, obradu pomoću moćnog hardvera i vraćanje rezultata putem interneta. Iako ova metoda omogućuje pristup najnaprednijim modelima, stvara ovisnost o internetskoj povezanosti, uvodi probleme s kašnjenjem i postavlja pitanja privatnosti kada se osjetljivi podaci moraju prenijeti na vanjske servere.

Postoji nekoliko osnovnih koncepata koje trebamo razumjeti kada radimo s tradicionalnim AI računalnim modelima, a to su:

- **☁️ Obrada u oblaku**: AI modeli se pokreću na moćnoj server infrastrukturi s visokim računalnim resursima.
- **🔌 Pristup putem API-ja**: Aplikacije pristupaju AI mogućnostima putem udaljenih API poziva umjesto lokalne obrade.
- **🎛️ Centralizirano upravljanje modelima**: Modeli se održavaju i ažuriraju centralno, osiguravajući dosljednost, ali zahtijevajući mrežnu povezanost.
- **📈 Skalabilnost resursa**: Infrastruktura u oblaku može dinamički skalirati kako bi se nosila s promjenjivim zahtjevima za računalnim resursima.

## Izazovi rubnog računalstva

Rubni uređaji poput prijenosnih računala, mobilnih telefona i uređaja Interneta stvari (IoT) poput Raspberry Pi-a i NVIDIA Orin Nano-a predstavljaju jedinstvena ograničenja u računalnim resursima. Ti uređaji obično imaju ograničenu procesorsku snagu, memoriju i energetske resurse u usporedbi s infrastrukturom podatkovnih centara.

Pokretanje tradicionalnih LLM-ova na takvim uređajima povijesno je bilo izazovno zbog ovih hardverskih ograničenja. Međutim, potreba za AI obradom na rubu postaje sve važnija u raznim scenarijima. Razmotrite situacije u kojima je internetska povezanost nepouzdana ili nedostupna, poput udaljenih industrijskih lokacija, vozila u tranzitu ili područja s lošom mrežnom pokrivenošću. Osim toga, aplikacije koje zahtijevaju visoke sigurnosne standarde, poput medicinskih uređaja, financijskih sustava ili vladinih aplikacija, možda će trebati lokalno obrađivati osjetljive podatke kako bi se održala privatnost i usklađenost.

### Ključna ograničenja rubnog računalstva

Okruženja rubnog računalstva suočavaju se s nekoliko temeljnih ograničenja koja tradicionalna AI rješenja temeljena na oblaku ne susreću:

- **Ograničena procesorska snaga**: Rubni uređaji obično imaju manje CPU jezgri i niže radne frekvencije u usporedbi s hardverom servera.
- **Ograničenja memorije**: Dostupna RAM memorija i kapacitet pohrane značajno su smanjeni na rubnim uređajima.
- **Ograničenja energije**: Uređaji na baterijski pogon moraju balansirati performanse s potrošnjom energije za produženi rad.
- **Termalno upravljanje**: Kompaktni oblici ograničavaju mogućnosti hlađenja, što utječe na održive performanse pod opterećenjem.

## Što je EdgeAI?

### Koncept: Definicija EdgeAI-a

EdgeAI se odnosi na implementaciju i izvršavanje algoritama umjetne inteligencije izravno na rubnim uređajima—fizičkom hardveru koji se nalazi na "rubu" mreže, blizu mjesta gdje se podaci generiraju i prikupljaju. Ti uređaji uključuju pametne telefone, IoT senzore, pametne kamere, autonomna vozila, nosive uređaje i industrijsku opremu. Za razliku od tradicionalnih AI sustava koji se oslanjaju na servere u oblaku za obradu, EdgeAI donosi inteligenciju izravno na izvor podataka.

U svojoj srži, EdgeAI se odnosi na decentralizaciju AI obrade, premještajući je iz centraliziranih podatkovnih centara i distribuirajući je kroz široku mrežu uređaja koji čine naš digitalni ekosustav. Ovo predstavlja temeljnu arhitektonsku promjenu u načinu na koji se AI sustavi dizajniraju i implementiraju.

Ključni konceptualni stupovi EdgeAI-a uključuju:

- **Obrada u blizini**: Obrada se odvija fizički blizu mjesta gdje podaci nastaju.
- **Decentralizirana inteligencija**: Sposobnost donošenja odluka raspoređena je na više uređaja.
- **Suverenitet podataka**: Informacije ostaju pod lokalnom kontrolom, često nikada ne napuštajući uređaj.
- **Autonomno djelovanje**: Uređaji mogu inteligentno funkcionirati bez stalne povezanosti.
- **Ugrađeni AI**: Inteligencija postaje intrinzična sposobnost svakodnevnih uređaja.

### Vizualizacija arhitekture EdgeAI-a

```
┌─────────────────────────────────────────────────────────────────────┐
│                         TRADITIONAL AI ARCHITECTURE                 │
└─────────────────────────────────────────────────────────────────────┘
                                  │
┌──────────────┐   Data Transfer  ┌───────────────┐   API Response   ┌───────────┐
│ Edge Devices ├─────────────────>│ Cloud Servers │────────────────> │ End Users │
└──────────────┘                  └───────────────┘                  └───────────┘
     Data                         Model Inference                     Results
   Collection                     High Latency
                                  High Bandwidth
                                  Privacy Concerns
                               
┌─────────────────────────────────────────────────────────────────────┐
│                            EDGE AI ARCHITECTURE                     │
└─────────────────────────────────────────────────────────────────────┘
                                  │
┌────────────────────────────────────────────────────┐   Direct Response  ┌───────────┐
│              Edge Devices with Embedded AI         │───────────────────>│ End Users │
│  ┌─────────┐  ┌───────────────┐  ┌──────────────┐  │                    └───────────┘
│  │ Sensors │─>│ SLM Inference │─>│ Local Action │  │
│  └─────────┘  └───────────────┘  └──────────────┘  │
└────────────────────────────────────────────────────┘
     Data         Low Latency       Immediate
   Collection     Processing        Response
                  No Data Transfer
                  Enhanced Privacy
```

EdgeAI predstavlja promjenu paradigme u primjeni umjetne inteligencije, donoseći AI mogućnosti izravno na rubne uređaje umjesto oslanjanja isključivo na obradu u oblaku. Ovaj pristup omogućuje pokretanje AI modela lokalno na uređajima s ograničenim računalnim resursima, pružajući mogućnosti za real-time inferenciju bez potrebe za stalnom internetskom povezanošću.

EdgeAI obuhvaća razne tehnologije i tehnike osmišljene za učiniti AI modele učinkovitijima i prikladnima za implementaciju na uređajima s ograničenim resursima. Cilj je održati razumnu izvedbu uz značajno smanjenje računalnih i memorijskih zahtjeva AI modela.

Pogledajmo osnovne pristupe koji omogućuju implementaciju EdgeAI-a na različitim vrstama uređaja i u različitim slučajevima primjene.

### Osnovni principi EdgeAI-a

EdgeAI se temelji na nekoliko temeljnih principa koji ga razlikuju od tradicionalnog AI-a temeljenog na oblaku:

- **Lokalna obrada**: AI inferencija odvija se izravno na rubnom uređaju bez potrebe za vanjskom povezanošću.
- **Optimizacija resursa**: Modeli su posebno optimizirani za hardverska ograničenja ciljanih uređaja.
- **Performanse u stvarnom vremenu**: Obrada se odvija s minimalnim kašnjenjem za aplikacije osjetljive na vrijeme.
- **Privatnost po dizajnu**: Osjetljivi podaci ostaju na uređaju, poboljšavajući sigurnost i usklađenost.

## Ključne tehnologije koje omogućuju EdgeAI

### Kvantizacija modela

Jedna od najvažnijih tehnika u EdgeAI-u je kvantizacija modela. Ovaj proces uključuje smanjenje preciznosti parametara modela, obično s 32-bitnih brojeva s pomičnim zarezom na 8-bitne cijele brojeve ili čak formate niže preciznosti. Iako se ovo smanjenje preciznosti može činiti zabrinjavajućim, istraživanja su pokazala da mnogi AI modeli mogu održati svoju izvedbu čak i uz značajno smanjenu preciznost.

Kvantizacija funkcionira mapiranjem raspona vrijednosti s pomičnim zarezom na manji skup diskretnih vrijednosti. Na primjer, umjesto korištenja 32 bita za predstavljanje svakog parametra, kvantizacija može koristiti samo 8 bita, što rezultira 4x smanjenjem zahtjeva za memorijom i često dovodi do bržih vremena inferencije.

```python
# Example: PyTorch model quantization 
import torch

# Load a pre-trained model
model = torch.load('large_model.pth')

# Quantize the model to INT8
quantized_model = torch.quantization.quantize_dynamic(
    model,  # model to quantize
    {torch.nn.Linear, torch.nn.Conv2d},  # layers to quantize
    dtype=torch.qint8  # quantization data type
)

# Save the quantized model
torch.save(quantized_model, 'quantized_model.pth')

# Memory usage comparison
original_size = model.size()
quantized_size = quantized_model.size()
print(f"Memory reduction: {original_size / quantized_size:.2f}x")
```

Različite tehnike kvantizacije uključuju:

- **Post-Training Quantization (PTQ)**: Primjenjuje se nakon treniranja modela bez potrebe za ponovnim treniranjem.
- **Quantization-Aware Training (QAT)**: Uključuje učinke kvantizacije tijekom treniranja za bolju točnost.
- **Dinamička kvantizacija**: Kvantizira težine na int8, ali dinamički izračunava aktivacije.
- **Statistička kvantizacija**: Predračunava sve parametre kvantizacije za težine i aktivacije.

Za EdgeAI implementacije, odabir odgovarajuće strategije kvantizacije ovisi o specifičnoj arhitekturi modela, zahtjevima izvedbe i hardverskim mogućnostima ciljanog uređaja.

### Kompresija i optimizacija modela

Osim kvantizacije, razne tehnike kompresije pomažu smanjiti veličinu modela i računalne zahtjeve. To uključuje:

**Pruning**: Ova tehnika uklanja nepotrebne veze ili neurone iz neuronskih mreža. Identificiranjem i eliminacijom parametara koji malo doprinose izvedbi modela, pruning može značajno smanjiti veličinu modela uz održavanje točnosti.

```python
# Example: Neural network pruning in TensorFlow
import tensorflow as tf
import tensorflow_model_optimization as tfmot

# Define the model
model = tf.keras.Sequential([
    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

# Apply pruning during training
pruning_schedule = tfmot.sparsity.keras.PolynomialDecay(
    initial_sparsity=0.0,
    final_sparsity=0.5,  # 50% of connections will be pruned
    begin_step=0,
    end_step=10000
)

pruned_model = tfmot.sparsity.keras.prune_low_magnitude(
    model, pruning_schedule=pruning_schedule
)

# Compile the pruned model
pruned_model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# Train the model while pruning
pruned_model.fit(x_train, y_train, epochs=10)

# Convert to a smaller model for deployment
final_model = tfmot.sparsity.keras.strip_pruning(pruned_model)
```

**Distilacija znanja**: Ovaj pristup uključuje treniranje manjeg "studentskog" modela da oponaša ponašanje većeg "učiteljskog" modela. Studentski model uči približiti učiteljeve izlaze, često postižući sličnu izvedbu uz značajno manje parametara.

**Optimizacija arhitekture modela**: Istraživači su razvili specijalizirane arhitekture dizajnirane posebno za implementaciju na rubu, poput MobileNets, EfficientNets i drugih laganih arhitektura koje balansiraju izvedbu s računalnom učinkovitošću.

### Mali jezični modeli (SLM)

Rastući trend u EdgeAI-u je razvoj malih jezičnih modela (SLM). Ovi modeli su dizajnirani od temelja da budu kompaktni i učinkoviti, a istovremeno pružaju značajne mogućnosti obrade prirodnog jezika. SLM-ovi to postižu pažljivim odabirom arhitekture, učinkovitim tehnikama treniranja i fokusiranim treniranjem na specifične domene ili zadatke.

Za razliku od tradicionalnih pristupa koji uključuju kompresiju velikih modela, SLM-ovi se često treniraju na manjim skupovima podataka i optimiziranim arhitekturama posebno dizajniranim za implementaciju na rubu. Ovaj pristup može rezultirati modelima koji su ne samo manji, već i učinkovitiji za specifične slučajeve primjene.

## Hardverska akceleracija za EdgeAI

Moderni rubni uređaji sve više uključuju specijalizirani hardver dizajniran za ubrzanje AI radnih opterećenja:

### Procesori za neuronsku obradu (NPUs)

NPUs su specijalizirani procesori dizajnirani posebno za izračune neuronskih mreža. Ovi čipovi mogu obavljati AI zadatke inferencije mnogo učinkovitije od tradicionalnih CPU-a, često uz nižu potrošnju energije. Mnogi moderni pametni telefoni, prijenosna računala i IoT uređaji sada uključuju NPUs za omogućavanje AI obrade na uređaju.

```csharp
// Example: Using Windows ML to target NPU acceleration in C#
using Microsoft.ML.OnnxRuntime;

// Create session options with NPU provider
var sessionOptions = new SessionOptions();
sessionOptions.AppendExecutionProvider_DmlExecutionProvider();  // DirectML for NPU

// Load the ONNX model
using var session = new InferenceSession("model.onnx", sessionOptions);

// Create input tensor
var inputTensor = new DenseTensor<float>(new[] { 1, 3, 224, 224 });  // Example input shape
var inputs = new List<NamedOnnxValue> { NamedOnnxValue.CreateFromTensor("input", inputTensor) };

// Run inference with NPU acceleration
using var results = session.Run(inputs);
var output = results.First().AsTensor<float>();

// Process output
Console.WriteLine($"Inference result: {output[0]}");
```

Uređaji s NPUs uključuju:

- **Apple**: A-serija i M-serija čipova s Neural Engine
- **Qualcomm**: Snapdragon procesori s Hexagon DSP/NPU
- **Samsung**: Exynos procesori s NPU
- **Intel**: Movidius VPUs i Habana Labs akceleratori
- **Microsoft**: Windows Copilot+ PC-ji s NPUs

### 🎮 GPU akceleracija

Iako rubni uređaji možda nemaju moćne GPU-ove koji se nalaze u podatkovnim centrima, mnogi ipak uključuju integrirane ili diskretne GPU-ove koji mogu ubrzati AI radne opterećenja. Moderni mobilni GPU-ovi i integrirani grafički procesori mogu pružiti značajna poboljšanja performansi za AI zadatke inferencije.

```python
# Example: Using TensorRT for GPU acceleration on edge devices
import tensorrt as trt
import numpy as np

# Create TensorRT logger and builder
TRT_LOGGER = trt.Logger(trt.Logger.WARNING)
builder = trt.Builder(TRT_LOGGER)
network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))
parser = trt.OnnxParser(network, TRT_LOGGER)

# Parse ONNX model
with open('model.onnx', 'rb') as model:
    parser.parse(model.read())

# Configure builder
config = builder.create_builder_config()
config.max_workspace_size = 1 << 28  # 256 MiB
config.set_flag(trt.BuilderFlag.FP16)  # Use FP16 precision for edge GPU

# Build and serialize engine
engine = builder.build_engine(network, config)
with open('model.trt', 'wb') as f:
    f.write(engine.serialize())
```

### Optimizacija CPU-a

Čak i uređaji koji koriste samo CPU mogu imati koristi od EdgeAI-a putem optimiziranih implementacija. Moderni CPU-ovi uključuju specijalizirane instrukcije za AI radne opterećenja, a razvijeni su softverski okviri za maksimiziranje performansi CPU-a za AI inferenciju.

```bash
# Example: Using XNNPACK with TFLite for optimized CPU inference
# Compilation command with XNNPACK acceleration enabled

bazel build -c opt --copt=-O3 --copt=-march=native \
  tensorflow/lite/delegates/xnnpack:libxnnpack_delegate.so

# Convert TensorFlow model to TFLite with optimization
tflite_convert \
  --keras_model_file=model.h5 \
  --output_file=model.tflite \
  --inference_type=FLOAT \
  --experimental_new_converter \
  --experimental_new_quantizer
```

Za softverske inženjere koji rade s EdgeAI-om, razumijevanje kako iskoristiti ove opcije hardverske akceleracije ključno je za optimizaciju performansi inferencije i energetske učinkovitosti na ciljanom uređaju.

## Prednosti EdgeAI-a

### Privatnost i sigurnost

Jedna od najznačajnijih prednosti EdgeAI-a je poboljšana privatnost i sigurnost. Obradom podataka lokalno na uređaju, osjetljive informacije nikada ne napuštaju kontrolu korisnika. Ovo je posebno važno za aplikacije koje obrađuju osobne podatke, medicinske informacije ili povjerljive poslovne podatke.

### Smanjeno kašnjenje

EdgeAI eliminira potrebu za slanjem podataka na udaljene servere za obradu, značajno smanjujući kašnjenje. Ovo je ključno za aplikacije u stvarnom vremenu poput autonomnih vozila, industrijske automatizacije ili interaktivnih aplikacija gdje su potrebni trenutni odgovori.

### Mogućnost rada bez interneta

EdgeAI omogućuje AI funkcionalnost čak i kada internetska povezanost nije dostupna. Ovo je vrijedno za aplikacije na udaljenim lokacijama, tijekom putovanja ili u situacijama gdje je pouzdanost mreže upitna.

### Troškovna učinkovitost

Smanjenjem oslanjanja na AI usluge temeljene na oblaku, EdgeAI može pomoći u smanjenju operativnih troškova, posebno za aplikacije s velikim volumenom korištenja. Organizacije mogu izbjeći stalne troškove API-ja i smanjiti zahtjeve za propusnošću.

### Skalabilnost

EdgeAI raspodjeljuje računalno opterećenje na rubne uređaje umjesto da ga centralizira u podatkovnim centrima. Ovo može pomoći u smanjenju troškova infrastrukture i poboljšanju ukupne skalabilnosti sustava.

## Primjene EdgeAI-a

### Pametni uređaji i IoT

EdgeAI pokreće mnoge značajke pametnih uređaja, od glasovnih asistenata koji mogu lokalno obrađivati naredbe do pametnih kamera koje mogu identificirati objekte i ljude bez slanja videa u oblak. IoT uređaji koriste EdgeAI za prediktivno održavanje, praćenje okoliša i automatizirano donošenje odluka.

### Mobilne aplikacije

Pametni telefoni i tableti koriste EdgeAI za razne značajke, uključujući poboljšanje fotografija, prijevod u stvarnom vremenu, proširenu stvarnost i personalizirane preporuke. Ove aplikacije imaju koristi od niskog kašnjenja i prednosti privatnosti lokalne obrade.

### Industrijske primjene

Proizvodni i industrijski okoliši koriste EdgeAI za kontrolu kvalitete, prediktivno održavanje i optimizaciju procesa. Ove aplikacije često zahtijevaju obradu u stvarnom vremenu i mogu raditi u okruženjima s ograničenom povezanošću.

### Zdravstvo

Medicinski uređaji i zdravstvene aplikacije koriste EdgeAI za praćenje pacijenata, pomoć u dijagnostici i preporuke za liječenje. Prednosti privatnosti i sigurnosti lokalne obrade posebno su važne u zdravstvenim aplikacijama.

## Izazovi i ograničenja

### Kompromisi u izvedbi

EdgeAI obično uključuje kompromise između veličine modela, računalne učinkovitosti i izvedbe. Iako tehnike poput kvantizacije i pruning-a mogu značajno smanjiti zahtjeve za resursima, mogu također utjecati na točnost ili sposob
- [02: EdgeAI Aplikacije](02.RealWorldCaseStudies.md)

---

**Odricanje od odgovornosti**:  
Ovaj dokument je preveden pomoću AI usluge za prevođenje [Co-op Translator](https://github.com/Azure/co-op-translator). Iako nastojimo osigurati točnost, imajte na umu da automatski prijevodi mogu sadržavati pogreške ili netočnosti. Izvorni dokument na izvornom jeziku treba smatrati autoritativnim izvorom. Za ključne informacije preporučuje se profesionalni prijevod od strane čovjeka. Ne odgovaramo za nesporazume ili pogrešna tumačenja koja proizlaze iz korištenja ovog prijevoda.