<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "78ca68df03ae43371b203ea43d346dec",
  "translation_date": "2025-10-30T15:11:30+00:00",
  "source_file": "CHANGELOG.md",
  "language_code": "uk"
}
-->
# Журнал змін

Усі важливі зміни в EdgeAI для початківців задокументовані тут. Цей проєкт використовує записи на основі дат і стиль "Keep a Changelog" (Додано, Змінено, Виправлено, Видалено, Документація, Переміщено).

## 2025-10-30

### Додано - Комплексне покращення AI агентів у Module06
- **Інтеграція Microsoft Agent Framework** (`Module06/01.IntroduceAgent.md`):
  - Повний розділ про Microsoft Agent Framework для розробки агентів, готових до виробництва
  - Детальні шаблони інтеграції з Foundry Local для розгортання на периферії
  - Приклади оркестрації мультиагентних систем зі спеціалізованими моделями SLM
  - Шаблони розгортання для підприємств із управлінням ресурсами та моніторингом
  - Функції безпеки та відповідності для систем агентів на периферії
  - Реальні приклади впровадження (роздрібна торгівля, охорона здоров’я, обслуговування клієнтів)

- **Стратегії розгортання агентів SLM у виробництві**:
  - **Foundry Local**: Повна документація про периферійний AI runtime корпоративного рівня з установкою, конфігурацією та шаблонами для виробництва
  - **Ollama**: Покращене розгортання для спільноти з комплексним моніторингом і управлінням моделями
  - **VLLM**: Двигун високопродуктивного інференсу з передовими техніками оптимізації та функціями для підприємств
  - Контрольні списки для розгортання у виробництві та порівняльні таблиці для всіх трьох платформ

- **Покращення периферійно-оптимізованих SLM фреймворків**:
  - **ONNX Runtime**: Новий розділ для кросплатформного розгортання агентів SLM
  - Універсальні шаблони розгортання для Windows, Linux, macOS, iOS та Android
  - Опції апаратного прискорення (CPU, GPU, NPU) з автоматичним визначенням
  - Функції, готові до виробництва, та оптимізації для агентів
  - Повні приклади впровадження з інтеграцією Microsoft Agent Framework

- **Ресурси та додаткова література**:
  - Комплексна бібліотека ресурсів із понад 100 авторитетних джерел
  - Основні наукові статті про AI агентів і моделі малого обсягу (SLM)
  - Офіційна документація для всіх основних фреймворків і інструментів
  - Галузеві звіти, аналіз ринку та технічні бенчмарки
  - Освітні ресурси, конференції та форуми спільноти
  - Стандарти, специфікації та рамки відповідності

### Змінено - Модернізація контенту Module06
- **Покращені навчальні цілі**: Додано освоєння Microsoft Agent Framework і можливості розгортання на периферії
- **Фокус на виробництво**: Перехід від концептуального до готового до впровадження керівництва з прикладами для виробництва
- **Приклади коду**: Оновлено всі приклади для використання сучасних SDK шаблонів і найкращих практик
- **Шаблони архітектури**: Додано ієрархічні архітектури агентів і координацію периферія-хмара
- **Оптимізація продуктивності**: Покращено рекомендації з управління ресурсами та автоматичного масштабування

### Документація - Покращення структури Module06
- **Комплексне висвітлення фреймворку агентів**: Від базових концепцій до розгортання на рівні підприємства
- **Стратегії розгортання у виробництві**: Повні керівництва для Foundry Local, Ollama та VLLM
- **Кросплатформна оптимізація**: Додано ONNX Runtime для універсального розгортання
- **Бібліотека ресурсів**: Розширені посилання для продовження навчання та впровадження

### Додано - Оновлення документації протоколу контексту моделі (MCP) у Module06
- **Модернізація введення MCP** (`Module06/03.IntroduceMCP.md`):
  - Оновлено останні специфікації MCP з modelcontextprotocol.io (версія 2025-06-18)
  - Додано офіційну аналогію USB-C для стандартизованих AI-з’єднань
  - Оновлено розділ архітектури з офіційним двошаровим дизайном (шар даних + транспортний шар)
  - Покращено документацію основних примітивів із серверними примітивами (інструменти, ресурси, підказки) та клієнтськими примітивами (вибірка, отримання, логування)

- **Комплексні посилання та ресурси MCP**:
  - Додано посилання **MCP для початківців** (https://aka.ms/mcp-for-beginners)
  - Офіційна документація та специфікації MCP (modelcontextprotocol.io)
  - Ресурси для розробки, включаючи MCP Inspector і референсні впровадження
  - Технічні стандарти (JSON-RPC 2.0, JSON Schema, OpenAPI, Server-Sent Events)

### Додано - Інтеграція Qualcomm QNN у Module04
- **Новий розділ 7: Qualcomm QNN Optimization Suite** (`Module04/05.QualcommQNN.md`):
  - Комплексний посібник на 400+ рядків, що охоплює єдиний фреймворк AI інференсу Qualcomm
  - Детальне висвітлення гетерогенного обчислення (Hexagon NPU, Adreno GPU, Kryo CPU)
  - Оптимізація, орієнтована на апаратне забезпечення для платформ Snapdragon з інтелектуальним розподілом навантаження
  - Передові техніки квантування (INT8, INT16, змішана точність) для мобільного розгортання
  - Енергоефективна оптимізація інференсу для пристроїв із живленням від батареї та додатків реального часу
  - Повний посібник з установки з налаштуванням SDK QNN і конфігурацією середовища
  - Практичні приклади: конверсія PyTorch у QNN, оптимізація мультибекенду, генерація контекстних бінарних файлів
  - Розширені шаблони використання: налаштування користувацького бекенду, динамічне квантування, профілювання продуктивності
  - Комплексний розділ усунення несправностей і ресурси спільноти

- **Покращена структура Module04**:
  - Оновлено README.md для включення 7 прогресивних розділів (було 6)
  - Додано Qualcomm QNN до таблиці бенчмарків продуктивності (покращення швидкості на 5-15x, зменшення пам’яті на 50-80%)
  - Комплексні результати навчання для мобільного AI розгортання та оптимізації енергоспоживання

### Змінено - Оновлення документації Module04
- **Покращення документації Microsoft Olive** (`Module04/03.MicrosoftOlive.md`):
  - Додано розділ "Репозиторій рецептів Olive", що охоплює понад 100 готових рецептів оптимізації
  - Детальне висвітлення підтримуваних сімейств моделей (Phi, Llama, Qwen, Gemma, Mistral, DeepSeek)
  - Практичні приклади використання для налаштування рецептів і внесків спільноти
  - Покращено бенчмарки продуктивності та керівництво з інтеграції

- **Перестановка розділів у Module04**:
  - Apple MLX переміщено до розділу 5 (було розділом 6)
  - Синтез робочого процесу переміщено до розділу 6 (було розділом 7)
  - Qualcomm QNN позиціоновано як розділ 7 (спеціалізований мобільний/периферійний фокус)
  - Оновлено всі посилання на файли та навігаційні лінки відповідно

### Виправлено - Валідація зразків для воркшопу
- **Валідація та ремонт chat_bootstrap.py**:
  - Виправлено пошкоджений імпорт (`util.util.workshop_utils` → `util.workshop_utils`)
  - Створено відсутній `__init__.py` у пакеті util для правильного вирішення модулів Python
  - Встановлено необхідні залежності (openai, foundry-local-sdk) у середовищі conda
  - Успішно перевірено виконання зразка з використанням як стандартних, так і користувацьких підказок
  - Підтверджено інтеграцію з сервісом Foundry Local і завантаження моделі (phi-4-mini з оптимізацією CUDA)

### Документація - Оновлення комплексного посібника
- **Повна реструктуризація README.md для Module04**:
  - Додано Qualcomm QNN як основний фреймворк оптимізації поряд із OpenVINO, Olive, MLX
  - Оновлено результати навчання розділу, щоб включити мобільне AI розгортання та оптимізацію енергоспоживання
  - Покращено таблицю порівняння продуктивності з метриками QNN і випадками використання мобільних/периферійних пристроїв
  - Збережено логічну прогресію від рішень для підприємств до оптимізацій, специфічних для платформи

- **Крос-посилання та навігація**:
  - Оновлено всі внутрішні посилання та посилання на файли для нової нумерації розділів
  - Покращено опис синтезу робочого процесу для включення мобільних, настільних і хмарних середовищ
  - Додано комплексні посилання на ресурси для екосистеми розробників Qualcomm

## 2025-10-08

### Додано - Комплексне оновлення воркшопу
- **Повний перепис README.md для воркшопу**:
  - Додано комплексне введення, що пояснює цінність Edge AI (конфіденційність, продуктивність, вартість)
  - Створено 6 основних навчальних цілей із детальними компетенціями
  - Додано таблицю результатів навчання з результатами та матрицею компетенцій
  - Включено розділ навичок, готових до кар’єри, для галузевої актуальності
  - Додано посібник швидкого старту з передумовами та 3-кроковою установкою
  - Створено таблиці ресурсів для зразків Python (8 файлів із часом виконання)
  - Додано таблицю Jupyter ноутбуків (8 ноутбуків із рейтингами складності)
  - Створено таблицю документації (7 ключових документів із рекомендаціями "Використовувати коли")
  - Додано рекомендації щодо навчального шляху для різних рівнів навичок

- **Інфраструктура валідації та тестування воркшопу**:
  - Створено `scripts/validate_samples.py` - Комплексний інструмент валідації для синтаксису, імпортів і найкращих практик
  - Створено `scripts/test_samples.py` - Інструмент тестування для всіх зразків Python
  - Додано документацію з валідації до `scripts/README.md`

- **Комплексна документація**:
  - Створено `SAMPLES_UPDATE_SUMMARY.md` - Детальний посібник на 400+ рядків, що охоплює всі покращення
  - Створено `UPDATE_COMPLETE.md` - Виконавче резюме завершення оновлення
  - Створено `QUICK_REFERENCE.md` - Швидка довідкова картка для воркшопу

### Змінено - Модернізація зразків Python для воркшопу
- **Оновлено всі 8 зразків Python із найкращими практиками**:
  - Покращено обробку помилок за допомогою блоків try-except навколо всіх операцій вводу/виводу
  - Додано підказки типів і комплексні docstrings
  - Реалізовано послідовний шаблон логування [INFO]/[ERROR]/[RESULT]
  - Захищено необов’язкові імпорти з підказками щодо встановлення
  - Покращено зворотний зв’язок із користувачем у всіх зразках

- **session01/chat_bootstrap.py**:
  - Покращено ініціалізацію клієнта з комплексними повідомленнями про помилки
  - Покращено обробку помилок потоків із перевіркою блоків
  - Додано кращу обробку винятків для недоступності сервісу

- **session02/rag_pipeline.py**:
  - Додано захист імпорту для sentence-transformers із підказками щодо встановлення
  - Покращено обробку помилок для операцій вбудовування та генерації
  - Покращено форматування виводу зі структурованими результатами

- **session02/rag_eval_ragas.py**:
  - Захищено необов’язкові імпорти (ragas, datasets) з дружніми повідомленнями про помилки
  - Додано обробку помилок для метрик оцінки
  - Покращено форматування виводу для результатів оцінки

- **session03/benchmark_oss_models.py**:
  - Реалізовано плавну деградацію (продовжує роботу при збоях моделей)
  - Додано детальне звітування про прогрес і обробку помилок для кожної моделі
  - Покращено обчислення статистики з комплексним відновленням після помилок

- **session04/model_compare.py**:
  - Додано підказки типів (типи повернення Tuple)
  - Покращено форматування виводу зі структурованими JSON результатами
  - Реалізовано обробку помилок для кожної моделі з відновленням

- **session05/agents_orchestrator.py**:
  - Покращено Agent.act() із комплексними docstrings
  - Додано обробку помилок конвеєра з логуванням на кожному етапі
  - Покращено управління пам’яттю та відстеження стану

- **session06/models_router.py**:
  - Покращено документацію функцій для всіх компонентів маршрутизації
  - Додано детальне логування у функції route()
  - Покращено тестовий вивід зі структурованими результатами

- **session06/models_pipeline.py**:
  - Додано обробку помилок до допоміжної функції chat()
  - Покращено pipeline() із логуванням етапів і звітуванням про прогрес
  - Покращено main() із комплексним відновленням після помилок

### Документація - Покращення документації воркшопу
- Оновлено основний README.md із розділом воркшопу, що підкреслює навчальний шлях із практичними завданнями
- Покращено STUDY_GUIDE.md із комплексним розділом воркшопу, включаючи:
  - Навчальні цілі та сфери фокусування
  - Питання для самостійної оцінки
  - Практичні завдання з оцінкою часу
  - Розподіл часу для концентрованого та часткового навчання
  - Додано воркшоп до шаблону відстеження прогресу
- Оновлено посібник із розподілу часу з 20 годин до 30 годин (включаючи воркшоп)
- Додано описи зразків воркшопу та результати навчання до README

### Виправлено
- Вирішено проблеми з непослідовними шаблонами обробки помилок у зразках воркшопу
- Виправлено помилки імпорту необов’язкових залежностей із правильними захистами
- Виправлено відсутні підказки типів у критичних функціях
- Усунуто недостатній зворотний зв’язок із користувачем у сценар
  - Виконувані приклади у `Module08/samples/01`–`06` з інструкціями для Windows cmd
    - `01` REST швидкий чат (`chat_quickstart.py`)
    - `02` SDK швидкий старт з підтримкою OpenAI/Foundry Local та Azure OpenAI (`sdk_quickstart.py`)
    - `03` CLI список і тестування (`list_and_bench.cmd`)
    - `04` Демонстрація Chainlit (`app.py`)
    - `05` Оркестрація багатокористувацьких агентів (`python -m samples.05.agents.coordinator`)
    - `06` Маршрутизатор Models-as-Tools (`router.py`)
- Підтримка Azure OpenAI у прикладі SDK для Сесії 2 з конфігурацією змінних середовища
- `.vscode/settings.json` для вказівки на `Module08/.venv` та покращення аналізу Python
- `.env` з підказкою `PYTHONPATH` для обізнаності VS Code/Pylance

### Змінено
- Модель за замовчуванням оновлено до `phi-4-mini` у документації та прикладах Module 08; видалено залишки згадок про `phi-3.5` у Module 08
- Покращення маршрутизатора (`Module08/samples/06/router.py`):
  - Виявлення кінцевих точок через `foundry service status` з парсингом за допомогою регулярних виразів
  - Перевірка стану `/v1/models` під час запуску
  - Реєстр моделей, що налаштовується через середовище (`GENERAL_MODEL`, `REASONING_MODEL`, `CODE_MODEL`, `TOOL_REGISTRY` JSON)
- Оновлені вимоги: `Module08/requirements.txt` тепер включає `openai` (разом із `requests`, `chainlit`)
- Уточнено інструкції для прикладу Chainlit та додано усунення несправностей; вирішення імпорту через налаштування робочого простору

### Виправлено
- Вирішено проблеми з імпортом:
  - Маршрутизатор більше не залежить від неіснуючого модуля `utils`; функції інтегровані
  - Координатор використовує відносний імпорт (`from .specialists import ...`) і викликається через шлях модуля
  - Конфігурація VS Code/Pylance для вирішення імпорту `chainlit` та пакетів
- Виправлено незначну помилку в `STUDY_GUIDE.md` та додано охоплення Module 08

### Видалено
- Видалено невикористовуваний `Module08/infra/obs.py` та порожній каталог `infra/`; шаблони спостереження залишені як опціональні в документації

### Переміщено
- Консолідовано демонстрації Module 08 у `Module08/samples` з папками, пронумерованими за сесіями
  - Переміщено додаток Chainlit до `samples/04`
  - Переміщено агентів до `samples/05` та додано файли `__init__.py` для вирішення пакетів

### Документація
- Документація сесій Module 08 та всі README прикладів доповнені посиланнями на Microsoft Learn та перевірених постачальників
- Оновлено `Module08/README.md` з оглядом прикладів, конфігурацією маршрутизатора та порадами щодо перевірки
- Перевірено розділ Windows Foundry Local у `Module07/README.md` відповідно до документації Learn
- Оновлено `STUDY_GUIDE.md`:
  - Додано Module 08 до огляду, розкладів, трекера прогресу
  - Додано розширений розділ Посилань (Foundry Local, Azure AI, Olive, ONNX Runtime, OpenVINO, MLX, Llama.cpp, vLLM, Ollama, AI Toolkit, Windows ML)

---

## Історичне (резюме)
- Створено архітектуру курсу та модулі (Modules 01–07)
- Поетапна модернізація контенту, стандартизація форматування та додані кейс-стаді
- Розширено охоплення фреймворків оптимізації (Llama.cpp, Olive, OpenVINO, Apple MLX)

## Невипущене / Заплановане (пропозиції)
- Опціональні тестування кожного прикладу для перевірки доступності Foundry Local
- Перегляд перекладів для узгодження згадок моделей (наприклад, `phi-4-mini`) де це доречно
- Додати мінімальну конфігурацію pyright, якщо команди віддають перевагу суворості на рівні робочого простору

---

**Відмова від відповідальності**:  
Цей документ був перекладений за допомогою сервісу автоматичного перекладу [Co-op Translator](https://github.com/Azure/co-op-translator). Хоча ми прагнемо до точності, будь ласка, майте на увазі, що автоматичні переклади можуть містити помилки або неточності. Оригінальний документ на його рідній мові слід вважати авторитетним джерелом. Для критичної інформації рекомендується професійний людський переклад. Ми не несемо відповідальності за будь-які непорозуміння або неправильні тлумачення, що виникають внаслідок використання цього перекладу.