<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "efb0e70d6e87d0795f4d381c3bc99074",
  "translation_date": "2025-10-21T07:44:50+00:00",
  "source_file": "Module07/aitoolkit.md",
  "language_code": "uk"
}
-->
# AI Toolkit для Visual Studio Code - Посібник з розробки Edge AI

## Вступ

Ласкаво просимо до детального посібника з використання AI Toolkit для Visual Studio Code у розробці Edge AI. У той час як штучний інтелект переходить від централізованих хмарних обчислень до розподілених пристроїв на краю мережі, розробникам потрібні потужні інтегровані інструменти, які можуть впоратися з унікальними викликами розгортання на краю - від обмежених ресурсів до вимог роботи в автономному режимі.

AI Toolkit для Visual Studio Code заповнює цю прогалину, забезпечуючи повноцінне середовище розробки, спеціально створене для побудови, тестування та оптимізації AI-додатків, які ефективно працюють на пристроях краю. Незалежно від того, чи розробляєте ви для IoT-сенсорів, мобільних пристроїв, вбудованих систем або серверів краю, цей набір інструментів спрощує весь процес розробки у знайомому середовищі VS Code.

Цей посібник проведе вас через основні концепції, інструменти та найкращі практики використання AI Toolkit у ваших проектах Edge AI, від вибору моделі до розгортання у виробництві.

## Огляд

AI Toolkit для Visual Studio Code - це потужне розширення, яке спрощує розробку агентів та створення AI-додатків. Набір інструментів забезпечує широкі можливості для дослідження, оцінки та розгортання AI-моделей від різних постачальників, включаючи Anthropic, OpenAI, GitHub, Google, а також підтримує локальне виконання моделей за допомогою ONNX та Ollama.

Що відрізняє AI Toolkit, так це його комплексний підхід до всього життєвого циклу розробки AI. На відміну від традиційних інструментів розробки AI, які зосереджуються на окремих аспектах, AI Toolkit забезпечує інтегроване середовище, яке охоплює відкриття моделей, експерименти, розробку агентів, оцінку та розгортання - все у знайомому середовищі VS Code.

Платформа спеціально розроблена для швидкого прототипування та розгортання у виробництві, з такими функціями, як генерація підказок, швидкі стартери, безшовна інтеграція MCP (Model Context Protocol) та розширені можливості оцінки. Для розробки Edge AI це означає, що ви можете ефективно розробляти, тестувати та оптимізувати AI-додатки для сценаріїв розгортання на краю, зберігаючи повний робочий процес розробки у VS Code.

## Навчальні цілі

До кінця цього посібника ви зможете:

### Основні компетенції
- **Встановити та налаштувати** AI Toolkit для Visual Studio Code для робочих процесів розробки Edge AI
- **Орієнтуватися та використовувати** інтерфейс AI Toolkit, включаючи Model Catalog, Playground та Agent Builder
- **Вибирати та оцінювати** AI-моделі, придатні для розгортання на краю, з урахуванням продуктивності та обмежень ресурсів
- **Конвертувати та оптимізувати** моделі за допомогою формату ONNX та технік квантування для пристроїв краю

### Навички розробки Edge AI
- **Проектувати та впроваджувати** Edge AI-додатки за допомогою інтегрованого середовища розробки
- **Проводити тестування моделей** в умовах, схожих на край, використовуючи локальне виконання та моніторинг ресурсів
- **Створювати та налаштовувати** AI-агентів, оптимізованих для сценаріїв розгортання на краю
- **Оцінювати продуктивність моделей** за допомогою метрик, релевантних для обчислень на краю (затримка, використання пам'яті, точність)

### Оптимізація та розгортання
- **Застосовувати техніки квантування та обрізання** для зменшення розміру моделі при збереженні прийнятної продуктивності
- **Оптимізувати моделі** для конкретних апаратних платформ краю, включаючи прискорення CPU, GPU та NPU
- **Впроваджувати найкращі практики** для розробки Edge AI, включаючи управління ресурсами та стратегії резервування
- **Готувати моделі та додатки** для розгортання у виробництві на пристроях краю

### Розширені концепції Edge AI
- **Інтегрувати з фреймворками Edge AI**, включаючи ONNX Runtime, Windows ML та TensorFlow Lite
- **Реалізовувати багатомодельні архітектури** та сценарії федеративного навчання для середовищ краю
- **Вирішувати поширені проблеми Edge AI**, включаючи обмеження пам'яті, швидкість виконання та сумісність апаратного забезпечення
- **Проектувати стратегії моніторингу та логування** для AI-додатків на краю у виробництві

### Практичне застосування
- **Створювати комплексні рішення Edge AI** від вибору моделі до розгортання
- **Демонструвати компетентність** у робочих процесах розробки та техніках оптимізації, специфічних для краю
- **Застосовувати отримані знання** до реальних випадків використання Edge AI, включаючи IoT, мобільні та вбудовані додатки
- **Оцінювати та порівнювати** різні стратегії розгортання Edge AI та їх компроміси

## Основні функції для розробки Edge AI

### 1. Каталог моделей та відкриття
- **Підтримка багатьох постачальників**: Перегляд та доступ до AI-моделей від Anthropic, OpenAI, GitHub, Google та інших постачальників
- **Інтеграція локальних моделей**: Спрощене відкриття моделей ONNX та Ollama для розгортання на краю
- **Моделі GitHub**: Пряма інтеграція з хостингом моделей GitHub для спрощеного доступу
- **Порівняння моделей**: Порівняння моделей для знаходження оптимального балансу для обмежень пристроїв краю

### 2. Інтерактивний Playground
- **Інтерактивне тестове середовище**: Швидке експериментування з можливостями моделі у контрольованому середовищі
- **Підтримка мультимодальності**: Тестування зображень, тексту та інших типових для краю входів
- **Експерименти в реальному часі**: Миттєвий зворотний зв'язок щодо відповідей моделі та продуктивності
- **Оптимізація параметрів**: Тонке налаштування параметрів моделі для вимог розгортання на краю

### 3. Конструктор підказок (Agent Builder)
- **Генерація природної мови**: Генерація стартових підказок за допомогою описів природною мовою
- **Ітеративне вдосконалення**: Покращення підказок на основі відповідей моделі та продуктивності
- **Розбиття завдань**: Розділення складних завдань за допомогою ланцюжка підказок та структурованих виходів
- **Підтримка змінних**: Використання змінних у підказках для динамічної поведінки агентів
- **Генерація виробничого коду**: Генерація готового до виробництва коду для швидкої розробки додатків

### 4. Масове виконання та оцінка
- **Тестування багатьох моделей**: Виконання кількох підказок на вибраних моделях одночасно
- **Ефективне тестування у масштабі**: Тестування різних входів та конфігурацій ефективно
- **Користувацькі тестові випадки**: Запуск агентів з тестовими випадками для перевірки функціональності
- **Порівняння продуктивності**: Порівняння результатів між різними моделями та конфігураціями

### 5. Оцінка моделей за допомогою наборів даних
- **Стандартні метрики**: Тестування AI-моделей за допомогою вбудованих оцінювачів (F1 score, релевантність, схожість, узгодженість)
- **Користувацькі оцінювачі**: Створення власних метрик оцінки для конкретних випадків використання
- **Інтеграція наборів даних**: Тестування моделей на основі комплексних наборів даних
- **Вимірювання продуктивності**: Кількісна оцінка продуктивності моделі для рішень розгортання на краю

### 6. Можливості тонкого налаштування
- **Налаштування моделей**: Налаштування моделей для конкретних випадків використання та доменів
- **Спеціалізована адаптація**: Адаптація моделей до спеціалізованих доменів та вимог
- **Оптимізація для краю**: Тонке налаштування моделей спеціально для обмежень розгортання на краю
- **Навчання для конкретного домену**: Створення моделей, адаптованих до специфічних випадків використання на краю

### 7. Інтеграція MCP Tool
- **Підключення до зовнішніх інструментів**: Підключення агентів до зовнішніх інструментів через сервери Model Context Protocol
- **Дії у реальному світі**: Дозвіл агентам запитувати бази даних, отримувати доступ до API або виконувати користувацьку логіку
- **Існуючі сервери MCP**: Використання інструментів з командного рядка (stdio) або HTTP (події, що надсилаються сервером)
- **Розробка користувацьких MCP**: Створення та тестування нових серверів MCP у Agent Builder

### 8. Розробка та тестування агентів
- **Підтримка виклику функцій**: Дозвіл агентам динамічно викликати зовнішні функції
- **Тестування інтеграції у реальному часі**: Тестування інтеграцій з реальними запусками та використанням інструментів
- **Версійність агентів**: Контроль версій агентів з можливістю порівняння результатів оцінки
- **Відлагодження та трасування**: Локальне трасування та відлагодження для розробки агентів

## Робочий процес розробки Edge AI

### Фаза 1: Відкриття та вибір моделі
1. **Дослідження каталогу моделей**: Використовуйте каталог моделей для пошуку моделей, придатних для розгортання на краю
2. **Порівняння продуктивності**: Оцінюйте моделі за розміром, точністю та швидкістю виконання
3. **Локальне тестування**: Використовуйте моделі Ollama або ONNX для локального тестування перед розгортанням на краю
4. **Оцінка вимог до ресурсів**: Визначте потреби у пам'яті та обчисленнях для цільових пристроїв краю

### Фаза 2: Оптимізація моделі
1. **Конвертація в ONNX**: Конвертуйте вибрані моделі у формат ONNX для сумісності з краєм
2. **Застосування квантування**: Зменшуйте розмір моделі за допомогою квантування INT8 або INT4
3. **Апаратна оптимізація**: Оптимізуйте для цільового апаратного забезпечення краю (ARM, x86, спеціалізовані прискорювачі)
4. **Перевірка продуктивності**: Переконайтеся, що оптимізовані моделі зберігають прийнятну точність

### Фаза 3: Розробка додатків
1. **Проектування агентів**: Використовуйте Agent Builder для створення AI-агентів, оптимізованих для краю
2. **Інженерія підказок**: Розробляйте підказки, які ефективно працюють з меншими моделями краю
3. **Тестування інтеграції**: Тестуйте агентів у симульованих умовах краю
4. **Генерація коду**: Генеруйте виробничий код, оптимізований для розгортання на краю

### Фаза 4: Оцінка та тестування
1. **Масова оцінка**: Тестуйте кілька конфігурацій для знаходження оптимальних налаштувань краю
2. **Профілювання продуктивності**: Аналізуйте швидкість виконання, використання пам'яті та точність
3. **Симуляція краю**: Тестуйте в умовах, схожих на цільове середовище розгортання на краю
4. **Стрес-тестування**: Оцінюйте продуктивність за різних умов навантаження

### Фаза 5: Підготовка до розгортання
1. **Остаточна оптимізація**: Застосовуйте остаточні оптимізації на основі результатів тестування
2. **Пакування для розгортання**: Пакуйте моделі та код для розгортання на краю
3. **Документація**: Документуйте вимоги до розгортання та конфігурацію
4. **Налаштування моніторингу**: Готуйте моніторинг та логування для розгортання на краю

## Цільова аудиторія для розробки Edge AI

### Розробники Edge AI
- Розробники додатків, які створюють пристрої краю з підтримкою AI та IoT-рішення
- Розробники вбудованих систем, які інтегрують AI-можливості у пристрої з обмеженими ресурсами
- Мобільні розробники, які створюють AI-додатки для смартфонів та планшетів

### Інженери Edge AI
- Інженери AI, які оптимізують моделі для розгортання на краю та керують конвеєрами виконання
- Інженери DevOps, які розгортають та керують AI-моделями у розподіленій інфраструктурі краю
- Інженери продуктивності, які оптимізують AI-навантаження для обмежень апаратного забезпечення краю

### Дослідники та викладачі
- Дослідники AI, які розробляють ефективні моделі та алгоритми для обчислень на краю
- Викладачі, які навчають концепціям Edge AI та демонструють техніки оптимізації
- Студенти, які вивчають виклики та рішення у розгортанні Edge AI

## Випадки використання Edge AI

### Розумні IoT-пристрої
- **Розпізнавання зображень у реальному часі**: Розгортання моделей комп'ютерного зору на IoT-камерах та сенсорах
- **Обробка голосу**: Реалізація розпізнавання мови та обробки природної мови на розумних колонках
- **Прогнозне обслуговування**: Виконання моделей виявлення аномалій на промислових пристроях краю
- **Моніторинг навколишнього середовища**: Розгортання моделей аналізу даних сенсорів для екологічних додатків

### Мобільні та вбудовані додатки
- **Переклад на пристрої**: Реалізація моделей перекладу мов, які працюють офлайн
- **Доповнена реальність**: Розгортання моделей розпізнавання та відстеження об'єктів у реальному часі для AR-додатків
- **Моніторинг здоров'я**: Виконання моделей аналізу здоров'я на носимих пристроях та медичному обладнанні
- **Автономні системи**: Реалізація моделей прийняття рішень для дронів, роботів та транспортних засобів

### Інфраструктура обчислень на краю
- **Центри даних на краю**: Розгортання AI-моделей у центрах даних на краю для дод
2. Генеруйте початкові підказки за допомогою описів природною мовою  
3. Повторюйте та вдосконалюйте підказки на основі відповідей моделі  
4. Інтегруйте інструменти MCP для розширення можливостей агентів  

#### Крок 3: Тестування та оцінка  
1. Використовуйте **Bulk Run** для тестування кількох підказок на вибраних моделях  
2. Запускайте агентів із тестовими випадками для перевірки функціональності  
3. Оцінюйте точність і продуктивність за допомогою вбудованих або власних метрик  
4. Порівнюйте різні моделі та конфігурації  

#### Крок 4: Тонке налаштування та оптимізація  
1. Налаштовуйте моделі для специфічних крайових сценаріїв  
2. Застосовуйте тонке налаштування для конкретної галузі  
3. Оптимізуйте для обмежень крайового розгортання  
4. Версіонуйте та порівнюйте різні конфігурації агентів  

#### Крок 5: Підготовка до розгортання  
1. Генеруйте готовий до виробництва код за допомогою Agent Builder  
2. Налаштуйте з'єднання MCP-сервера для використання у виробництві  
3. Підготуйте пакети розгортання для крайових пристроїв  
4. Налаштуйте метрики моніторингу та оцінки  

## Зразки для AI Toolkit  

Спробуйте наші зразки  
[Зразки AI Toolkit](https://github.com/Azure-Samples/AI_Toolkit_Samples) створені для того, щоб допомогти розробникам і дослідникам ефективно досліджувати та впроваджувати AI-рішення.  

Наші зразки включають:  

Зразковий код: Готові приклади, які демонструють функціональність AI, такі як навчання, розгортання або інтеграція моделей у додатки.  
Документація: Посібники та навчальні матеріали, які допомагають користувачам зрозуміти функції AI Toolkit і як їх використовувати.  
Передумови  

- Visual Studio Code  
- AI Toolkit для Visual Studio Code  
- GitHub Fine-grained personal access token (PAT)  
- Foundry Local  

## Найкращі практики для розробки Edge AI  

### Вибір моделі  
- **Обмеження розміру**: Обирайте моделі, які відповідають обмеженням пам'яті цільових пристроїв  
- **Швидкість інференції**: Віддавайте перевагу моделям із швидкою інференцією для додатків у реальному часі  
- **Компроміси точності**: Балансуйте точність моделі з обмеженнями ресурсів  
- **Сумісність формату**: Віддавайте перевагу форматам ONNX або оптимізованим для апаратного забезпечення для крайового розгортання  

### Техніки оптимізації  
- **Квантування**: Використовуйте квантування INT8 або INT4 для зменшення розміру моделі та покращення швидкості  
- **Обрізання**: Видаляйте непотрібні параметри моделі для зменшення вимог до обчислень  
- **Дистиляція знань**: Створюйте менші моделі, які зберігають продуктивність більших  
- **Апаратне прискорення**: Використовуйте NPUs, GPUs або спеціалізовані прискорювачі, якщо доступні  

### Робочий процес розробки  
- **Ітеративне тестування**: Часто тестуйте в умовах, схожих на крайові, під час розробки  
- **Моніторинг продуктивності**: Постійно відстежуйте використання ресурсів і швидкість інференції  
- **Контроль версій**: Відстежуйте версії моделі та налаштування оптимізації  
- **Документація**: Документуйте всі рішення щодо оптимізації та компроміси продуктивності  

### Міркування щодо розгортання  
- **Моніторинг ресурсів**: Відстежуйте пам'ять, CPU та споживання енергії у виробництві  
- **Стратегії резервування**: Реалізуйте механізми резервування для збоїв моделі  
- **Механізми оновлення**: Плануйте оновлення моделей і управління версіями  
- **Безпека**: Реалізуйте відповідні заходи безпеки для додатків Edge AI  

## Інтеграція з Edge AI Frameworks  

### ONNX Runtime  
- **Кросплатформне розгортання**: Розгортайте моделі ONNX на різних крайових платформах  
- **Оптимізація апаратного забезпечення**: Використовуйте апаратно-специфічні оптимізації ONNX Runtime  
- **Підтримка мобільних пристроїв**: Використовуйте ONNX Runtime Mobile для смартфонів і планшетів  
- **Інтеграція IoT**: Розгортайте на IoT-пристроях за допомогою легких дистрибутивів ONNX Runtime  

### Windows ML  
- **Пристрої Windows**: Оптимізуйте для крайових пристроїв і ПК на базі Windows  
- **Прискорення NPU**: Використовуйте Neural Processing Units на пристроях Windows  
- **DirectML**: Використовуйте DirectML для прискорення GPU на платформах Windows  
- **Інтеграція UWP**: Інтегруйте з додатками Universal Windows Platform  

### TensorFlow Lite  
- **Оптимізація для мобільних пристроїв**: Розгортайте моделі TensorFlow Lite на мобільних і вбудованих пристроях  
- **Апаратні делегати**: Використовуйте спеціалізовані апаратні делегати для прискорення  
- **Мікроконтролери**: Розгортайте на мікроконтролерах за допомогою TensorFlow Lite Micro  
- **Кросплатформна підтримка**: Розгортайте на Android, iOS і вбудованих системах Linux  

### Azure IoT Edge  
- **Гібрид хмара-край**: Поєднуйте навчання в хмарі з інференцією на краю  
- **Розгортання модулів**: Розгортайте AI-моделі як модулі IoT Edge  
- **Управління пристроями**: Керуйте крайовими пристроями та оновленнями моделей дистанційно  
- **Телеметрія**: Збирайте дані продуктивності та метрики моделей із крайових розгортань  

## Розширені сценарії Edge AI  

### Розгортання кількох моделей  
- **Енсамблі моделей**: Розгортайте кілька моделей для покращення точності або резервування  
- **A/B тестування**: Тестуйте різні моделі одночасно на крайових пристроях  
- **Динамічний вибір**: Обирайте моделі залежно від поточних умов пристрою  
- **Спільне використання ресурсів**: Оптимізуйте використання ресурсів між кількома розгорнутими моделями  

### Федеративне навчання  
- **Розподілене навчання**: Навчайте моделі на кількох крайових пристроях  
- **Збереження конфіденційності**: Залишайте дані навчання локальними, обмінюючись лише покращеннями моделі  
- **Спільне навчання**: Дозволяйте пристроям навчатися на колективному досвіді  
- **Координація край-хмара**: Координуйте навчання між крайовими пристроями та хмарною інфраструктурою  

### Обробка в реальному часі  
- **Обробка потоків**: Обробляйте безперервні потоки даних на крайових пристроях  
- **Інференція з низькою затримкою**: Оптимізуйте для мінімальної затримки інференції  
- **Пакетна обробка**: Ефективно обробляйте пакети даних на крайових пристроях  
- **Адаптивна обробка**: Регулюйте обробку залежно від поточних можливостей пристрою  

## Вирішення проблем у розробці Edge AI  

### Поширені проблеми  
- **Обмеження пам'яті**: Модель занадто велика для пам'яті цільового пристрою  
- **Швидкість інференції**: Інференція моделі занадто повільна для вимог реального часу  
- **Погіршення точності**: Оптимізація знижує точність моделі до неприйнятного рівня  
- **Сумісність апаратного забезпечення**: Модель несумісна з цільовим апаратним забезпеченням  

### Стратегії налагодження  
- **Профілювання продуктивності**: Використовуйте функції трасування AI Toolkit для виявлення вузьких місць  
- **Моніторинг ресурсів**: Відстежуйте використання пам'яті та CPU під час розробки  
- **Інкрементне тестування**: Тестуйте оптимізації поступово, щоб ізолювати проблеми  
- **Симуляція апаратного забезпечення**: Використовуйте інструменти розробки для симуляції цільового апаратного забезпечення  

### Рішення для оптимізації  
- **Додаткове квантування**: Застосовуйте більш агресивні техніки квантування  
- **Архітектура моделі**: Розгляньте різні архітектури моделей, оптимізовані для краю  
- **Оптимізація попередньої обробки**: Оптимізуйте попередню обробку даних для крайових обмежень  
- **Оптимізація інференції**: Використовуйте апаратно-специфічні оптимізації інференції  

## Ресурси та наступні кроки  

### Офіційна документація  
- [Документація для розробників AI Toolkit](https://aka.ms/AIToolkit/doc)  
- [Посібник з установки та налаштування](https://code.visualstudio.com/docs/intelligentapps/overview#_install-and-setup)  
- [Документація VS Code Intelligent Apps](https://code.visualstudio.com/docs/intelligentapps)  
- [Документація Model Context Protocol (MCP)](https://modelcontextprotocol.io/)  

### Спільнота та підтримка  
- [Репозиторій AI Toolkit на GitHub](https://github.com/microsoft/vscode-ai-toolkit)  
- [Проблеми та запити на функції GitHub](https://aka.ms/AIToolkit/feedback)  
- [Спільнота Azure AI Foundry у Discord](https://aka.ms/azureaifoundry/discord)  
- [Ринок розширень VS Code](https://marketplace.visualstudio.com/items?itemName=ms-windows-ai-studio.windows-ai-studio)  

### Технічні ресурси  
- [Документація ONNX Runtime](https://onnxruntime.ai/)  
- [Документація Ollama](https://ollama.ai/)  
- [Документація Windows ML](https://docs.microsoft.com/en-us/windows/ai/)  
- [Документація Azure AI Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/)  

### Навчальні шляхи  
- [Курс основ Edge AI](../Module01/README.md)  
- [Посібник з малих мовних моделей](../Module02/README.md)  
- [Стратегії розгортання на краю](../Module03/README.md)  
- [Розробка Edge AI для Windows](./windowdeveloper.md)  

### Додаткові ресурси  
- **Статистика репозиторію**: 1.8k+ зірок, 150+ форків, 18+ учасників  
- **Ліцензія**: Ліцензія MIT  
- **Безпека**: Застосовуються політики безпеки Microsoft  
- **Телеметрія**: Відповідає налаштуванням телеметрії VS Code  

## Висновок  

AI Toolkit для Visual Studio Code представляє собою комплексну платформу для сучасної розробки AI, забезпечуючи спрощені можливості розробки агентів, які особливо цінні для додатків Edge AI. Завдяки широкому каталогу моделей, що підтримують постачальників, таких як Anthropic, OpenAI, GitHub і Google, у поєднанні з локальним виконанням через ONNX і Ollama, інструментарій пропонує необхідну гнучкість для різноманітних сценаріїв розгортання на краю.  

Сила інструментарію полягає в його інтегрованому підході — від відкриття моделей і експериментів у Playground до складної розробки агентів за допомогою Prompt Builder, комплексних можливостей оцінки та безперешкодної інтеграції інструментів MCP. Для розробників Edge AI це означає швидке створення прототипів і тестування AI-агентів перед розгортанням на краю з можливістю швидко ітеративно вдосконалювати та оптимізувати для середовищ із обмеженими ресурсами.  

Основні переваги для розробки Edge AI включають:  
- **Швидке експериментування**: Тестуйте моделі та агентів швидко перед розгортанням на краю  
- **Гнучкість багатопостачальника**: Доступ до моделей з різних джерел для пошуку оптимальних рішень для краю  
- **Локальна розробка**: Тестуйте з ONNX і Ollama для офлайн-розробки з дотриманням конфіденційності  
- **Готовність до виробництва**: Генеруйте готовий до виробництва код і інтегруйте з зовнішніми інструментами через MCP  
- **Комплексна оцінка**: Використовуйте вбудовані та власні метрики для перевірки продуктивності Edge AI  

Оскільки AI продовжує рухатися до сценаріїв розгортання на краю, AI Toolkit для VS Code забезпечує середовище розробки та робочий процес, необхідні для створення, тестування та оптимізації інтелектуальних додатків для середовищ із обмеженими ресурсами. Незалежно від того, чи розробляєте ви IoT-рішення, мобільні AI-додатки або вбудовані інтелектуальні системи, комплексний набір функцій інструментарію та інтегрований робочий процес підтримують весь життєвий цикл розробки Edge AI.  

З постійним розвитком і активною спільнотою (1.8k+ зірок на GitHub) AI Toolkit залишається на передовій серед інструментів розробки AI, постійно вдосконалюючись, щоб задовольнити потреби сучасних розробників AI, які створюють сценарії розгортання на краю.  

[Next Foundry Local](./foundrylocal.md)  

---

**Відмова від відповідальності**:  
Цей документ був перекладений за допомогою сервісу автоматичного перекладу [Co-op Translator](https://github.com/Azure/co-op-translator). Хоча ми прагнемо до точності, будь ласка, майте на увазі, що автоматичні переклади можуть містити помилки або неточності. Оригінальний документ на його рідній мові слід вважати авторитетним джерелом. Для критичної інформації рекомендується професійний людський переклад. Ми не несемо відповідальності за будь-які непорозуміння або неправильні тлумачення, що виникають внаслідок використання цього перекладу.