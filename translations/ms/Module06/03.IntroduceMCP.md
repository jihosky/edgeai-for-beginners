<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8a7765b85f123e8a62aa3847141ca072",
  "translation_date": "2025-10-30T13:46:25+00:00",
  "source_file": "Module06/03.IntroduceMCP.md",
  "language_code": "ms"
}
-->
# Seksyen 03 - Integrasi Protokol Konteks Model (MCP)

## Pengenalan kepada MCP (Protokol Konteks Model)

Protokol Konteks Model (MCP) adalah standard sumber terbuka untuk menghubungkan aplikasi AI kepada sistem luaran. Dengan MCP, aplikasi AI seperti Claude atau ChatGPT boleh berhubung dengan sumber data (contohnya, fail tempatan, pangkalan data), alat (contohnya, enjin carian, kalkulator), dan aliran kerja (contohnya, arahan khusus)—membolehkan mereka mengakses maklumat penting dan melaksanakan tugas.

Fikirkan MCP seperti **port USB-C untuk aplikasi AI**. Sama seperti USB-C menyediakan cara standard untuk menghubungkan peranti elektronik, MCP menyediakan cara standard untuk menghubungkan aplikasi AI kepada sistem luaran.

### Apa yang MCP Boleh Lakukan?

MCP membuka keupayaan yang hebat untuk aplikasi AI:

- **Pembantu AI Peribadi**: Agen boleh mengakses Google Calendar dan Notion anda, bertindak sebagai pembantu AI yang lebih peribadi
- **Penjanaan Kod Lanjutan**: Claude Code boleh menghasilkan keseluruhan aplikasi web menggunakan reka bentuk Figma
- **Integrasi Data Perusahaan**: Chatbot perusahaan boleh berhubung dengan pelbagai pangkalan data dalam organisasi, membolehkan pengguna menganalisis data melalui perbualan
- **Aliran Kerja Kreatif**: Model AI boleh mencipta reka bentuk 3D di Blender dan mencetaknya menggunakan pencetak 3D
- **Akses Maklumat Masa Nyata**: Berhubung dengan sumber data luaran untuk maklumat terkini
- **Operasi Pelbagai Langkah yang Kompleks**: Melaksanakan aliran kerja canggih yang menggabungkan pelbagai alat dan sistem

### Mengapa MCP Penting?

MCP memberikan manfaat kepada ekosistem:

**Untuk Pembangun**: MCP mengurangkan masa pembangunan dan kerumitan apabila membina atau mengintegrasikan aplikasi atau agen AI.

**Untuk Aplikasi AI**: MCP menyediakan akses kepada ekosistem sumber data, alat dan aplikasi yang meningkatkan keupayaan dan memperbaiki pengalaman pengguna akhir.

**Untuk Pengguna Akhir**: MCP menghasilkan aplikasi atau agen AI yang lebih berkemampuan yang boleh mengakses data anda dan mengambil tindakan bagi pihak anda apabila diperlukan.

## Model Bahasa Kecil (SLM) dalam MCP

Model Bahasa Kecil mewakili pendekatan yang cekap untuk penggunaan AI, menawarkan beberapa kelebihan:

### Kelebihan SLM
- **Kecekapan Sumber**: Keperluan pengiraan yang lebih rendah
- **Masa Respons Lebih Cepat**: Latensi yang dikurangkan untuk aplikasi masa nyata  
- **Kos Efektif**: Keperluan infrastruktur yang minimum
- **Privasi**: Boleh dijalankan secara tempatan tanpa penghantaran data
- **Penyesuaian**: Lebih mudah untuk disesuaikan dengan domain tertentu

### Mengapa SLM Berfungsi Baik dengan MCP

SLM yang digabungkan dengan MCP mencipta kombinasi yang kuat di mana keupayaan penaakulan model ditingkatkan oleh alat luaran, mengimbangi bilangan parameter yang lebih kecil dengan fungsi yang dipertingkatkan.

## Gambaran Keseluruhan Python MCP SDK

Python MCP SDK menyediakan asas untuk membina aplikasi yang diaktifkan MCP. SDK ini termasuk:

- **Perpustakaan Klien**: Untuk berhubung dengan pelayan MCP
- **Kerangka Pelayan**: Untuk mencipta pelayan MCP khusus
- **Pengendali Protokol**: Untuk mengurus komunikasi
- **Integrasi Alat**: Untuk melaksanakan fungsi luaran

## Pelaksanaan Praktikal: Klien MCP Phi-4

Mari kita terokai pelaksanaan dunia sebenar menggunakan model mini Phi-4 Microsoft yang diintegrasikan dengan keupayaan MCP.

### Gambaran Keseluruhan Seni Bina MCP

MCP mengikuti **seni bina klien-pelayan** di mana hos MCP (aplikasi AI seperti Claude Code atau Claude Desktop) mewujudkan sambungan kepada satu atau lebih pelayan MCP. Hos MCP melakukannya dengan mencipta satu klien MCP untuk setiap pelayan MCP.

#### Peserta Utama

- **Hos MCP**: Aplikasi AI yang menyelaraskan dan menguruskan satu atau beberapa klien MCP
- **Klien MCP**: Komponen yang mengekalkan sambungan kepada pelayan MCP dan mendapatkan konteks daripada pelayan MCP untuk digunakan oleh hos MCP
- **Pelayan MCP**: Program yang menyediakan konteks kepada klien MCP

#### Seni Bina Dua Lapisan

MCP terdiri daripada dua lapisan yang berbeza:

**Lapisan Data**: Mendefinisikan protokol berasaskan JSON-RPC untuk komunikasi klien-pelayan, termasuk:
- Pengurusan kitaran hayat (pemulaan sambungan, rundingan keupayaan)
- Primitif teras (alat, sumber, arahan)
- Ciri klien (pensampelan, pengumpulan maklumat, log)
- Ciri utiliti (pemberitahuan, penjejakan kemajuan)

**Lapisan Pengangkutan**: Mendefinisikan mekanisme dan saluran komunikasi:
- **Pengangkutan STDIO**: Menggunakan aliran input/output standard untuk proses tempatan (prestasi optimum, tiada overhead rangkaian)
- **Pengangkutan HTTP yang Boleh Distrim**: Menggunakan HTTP POST dengan Server-Sent Events pilihan untuk pelayan jauh (menyokong pengesahan HTTP standard)

```
┌─────────────────────────────────────┐
│           MCP Host                  │
│     (AI Application)                │
└─────────────────┬───────────────────┘
                  │
┌─────────────────┴───────────────────┐
│         MCP Client 1                │
│  ┌─────────────────────────────────┐ │
│  │        Data Layer               │ │
│  │  ├── Lifecycle Management       │ │
│  │  ├── Primitives (Tools/Resources)│ │
│  │  └── Notifications              │ │
│  └─────────────────────────────────┘ │
│  ┌─────────────────────────────────┐ │
│  │      Transport Layer           │ │
│  │  ├── STDIO Transport           │ │
│  │  └── HTTP Transport            │ │
│  └─────────────────────────────────┘ │
└─────────────────┬───────────────────┘
                  │
┌─────────────────┴───────────────────┐
│         MCP Server 1                │
│    (Local/Remote Context Provider)  │
└─────────────────────────────────────┘
```

### Primitif Teras MCP

MCP mendefinisikan primitif yang menentukan jenis maklumat konteks yang boleh dikongsi dengan aplikasi AI dan pelbagai tindakan yang boleh dilakukan.

#### Primitif Pelayan

MCP mendefinisikan tiga primitif teras yang boleh didedahkan oleh pelayan:

**Alat**: Fungsi yang boleh dilaksanakan yang boleh dipanggil oleh aplikasi AI untuk melaksanakan tindakan
- Contoh: operasi fail, panggilan API, pertanyaan pangkalan data
- Kaedah: `tools/list`, `tools/call`
- Menyokong penemuan dan pelaksanaan dinamik

**Sumber**: Sumber data yang menyediakan maklumat konteks kepada aplikasi AI
- Contoh: kandungan fail, rekod pangkalan data, respons API
- Kaedah: `resources/list`, `resources/read`
- Membolehkan akses kepada data berstruktur

**Arahan**: Templat yang boleh digunakan semula yang membantu menyusun interaksi dengan model bahasa
- Contoh: arahan sistem, contoh few-shot
- Kaedah: `prompts/list`, `prompts/get`
- Menstandardkan corak interaksi AI

#### Primitif Klien

MCP juga mendefinisikan primitif yang boleh didedahkan oleh klien untuk membolehkan interaksi yang lebih kaya:

**Pensampelan**: Membolehkan pelayan meminta penyempurnaan model bahasa daripada aplikasi AI klien
- Kaedah: `sampling/complete`
- Membolehkan pembangunan pelayan bebas model
- Memberikan akses kepada model bahasa hos

**Pengumpulan Maklumat**: Membolehkan pelayan meminta maklumat tambahan daripada pengguna
- Kaedah: `elicitation/request`
- Membolehkan interaksi dan pengesahan pengguna
- Menyokong pengumpulan maklumat dinamik

**Log**: Membolehkan pelayan menghantar mesej log kepada klien
- Digunakan untuk tujuan debugging dan pemantauan
- Memberikan keterlihatan kepada operasi pelayan

### Kitaran Hayat Protokol MCP

#### Pemulaan dan Rundingan Keupayaan

MCP adalah protokol berkeadaan yang memerlukan pengurusan kitaran hayat. Proses pemulaan berfungsi untuk beberapa tujuan kritikal:

1. **Rundingan Versi Protokol**: Memastikan klien dan pelayan menggunakan versi protokol yang serasi (contohnya, "2025-06-18")
2. **Penemuan Keupayaan**: Setiap pihak menyatakan ciri dan primitif yang disokong
3. **Pertukaran Identiti**: Memberikan maklumat pengenalan dan versi

```python
# Example initialization request
{
  "jsonrpc": "2.0",
  "id": 1,
  "method": "initialize",
  "params": {
    "protocolVersion": "2025-06-18",
    "capabilities": {
      "elicitation": {},  # Client supports user interaction
      "sampling": {}      # Client can provide LLM completions
    },
    "clientInfo": {
      "name": "edge-ai-client",
      "version": "1.0.0"
    }
  }
}
```

#### Penemuan dan Pelaksanaan Alat

Selepas pemulaan, klien boleh menemui dan melaksanakan alat:

```python
# Discover available tools
tools_response = await session.list_tools()

# Execute a tool
result = await session.call_tool(
    "weather_current",
    {
        "location": "San Francisco",
        "units": "imperial"
    }
)
```

#### Pemberitahuan Masa Nyata

MCP menyokong pemberitahuan masa nyata untuk kemas kini dinamik:

```python
# Server sends notification when tools change
{
  "jsonrpc": "2.0",
  "method": "notifications/tools/list_changed"
}

# Client responds by refreshing tool list
await session.list_tools()  # Get updated tools
```

## Memulakan: Panduan Langkah Demi Langkah

### Langkah 1: Persediaan Persekitaran

Pasang keperluan yang diperlukan:
```bash
pip install fastmcp mcp-python-client openai requests pyautogui Pillow
```

### Langkah 2: Konfigurasi Asas

Tetapkan pembolehubah persekitaran anda:
```python
# System Configuration
SYSTEM_PROMPT = "You are an AI assistant with some tools."

# Ollama Configuration (Local)
OLLAMA_URL = "http://localhost:11434/api/chat"
OLLAMA_MODEL_ID = "phi4-mini:3.8b-fp16"

# vLLM Configuration (Server)
VLLM_URL = "http://localhost:8000/v1"
VLLM_MODEL_ID = "microsoft/Phi-4-mini-instruct"
```

### Langkah 3: Menjalankan Klien MCP Pertama Anda

**Persediaan Asas Ollama:**
```bash
python ghmodel_mcp_demo.py
```

**Menggunakan Backend vLLM:**
```bash
python ghmodel_mcp_demo.py --env vllm
```

**Sambungan Server-Sent Events:**
```bash
python ghmodel_mcp_demo.py --run sse
```

**Pelayan MCP Khusus:**
```bash
python ghmodel_mcp_demo.py --server /path/to/server.py
```

### Langkah 4: Penggunaan Programatik

```python
import asyncio
from ghmodel_mcp_demo import OllamaClient, Phi4MiniMCPClient

async def automated_interaction():
    # Configure MCP server parameters
    server_params = StdioServerParameters(
        command="npx",
        args=["@playwright/mcp@latest"],
        env=None,
    )
    
    # Create MCP client and process tools
    async with Phi4MiniMCPClient(server_params) as mcp_client:
        tools = await process_mcp_tools(mcp_client)
        llm_client = OllamaClient()
        
        # Generate response with tool capabilities
        response, messages = await llm_client.generate_response(
            "Help me automate a web task",
            tools
        )
        return response

# Execute the automation
result = asyncio.run(automated_interaction())
print(result)
```

## Ciri Lanjutan

### Sokongan Multi-Backend

Pelaksanaan menyokong kedua-dua backend Ollama dan vLLM, membolehkan anda memilih berdasarkan keperluan anda:

- **Ollama**: Lebih baik untuk pembangunan dan ujian tempatan
- **vLLM**: Dioptimumkan untuk senario pengeluaran dan throughput tinggi

### Protokol Sambungan Fleksibel

Dua mod sambungan disokong:

**Mod STDIO**: Komunikasi proses langsung
- Latensi lebih rendah
- Sesuai untuk alat tempatan
- Persediaan mudah

**Mod SSE**: Penstriman berasaskan HTTP
- Mampu rangkaian
- Lebih baik untuk sistem teragih
- Kemas kini masa nyata

### Keupayaan Integrasi Alat

Sistem boleh diintegrasikan dengan pelbagai alat:
- Automasi web (Playwright)
- Operasi fail
- Interaksi API
- Perintah sistem
- Fungsi khusus

## Pengendalian Ralat dan Amalan Terbaik

### Pengurusan Ralat Komprehensif

Pelaksanaan termasuk pengendalian ralat yang kukuh untuk:

**Ralat Sambungan**:
- Kegagalan pelayan MCP
- Masa tamat rangkaian
- Masalah sambungan

**Ralat Pelaksanaan Alat**:
- Alat yang hilang
- Pengesahan parameter
- Kegagalan pelaksanaan

**Ralat Pemprosesan Respons**:
- Masalah penguraian JSON
- Ketidakkonsistenan format
- Anomali respons LLM

### Amalan Terbaik

1. **Pengurusan Sumber**: Gunakan pengurus konteks async
2. **Pengendalian Ralat**: Laksanakan blok try-catch yang komprehensif
3. **Log**: Aktifkan tahap log yang sesuai
4. **Keselamatan**: Sahkan input dan sanitasi output
5. **Prestasi**: Gunakan pengumpulan sambungan dan caching

## Aplikasi Dunia Sebenar

### Automasi Web
```python
# Example: Automated web testing
async def web_automation_example():
    tools = await setup_playwright_tools()
    response = await llm_client.generate_response(
        "Navigate to example.com and take a screenshot",
        tools
    )
```

### Pemprosesan Data
```python
# Example: File analysis
async def data_processing_example():
    tools = await setup_file_tools()
    response = await llm_client.generate_response(
        "Analyze the CSV file and generate a summary report",
        tools
    )
```

### Integrasi API
```python
# Example: API interactions
async def api_integration_example():
    tools = await setup_api_tools()
    response = await llm_client.generate_response(
        "Fetch weather data and create a forecast summary",
        tools
    )
```

## Pengoptimuman Prestasi

### Pengurusan Memori
- Pengendalian sejarah mesej yang cekap
- Pembersihan sumber yang betul
- Pengumpulan sambungan

### Pengoptimuman Rangkaian
- Operasi HTTP async
- Masa tamat yang boleh dikonfigurasi
- Pemulihan ralat yang lancar

### Pemprosesan Serentak
- I/O tanpa blok
- Pelaksanaan alat secara selari
- Corak async yang cekap

## Pertimbangan Keselamatan

### Perlindungan Data
- Pengurusan kunci API yang selamat
- Pengesahan input
- Sanitasi output

### Keselamatan Rangkaian
- Sokongan HTTPS
- Tetapan lalai titik akhir tempatan
- Pengendalian token yang selamat

### Keselamatan Pelaksanaan
- Penapisan alat
- Persekitaran sandboxed
- Log audit

## Ekosistem dan Pembangunan MCP

### Skop Projek MCP

Ekosistem Protokol Konteks Model merangkumi beberapa komponen utama:

- **[Spesifikasi MCP](https://modelcontextprotocol.io/specification/latest)**: Spesifikasi rasmi yang menggariskan keperluan pelaksanaan untuk klien dan pelayan
- **[SDK MCP](https://modelcontextprotocol.io/docs/sdk)**: SDK untuk pelbagai bahasa pengaturcaraan yang melaksanakan MCP
- **Alat Pembangunan MCP**: Alat untuk membangunkan pelayan dan klien MCP, termasuk [MCP Inspector](https://github.com/modelcontextprotocol/inspector)
- **[Pelaksanaan Pelayan Rujukan MCP](https://github.com/modelcontextprotocol/servers)**: Pelaksanaan rujukan pelayan MCP

### Memulakan Pembangunan MCP

Untuk mula membina dengan MCP:

**Bina Pelayan**: [Cipta pelayan MCP](https://modelcontextprotocol.io/docs/develop/build-server) untuk mendedahkan data dan alat anda

**Bina Klien**: [Bangunkan aplikasi](https://modelcontextprotocol.io/docs/develop/build-client) yang berhubung dengan pelayan MCP

**Belajar Konsep**: [Fahami konsep teras](https://modelcontextprotocol.io/docs/learn/architecture) dan seni bina MCP

## Kesimpulan

SLM yang diintegrasikan dengan MCP mewakili perubahan paradigma dalam pembangunan aplikasi AI. Dengan menggabungkan kecekapan model kecil dengan kuasa alat luaran, pembangun boleh mencipta sistem pintar yang cekap sumber dan sangat berkemampuan.

Protokol Konteks Model menyediakan cara standard untuk menghubungkan aplikasi AI kepada sistem luaran, sama seperti USB-C menyediakan standard sambungan universal untuk peranti elektronik. Standardisasi ini membolehkan:

- **Integrasi Lancar**: Menghubungkan model AI kepada pelbagai sumber data dan alat
- **Pertumbuhan Ekosistem**: Bina sekali, gunakan di pelbagai aplikasi AI
- **Keupayaan Dipertingkatkan**: Tingkatkan SLM dengan fungsi luaran
- **Kemas Kini Masa Nyata**: Menyokong aplikasi AI yang dinamik dan responsif

Pengajaran utama:
- MCP adalah standard terbuka yang menghubungkan aplikasi AI dan sistem luaran
- Protokol ini menyokong alat, sumber, dan arahan sebagai primitif teras
- Pemberitahuan masa nyata membolehkan aplikasi yang dinamik dan responsif
- Pengurusan kitaran hayat dan pengendalian ralat yang betul adalah penting untuk penggunaan pengeluaran
- Ekosistem ini menyediakan SDK dan alat pembangunan yang komprehensif

## Rujukan dan Bacaan Lanjut

### Dokumentasi Rasmi MCP

- **[Laman Rasmi Protokol Konteks Model](https://modelcontextprotocol.io/)** - Dokumentasi dan spesifikasi lengkap
- **[Panduan Memulakan MCP](https://modelcontextprotocol.io/docs/getting-started/intro)** - Pengenalan dan konsep teras
- **[Gambaran Keseluruhan Seni Bina MCP](https://modelcontextprotocol.io/docs/learn/architecture)** - Seni bina teknikal terperinci
- **[Spesifikasi MCP](https://modelcontextprotocol.io/specification/latest)** - Spesifikasi protokol rasmi
- **[Dokumentasi SDK MCP](https://modelcontextprotocol.io/docs/sdk)** - Panduan SDK khusus bahasa

### Sumber Pembangunan

- **[MCP untuk Pemula](https://aka.ms/mcp-for-beginners)** - Panduan pemula yang komprehensif untuk Protokol Konteks Model
- **[Organisasi GitHub MCP](https://github.com/modelcontextprotocol)** - Repositori rasmi dan contoh
- **[Repositori Pelayan MCP](https://github.com/modelcontextprotocol/servers)** - Pelaksanaan pelayan rujukan
- **[MCP Inspector](https://github.com/modelcontextprotocol/inspector)** - Alat pembangunan dan debugging
- **[Panduan Membina Pelayan MCP](https://modelcontextprotocol.io/docs/develop/build-server)** - Tutorial pembangunan pelayan
- **[Panduan Membina Klien MCP](https://modelcontextprotocol.io/docs/develop/build-client)** - Tutorial pembangunan klien

### Model Bahasa Kecil dan AI Tepi

- **[Model Phi Microsoft](https://aka.ms/phicookbook)** - Keluarga model Phi 
- **[Dokumentasi Foundry Local](https://github.com/microsoft/Foundry-Local)** - Runtime AI tepi Microsoft
- **[Dokumentasi Ollama](https://ollama.ai/docs)** - Platform penyebaran LLM secara tempatan
- **[Dokumentasi vLLM](https://docs.vllm.ai/)** - Penyediaan LLM berprestasi tinggi

### Piawaian Teknikal dan Protokol

- **[Spesifikasi JSON-RPC 2.0](https://www.jsonrpc.org/)** - Protokol RPC asas yang digunakan oleh MCP
- **[JSON Schema](https://json-schema.org/)** - Piawaian definisi skema untuk alat MCP
- **[Spesifikasi OpenAPI](https://swagger.io/specification/)** - Piawaian dokumentasi API
- **[Server-Sent Events (SSE)](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events)** - Piawaian web untuk kemas kini masa nyata

### Pembangunan Ejen AI

- **[Kerangka Ejen Microsoft](https://github.com/microsoft/agent-framework)** - Pembangunan ejen yang sedia untuk pengeluaran
- **[Dokumentasi LangChain](https://docs.langchain.com/)** - Kerangka integrasi ejen dan alat
- **[Kernel Semantik](https://learn.microsoft.com/en-us/semantic-kernel/)** - SDK orkestrasi AI dari Microsoft

### Laporan Industri dan Penyelidikan

- **[Pengumuman Protokol Konteks Model oleh Anthropic](https://www.anthropic.com/news/model-context-protocol)** - Pengenalan MCP asal
- **[Kajian Model Bahasa Kecil](https://arxiv.org/abs/2410.20011)** - Kajian akademik mengenai penyelidikan SLM
- **[Analisis Pasaran AI Tepi](https://www.marketsandmarkets.com/Market-Reports/edge-ai-software-market-74385617.html)** - Trend dan ramalan industri
- **[Amalan Terbaik Pembangunan Ejen AI](https://arxiv.org/abs/2309.02427)** - Penyelidikan mengenai seni bina ejen

Bahagian ini menyediakan asas untuk membina aplikasi MCP yang dikuasakan oleh SLM anda sendiri, membuka peluang untuk automasi, pemprosesan data, dan integrasi sistem pintar.

## ➡️ Apa yang seterusnya

- [Modul 7. Sampel AI Tepi](../Module07/README.md)

---

**Penafian**:  
Dokumen ini telah diterjemahkan menggunakan perkhidmatan terjemahan AI [Co-op Translator](https://github.com/Azure/co-op-translator). Walaupun kami berusaha untuk ketepatan, sila ambil perhatian bahawa terjemahan automatik mungkin mengandungi kesilapan atau ketidaktepatan. Dokumen asal dalam bahasa asalnya harus dianggap sebagai sumber yang berwibawa. Untuk maklumat kritikal, terjemahan manusia profesional adalah disyorkan. Kami tidak bertanggungjawab atas sebarang salah faham atau salah tafsir yang timbul daripada penggunaan terjemahan ini.