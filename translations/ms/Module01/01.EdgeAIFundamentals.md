<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "be25052ac4c842765e7f6f7eb4d7dcc5",
  "translation_date": "2025-10-20T09:53:14+00:00",
  "source_file": "Module01/01.EdgeAIFundamentals.md",
  "language_code": "ms"
}
-->
# Seksyen 1: Asas EdgeAI

EdgeAI mewakili perubahan paradigma dalam pelaksanaan kecerdasan buatan, membawa keupayaan AI terus ke peranti tepi tanpa bergantung sepenuhnya pada pemprosesan berasaskan awan. Penting untuk memahami bagaimana EdgeAI membolehkan pemprosesan AI tempatan pada peranti dengan sumber yang terhad sambil mengekalkan prestasi yang munasabah dan menangani cabaran seperti privasi, kependaman, dan keupayaan luar talian.

## Pengenalan

Dalam pelajaran ini, kita akan meneroka EdgeAI dan konsep asasnya. Kita akan membincangkan paradigma pengkomputeran AI tradisional, cabaran pengkomputeran tepi, teknologi utama yang memungkinkan EdgeAI, dan aplikasi praktikal dalam pelbagai industri.

## Objektif Pembelajaran

Pada akhir pelajaran ini, anda akan dapat:

- Memahami perbezaan antara pendekatan AI berasaskan awan tradisional dan EdgeAI.
- Mengenal pasti teknologi utama yang memungkinkan pemprosesan AI pada peranti tepi.
- Mengenali manfaat dan batasan pelaksanaan EdgeAI.
- Mengaplikasikan pengetahuan tentang EdgeAI dalam senario dunia nyata dan kes penggunaan.

## Memahami Paradigma Pengkomputeran AI Tradisional

Secara tradisional, aplikasi AI generatif bergantung pada infrastruktur pengkomputeran berprestasi tinggi untuk menjalankan model bahasa besar (LLM) dengan berkesan. Organisasi biasanya melaksanakan model ini pada kluster GPU dalam persekitaran awan, mengakses keupayaannya melalui antara muka API.

Model berpusat ini berfungsi dengan baik untuk banyak aplikasi tetapi mempunyai batasan yang wujud apabila melibatkan senario pengkomputeran tepi. Pendekatan konvensional melibatkan penghantaran pertanyaan pengguna ke pelayan jauh, memprosesnya menggunakan perkakasan yang berkuasa, dan mengembalikan hasil melalui internet. Walaupun kaedah ini menyediakan akses kepada model terkini, ia mencipta kebergantungan pada sambungan internet, memperkenalkan kebimbangan kependaman, dan menimbulkan isu privasi apabila data sensitif perlu dihantar ke pelayan luar.

Terdapat beberapa konsep teras yang perlu kita fahami semasa bekerja dengan paradigma pengkomputeran AI tradisional iaitu:

- **☁️ Pemprosesan Berasaskan Awan**: Model AI dijalankan pada infrastruktur pelayan yang berkuasa dengan sumber pengkomputeran yang tinggi.
- **🔌 Akses Berasaskan API**: Aplikasi mengakses keupayaan AI melalui panggilan API jauh dan bukannya pemprosesan tempatan.
- **🎛️ Pengurusan Model Berpusat**: Model dikekalkan dan dikemas kini secara berpusat, memastikan konsistensi tetapi memerlukan sambungan rangkaian.
- **📈 Skalabiliti Sumber**: Infrastruktur awan boleh meningkatkan skala secara dinamik untuk menangani permintaan pengkomputeran yang berbeza-beza.

## Cabaran Pengkomputeran Tepi

Peranti tepi seperti komputer riba, telefon bimbit, dan peranti Internet of Things (IoT) seperti Raspberry Pi dan NVIDIA Orin Nano mempunyai kekangan pengkomputeran yang unik. Peranti ini biasanya mempunyai kuasa pemprosesan, memori, dan sumber tenaga yang terhad berbanding infrastruktur pusat data.

Menjalankan LLM tradisional pada peranti sedemikian secara sejarahnya mencabar disebabkan oleh batasan perkakasan ini. Walau bagaimanapun, keperluan untuk pemprosesan AI tepi menjadi semakin penting dalam pelbagai senario. Pertimbangkan situasi di mana sambungan internet tidak boleh dipercayai atau tidak tersedia, seperti tapak industri terpencil, kenderaan dalam perjalanan, atau kawasan dengan liputan rangkaian yang lemah. Selain itu, aplikasi yang memerlukan standard keselamatan tinggi, seperti peranti perubatan, sistem kewangan, atau aplikasi kerajaan, mungkin perlu memproses data sensitif secara tempatan untuk mengekalkan privasi dan keperluan pematuhan.

### Kekangan Utama Pengkomputeran Tepi

Persekitaran pengkomputeran tepi menghadapi beberapa kekangan asas yang tidak dihadapi oleh penyelesaian AI berasaskan awan tradisional:

- **Kuasa Pemprosesan Terhad**: Peranti tepi biasanya mempunyai teras CPU yang lebih sedikit dan kelajuan jam yang lebih rendah berbanding perkakasan gred pelayan.
- **Kekangan Memori**: RAM dan kapasiti storan yang tersedia jauh lebih kecil pada peranti tepi.
- **Had Kuasa**: Peranti yang menggunakan bateri perlu mengimbangi prestasi dengan penggunaan tenaga untuk operasi yang berpanjangan.
- **Pengurusan Terma**: Faktor bentuk yang padat mengehadkan keupayaan penyejukan, yang mempengaruhi prestasi berterusan di bawah beban.

## Apa itu EdgeAI?

### Konsep: Definisi Edge AI

Edge AI merujuk kepada pelaksanaan dan pelaksanaan algoritma kecerdasan buatan secara langsung pada peranti tepi—perkakasan fizikal yang wujud di "tepi" rangkaian, dekat dengan tempat data dihasilkan dan dikumpulkan. Peranti ini termasuk telefon pintar, sensor IoT, kamera pintar, kenderaan autonomi, peranti boleh pakai, dan peralatan industri. Tidak seperti sistem AI tradisional yang bergantung pada pelayan awan untuk pemprosesan, Edge AI membawa kecerdasan terus ke sumber data.

Pada asasnya, Edge AI adalah tentang mendesentralisasi pemprosesan AI, mengalihkannya dari pusat data berpusat dan menyebarkannya ke seluruh rangkaian peranti yang membentuk ekosistem digital kita. Ini mewakili perubahan asas dalam cara sistem AI direka dan dilaksanakan.

Tiang konsep utama Edge AI termasuk:

- **Pemprosesan Berdekatan**: Pengiraan berlaku secara fizikal dekat dengan tempat data berasal.
- **Kecerdasan Desentralisasi**: Keupayaan membuat keputusan diedarkan di seluruh pelbagai peranti.
- **Kedaulatan Data**: Maklumat kekal di bawah kawalan tempatan, sering kali tidak meninggalkan peranti.
- **Operasi Autonomi**: Peranti boleh berfungsi dengan bijak tanpa memerlukan sambungan berterusan.
- **AI Tertanam**: Kecerdasan menjadi keupayaan intrinsik peranti harian.

### Visualisasi Seni Bina Edge AI

```
┌─────────────────────────────────────────────────────────────────────┐
│                         TRADITIONAL AI ARCHITECTURE                 │
└─────────────────────────────────────────────────────────────────────┘
                                  │
┌──────────────┐   Data Transfer  ┌───────────────┐   API Response   ┌───────────┐
│ Edge Devices ├─────────────────>│ Cloud Servers │────────────────> │ End Users │
└──────────────┘                  └───────────────┘                  └───────────┘
     Data                         Model Inference                     Results
   Collection                     High Latency
                                  High Bandwidth
                                  Privacy Concerns
                               
┌─────────────────────────────────────────────────────────────────────┐
│                            EDGE AI ARCHITECTURE                     │
└─────────────────────────────────────────────────────────────────────┘
                                  │
┌────────────────────────────────────────────────────┐   Direct Response  ┌───────────┐
│              Edge Devices with Embedded AI         │───────────────────>│ End Users │
│  ┌─────────┐  ┌───────────────┐  ┌──────────────┐  │                    └───────────┘
│  │ Sensors │─>│ SLM Inference │─>│ Local Action │  │
│  └─────────┘  └───────────────┘  └──────────────┘  │
└────────────────────────────────────────────────────┘
     Data         Low Latency       Immediate
   Collection     Processing        Response
                  No Data Transfer
                  Enhanced Privacy
```

EdgeAI mewakili perubahan paradigma dalam pelaksanaan kecerdasan buatan, membawa keupayaan AI terus ke peranti tepi tanpa bergantung sepenuhnya pada pemprosesan berasaskan awan. Pendekatan ini membolehkan model AI dijalankan secara tempatan pada peranti dengan sumber pengkomputeran yang terhad, menyediakan keupayaan inferens masa nyata tanpa memerlukan sambungan internet yang berterusan.

EdgeAI merangkumi pelbagai teknologi dan teknik yang direka untuk menjadikan model AI lebih cekap dan sesuai untuk pelaksanaan pada peranti dengan sumber terhad. Matlamatnya adalah untuk mengekalkan prestasi yang munasabah sambil mengurangkan keperluan pengkomputeran dan memori model AI dengan ketara.

Mari kita lihat pendekatan asas yang memungkinkan pelaksanaan EdgeAI merentasi pelbagai jenis peranti dan kes penggunaan.

### Prinsip Asas EdgeAI

EdgeAI dibina berdasarkan beberapa prinsip asas yang membezakannya daripada AI berasaskan awan tradisional:

- **Pemprosesan Tempatan**: Inferens AI berlaku secara langsung pada peranti tepi tanpa memerlukan sambungan luaran.
- **Pengoptimuman Sumber**: Model dioptimumkan khusus untuk kekangan perkakasan peranti sasaran.
- **Prestasi Masa Nyata**: Pemprosesan berlaku dengan kependaman minimum untuk aplikasi yang sensitif terhadap masa.
- **Privasi Secara Reka Bentuk**: Data sensitif kekal pada peranti, meningkatkan keselamatan dan pematuhan.

## Teknologi Utama yang Memungkinkan EdgeAI

### Kuantisasi Model

Salah satu teknik paling penting dalam EdgeAI adalah kuantisasi model. Proses ini melibatkan pengurangan ketepatan parameter model, biasanya dari nombor titik terapung 32-bit kepada integer 8-bit atau format ketepatan yang lebih rendah. Walaupun pengurangan ketepatan ini mungkin kelihatan membimbangkan, penyelidikan telah menunjukkan bahawa banyak model AI dapat mengekalkan prestasi mereka walaupun dengan ketepatan yang dikurangkan dengan ketara.

Kuantisasi berfungsi dengan memetakan julat nilai titik terapung kepada set nilai diskret yang lebih kecil. Sebagai contoh, daripada menggunakan 32 bit untuk mewakili setiap parameter, kuantisasi mungkin hanya menggunakan 8 bit, menghasilkan pengurangan keperluan memori sebanyak 4x dan sering membawa kepada masa inferens yang lebih cepat.

```python
# Example: PyTorch model quantization 
import torch

# Load a pre-trained model
model = torch.load('large_model.pth')

# Quantize the model to INT8
quantized_model = torch.quantization.quantize_dynamic(
    model,  # model to quantize
    {torch.nn.Linear, torch.nn.Conv2d},  # layers to quantize
    dtype=torch.qint8  # quantization data type
)

# Save the quantized model
torch.save(quantized_model, 'quantized_model.pth')

# Memory usage comparison
original_size = model.size()
quantized_size = quantized_model.size()
print(f"Memory reduction: {original_size / quantized_size:.2f}x")
```

Teknik kuantisasi yang berbeza termasuk:

- **Kuantisasi Selepas Latihan (PTQ)**: Digunakan selepas latihan model tanpa memerlukan latihan semula.
- **Latihan Sedar Kuantisasi (QAT)**: Menggabungkan kesan kuantisasi semasa latihan untuk ketepatan yang lebih baik.
- **Kuantisasi Dinamik**: Mengkuantisasi berat kepada int8 tetapi mengira pengaktifan secara dinamik.
- **Kuantisasi Statik**: Pra-mengira semua parameter kuantisasi untuk kedua-dua berat dan pengaktifan.

Untuk pelaksanaan EdgeAI, pemilihan strategi kuantisasi yang sesuai bergantung pada seni bina model tertentu, keperluan prestasi, dan keupayaan perkakasan peranti sasaran.

### Pemampatan dan Pengoptimuman Model

Selain kuantisasi, pelbagai teknik pemampatan membantu mengurangkan saiz model dan keperluan pengkomputeran. Ini termasuk:

**Pemangkasan**: Teknik ini menghapuskan sambungan atau neuron yang tidak diperlukan dari rangkaian neural. Dengan mengenal pasti dan menghapuskan parameter yang kurang menyumbang kepada prestasi model, pemangkasan dapat mengurangkan saiz model dengan ketara sambil mengekalkan ketepatan.

```python
# Example: Neural network pruning in TensorFlow
import tensorflow as tf
import tensorflow_model_optimization as tfmot

# Define the model
model = tf.keras.Sequential([
    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

# Apply pruning during training
pruning_schedule = tfmot.sparsity.keras.PolynomialDecay(
    initial_sparsity=0.0,
    final_sparsity=0.5,  # 50% of connections will be pruned
    begin_step=0,
    end_step=10000
)

pruned_model = tfmot.sparsity.keras.prune_low_magnitude(
    model, pruning_schedule=pruning_schedule
)

# Compile the pruned model
pruned_model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# Train the model while pruning
pruned_model.fit(x_train, y_train, epochs=10)

# Convert to a smaller model for deployment
final_model = tfmot.sparsity.keras.strip_pruning(pruned_model)
```

**Distilasi Pengetahuan**: Pendekatan ini melibatkan latihan model "pelajar" yang lebih kecil untuk meniru tingkah laku model "guru" yang lebih besar. Model pelajar belajar untuk menghampiri output guru, sering mencapai prestasi yang serupa dengan parameter yang jauh lebih sedikit.

**Pengoptimuman Seni Bina Model**: Penyelidik telah membangunkan seni bina khusus yang direka khas untuk pelaksanaan tepi, seperti MobileNets, EfficientNets, dan seni bina ringan lain yang mengimbangi prestasi dengan kecekapan pengkomputeran.

### Model Bahasa Kecil (SLM)

Trend yang semakin berkembang dalam EdgeAI adalah pembangunan Model Bahasa Kecil (SLM). Model ini direka dari awal untuk menjadi padat dan cekap sambil tetap menyediakan keupayaan bahasa semula jadi yang bermakna. SLM mencapai ini melalui pilihan seni bina yang teliti, teknik latihan yang cekap, dan latihan yang difokuskan pada domain atau tugas tertentu.

Tidak seperti pendekatan tradisional yang melibatkan pemampatan model besar, SLM sering dilatih dengan dataset yang lebih kecil dan seni bina yang dioptimumkan khusus untuk pelaksanaan tepi. Pendekatan ini boleh menghasilkan model yang bukan sahaja lebih kecil tetapi juga lebih cekap untuk kes penggunaan tertentu.

## Pecutan Perkakasan untuk EdgeAI

Peranti tepi moden semakin termasuk perkakasan khusus yang direka untuk mempercepatkan beban kerja AI:

### Unit Pemprosesan Neural (NPUs)

NPUs adalah pemproses khusus yang direka khas untuk pengiraan rangkaian neural. Cip ini boleh melaksanakan tugas inferens AI dengan lebih cekap daripada CPU tradisional, sering dengan penggunaan kuasa yang lebih rendah. Banyak telefon pintar, komputer riba, dan peranti IoT moden kini termasuk NPUs untuk memungkinkan pemprosesan AI pada peranti.

```csharp
// Example: Using Windows ML to target NPU acceleration in C#
using Microsoft.ML.OnnxRuntime;

// Create session options with NPU provider
var sessionOptions = new SessionOptions();
sessionOptions.AppendExecutionProvider_DmlExecutionProvider();  // DirectML for NPU

// Load the ONNX model
using var session = new InferenceSession("model.onnx", sessionOptions);

// Create input tensor
var inputTensor = new DenseTensor<float>(new[] { 1, 3, 224, 224 });  // Example input shape
var inputs = new List<NamedOnnxValue> { NamedOnnxValue.CreateFromTensor("input", inputTensor) };

// Run inference with NPU acceleration
using var results = session.Run(inputs);
var output = results.First().AsTensor<float>();

// Process output
Console.WriteLine($"Inference result: {output[0]}");
```

Peranti dengan NPUs termasuk:

- **Apple**: Cip siri A dan siri M dengan Neural Engine
- **Qualcomm**: Pemproses Snapdragon dengan Hexagon DSP/NPU
- **Samsung**: Pemproses Exynos dengan NPU
- **Intel**: Movidius VPUs dan pemecut Habana Labs
- **Microsoft**: Windows Copilot+ PC dengan NPUs

### 🎮 Pecutan GPU

Walaupun peranti tepi mungkin tidak mempunyai GPU yang berkuasa seperti yang terdapat di pusat data, banyak yang masih termasuk GPU bersepadu atau diskret yang boleh mempercepatkan beban kerja AI. GPU mudah alih moden dan pemproses grafik bersepadu boleh memberikan peningkatan prestasi yang ketara untuk tugas inferens AI.

```python
# Example: Using TensorRT for GPU acceleration on edge devices
import tensorrt as trt
import numpy as np

# Create TensorRT logger and builder
TRT_LOGGER = trt.Logger(trt.Logger.WARNING)
builder = trt.Builder(TRT_LOGGER)
network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))
parser = trt.OnnxParser(network, TRT_LOGGER)

# Parse ONNX model
with open('model.onnx', 'rb') as model:
    parser.parse(model.read())

# Configure builder
config = builder.create_builder_config()
config.max_workspace_size = 1 << 28  # 256 MiB
config.set_flag(trt.BuilderFlag.FP16)  # Use FP16 precision for edge GPU

# Build and serialize engine
engine = builder.build_engine(network, config)
with open('model.trt', 'wb') as f:
    f.write(engine.serialize())
```

### Pengoptimuman CPU

Malah peranti yang hanya menggunakan CPU boleh mendapat manfaat daripada EdgeAI melalui pelaksanaan yang dioptimumkan. CPU moden termasuk arahan khusus untuk beban kerja AI, dan rangka kerja perisian telah dibangunkan untuk memaksimumkan prestasi CPU untuk inferens AI.

```bash
# Example: Using XNNPACK with TFLite for optimized CPU inference
# Compilation command with XNNPACK acceleration enabled

bazel build -c opt --copt=-O3 --copt=-march=native \
  tensorflow/lite/delegates/xnnpack:libxnnpack_delegate.so

# Convert TensorFlow model to TFLite with optimization
tflite_convert \
  --keras_model_file=model.h5 \
  --output_file=model.tflite \
  --inference_type=FLOAT \
  --experimental_new_converter \
  --experimental_new_quantizer
```

Bagi jurutera perisian yang bekerja dengan EdgeAI, memahami cara memanfaatkan pilihan pecutan perkakasan ini adalah penting untuk mengoptimumkan prestasi inferens dan kecekapan tenaga pada peranti sasaran.

## Manfaat EdgeAI

### Privasi dan Keselamatan

Salah satu kelebihan terbesar EdgeAI adalah peningkatan privasi dan keselamatan. Dengan memproses data secara tempatan pada peranti, maklumat sensitif tidak pernah meninggalkan kawalan pengguna. Ini sangat penting untuk aplikasi yang mengendalikan data peribadi, maklumat perubatan, atau data perniagaan yang sulit.

### Pengurangan Kependaman
EdgeAI menghapuskan keperluan untuk menghantar data ke pelayan jauh untuk pemprosesan, mengurangkan kependaman dengan ketara. Ini penting untuk aplikasi masa nyata seperti kenderaan autonomi, automasi industri, atau aplikasi interaktif yang memerlukan tindak balas segera.

### Keupayaan Luar Talian

EdgeAI memungkinkan fungsi AI walaupun sambungan internet tidak tersedia. Ini sangat berharga untuk aplikasi di lokasi terpencil, semasa perjalanan, atau dalam situasi di mana kebolehpercayaan rangkaian menjadi kebimbangan.

### Kecekapan Kos

Dengan mengurangkan kebergantungan pada perkhidmatan AI berasaskan awan, EdgeAI dapat membantu mengurangkan kos operasi, terutamanya untuk aplikasi dengan jumlah penggunaan yang tinggi. Organisasi dapat mengelakkan kos API yang berterusan dan mengurangkan keperluan jalur lebar.

### Skalabiliti

EdgeAI mengedarkan beban pengkomputeran di seluruh peranti tepi dan bukannya memusatkannya di pusat data. Ini dapat membantu mengurangkan kos infrastruktur dan meningkatkan skalabiliti sistem secara keseluruhan.

## Aplikasi EdgeAI

### Peranti Pintar dan IoT

EdgeAI menggerakkan banyak ciri peranti pintar, daripada pembantu suara yang dapat memproses arahan secara tempatan hingga kamera pintar yang dapat mengenal pasti objek dan orang tanpa menghantar video ke awan. Peranti IoT menggunakan EdgeAI untuk penyelenggaraan ramalan, pemantauan persekitaran, dan pembuatan keputusan automatik.

### Aplikasi Mudah Alih

Telefon pintar dan tablet menggunakan EdgeAI untuk pelbagai ciri, termasuk peningkatan foto, terjemahan masa nyata, realiti tambahan, dan cadangan yang diperibadikan. Aplikasi ini mendapat manfaat daripada kelebihan kependaman rendah dan privasi pemprosesan tempatan.

### Aplikasi Industri

Persekitaran pembuatan dan industri menggunakan EdgeAI untuk kawalan kualiti, penyelenggaraan ramalan, dan pengoptimuman proses. Aplikasi ini sering memerlukan pemprosesan masa nyata dan mungkin beroperasi dalam persekitaran dengan sambungan yang terhad.

### Penjagaan Kesihatan

Peranti perubatan dan aplikasi penjagaan kesihatan menggunakan EdgeAI untuk pemantauan pesakit, bantuan diagnostik, dan cadangan rawatan. Kelebihan privasi dan keselamatan pemprosesan tempatan sangat penting dalam aplikasi penjagaan kesihatan.

## Cabaran dan Batasan

### Pertukaran Prestasi

EdgeAI biasanya melibatkan pertukaran antara saiz model, kecekapan pengkomputeran, dan prestasi. Walaupun teknik seperti kuantisasi dan pemangkasan dapat mengurangkan keperluan sumber dengan ketara, ia juga mungkin memberi kesan kepada ketepatan atau keupayaan model.

### Kerumitan Pembangunan

Membangunkan aplikasi EdgeAI memerlukan pengetahuan dan alat khusus. Pembangun perlu memahami teknik pengoptimuman, keupayaan perkakasan, dan kekangan pelaksanaan, yang boleh meningkatkan kerumitan pembangunan.

### Batasan Perkakasan

Walaupun terdapat kemajuan dalam perkakasan tepi, peranti ini masih mempunyai batasan yang ketara berbanding infrastruktur pusat data. Tidak semua aplikasi AI dapat dilaksanakan dengan berkesan pada peranti tepi, dan sesetengahnya mungkin memerlukan pendekatan hibrid.

### Kemas Kini dan Penyelenggaraan Model

Mengemas kini model AI yang dilaksanakan pada peranti tepi boleh menjadi mencabar, terutamanya untuk peranti dengan sambungan atau kapasiti storan yang terhad. Organisasi perlu membangunkan strategi untuk versi model, kemas kini, dan penyelenggaraan.

## Masa Depan EdgeAI

Landskap EdgeAI terus berkembang pesat, dengan perkembangan berterusan dalam perkakasan, perisian, dan teknik. Trend masa depan termasuk cip AI tepi yang lebih khusus, teknik pengoptimuman yang lebih baik, dan alat yang lebih baik untuk pembangunan dan pelaksanaan EdgeAI.

Apabila rangkaian 5G menjadi lebih meluas, kita mungkin melihat pendekatan hibrid yang menggabungkan pemprosesan tepi dengan keupayaan awan, memungkinkan aplikasi AI yang lebih canggih sambil mengekalkan manfaat pemprosesan tempatan.

EdgeAI mewakili perubahan asas ke arah sistem AI yang lebih terdesentralisasi, cekap, dan memelihara privasi. Apabila teknologi terus matang, kita boleh menjangkakan EdgeAI menjadi semakin penting dalam memungkinkan keupayaan AI di seluruh pelbagai aplikasi dan peranti.

Demokratisasi AI melalui EdgeAI membuka kemungkinan baru untuk inovasi, membolehkan pembangun mencipta aplikasi berkuasa AI yang berfungsi dengan boleh dipercayai dalam persekitaran yang pelbagai sambil menghormati privasi pengguna dan menyediakan pengalaman masa nyata yang responsif. Memahami EdgeAI menjadi semakin penting bagi sesiapa yang bekerja dengan teknologi AI, kerana ia mewakili masa depan bagaimana AI akan dilaksanakan dan dialami dalam kehidupan seharian kita.

## ➡️ Apa yang seterusnya
- [02: Aplikasi EdgeAI](02.RealWorldCaseStudies.md)

---

**Penafian**:  
Dokumen ini telah diterjemahkan menggunakan perkhidmatan terjemahan AI [Co-op Translator](https://github.com/Azure/co-op-translator). Walaupun kami berusaha untuk ketepatan, sila ambil perhatian bahawa terjemahan automatik mungkin mengandungi kesilapan atau ketidaktepatan. Dokumen asal dalam bahasa asalnya harus dianggap sebagai sumber yang berwibawa. Untuk maklumat penting, terjemahan manusia profesional adalah disyorkan. Kami tidak bertanggungjawab atas sebarang salah faham atau salah tafsir yang timbul daripada penggunaan terjemahan ini.