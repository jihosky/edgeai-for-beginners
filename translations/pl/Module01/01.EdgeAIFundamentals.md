<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "be25052ac4c842765e7f6f7eb4d7dcc5",
  "translation_date": "2025-10-20T09:45:35+00:00",
  "source_file": "Module01/01.EdgeAIFundamentals.md",
  "language_code": "pl"
}
-->
# Sekcja 1: Podstawy EdgeAI

EdgeAI to nowy sposób wdrażania sztucznej inteligencji, który przenosi jej możliwości bezpośrednio na urządzenia brzegowe, zamiast polegać wyłącznie na przetwarzaniu w chmurze. Ważne jest zrozumienie, jak EdgeAI umożliwia lokalne przetwarzanie AI na urządzeniach o ograniczonych zasobach, jednocześnie utrzymując odpowiednią wydajność i rozwiązując problemy takie jak prywatność, opóźnienia czy działanie offline.

## Wprowadzenie

W tej lekcji zgłębimy temat EdgeAI i jego podstawowe koncepcje. Omówimy tradycyjny paradygmat obliczeń AI, wyzwania związane z przetwarzaniem na brzegu sieci, kluczowe technologie umożliwiające EdgeAI oraz praktyczne zastosowania w różnych branżach.

## Cele nauki

Po zakończeniu tej lekcji będziesz w stanie:

- Zrozumieć różnicę między tradycyjnym podejściem AI opartym na chmurze a podejściem EdgeAI.
- Zidentyfikować kluczowe technologie umożliwiające przetwarzanie AI na urządzeniach brzegowych.
- Rozpoznać korzyści i ograniczenia wdrożeń EdgeAI.
- Zastosować wiedzę o EdgeAI w rzeczywistych scenariuszach i przypadkach użycia.

## Zrozumienie tradycyjnego paradygmatu obliczeń AI

Tradycyjnie aplikacje generatywnej AI opierają się na infrastrukturze obliczeniowej o wysokiej wydajności, aby skutecznie uruchamiać duże modele językowe (LLM). Organizacje zazwyczaj wdrażają te modele na klastrach GPU w środowiskach chmurowych, uzyskując dostęp do ich możliwości za pośrednictwem interfejsów API.

Ten scentralizowany model sprawdza się w wielu aplikacjach, ale ma wady w scenariuszach przetwarzania na brzegu sieci. Tradycyjne podejście polega na przesyłaniu zapytań użytkownika do zdalnych serwerów, przetwarzaniu ich za pomocą wydajnego sprzętu i zwracaniu wyników przez internet. Chociaż metoda ta zapewnia dostęp do najnowocześniejszych modeli, tworzy zależności od łączności internetowej, wprowadza opóźnienia i rodzi obawy dotyczące prywatności, gdy wrażliwe dane muszą być przesyłane na zewnętrzne serwery.

Istnieje kilka kluczowych koncepcji, które należy zrozumieć, pracując z tradycyjnymi paradygmatami obliczeń AI, mianowicie:

- **☁️ Przetwarzanie w chmurze**: Modele AI działają na potężnej infrastrukturze serwerowej z dużymi zasobami obliczeniowymi.
- **🔌 Dostęp przez API**: Aplikacje uzyskują dostęp do możliwości AI za pośrednictwem zdalnych wywołań API, zamiast lokalnego przetwarzania.
- **🎛️ Scentralizowane zarządzanie modelami**: Modele są utrzymywane i aktualizowane centralnie, co zapewnia spójność, ale wymaga łączności sieciowej.
- **📈 Skalowalność zasobów**: Infrastruktura chmurowa może dynamicznie skalować się, aby sprostać zmiennym wymaganiom obliczeniowym.

## Wyzwania przetwarzania na brzegu sieci

Urządzenia brzegowe, takie jak laptopy, telefony komórkowe czy urządzenia Internetu Rzeczy (IoT) jak Raspberry Pi i NVIDIA Orin Nano, mają unikalne ograniczenia obliczeniowe. Zazwyczaj dysponują one mniejszą mocą obliczeniową, pamięcią i zasobami energetycznymi w porównaniu z infrastrukturą centrów danych.

Uruchamianie tradycyjnych LLM na takich urządzeniach było historycznie trudne z powodu tych ograniczeń sprzętowych. Jednak potrzeba przetwarzania AI na brzegu sieci staje się coraz bardziej istotna w różnych scenariuszach. Weźmy pod uwagę sytuacje, w których łączność internetowa jest zawodna lub niedostępna, takie jak odległe miejsca przemysłowe, pojazdy w ruchu czy obszary o słabym zasięgu sieci. Dodatkowo aplikacje wymagające wysokich standardów bezpieczeństwa, takie jak urządzenia medyczne, systemy finansowe czy aplikacje rządowe, mogą potrzebować lokalnego przetwarzania danych w celu zachowania prywatności i zgodności z przepisami.

### Kluczowe ograniczenia przetwarzania na brzegu sieci

Środowiska przetwarzania na brzegu sieci napotykają kilka fundamentalnych ograniczeń, których nie doświadczają tradycyjne rozwiązania AI oparte na chmurze:

- **Ograniczona moc obliczeniowa**: Urządzenia brzegowe zazwyczaj mają mniej rdzeni CPU i niższe taktowanie w porównaniu z serwerami.
- **Ograniczenia pamięci**: Dostępna pamięć RAM i pojemność magazynowa są znacznie mniejsze na urządzeniach brzegowych.
- **Ograniczenia energetyczne**: Urządzenia zasilane bateriami muszą równoważyć wydajność z zużyciem energii, aby działać przez dłuższy czas.
- **Zarządzanie termiczne**: Kompaktowe formy urządzeń ograniczają możliwości chłodzenia, co wpływa na wydajność pod obciążeniem.

## Czym jest EdgeAI?

### Koncepcja: Definicja Edge AI

Edge AI odnosi się do wdrażania i wykonywania algorytmów sztucznej inteligencji bezpośrednio na urządzeniach brzegowych—fizycznym sprzęcie znajdującym się na "krawędzi" sieci, blisko miejsca, gdzie dane są generowane i zbierane. Do tych urządzeń należą smartfony, czujniki IoT, inteligentne kamery, pojazdy autonomiczne, urządzenia noszone oraz sprzęt przemysłowy. W przeciwieństwie do tradycyjnych systemów AI, które polegają na serwerach chmurowych do przetwarzania, Edge AI przenosi inteligencję bezpośrednio do źródła danych.

W swojej istocie Edge AI polega na decentralizacji przetwarzania AI, przenosząc je z centralnych centrów danych i rozpraszając w rozległej sieci urządzeń, które tworzą nasz cyfrowy ekosystem. To fundamentalna zmiana w architekturze projektowania i wdrażania systemów AI.

Kluczowe filary koncepcyjne Edge AI obejmują:

- **Przetwarzanie w pobliżu**: Obliczenia odbywają się fizycznie blisko miejsca, gdzie dane powstają.
- **Zdecentralizowana inteligencja**: Zdolności decyzyjne są rozproszone na wiele urządzeń.
- **Suwerenność danych**: Informacje pozostają pod lokalną kontrolą, często nigdy nie opuszczając urządzenia.
- **Autonomiczne działanie**: Urządzenia mogą działać inteligentnie bez konieczności stałej łączności.
- **Wbudowana inteligencja**: Inteligencja staje się integralną częścią codziennych urządzeń.

### Wizualizacja architektury Edge AI

```
┌─────────────────────────────────────────────────────────────────────┐
│                         TRADITIONAL AI ARCHITECTURE                 │
└─────────────────────────────────────────────────────────────────────┘
                                  │
┌──────────────┐   Data Transfer  ┌───────────────┐   API Response   ┌───────────┐
│ Edge Devices ├─────────────────>│ Cloud Servers │────────────────> │ End Users │
└──────────────┘                  └───────────────┘                  └───────────┘
     Data                         Model Inference                     Results
   Collection                     High Latency
                                  High Bandwidth
                                  Privacy Concerns
                               
┌─────────────────────────────────────────────────────────────────────┐
│                            EDGE AI ARCHITECTURE                     │
└─────────────────────────────────────────────────────────────────────┘
                                  │
┌────────────────────────────────────────────────────┐   Direct Response  ┌───────────┐
│              Edge Devices with Embedded AI         │───────────────────>│ End Users │
│  ┌─────────┐  ┌───────────────┐  ┌──────────────┐  │                    └───────────┘
│  │ Sensors │─>│ SLM Inference │─>│ Local Action │  │
│  └─────────┘  └───────────────┘  └──────────────┘  │
└────────────────────────────────────────────────────┘
     Data         Low Latency       Immediate
   Collection     Processing        Response
                  No Data Transfer
                  Enhanced Privacy
```

EdgeAI reprezentuje zmianę paradygmatu w wdrażaniu sztucznej inteligencji, przenosząc jej możliwości bezpośrednio na urządzenia brzegowe, zamiast polegać wyłącznie na przetwarzaniu w chmurze. Podejście to umożliwia uruchamianie modeli AI lokalnie na urządzeniach o ograniczonych zasobach obliczeniowych, zapewniając możliwości wnioskowania w czasie rzeczywistym bez konieczności stałej łączności internetowej.

EdgeAI obejmuje różne technologie i techniki zaprojektowane w celu uczynienia modeli AI bardziej efektywnymi i odpowiednimi do wdrożenia na urządzeniach o ograniczonych zasobach. Celem jest utrzymanie odpowiedniej wydajności przy jednoczesnym znacznym zmniejszeniu wymagań obliczeniowych i pamięciowych modeli AI.

Przyjrzyjmy się podstawowym podejściom umożliwiającym wdrożenia EdgeAI na różnych typach urządzeń i w różnych przypadkach użycia.

### Podstawowe zasady EdgeAI

EdgeAI opiera się na kilku fundamentalnych zasadach, które odróżniają go od tradycyjnego AI opartego na chmurze:

- **Lokalne przetwarzanie**: Wnioskowanie AI odbywa się bezpośrednio na urządzeniu brzegowym, bez potrzeby zewnętrznej łączności.
- **Optymalizacja zasobów**: Modele są specjalnie zoptymalizowane pod kątem ograniczeń sprzętowych docelowych urządzeń.
- **Wydajność w czasie rzeczywistym**: Przetwarzanie odbywa się z minimalnym opóźnieniem dla aplikacji wymagających szybkiej reakcji.
- **Prywatność w standardzie**: Wrażliwe dane pozostają na urządzeniu, co zwiększa bezpieczeństwo i zgodność z przepisami.

## Kluczowe technologie umożliwiające EdgeAI

### Kwantyzacja modelu

Jedną z najważniejszych technik w EdgeAI jest kwantyzacja modelu. Proces ten polega na redukcji precyzji parametrów modelu, zazwyczaj z 32-bitowych liczb zmiennoprzecinkowych do 8-bitowych liczb całkowitych lub jeszcze niższych formatów precyzji. Chociaż taka redukcja precyzji może wydawać się niepokojąca, badania wykazały, że wiele modeli AI może utrzymać swoją wydajność nawet przy znacznie zmniejszonej precyzji.

Kwantyzacja działa poprzez mapowanie zakresu wartości zmiennoprzecinkowych na mniejszy zestaw wartości dyskretnych. Na przykład, zamiast używać 32 bitów do reprezentowania każdego parametru, kwantyzacja może używać tylko 8 bitów, co prowadzi do 4-krotnego zmniejszenia wymagań pamięciowych i często szybszego czasu wnioskowania.

```python
# Example: PyTorch model quantization 
import torch

# Load a pre-trained model
model = torch.load('large_model.pth')

# Quantize the model to INT8
quantized_model = torch.quantization.quantize_dynamic(
    model,  # model to quantize
    {torch.nn.Linear, torch.nn.Conv2d},  # layers to quantize
    dtype=torch.qint8  # quantization data type
)

# Save the quantized model
torch.save(quantized_model, 'quantized_model.pth')

# Memory usage comparison
original_size = model.size()
quantized_size = quantized_model.size()
print(f"Memory reduction: {original_size / quantized_size:.2f}x")
```

Różne techniki kwantyzacji obejmują:

- **Kwantyzacja po treningu (PTQ)**: Stosowana po treningu modelu, bez konieczności ponownego trenowania.
- **Trening uwzględniający kwantyzację (QAT)**: Uwzględnia efekty kwantyzacji podczas treningu dla lepszej dokładności.
- **Dynamiczna kwantyzacja**: Kwantyzuje wagi do int8, ale oblicza aktywacje dynamicznie.
- **Statyczna kwantyzacja**: Wstępnie oblicza wszystkie parametry kwantyzacji zarówno dla wag, jak i aktywacji.

W przypadku wdrożeń EdgeAI wybór odpowiedniej strategii kwantyzacji zależy od konkretnej architektury modelu, wymagań wydajnościowych i możliwości sprzętowych docelowego urządzenia.

### Kompresja i optymalizacja modelu

Oprócz kwantyzacji, różne techniki kompresji pomagają zmniejszyć rozmiar modelu i wymagania obliczeniowe. Należą do nich:

**Przycinanie**: Technika ta usuwa niepotrzebne połączenia lub neurony z sieci neuronowych. Identyfikując i eliminując parametry, które mają niewielki wpływ na wydajność modelu, przycinanie może znacznie zmniejszyć rozmiar modelu, zachowując jednocześnie dokładność.

```python
# Example: Neural network pruning in TensorFlow
import tensorflow as tf
import tensorflow_model_optimization as tfmot

# Define the model
model = tf.keras.Sequential([
    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

# Apply pruning during training
pruning_schedule = tfmot.sparsity.keras.PolynomialDecay(
    initial_sparsity=0.0,
    final_sparsity=0.5,  # 50% of connections will be pruned
    begin_step=0,
    end_step=10000
)

pruned_model = tfmot.sparsity.keras.prune_low_magnitude(
    model, pruning_schedule=pruning_schedule
)

# Compile the pruned model
pruned_model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# Train the model while pruning
pruned_model.fit(x_train, y_train, epochs=10)

# Convert to a smaller model for deployment
final_model = tfmot.sparsity.keras.strip_pruning(pruned_model)
```

**Destylacja wiedzy**: Podejście to polega na trenowaniu mniejszego modelu "ucznia", aby naśladował zachowanie większego modelu "nauczyciela". Model uczeń uczy się naśladować wyniki nauczyciela, często osiągając podobną wydajność przy znacznie mniejszej liczbie parametrów.

**Optymalizacja architektury modelu**: Naukowcy opracowali specjalne architektury zaprojektowane specjalnie do wdrożeń na brzegu, takie jak MobileNets, EfficientNets i inne lekkie architektury, które równoważą wydajność z efektywnością obliczeniową.

### Małe modele językowe (SLM)

Nowym trendem w EdgeAI jest rozwój małych modeli językowych (SLM). Modele te są projektowane od podstaw, aby były kompaktowe i wydajne, jednocześnie oferując znaczące możliwości w zakresie języka naturalnego. SLM osiągają to dzięki starannym wyborom architektonicznym, efektywnym technikom treningowym i skoncentrowanemu treningowi na określonych domenach lub zadaniach.

W przeciwieństwie do tradycyjnych podejść, które polegają na kompresji dużych modeli, SLM są często trenowane na mniejszych zbiorach danych i zoptymalizowanych architekturach zaprojektowanych specjalnie do wdrożeń na brzegu. Podejście to może prowadzić do modeli, które są nie tylko mniejsze, ale także bardziej wydajne w określonych przypadkach użycia.

## Przyspieszenie sprzętowe dla EdgeAI

Nowoczesne urządzenia brzegowe coraz częściej zawierają specjalistyczny sprzęt zaprojektowany do przyspieszania obciążeń AI:

### Jednostki przetwarzania neuronowego (NPU)

NPU to specjalistyczne procesory zaprojektowane specjalnie do obliczeń związanych z sieciami neuronowymi. Układy te mogą wykonywać zadania wnioskowania AI znacznie bardziej efektywnie niż tradycyjne CPU, często przy niższym zużyciu energii. Wiele nowoczesnych smartfonów, laptopów i urządzeń IoT zawiera teraz NPU, aby umożliwić przetwarzanie AI na urządzeniu.

```csharp
// Example: Using Windows ML to target NPU acceleration in C#
using Microsoft.ML.OnnxRuntime;

// Create session options with NPU provider
var sessionOptions = new SessionOptions();
sessionOptions.AppendExecutionProvider_DmlExecutionProvider();  // DirectML for NPU

// Load the ONNX model
using var session = new InferenceSession("model.onnx", sessionOptions);

// Create input tensor
var inputTensor = new DenseTensor<float>(new[] { 1, 3, 224, 224 });  // Example input shape
var inputs = new List<NamedOnnxValue> { NamedOnnxValue.CreateFromTensor("input", inputTensor) };

// Run inference with NPU acceleration
using var results = session.Run(inputs);
var output = results.First().AsTensor<float>();

// Process output
Console.WriteLine($"Inference result: {output[0]}");
```

Urządzenia z NPU obejmują:

- **Apple**: Chipy serii A i M z Neural Engine
- **Qualcomm**: Procesory Snapdragon z Hexagon DSP/NPU
- **Samsung**: Procesory Exynos z NPU
- **Intel**: Movidius VPUs i akceleratory Habana Labs
- **Microsoft**: Komputery Windows Copilot+ z NPU

### 🎮 Przyspieszenie GPU

Chociaż urządzenia brzegowe mogą nie mieć potężnych GPU znajdujących się w centrach danych, wiele z nich nadal zawiera zintegrowane lub dedykowane GPU, które mogą przyspieszać obciążenia AI. Nowoczesne mobilne GPU i zintegrowane procesory graficzne mogą zapewnić znaczące poprawy wydajności dla zadań wnioskowania AI.

```python
# Example: Using TensorRT for GPU acceleration on edge devices
import tensorrt as trt
import numpy as np

# Create TensorRT logger and builder
TRT_LOGGER = trt.Logger(trt.Logger.WARNING)
builder = trt.Builder(TRT_LOGGER)
network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))
parser = trt.OnnxParser(network, TRT_LOGGER)

# Parse ONNX model
with open('model.onnx', 'rb') as model:
    parser.parse(model.read())

# Configure builder
config = builder.create_builder_config()
config.max_workspace_size = 1 << 28  # 256 MiB
config.set_flag(trt.BuilderFlag.FP16)  # Use FP16 precision for edge GPU

# Build and serialize engine
engine = builder.build_engine(network, config)
with open('model.trt', 'wb') as f:
    f.write(engine.serialize())
```

### Optymalizacja CPU

Nawet urządzenia wyposażone wyłącznie w CPU mogą korzystać z EdgeAI dzięki zoptymalizowanym implementacjom. Nowoczesne CPU zawierają specjalistyczne instrukcje dla obciążeń AI, a opracowano oprogramowanie maksymalizujące wydajność CPU dla wnioskowania AI.

```bash
# Example: Using XNNPACK with TFLite for optimized CPU inference
# Compilation command with XNNPACK acceleration enabled

bazel build -c opt --copt=-O3 --copt=-march=native \
  tensorflow/lite/delegates/xnnpack:libxnnpack_delegate.so

# Convert TensorFlow model to TFLite with optimization
tflite_convert \
  --keras_model_file=model.h5 \
  --output_file=model.tflite \
  --inference_type=FLOAT \
  --experimental_new_converter \
  --experimental_new_quantizer
```

Dla inżynierów oprogramowania pracujących z EdgeAI, zrozumienie, jak wykorzystać te opcje przyspieszenia sprzętowego, jest kluczowe dla optymalizacji wydajności wnioskowania i efektywności energetycznej na docelowych urządzeniach.

## Korzyści EdgeAI

### Prywatność i bezpieczeństwo

Jedną z najważniejszych zalet EdgeAI jest zwiększona prywatność i bezpieczeństwo. Przetwarzając dane lokalnie na urządzeniu, wrażliwe informacje nigdy nie opuszczają kontroli użytkownika. Jest to szczególnie ważne dla aplikacji obsługujących dane osobowe, informacje medyczne czy poufne dane biznesowe.

### Zmniejszone opóźnienia

EdgeAI eliminuje konieczność przesyłania danych do zdalnych serwerów w celu przetwarzania, co znacznie zmniejsza opóźnienia. Jest to kluczowe dla aplikacji w czasie rzeczywistym, takich jak pojazdy autonomiczne, automatyzacja przemysłowa czy interaktywne aplikacje wymagające natychmiastowych odpowiedzi.

### Możliwość działania offline

EdgeAI umożliwia funkcjonalność AI nawet wtedy, gdy łączność internetowa jest niedostępna. Jest to cenne dla aplikacji w odległych lokalizacjach, podczas podróży lub w sytuacjach, gdy niezawodność sieci jest problemem.

### Efektywność kosztowa

Zmniejszając zależność od usług AI opartych na chmurze, EdgeAI może pomóc obniżyć koszty operacyjne, szczególnie dla aplikacji o dużym natężeniu użytkowania. Organizacje mogą uniknąć ciągłych kosztów API i zmniejszyć wymagania dotyczące przepustowości.

### Skalowalność

EdgeAI rozkłada obciążenie obliczeniowe na urządzenia brzegowe, zamiast centralizować je w centrach danych. Może to pomóc zmniejszyć koszty infrastruktury i poprawić ogólną skalowalność systemu.

## Zastosowania EdgeAI

### Inteligentne urządzenia i IoT

EdgeAI zasila wiele funkcji inteligentnych urządzeń, od asystentów głosowych, które mogą przetwarzać polecenia lokalnie, po inteligentne kamery, które mogą identyfikować obiekty i osoby bez przesyłania wideo do chmury. Urządzenia IoT wykorzystują EdgeAI do predykcyjnej konserwacji, monitorowania
- [02: Zastosowania EdgeAI](02.RealWorldCaseStudies.md)

---

**Zastrzeżenie**:  
Ten dokument został przetłumaczony za pomocą usługi tłumaczenia AI [Co-op Translator](https://github.com/Azure/co-op-translator). Chociaż staramy się zapewnić dokładność, prosimy pamiętać, że automatyczne tłumaczenia mogą zawierać błędy lub nieścisłości. Oryginalny dokument w jego rodzimym języku powinien być uznawany za autorytatywne źródło. W przypadku informacji krytycznych zaleca się skorzystanie z profesjonalnego tłumaczenia przez człowieka. Nie ponosimy odpowiedzialności za jakiekolwiek nieporozumienia lub błędne interpretacje wynikające z użycia tego tłumaczenia.