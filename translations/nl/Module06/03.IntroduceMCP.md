<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8a7765b85f123e8a62aa3847141ca072",
  "translation_date": "2025-10-30T13:24:29+00:00",
  "source_file": "Module06/03.IntroduceMCP.md",
  "language_code": "nl"
}
-->
# Sectie 03 - Model Context Protocol (MCP) Integratie

## Introductie tot MCP (Model Context Protocol)

Het Model Context Protocol (MCP) is een open-source standaard voor het verbinden van AI-toepassingen met externe systemen. Met MCP kunnen AI-toepassingen zoals Claude of ChatGPT verbinding maken met gegevensbronnen (bijv. lokale bestanden, databases), tools (bijv. zoekmachines, rekenmachines) en workflows (bijv. gespecialiseerde prompts)—waardoor ze toegang krijgen tot belangrijke informatie en taken kunnen uitvoeren.

Zie MCP als een **USB-C poort voor AI-toepassingen**. Net zoals USB-C een gestandaardiseerde manier biedt om elektronische apparaten te verbinden, biedt MCP een gestandaardiseerde manier om AI-toepassingen te koppelen aan externe systemen.

### Wat kan MCP mogelijk maken?

MCP ontsluit krachtige mogelijkheden voor AI-toepassingen:

- **Gepersonaliseerde AI-assistenten**: Agents kunnen toegang krijgen tot je Google Agenda en Notion, en fungeren als een meer gepersonaliseerde AI-assistent.
- **Geavanceerde codegeneratie**: Claude Code kan een complete webapplicatie genereren op basis van een Figma-ontwerp.
- **Integratie van bedrijfsgegevens**: Bedrijfschatbots kunnen verbinding maken met meerdere databases binnen een organisatie, waardoor gebruikers gegevens kunnen analyseren via chat.
- **Creatieve workflows**: AI-modellen kunnen 3D-ontwerpen maken in Blender en deze printen met een 3D-printer.
- **Toegang tot realtime informatie**: Verbinding maken met externe gegevensbronnen voor actuele informatie.
- **Complexe meerstapsoperaties**: Uitvoeren van geavanceerde workflows die meerdere tools en systemen combineren.

### Waarom is MCP belangrijk?

MCP biedt voordelen voor het hele ecosysteem:

**Voor ontwikkelaars**: MCP vermindert de ontwikkeltijd en complexiteit bij het bouwen of integreren van een AI-toepassing of agent.

**Voor AI-toepassingen**: MCP biedt toegang tot een ecosysteem van gegevensbronnen, tools en apps die de mogelijkheden verbeteren en de gebruikerservaring optimaliseren.

**Voor eindgebruikers**: MCP resulteert in meer capabele AI-toepassingen of agents die toegang hebben tot jouw gegevens en indien nodig namens jou acties kunnen ondernemen.

## Kleine Taalmodellen (SLMs) in MCP

Kleine Taalmodellen bieden een efficiënte aanpak voor AI-implementatie en hebben verschillende voordelen:

### Voordelen van SLMs
- **Efficiënt gebruik van middelen**: Lagere computereisen
- **Snellere reactietijden**: Verminderde latentie voor realtime toepassingen  
- **Kosteneffectiviteit**: Minimale infrastructuurbehoeften
- **Privacy**: Kan lokaal draaien zonder dat gegevens worden verzonden
- **Aanpasbaarheid**: Makkelijker af te stemmen op specifieke domeinen

### Waarom werken SLMs goed met MCP

SLMs in combinatie met MCP vormen een krachtige combinatie waarbij de redeneercapaciteiten van het model worden aangevuld met externe tools, waardoor hun kleinere parameteromvang wordt gecompenseerd door verbeterde functionaliteit.

## Python MCP SDK Overzicht

De Python MCP SDK biedt de basis voor het bouwen van MCP-compatibele toepassingen. De SDK bevat:

- **Clientbibliotheken**: Voor verbinding met MCP-servers
- **Serverframework**: Voor het maken van aangepaste MCP-servers
- **Protocolhandlers**: Voor het beheren van communicatie
- **Toolintegratie**: Voor het uitvoeren van externe functies

## Praktische Implementatie: Phi-4 MCP Client

Laten we een praktijkvoorbeeld bekijken met Microsoft's Phi-4 mini-model geïntegreerd met MCP-mogelijkheden.

### MCP Architectuuroverzicht

MCP volgt een **client-serverarchitectuur** waarbij een MCP-host (een AI-toepassing zoals Claude Code of Claude Desktop) verbindingen tot stand brengt met een of meer MCP-servers. De MCP-host doet dit door één MCP-client te maken voor elke MCP-server.

#### Belangrijke deelnemers

- **MCP Host**: De AI-toepassing die één of meerdere MCP-clients coördineert en beheert.
- **MCP Client**: Een component die een verbinding onderhoudt met een MCP-server en context verkrijgt van een MCP-server voor gebruik door de MCP-host.
- **MCP Server**: Een programma dat context biedt aan MCP-clients.

#### Twee-laags architectuur

MCP bestaat uit twee afzonderlijke lagen:

**Datalayer**: Definieert het JSON-RPC-gebaseerde protocol voor client-servercommunicatie, inclusief:
- Lifecyclebeheer (initialisatie van verbinding, capaciteitsonderhandeling)
- Kernprimitieven (tools, bronnen, prompts)
- Clientfuncties (sampling, informatieverzameling, logging)
- Hulpfuncties (meldingen, voortgangstracking)

**Transportlaag**: Definieert de communicatiemechanismen en -kanalen:
- **STDIO Transport**: Gebruikt standaard invoer/uitvoer streams voor lokale processen (optimale prestaties, geen netwerkoverhead).
- **Streamable HTTP Transport**: Gebruikt HTTP POST met optionele Server-Sent Events voor externe servers (ondersteunt standaard HTTP-authenticatie).

```
┌─────────────────────────────────────┐
│           MCP Host                  │
│     (AI Application)                │
└─────────────────┬───────────────────┘
                  │
┌─────────────────┴───────────────────┐
│         MCP Client 1                │
│  ┌─────────────────────────────────┐ │
│  │        Data Layer               │ │
│  │  ├── Lifecycle Management       │ │
│  │  ├── Primitives (Tools/Resources)│ │
│  │  └── Notifications              │ │
│  └─────────────────────────────────┘ │
│  ┌─────────────────────────────────┐ │
│  │      Transport Layer           │ │
│  │  ├── STDIO Transport           │ │
│  │  └── HTTP Transport            │ │
│  └─────────────────────────────────┘ │
└─────────────────┬───────────────────┘
                  │
┌─────────────────┴───────────────────┐
│         MCP Server 1                │
│    (Local/Remote Context Provider)  │
└─────────────────────────────────────┘
```

### MCP Kernprimitieven

MCP definieert primitieven die de soorten contextuele informatie specificeren die kunnen worden gedeeld met AI-toepassingen en de acties die kunnen worden uitgevoerd.

#### Serverprimitieven

MCP definieert drie kernprimitieven die servers kunnen aanbieden:

**Tools**: Uitvoerbare functies die AI-toepassingen kunnen aanroepen om acties uit te voeren.
- Voorbeelden: bestandsbewerkingen, API-aanroepen, databasequery's
- Methoden: `tools/list`, `tools/call`
- Ondersteunt dynamische ontdekking en uitvoering

**Resources**: Gegevensbronnen die contextuele informatie bieden aan AI-toepassingen.
- Voorbeelden: bestandsinhoud, databaserecords, API-antwoorden
- Methoden: `resources/list`, `resources/read`
- Biedt toegang tot gestructureerde gegevens

**Prompts**: Herbruikbare sjablonen die helpen bij het structureren van interacties met taalmodellen.
- Voorbeelden: systeemprompts, few-shot voorbeelden
- Methoden: `prompts/list`, `prompts/get`
- Standaardiseert AI-interactiepatronen

#### Clientprimitieven

MCP definieert ook primitieven die clients kunnen aanbieden om rijkere interacties mogelijk te maken:

**Sampling**: Hiermee kunnen servers taalmodelvoltooiingen aanvragen van de AI-toepassing van de client.
- Methode: `sampling/complete`
- Maakt modelonafhankelijke serverontwikkeling mogelijk
- Biedt toegang tot het taalmodel van de host

**Elicitation**: Hiermee kunnen servers aanvullende informatie van gebruikers opvragen.
- Methode: `elicitation/request`
- Maakt gebruikersinteractie en bevestiging mogelijk
- Ondersteunt dynamische informatieverzameling

**Logging**: Hiermee kunnen servers logberichten naar clients sturen.
- Gebruikt voor foutopsporing en monitoring
- Biedt inzicht in serveractiviteiten

### MCP Protocol Lifecycle

#### Initialisatie en capaciteitsonderhandeling

MCP is een stateful protocol dat lifecyclebeheer vereist. Het initialisatieproces dient verschillende kritieke doelen:

1. **Protocolversieonderhandeling**: Zorgt ervoor dat zowel client als server compatibele protocolversies gebruiken (bijv. "2025-06-18").
2. **Capaciteitsontdekking**: Elke partij geeft ondersteunde functies en primitieven aan.
3. **Identiteitsuitwisseling**: Biedt identificatie- en versie-informatie.

```python
# Example initialization request
{
  "jsonrpc": "2.0",
  "id": 1,
  "method": "initialize",
  "params": {
    "protocolVersion": "2025-06-18",
    "capabilities": {
      "elicitation": {},  # Client supports user interaction
      "sampling": {}      # Client can provide LLM completions
    },
    "clientInfo": {
      "name": "edge-ai-client",
      "version": "1.0.0"
    }
  }
}
```

#### Toolontdekking en uitvoering

Na initialisatie kunnen clients tools ontdekken en uitvoeren:

```python
# Discover available tools
tools_response = await session.list_tools()

# Execute a tool
result = await session.call_tool(
    "weather_current",
    {
        "location": "San Francisco",
        "units": "imperial"
    }
)
```

#### Realtime meldingen

MCP ondersteunt realtime meldingen voor dynamische updates:

```python
# Server sends notification when tools change
{
  "jsonrpc": "2.0",
  "method": "notifications/tools/list_changed"
}

# Client responds by refreshing tool list
await session.list_tools()  # Get updated tools
```

## Aan de slag: Stapsgewijze handleiding

### Stap 1: Omgevingsinstellingen

Installeer vereiste afhankelijkheden:
```bash
pip install fastmcp mcp-python-client openai requests pyautogui Pillow
```

### Stap 2: Basisconfiguratie

Stel je omgevingsvariabelen in:
```python
# System Configuration
SYSTEM_PROMPT = "You are an AI assistant with some tools."

# Ollama Configuration (Local)
OLLAMA_URL = "http://localhost:11434/api/chat"
OLLAMA_MODEL_ID = "phi4-mini:3.8b-fp16"

# vLLM Configuration (Server)
VLLM_URL = "http://localhost:8000/v1"
VLLM_MODEL_ID = "microsoft/Phi-4-mini-instruct"
```

### Stap 3: Je eerste MCP-client uitvoeren

**Basis Ollama Setup:**
```bash
python ghmodel_mcp_demo.py
```

**Gebruik van vLLM Backend:**
```bash
python ghmodel_mcp_demo.py --env vllm
```

**Server-Sent Events Verbinding:**
```bash
python ghmodel_mcp_demo.py --run sse
```

**Aangepaste MCP Server:**
```bash
python ghmodel_mcp_demo.py --server /path/to/server.py
```

### Stap 4: Programma gebruik

```python
import asyncio
from ghmodel_mcp_demo import OllamaClient, Phi4MiniMCPClient

async def automated_interaction():
    # Configure MCP server parameters
    server_params = StdioServerParameters(
        command="npx",
        args=["@playwright/mcp@latest"],
        env=None,
    )
    
    # Create MCP client and process tools
    async with Phi4MiniMCPClient(server_params) as mcp_client:
        tools = await process_mcp_tools(mcp_client)
        llm_client = OllamaClient()
        
        # Generate response with tool capabilities
        response, messages = await llm_client.generate_response(
            "Help me automate a web task",
            tools
        )
        return response

# Execute the automation
result = asyncio.run(automated_interaction())
print(result)
```

## Geavanceerde functies

### Ondersteuning voor meerdere backends

De implementatie ondersteunt zowel Ollama als vLLM backends, zodat je kunt kiezen op basis van je behoeften:

- **Ollama**: Beter voor lokale ontwikkeling en testen
- **vLLM**: Geoptimaliseerd voor productie en scenario's met hoge doorvoer

### Flexibele verbindingsprotocollen

Twee verbindingsmodi worden ondersteund:

**STDIO Mode**: Directe procescommunicatie
- Lagere latentie
- Geschikt voor lokale tools
- Eenvoudige setup

**SSE Mode**: HTTP-gebaseerde streaming
- Netwerkgeschikt
- Beter voor gedistribueerde systemen
- Realtime updates

### Toolintegratiemogelijkheden

Het systeem kan integreren met verschillende tools:
- Webautomatisering (Playwright)
- Bestandsbewerkingen
- API-interacties
- Systeemcommando's
- Aangepaste functies

## Foutafhandeling en best practices

### Uitgebreid foutbeheer

De implementatie bevat robuuste foutafhandeling voor:

**Verbindingsfouten:**
- MCP-serverstoringen
- Netwerktime-outs
- Connectiviteitsproblemen

**Tooluitvoeringsfouten:**
- Ontbrekende tools
- Parametervalidatie
- Uitvoeringsfouten

**Reactieverwerkingsfouten:**
- JSON-parsingproblemen
- Formaatinconsistenties
- LLM-reactieafwijkingen

### Best practices

1. **Resourcebeheer**: Gebruik asynchrone contextmanagers
2. **Foutafhandeling**: Implementeer uitgebreide try-catch blokken
3. **Logging**: Schakel geschikte logniveaus in
4. **Beveiliging**: Valideer invoer en zuiver uitvoer
5. **Prestaties**: Gebruik connectiepooling en caching

## Toepassingen in de praktijk

### Webautomatisering
```python
# Example: Automated web testing
async def web_automation_example():
    tools = await setup_playwright_tools()
    response = await llm_client.generate_response(
        "Navigate to example.com and take a screenshot",
        tools
    )
```

### Gegevensverwerking
```python
# Example: File analysis
async def data_processing_example():
    tools = await setup_file_tools()
    response = await llm_client.generate_response(
        "Analyze the CSV file and generate a summary report",
        tools
    )
```

### API-integratie
```python
# Example: API interactions
async def api_integration_example():
    tools = await setup_api_tools()
    response = await llm_client.generate_response(
        "Fetch weather data and create a forecast summary",
        tools
    )
```

## Prestatieoptimalisatie

### Geheugenbeheer
- Efficiënt beheer van berichtgeschiedenis
- Correct opruimen van resources
- Connectiepooling

### Netwerkoptimalisatie
- Asynchrone HTTP-bewerkingen
- Configureerbare time-outs
- Gracieus foutherstel

### Gelijktijdige verwerking
- Niet-blokkerende I/O
- Parallelle tooluitvoering
- Efficiënte asynchrone patronen

## Beveiligingsoverwegingen

### Gegevensbescherming
- Beveiligd beheer van API-sleutels
- Validatie van invoer
- Zuivering van uitvoer

### Netwerkbeveiliging
- Ondersteuning voor HTTPS
- Standaard lokale eindpunten
- Beveiligd tokenbeheer

### Veilige uitvoering
- Toolfiltering
- Gesandboxte omgevingen
- Auditlogging

## MCP Ecosysteem en Ontwikkeling

### MCP Projectomvang

Het Model Context Protocol ecosysteem omvat verschillende belangrijke componenten:

- **[MCP Specificatie](https://modelcontextprotocol.io/specification/latest)**: Officiële specificatie met implementatievereisten voor clients en servers.
- **[MCP SDKs](https://modelcontextprotocol.io/docs/sdk)**: SDKs voor verschillende programmeertalen die MCP implementeren.
- **MCP Ontwikkeltools**: Tools voor het ontwikkelen van MCP-servers en clients, inclusief de [MCP Inspector](https://github.com/modelcontextprotocol/inspector).
- **[MCP Referentie Server Implementaties](https://github.com/modelcontextprotocol/servers)**: Referentie-implementaties van MCP-servers.

### Aan de slag met MCP-ontwikkeling

Om te beginnen met bouwen met MCP:

**Servers bouwen**: [Maak MCP-servers](https://modelcontextprotocol.io/docs/develop/build-server) om je gegevens en tools beschikbaar te maken.

**Clients bouwen**: [Ontwikkel toepassingen](https://modelcontextprotocol.io/docs/develop/build-client) die verbinding maken met MCP-servers.

**Concepten leren**: [Begrijp de kernconcepten](https://modelcontextprotocol.io/docs/learn/architecture) en architectuur van MCP.

## Conclusie

SLMs geïntegreerd met MCP vertegenwoordigen een paradigmaverschuiving in de ontwikkeling van AI-toepassingen. Door de efficiëntie van kleine modellen te combineren met de kracht van externe tools, kunnen ontwikkelaars intelligente systemen creëren die zowel middelen-efficiënt als zeer capabel zijn.

Het Model Context Protocol biedt een gestandaardiseerde manier om AI-toepassingen te verbinden met externe systemen, net zoals USB-C een universele verbindingsstandaard biedt voor elektronische apparaten. Deze standaardisatie maakt het mogelijk:

- **Naadloze integratie**: Verbind AI-modellen met diverse gegevensbronnen en tools.
- **Ecosysteemgroei**: Bouw één keer, gebruik in meerdere AI-toepassingen.
- **Verbeterde mogelijkheden**: Vul SLMs aan met externe functionaliteit.
- **Realtime updates**: Ondersteun dynamische, responsieve AI-toepassingen.

Belangrijke punten:
- MCP is een open standaard die AI-toepassingen en externe systemen verbindt.
- Het protocol ondersteunt tools, bronnen en prompts als kernprimitieven.
- Realtime meldingen maken dynamische, responsieve toepassingen mogelijk.
- Correct lifecyclebeheer en foutafhandeling zijn essentieel voor productiegebruik.
- Het ecosysteem biedt uitgebreide SDKs en ontwikkeltools.

## Referenties en Verdere Lezing

### Officiële MCP Documentatie

- **[Model Context Protocol Officiële Site](https://modelcontextprotocol.io/)** - Complete documentatie en specificaties.
- **[MCP Aan de Slag Gids](https://modelcontextprotocol.io/docs/getting-started/intro)** - Introductie en kernconcepten.
- **[MCP Architectuuroverzicht](https://modelcontextprotocol.io/docs/learn/architecture)** - Gedetailleerde technische architectuur.
- **[MCP Specificatie](https://modelcontextprotocol.io/specification/latest)** - Officiële protocolspecificatie.
- **[MCP SDKs Documentatie](https://modelcontextprotocol.io/docs/sdk)** - Taal-specifieke SDK-gidsen.

### Ontwikkelbronnen

- **[MCP voor Beginners](https://aka.ms/mcp-for-beginners)** - Uitgebreide beginnersgids voor Model Context Protocol.
- **[MCP GitHub Organisatie](https://github.com/modelcontextprotocol)** - Officiële repositories en voorbeelden.
- **[MCP Server Repository](https://github.com/modelcontextprotocol/servers)** - Referentie serverimplementaties.
- **[MCP Inspector](https://github.com/modelcontextprotocol/inspector)** - Ontwikkel- en debuggingtool.
- **[Maak MCP Servers Gids](https://modelcontextprotocol.io/docs/develop/build-server)** - Serverontwikkelingshandleiding.
- **[Maak MCP Clients Gids](https://modelcontextprotocol.io/docs/develop/build-client)** - Clientontwikkelingshandleiding.

### Kleine Taalmodellen en Edge AI

- **[Microsoft Phi Modellen](https://aka.ms/phicookbook)** - Phi model familie.
- **[Foundry Local Documentatie](https://github.com/microsoft/Foundry-Local)** - Microsoft's edge AI runtime.
- **[Ollama Documentatie](https://ollama.ai/docs)** - Platform voor lokale LLM-implementatie
- **[vLLM Documentatie](https://docs.vllm.ai/)** - High-performance LLM-server

### Technische standaarden en protocollen

- **[JSON-RPC 2.0 Specificatie](https://www.jsonrpc.org/)** - Onderliggend RPC-protocol gebruikt door MCP
- **[JSON Schema](https://json-schema.org/)** - Standaard voor schema-definitie voor MCP-tools
- **[OpenAPI Specificatie](https://swagger.io/specification/)** - Standaard voor API-documentatie
- **[Server-Sent Events (SSE)](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events)** - Webstandaard voor realtime updates

### Ontwikkeling van AI-agenten

- **[Microsoft Agent Framework](https://github.com/microsoft/agent-framework)** - Productieklaar framework voor agentontwikkeling
- **[LangChain Documentatie](https://docs.langchain.com/)** - Framework voor integratie van agenten en tools
- **[Semantic Kernel](https://learn.microsoft.com/en-us/semantic-kernel/)** - Microsoft's AI-orkestratie SDK

### Industriële rapporten en onderzoek

- **[Anthropic's Model Context Protocol Aankondiging](https://www.anthropic.com/news/model-context-protocol)** - Originele introductie van MCP
- **[Survey over Small Language Models](https://arxiv.org/abs/2410.20011)** - Academisch onderzoek naar SLM
- **[Edge AI Marktanalyse](https://www.marketsandmarkets.com/Market-Reports/edge-ai-software-market-74385617.html)** - Trends en voorspellingen in de industrie
- **[Best Practices voor AI-agentontwikkeling](https://arxiv.org/abs/2309.02427)** - Onderzoek naar agentarchitecturen

Deze sectie biedt de basis voor het bouwen van je eigen SLM-aangedreven MCP-toepassingen, waarmee mogelijkheden worden geopend voor automatisering, gegevensverwerking en integratie van intelligente systemen.

## ➡️ Wat nu?

- [Module 7. Edge AI voorbeelden](../Module07/README.md)

---

**Disclaimer**:  
Dit document is vertaald met behulp van de AI-vertalingsservice [Co-op Translator](https://github.com/Azure/co-op-translator). Hoewel we streven naar nauwkeurigheid, dient u zich ervan bewust te zijn dat geautomatiseerde vertalingen fouten of onnauwkeurigheden kunnen bevatten. Het originele document in de oorspronkelijke taal moet worden beschouwd als de gezaghebbende bron. Voor kritieke informatie wordt professionele menselijke vertaling aanbevolen. Wij zijn niet aansprakelijk voor eventuele misverstanden of verkeerde interpretaties die voortvloeien uit het gebruik van deze vertaling.