<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "44bc28c27b993c5fb988791b7a115705",
  "translation_date": "2025-10-30T12:00:18+00:00",
  "source_file": "Module06/01.IntroduceAgent.md",
  "language_code": "ne"
}
-->
# рдПрдЖрдИ рдПрдЬреЗрдиреНрдЯрд╣рд░реВ рд░ рд╕рд╛рдиреЛ рднрд╛рд╖рд╛ рдореЛрдбреЗрд▓рд╣рд░реВ: рд╡рд┐рд╕реНрддреГрдд рдорд╛рд░реНрдЧрджрд░реНрд╢рди

## рдкрд░рд┐рдЪрдп

рдпрд╕ рдЯреНрдпреБрдЯреЛрд░рд┐рдпрд▓рдорд╛, рд╣рд╛рдореА рдПрдЖрдИ рдПрдЬреЗрдиреНрдЯрд╣рд░реВ рд░ рд╕рд╛рдиреЛ рднрд╛рд╖рд╛ рдореЛрдбреЗрд▓рд╣рд░реВ (SLMs) рдХреЛ рдЕрдзреНрдпрдпрди рдЧрд░реНрдиреЗрдЫреМрдВ рд░ рддрд┐рдиреАрд╣рд░реВрдХреЛ рдЙрдиреНрдирдд рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди рд░рдгрдиреАрддрд┐рд╣рд░реВ рдХрд┐рдирд╛рд░рд╛ рдХрдореНрдкреНрдпреБрдЯрд┐рдЩ рд╡рд╛рддрд╛рд╡рд░рдгрдХрд╛ рд▓рд╛рдЧрд┐ рдЕрдиреНрд╡реЗрд╖рдг рдЧрд░реНрдиреЗрдЫреМрдВред рд╣рд╛рдореА рдПрдЬреЗрдиреНрдЯрд┐рдХ рдПрдЖрдИрдХрд╛ рдЖрдзрд╛рд░рднреВрдд рдЕрд╡рдзрд╛рд░рдгрд╛рд╣рд░реВ, SLM рдЕрдиреБрдХреВрд▓рди рдкреНрд░рд╡рд┐рдзрд┐рд╣рд░реВ, рд╕реНрд░реЛрдд-рд╕реАрдорд┐рдд рдЙрдкрдХрд░рдгрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рд╡реНрдпрд╛рд╡рд╣рд╛рд░рд┐рдХ рдкрд░рд┐рдирд┐рдпреЛрдЬрди рд░рдгрдиреАрддрд┐рд╣рд░реВ, рд░ рдЙрддреНрдкрд╛рджрди-рддрдпрд╛рд░ рдПрдЬреЗрдиреНрдЯ рдкреНрд░рдгрд╛рд▓реА рдирд┐рд░реНрдорд╛рдг рдЧрд░реНрди рдорд╛рдЗрдХреНрд░реЛрд╕рдлреНрдЯ рдПрдЬреЗрдиреНрдЯ рдлреНрд░реЗрдорд╡рд░реНрдХрдХреЛ рдмрд╛рд░реЗрдорд╛ рдЪрд░реНрдЪрд╛ рдЧрд░реНрдиреЗрдЫреМрдВред

рдХреГрддреНрд░рд┐рдо рдмреБрджреНрдзрд┐рдорддреНрддрд╛рдХреЛ рдХреНрд╖реЗрддреНрд░ реирежреирел рдорд╛ рдПрдХ рдирдпрд╛рдБ рдпреБрдЧрдорд╛ рдкреНрд░рд╡реЗрд╢ рдЧрд░реНрджреИрдЫред рдЬрд╣рд╛рдБ реирежреирей рдЪреНрдпрд╛рдЯрдмреЛрдЯрд╣рд░реВрдХреЛ рд╡рд░реНрд╖ рдерд┐рдпреЛ рд░ реирежреирек рдХреЛрдкрд╛рдЗрд▓рдЯрд╣рд░реВрдХреЛ рдмреГрджреНрдзрд┐ рджреЗрдЦрд┐рдпреЛ, реирежреирел рдПрдЖрдИ рдПрдЬреЗрдиреНрдЯрд╣рд░реВрдХреЛ рд╣реЛ тАФ рдпрд╕реНрддрд╛ рдмреБрджреНрдзрд┐рдорд╛рди рдкреНрд░рдгрд╛рд▓реАрд╣рд░реВ рдЬрд╕рд▓реЗ рд╕реЛрдЪреНрди, рддрд░реНрдХ рдЧрд░реНрди, рдпреЛрдЬрдирд╛ рдмрдирд╛рдЙрди, рдЙрдкрдХрд░рдгрд╣рд░реВ рдкреНрд░рдпреЛрдЧ рдЧрд░реНрди, рд░ рдиреНрдпреВрдирддрдо рдорд╛рдирд╡реАрдп рд╣рд╕реНрддрдХреНрд╖реЗрдкрдХрд╛ рд╕рд╛рде рдХрд╛рд░реНрдпрд╣рд░реВ рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди рдЧрд░реНрди рд╕рдХреНрдЫрдиреНред рдпреА рдкреНрд░рдгрд╛рд▓реАрд╣рд░реВ рдкреНрд░рднрд╛рд╡рдХрд╛рд░реА рд╕рд╛рдиреЛ рднрд╛рд╖рд╛ рдореЛрдбреЗрд▓рд╣рд░реВрджреНрд╡рд╛рд░рд╛ рд╕рдВрдЪрд╛рд▓рд┐рдд рдЫрдиреНред рдорд╛рдЗрдХреНрд░реЛрд╕рдлреНрдЯ рдПрдЬреЗрдиреНрдЯ рдлреНрд░реЗрдорд╡рд░реНрдХ рдХрд┐рдирд╛рд░рд╛-рдЖрдзрд╛рд░рд┐рдд рдХреНрд╖рдорддрд╛рд╣рд░реВрдХреЛ рд╕рд╛рде рдпреА рдмреБрджреНрдзрд┐рдорд╛рди рдкреНрд░рдгрд╛рд▓реАрд╣рд░реВ рдирд┐рд░реНрдорд╛рдг рдЧрд░реНрди рдПрдХ рдкреНрд░рдореБрдЦ рд╕рдорд╛рдзрд╛рдирдХреЛ рд░реВрдкрдорд╛ рджреЗрдЦрд╛ рдкрд░реЗрдХреЛ рдЫред

## рд╕рд┐рдХрд╛рдЗ рдЙрджреНрджреЗрд╢реНрдпрд╣рд░реВ

рдпрд╕ рдЯреНрдпреБрдЯреЛрд░рд┐рдпрд▓рдХреЛ рдЕрдиреНрддреНрдпрд╕рдореНрдордорд╛, рддрдкрд╛рдИрдВ рд╕рдХреНрд╖рдо рд╣реБрдиреБрд╣реБрдиреЗрдЫ:

- ЁЯдЦ рдПрдЖрдИ рдПрдЬреЗрдиреНрдЯрд╣рд░реВ рд░ рдПрдЬреЗрдиреНрдЯрд┐рдХ рдкреНрд░рдгрд╛рд▓реАрд╣рд░реВрдХреЛ рдЖрдзрд╛рд░рднреВрдд рдЕрд╡рдзрд╛рд░рдгрд╛рд╣рд░реВ рдмреБрдЭреНрди
- ЁЯФм рд╕рд╛рдиреЛ рднрд╛рд╖рд╛ рдореЛрдбреЗрд▓рд╣рд░реВрдХреЛ рд▓рд╛рднрд╣рд░реВ рдареВрд▓рд╛ рднрд╛рд╖рд╛ рдореЛрдбреЗрд▓рд╣рд░реВрдХреЛ рддреБрд▓рдирд╛рдорд╛ рдПрдЬреЗрдиреНрдЯрд┐рдХ рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╣рд░реВрдорд╛ рдкрд╣рд┐рдЪрд╛рди рдЧрд░реНрди
- ЁЯЪА рдХрд┐рдирд╛рд░рд╛ рдХрдореНрдкреНрдпреБрдЯрд┐рдЩ рд╡рд╛рддрд╛рд╡рд░рдгрдХрд╛ рд▓рд╛рдЧрд┐ рдЙрдиреНрдирдд SLM рдкрд░рд┐рдирд┐рдпреЛрдЬрди рд░рдгрдиреАрддрд┐рд╣рд░реВ рд╕рд┐рдХреНрди
- ЁЯУ▒ рд╡рд╛рд╕реНрддрд╡рд┐рдХ рд╕рдВрд╕рд╛рд░рдХрд╛ рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рд╡реНрдпрд╛рд╡рд╣рд╛рд░рд┐рдХ SLM-рд╕рдВрдЪрд╛рд▓рд┐рдд рдПрдЬреЗрдиреНрдЯрд╣рд░реВ рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди рдЧрд░реНрди
- ЁЯПЧя╕П рдорд╛рдЗрдХреНрд░реЛрд╕рдлреНрдЯ рдПрдЬреЗрдиреНрдЯ рдлреНрд░реЗрдорд╡рд░реНрдХ рдкреНрд░рдпреЛрдЧ рдЧрд░реЗрд░ рдЙрддреНрдкрд╛рджрди-рддрдпрд╛рд░ рдПрдЬреЗрдиреНрдЯрд╣рд░реВ рдирд┐рд░реНрдорд╛рдг рдЧрд░реНрди
- ЁЯМР рд╕реНрдерд╛рдиреАрдп LLM рд░ SLM рдПрдХреАрдХрд░рдгрдХреЛ рд╕рд╛рде рдХрд┐рдирд╛рд░рд╛-рдЖрдзрд╛рд░рд┐рдд рдПрдЬреЗрдиреНрдЯрд╣рд░реВ рдкрд░рд┐рдирд┐рдпреЛрдЬрди рдЧрд░реНрди
- ЁЯФз рдорд╛рдЗрдХреНрд░реЛрд╕рдлреНрдЯ рдПрдЬреЗрдиреНрдЯ рдлреНрд░реЗрдорд╡рд░реНрдХрд▓рд╛рдИ рдлрд╛рдЙрдиреНрдбреНрд░реА рд▓реЛрдХрд▓рд╕рдБрдЧ рдХрд┐рдирд╛рд░рд╛ рдкрд░рд┐рдирд┐рдпреЛрдЬрдирдХрд╛ рд▓рд╛рдЧрд┐ рдПрдХреАрдХреГрдд рдЧрд░реНрди

## рдПрдЖрдИ рдПрдЬреЗрдиреНрдЯрд╣рд░реВ рдмреБрдЭреНрджреИ: рдЖрдзрд╛рд░рднреВрдд рд░ рд╡рд░реНрдЧреАрдХрд░рдг

### рдкрд░рд┐рднрд╛рд╖рд╛ рд░ рдореБрдЦреНрдп рдЕрд╡рдзрд╛рд░рдгрд╛рд╣рд░реВ

рдХреГрддреНрд░рд┐рдо рдмреБрджреНрдзрд┐рдорддреНрддрд╛ (AI) рдПрдЬреЗрдиреНрдЯ рднрдиреНрдирд╛рд▓реЗ рдпрд╕реНрддреЛ рдкреНрд░рдгрд╛рд▓реА рд╡рд╛ рдХрд╛рд░реНрдпрдХреНрд░рдорд▓рд╛рдИ рдЬрдирд╛рдЙрдБрдЫ рдЬрд╕рд▓реЗ рдкреНрд░рдпреЛрдЧрдХрд░реНрддрд╛ рд╡рд╛ рдЕрд░реНрдХреЛ рдкреНрд░рдгрд╛рд▓реАрдХреЛ рддрд░реНрдлрдмрд╛рдЯ рд╕реНрд╡рддрдиреНрддреНрд░ рд░реВрдкрдорд╛ рдХрд╛рд░реНрдпрд╣рд░реВ рдкреНрд░рджрд░реНрд╢рди рдЧрд░реНрди рд╕рдХреНрд╖рдо рдЫред рдпрд╕рд▓реЗ рдЖрдлреНрдиреЛ рдХрд╛рд░реНрдпрдкреНрд░рд╡рд╛рд╣ рдбрд┐рдЬрд╛рдЗрди рдЧрд░реНрди рд░ рдЙрдкрд▓рдмреНрдз рдЙрдкрдХрд░рдгрд╣рд░реВрдХреЛ рдЙрдкрдпреЛрдЧ рдЧрд░реНрди рд╕рдХреНрдЫред рдкрд░рдореНрдкрд░рд╛рдЧрдд рдПрдЖрдИрд▓реЗ рдХреЗрд╡рд▓ рддрдкрд╛рдИрдВрдХреЛ рдкреНрд░рд╢реНрдирд╣рд░реВрдХреЛ рдЙрддреНрддрд░ рджрд┐рдиреНрдЫ рднрдиреЗ, рдПрдЬреЗрдиреНрдЯрд▓реЗ рд╕реНрд╡рддрдиреНрддреНрд░ рд░реВрдкрдорд╛ рд▓рдХреНрд╖реНрдпрд╣рд░реВ рдкреНрд░рд╛рдкреНрдд рдЧрд░реНрди рдХрд╛рд░реНрдп рдЧрд░реНрди рд╕рдХреНрдЫред

### рдПрдЬреЗрдиреНрдЯ рд╡рд░реНрдЧреАрдХрд░рдг рдлреНрд░реЗрдорд╡рд░реНрдХ

рдПрдЬреЗрдиреНрдЯ рд╕реАрдорд╛рд╣рд░реВ рдмреБрдЭреНрджрд╛ рд╡рд┐рднрд┐рдиреНрди рдХрдореНрдкреНрдпреБрдЯрд┐рдЩ рдкрд░рд┐рджреГрд╢реНрдпрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЙрдкрдпреБрдХреНрдд рдПрдЬреЗрдиреНрдЯ рдкреНрд░рдХрд╛рд░рд╣рд░реВ рдЪрдпрди рдЧрд░реНрди рдорджреНрджрдд рдЧрд░реНрджрдЫ:

- **ЁЯФм рд╕рд╛рдзрд╛рд░рдг рд░рд┐рдлреНрд▓реЗрдХреНрд╕ рдПрдЬреЗрдиреНрдЯрд╣рд░реВ**: рдирд┐рдпрдо-рдЖрдзрд╛рд░рд┐рдд рдкреНрд░рдгрд╛рд▓реАрд╣рд░реВ рдЬрд╕рд▓реЗ рддрддреНрдХрд╛рд▓ рдзрд╛рд░рдгрд╛рд╣рд░реВрдорд╛ рдкреНрд░рддрд┐рдХреНрд░рд┐рдпрд╛ рджрд┐рдиреНрдЫрдиреН (рдерд░реНрдореЛрд╕реНрдЯреНрдпрд╛рдЯрд╣рд░реВ, рдЖрдзрд╛рд░рднреВрдд рд╕реНрд╡рдЪрд╛рд▓рди)
- **ЁЯУ▒ рдореЛрдбреЗрд▓-рдЖрдзрд╛рд░рд┐рдд рдПрдЬреЗрдиреНрдЯрд╣рд░реВ**: рдкреНрд░рдгрд╛рд▓реАрд╣рд░реВ рдЬрд╕рд▓реЗ рдЖрдиреНрддрд░рд┐рдХ рдЕрд╡рд╕реНрдерд╛ рд░ рд╕реНрдореГрддрд┐ рдХрд╛рдпрдо рд░рд╛рдЦреНрдЫрдиреН (рд░реЛрдмреЛрдЯ рднреНрдпрд╛рдХреБрдорд╣рд░реВ, рдиреЗрднрд┐рдЧреЗрд╕рди рдкреНрд░рдгрд╛рд▓реАрд╣рд░реВ)
- **тЪЦя╕П рд▓рдХреНрд╖реНрдп-рдЖрдзрд╛рд░рд┐рдд рдПрдЬреЗрдиреНрдЯрд╣рд░реВ**: рдкреНрд░рдгрд╛рд▓реАрд╣рд░реВ рдЬрд╕рд▓реЗ рдЙрджреНрджреЗрд╢реНрдпрд╣рд░реВ рдкреНрд░рд╛рдкреНрдд рдЧрд░реНрди рдпреЛрдЬрдирд╛ рдмрдирд╛рдЙрдБрдЫрдиреН рд░ рдХреНрд░рдорд╣рд░реВ рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди рдЧрд░реНрдЫрдиреН (рд░реВрдЯ рдпреЛрдЬрдирд╛рдХрд╛рд░рд╣рд░реВ, рдХрд╛рд░реНрдп рддрд╛рд▓рд┐рдХрд╛рдХрд╛рд░рд╣рд░реВ)
- **ЁЯза рд╕рд┐рдХреНрдиреЗ рдПрдЬреЗрдиреНрдЯрд╣рд░реВ**: рдЕрдиреБрдХреВрд▓рди рдкреНрд░рдгрд╛рд▓реАрд╣рд░реВ рдЬрд╕рд▓реЗ рд╕рдордпрд╕рдБрдЧреИ рдкреНрд░рджрд░реНрд╢рди рд╕реБрдзрд╛рд░ рдЧрд░реНрдЫрдиреН (рд╕рд┐рдлрд╛рд░рд┐рд╕ рдкреНрд░рдгрд╛рд▓реАрд╣рд░реВ, рд╡реНрдпрдХреНрддрд┐рдЧрдд рд╕рд╣рд╛рдпрдХрд╣рд░реВ)

### рдПрдЖрдИ рдПрдЬреЗрдиреНрдЯрд╣рд░реВрдХреЛ рдореБрдЦреНрдп рд▓рд╛рднрд╣рд░реВ

рдПрдЖрдИ рдПрдЬреЗрдиреНрдЯрд╣рд░реВрд▓реЗ рдХрд┐рдирд╛рд░рд╛ рдХрдореНрдкреНрдпреБрдЯрд┐рдЩ рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЖрджрд░реНрд╢ рдмрдирд╛рдЙрдиреЗ рдХреЗрд╣реА рдЖрдзрд╛рд░рднреВрдд рд▓рд╛рднрд╣рд░реВ рдкреНрд░рджрд╛рди рдЧрд░реНрдЫрдиреН:

**рд╕рдЮреНрдЪрд╛рд▓рди рд╕реНрд╡рддрдиреНрддреНрд░рддрд╛**: рдПрдЬреЗрдиреНрдЯрд╣рд░реВрд▓реЗ рд╡рд╛рд╕реНрддрд╡рд┐рдХ-рд╕рдордп рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдиреНрдпреВрдирддрдо рдорд╛рдирд╡реАрдп рдирд┐рд░реАрдХреНрд╖рдгрдХреЛ рд╕рд╛рде рд╕реНрд╡рддрдиреНрддреНрд░ рдХрд╛рд░реНрдп рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди рдкреНрд░рджрд╛рди рдЧрд░реНрдЫрдиреНред рддрд┐рдиреАрд╣рд░реВрд▓реЗ рдЕрдиреБрдХреВрд▓рди рд╡реНрдпрд╡рд╣рд╛рд░ рдХрд╛рдпрдо рд░рд╛рдЦреНрджреИ рд╕реНрд░реЛрдд-рд╕реАрдорд┐рдд рдЙрдкрдХрд░рдгрд╣рд░реВрдорд╛ рдкрд░рд┐рдирд┐рдпреЛрдЬрди рд╕рдХреНрд╖рдо рдмрдирд╛рдЙрдБрдЫрдиреНред

**рдкрд░рд┐рдирд┐рдпреЛрдЬрди рд▓рдЪрд┐рд▓реЛрдкрди**: рдпреА рдкреНрд░рдгрд╛рд▓реАрд╣рд░реВрд▓реЗ рдЗрдиреНрдЯрд░рдиреЗрдЯ рдЬрдбрд╛рди рдЖрд╡рд╢реНрдпрдХрддрд╛рд╣рд░реВ рдмрд┐рдирд╛ рдЙрдкрдХрд░рдгрдорд╛ рдПрдЖрдИ рдХреНрд╖рдорддрд╛рд╣рд░реВ рд╕рдХреНрд╖рдо рдмрдирд╛рдЙрдБрдЫрдиреН, рд╕реНрдерд╛рдиреАрдп рдкреНрд░рд╢реЛрдзрди рдорд╛рд░реНрдлрдд рдЧреЛрдкрдиреАрдпрддрд╛ рд░ рд╕реБрд░рдХреНрд╖рд╛ рдмрдврд╛рдЙрдБрдЫрдиреН, рдбреЛрдореЗрди-рд╡рд┐рд╢рд┐рд╖реНрдЯ рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЕрдиреБрдХреВрд▓рди рдЧрд░реНрди рд╕рдХрд┐рдиреНрдЫ, рд░ рд╡рд┐рднрд┐рдиреНрди рдХрд┐рдирд╛рд░рд╛ рдХрдореНрдкреНрдпреБрдЯрд┐рдЩ рд╡рд╛рддрд╛рд╡рд░рдгрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЙрдкрдпреБрдХреНрдд рдЫрдиреНред

**рд▓рд╛рдЧрдд рдкреНрд░рднрд╛рд╡рдХрд╛рд░рд┐рддрд╛**: рдПрдЬреЗрдиреНрдЯ рдкреНрд░рдгрд╛рд▓реАрд╣рд░реВрд▓реЗ рдХреНрд▓рд╛рдЙрдб-рдЖрдзрд╛рд░рд┐рдд рд╕рдорд╛рдзрд╛рдирд╣рд░реВрдХреЛ рддреБрд▓рдирд╛рдорд╛ рд▓рд╛рдЧрдд-рдкреНрд░рднрд╛рд╡рдХрд╛рд░реА рдкрд░рд┐рдирд┐рдпреЛрдЬрди рдкреНрд░рджрд╛рди рдЧрд░реНрдЫрдиреН, рдХрд┐рдирд╛рд░рд╛ рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдХрдо рдкрд░рд┐рдЪрд╛рд▓рди рд▓рд╛рдЧрдд рд░ рдХрдо рдмреНрдпрд╛рдиреНрдбрд╡рд┐рде рдЖрд╡рд╢реНрдпрдХрддрд╛рд╣рд░реВрдХреЛ рд╕рд╛рдеред

## рдЙрдиреНрдирдд рд╕рд╛рдиреЛ рднрд╛рд╖рд╛ рдореЛрдбреЗрд▓ рд░рдгрдиреАрддрд┐рд╣рд░реВ

### SLM (рд╕рд╛рдиреЛ рднрд╛рд╖рд╛ рдореЛрдбреЗрд▓) рдХрд╛ рдЖрдзрд╛рд░рднреВрдд рдХреБрд░рд╛

рд╕рд╛рдиреЛ рднрд╛рд╖рд╛ рдореЛрдбреЗрд▓ (SLM) рднрдиреНрдирд╛рд▓реЗ рдпрд╕реНрддреЛ рднрд╛рд╖рд╛ рдореЛрдбреЗрд▓рд▓рд╛рдИ рдЬрдирд╛рдЙрдБрдЫ рдЬреБрди рд╕рд╛рдорд╛рдиреНрдп рдЙрдкрднреЛрдХреНрддрд╛ рдЗрд▓реЗрдХреНрдЯреНрд░реЛрдирд┐рдХ рдЙрдкрдХрд░рдгрдорд╛ рдлрд┐рдЯ рд╣реБрди рд╕рдХреНрдЫ рд░ рдПрдХ рдкреНрд░рдпреЛрдЧрдХрд░реНрддрд╛рдХреЛ рдПрдЬреЗрдиреНрдЯрд┐рдХ рдЕрдиреБрд░реЛрдзрд╣рд░реВрдХреЛ рд╕реЗрд╡рд╛ рдЧрд░реНрджрд╛ рд╡реНрдпрд╛рд╡рд╣рд╛рд░рд┐рдХ рд░реВрдкрдорд╛ рдХрдо рд╡рд┐рд▓рдореНрдмрддрд╛рд╕рдБрдЧ рдЕрдиреБрдорд╛рди рдЧрд░реНрди рд╕рдХреНрдЫред рд╡реНрдпрд╛рд╡рд╣рд╛рд░рд┐рдХ рд░реВрдкрдорд╛, SLMрд╣рд░реВ рд╕рд╛рдорд╛рдиреНрдпрддрдпрд╛ резреж рдЕрд░реНрдм рднрдиреНрджрд╛ рдХрдо рдкреНрдпрд╛рд░рд╛рдорд┐рдЯрд░рд╣рд░реВ рднрдПрдХрд╛ рдореЛрдбреЗрд▓рд╣рд░реВ рд╣реБрдиреНред

**рдлрд╛рд░рдореНрдпрд╛рдЯ рдбрд┐рд╕реНрдХрднрд░реА рд╕реБрд╡рд┐рдзрд╛рд╣рд░реВ**: SLMрд╣рд░реВрд▓реЗ рд╡рд┐рднрд┐рдиреНрди рдХреНрд╡рд╛рдиреНрдЯрд╛рдЗрдЬреЗрд╕рди рд╕реНрддрд░рд╣рд░реВ, рдХреНрд░рд╕-рдкреНрд▓реНрдпрд╛рдЯрдлрд░реНрдо рдЕрдиреБрдХреВрд▓рддрд╛, рд╡рд╛рд╕реНрддрд╡рд┐рдХ-рд╕рдордп рдкреНрд░рджрд░реНрд╢рди рдЕрдиреБрдХреВрд▓рди, рд░ рдХрд┐рдирд╛рд░рд╛ рдкрд░рд┐рдирд┐рдпреЛрдЬрди рдХреНрд╖рдорддрд╛рд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЙрдиреНрдирдд рд╕рдорд░реНрдерди рдкреНрд░рджрд╛рди рдЧрд░реНрдЫрдиреНред рдкреНрд░рдпреЛрдЧрдХрд░реНрддрд╛рд╣рд░реВрд▓реЗ рд╕реНрдерд╛рдиреАрдп рдкреНрд░рд╢реЛрдзрди рдорд╛рд░реНрдлрдд рдЧреЛрдкрдиреАрдпрддрд╛ рдмрдврд╛рдЙрди рд░ рдмреНрд░рд╛рдЙрдЬрд░-рдЖрдзрд╛рд░рд┐рдд рдкрд░рд┐рдирд┐рдпреЛрдЬрдирдХреЛ рд▓рд╛рдЧрд┐ WebGPU рд╕рдорд░реНрдерди рдкрд╣реБрдБрдЪ рдЧрд░реНрди рд╕рдХреНрдЫрдиреНред

**рдХреНрд╡рд╛рдиреНрдЯрд╛рдЗрдЬреЗрд╕рди рд╕реНрддрд░ рд╕рдВрдЧреНрд░рд╣рд╣рд░реВ**: рд▓реЛрдХрдкреНрд░рд┐рдп SLM рдлрд╛рд░рдореНрдпрд╛рдЯрд╣рд░реВрдорд╛ рдореЛрдмрд╛рдЗрд▓ рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рд╕рдиреНрддреБрд▓рд┐рдд рдХрдореНрдкреНрд░реЗрд╕рдирдХреЛ рд▓рд╛рдЧрд┐ Q4_K_M, рдХрд┐рдирд╛рд░рд╛ рдкрд░рд┐рдирд┐рдпреЛрдЬрдирдХреЛ рд▓рд╛рдЧрд┐ рдЧреБрдгрд╕реНрддрд░-рдХреЗрдВрджреНрд░рд┐рдд Q5_K_S рд╢реНрд░реГрдВрдЦрд▓рд╛, рд╢рдХреНрддрд┐рд╢рд╛рд▓реА рдХрд┐рдирд╛рд░рд╛ рдЙрдкрдХрд░рдгрд╣рд░реВрдорд╛ рд▓рдЧрднрдЧ-рдореВрд▓ рд╕рдЯреАрдХрддрд╛рдХреЛ рд▓рд╛рдЧрд┐ Q8_0, рд░ рдЕрд▓реНрдЯреНрд░рд╛-рд▓реЛ рд╕реНрд░реЛрдд рдкрд░рд┐рджреГрд╢реНрдпрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдкреНрд░рдпреЛрдЧрд╛рддреНрдордХ рдлрд╛рд░рдореНрдпрд╛рдЯрд╣рд░реВ рдЬрд╕реНрддреИ Q2_K рд╕рдорд╛рд╡реЗрд╢ рдЫрдиреНред

### GGUF (рдЬрдирд░рд▓ GGML рдпреБрдирд┐рднрд░реНрд╕рд▓ рдлрд╛рд░рдореНрдпрд╛рдЯ) SLM рдкрд░рд┐рдирд┐рдпреЛрдЬрдирдХрд╛ рд▓рд╛рдЧрд┐

GGUF рдХрд┐рдирд╛рд░рд╛ рдЙрдкрдХрд░рдгрд╣рд░реВрдорд╛ рдХреНрд╡рд╛рдиреНрдЯрд╛рдЗрдЬ рдЧрд░рд┐рдПрдХреЛ SLMрд╣рд░реВ рдкрд░рд┐рдирд┐рдпреЛрдЬрди рдЧрд░реНрдирдХреЛ рд▓рд╛рдЧрд┐ рдкреНрд░рд╛рдердорд┐рдХ рдлрд╛рд░рдореНрдпрд╛рдЯрдХреЛ рд░реВрдкрдорд╛ рд╕реЗрд╡рд╛ рдЧрд░реНрджрдЫ, рд╡рд┐рд╢реЗрд╖ рд░реВрдкрдорд╛ рдПрдЬреЗрдиреНрдЯрд┐рдХ рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЕрдиреБрдХреВрд▓рд┐рдд:

**рдПрдЬреЗрдиреНрдЯ-рдЕрдиреБрдХреВрд▓рд┐рдд рд╕реБрд╡рд┐рдзрд╛рд╣рд░реВ**: рдлрд╛рд░рдореНрдпрд╛рдЯрд▓реЗ SLM рд░реВрдкрд╛рдиреНрддрд░рдг рд░ рдкрд░рд┐рдирд┐рдпреЛрдЬрдирдХрд╛ рд▓рд╛рдЧрд┐ рд╡реНрдпрд╛рдкрдХ рд╕реНрд░реЛрддрд╣рд░реВ рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫ, рдЙрдкрдХрд░рдг рдХрд▓рд┐рдВрдЧ, рд╕рдВрд░рдЪрд┐рдд рдЖрдЙрдЯрдкреБрдЯ рдЙрддреНрдкрд╛рджрди, рд░ рдмрд╣реБ-рдЯрд░реНрди рдХреБрд░рд╛рдХрд╛рдиреАрдХреЛ рд▓рд╛рдЧрд┐ рдЙрдиреНрдирдд рд╕рдорд░реНрдердирдХреЛ рд╕рд╛рдеред рдХреНрд░рд╕-рдкреНрд▓реНрдпрд╛рдЯрдлрд░реНрдо рдЕрдиреБрдХреВрд▓рддрд╛рд▓реЗ рд╡рд┐рднрд┐рдиреНрди рдХрд┐рдирд╛рд░рд╛ рдЙрдкрдХрд░рдгрд╣рд░реВрдорд╛ рд╕реНрдерд┐рд░ рдПрдЬреЗрдиреНрдЯ рд╡реНрдпрд╡рд╣рд╛рд░ рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдЧрд░реНрджрдЫред

**рдкреНрд░рджрд░реНрд╢рди рдЕрдиреБрдХреВрд▓рди**: GGUFрд▓реЗ рдПрдЬреЗрдиреНрдЯ рдХрд╛рд░реНрдпрдкреНрд░рд╡рд╛рд╣рд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдкреНрд░рднрд╛рд╡рдХрд╛рд░реА рдореЗрдореЛрд░реА рдкреНрд░рдпреЛрдЧ рд╕рдХреНрд╖рдо рдмрдирд╛рдЙрдБрдЫ, рдмрд╣реБ-рдПрдЬреЗрдиреНрдЯ рдкреНрд░рдгрд╛рд▓реАрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЧрддрд┐рд╢реАрд▓ рдореЛрдбреЗрд▓ рд▓реЛрдбрд┐рдВрдЧ рд╕рдорд░реНрдерди рдЧрд░реНрджрдЫ, рд░ рд╡рд╛рд╕реНрддрд╡рд┐рдХ-рд╕рдордп рдПрдЬреЗрдиреНрдЯ рдЕрдиреНрддрд░рдХреНрд░рд┐рдпрд╛рдХреЛ рд▓рд╛рдЧрд┐ рдЕрдиреБрдХреВрд▓рд┐рдд рдЕрдиреБрдорд╛рди рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫред

### рдХрд┐рдирд╛рд░рд╛-рдЕрдиреБрдХреВрд▓рд┐рдд SLM рдлреНрд░реЗрдорд╡рд░реНрдХрд╣рд░реВ

#### Llama.cpp рдПрдЬреЗрдиреНрдЯрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЕрдиреБрдХреВрд▓рди

Llama.cppрд▓реЗ рдПрдЬреЗрдиреНрдЯрд┐рдХ SLM рдкрд░рд┐рдирд┐рдпреЛрдЬрдирдХрд╛ рд▓рд╛рдЧрд┐ рд╡рд┐рд╢реЗрд╖ рд░реВрдкрдорд╛ рдЕрдиреБрдХреВрд▓рд┐рдд рдХреНрд╡рд╛рдиреНрдЯрд╛рдЗрдЬреЗрд╕рди рдкреНрд░рд╡рд┐рдзрд┐рд╣рд░реВ рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫ:

**рдПрдЬреЗрдиреНрдЯ-рд╡рд┐рд╢рд┐рд╖реНрдЯ рдХреНрд╡рд╛рдиреНрдЯрд╛рдЗрдЬреЗрд╕рди**: рдлреНрд░реЗрдорд╡рд░реНрдХрд▓реЗ Q4_0 (рдореЛрдмрд╛рдЗрд▓ рдПрдЬреЗрдиреНрдЯ рдкрд░рд┐рдирд┐рдпреЛрдЬрдирдХреЛ рд▓рд╛рдЧрд┐ ренрел% рдЖрдХрд╛рд░ рдШрдЯрд╛рдЙрдиреЗ), Q5_1 (рдХрд┐рдирд╛рд░рд╛ рдЕрдиреБрдорд╛рди рдПрдЬреЗрдиреНрдЯрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рд╕рдиреНрддреБрд▓рд┐рдд рдЧреБрдгрд╕реНрддрд░-рдХрдореНрдкреНрд░реЗрд╕рди), рд░ Q8_0 (рдЙрддреНрдкрд╛рджрди рдПрдЬреЗрдиреНрдЯ рдкреНрд░рдгрд╛рд▓реАрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рд▓рдЧрднрдЧ-рдореВрд▓ рдЧреБрдгрд╕реНрддрд░) рд╕рдорд░реНрдерди рдЧрд░реНрджрдЫред рдЙрдиреНрдирдд рдлрд╛рд░рдореНрдпрд╛рдЯрд╣рд░реВрд▓реЗ рдЪрд░рдо рдХрд┐рдирд╛рд░рд╛ рдкрд░рд┐рджреГрд╢реНрдпрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЕрд▓реНрдЯреНрд░рд╛-рдХрдореНрдкреНрд░реЗрд╕реНрдб рдПрдЬреЗрдиреНрдЯрд╣рд░реВ рд╕рдХреНрд╖рдо рдмрдирд╛рдЙрдБрдЫрдиреНред

**рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди рд▓рд╛рднрд╣рд░реВ**: SIMD рдПрдХреНрд╕реЗрд▓реЗрд░реЗрд╢рдирдХреЛ рд╕рд╛рде CPU-рдЕрдиреБрдХреВрд▓рд┐рдд рдЕрдиреБрдорд╛рдирд▓реЗ рдореЗрдореЛрд░реА-рдХреБрд╢рд▓ рдПрдЬреЗрдиреНрдЯ рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫред x86, ARM, рд░ Apple Silicon рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░рд╣рд░реВрдорд╛ рдХреНрд░рд╕-рдкреНрд▓реНрдпрд╛рдЯрдлрд░реНрдо рдЕрдиреБрдХреВрд▓рддрд╛рд▓реЗ рд╕рд╛рд░реНрд╡рднреМрдорд┐рдХ рдПрдЬреЗрдиреНрдЯ рдкрд░рд┐рдирд┐рдпреЛрдЬрди рдХреНрд╖рдорддрд╛рд╣рд░реВ рд╕рдХреНрд╖рдо рдмрдирд╛рдЙрдБрдЫред

#### Apple MLX рдлреНрд░реЗрдорд╡рд░реНрдХ SLM рдПрдЬреЗрдиреНрдЯрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐

Apple MLXрд▓реЗ Apple Silicon рдЙрдкрдХрд░рдгрд╣рд░реВрдорд╛ SLM-рд╕рдВрдЪрд╛рд▓рд┐рдд рдПрдЬреЗрдиреНрдЯрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рд╡рд┐рд╢реЗрд╖ рд░реВрдкрдорд╛ рдбрд┐рдЬрд╛рдЗрди рдЧрд░рд┐рдПрдХреЛ рджреЗрд╢реА рдЕрдиреБрдХреВрд▓рди рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫ:

**Apple Silicon рдПрдЬреЗрдиреНрдЯ рдЕрдиреБрдХреВрд▓рди**: рдлреНрд░реЗрдорд╡рд░реНрдХрд▓реЗ рдореЗрдЯрд▓ рдкреНрд░рджрд░реНрд╢рди рд╢реЗрдбрд░рд╣рд░реВрдХреЛ рдПрдХреАрдХрд░рдг, рдПрдЬреЗрдиреНрдЯ рдЕрдиреБрдорд╛рдирдХреЛ рд▓рд╛рдЧрд┐ рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рдорд┐рд╢реНрд░рд┐рдд рд╕рдЯреАрдХрддрд╛, рд░ рдмрд╣реБ-рдПрдЬреЗрдиреНрдЯ рдкреНрд░рдгрд╛рд▓реАрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЕрдиреБрдХреВрд▓рд┐рдд рдореЗрдореЛрд░реА рдмреНрдпрд╛рдиреНрдбрд╡рд┐рдердХреЛ рд╕рд╛рде рдПрдХреАрдХреГрдд рдореЗрдореЛрд░реА рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░ рдкреНрд░рдпреЛрдЧ рдЧрд░реНрджрдЫред M-рд╢реНрд░реГрдВрдЦрд▓рд╛ рдЪрд┐рдкреНрд╕рдорд╛ SLM рдПрдЬреЗрдиреНрдЯрд╣рд░реВрд▓реЗ рдЕрд╕рд╛рдзрд╛рд░рдг рдкреНрд░рджрд░реНрд╢рди рджреЗрдЦрд╛рдЙрдБрдЫрдиреНред

**рд╡рд┐рдХрд╛рд╕ рд╕реБрд╡рд┐рдзрд╛рд╣рд░реВ**: рдПрдЬреЗрдиреНрдЯ-рд╡рд┐рд╢рд┐рд╖реНрдЯ рдЕрдиреБрдХреВрд▓рдирд╣рд░реВ, рдПрдЬреЗрдиреНрдЯ рд╕рд┐рдХрд╛рдЗрдХреЛ рд▓рд╛рдЧрд┐ рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рднрд┐рдиреНрдирддрд╛, рд░ Apple рд╡рд┐рдХрд╛рд╕ рдЙрдкрдХрд░рдгрд╣рд░реВрд╕рдБрдЧ рд╕рд╣рдЬ рдПрдХреАрдХрд░рдгрдХреЛ рд╕рд╛рде Python рд░ Swift API рд╕рдорд░реНрдердирд▓реЗ рд╡реНрдпрд╛рдкрдХ рдПрдЬреЗрдиреНрдЯ рд╡рд┐рдХрд╛рд╕ рд╡рд╛рддрд╛рд╡рд░рдгрд╣рд░реВ рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫред

#### ONNX Runtime рдХреНрд░рд╕-рдкреНрд▓реНрдпрд╛рдЯрдлрд░реНрдо SLM рдПрдЬреЗрдиреНрдЯрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐

ONNX Runtimeрд▓реЗ рдПрдХ рд╕рд╛рд░реНрд╡рднреМрдорд┐рдХ рдЕрдиреБрдорд╛рди рдЗрдиреНрдЬрд┐рди рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫ рдЬрд╕рд▓реЗ SLM рдПрдЬреЗрдиреНрдЯрд╣рд░реВрд▓рд╛рдИ рд╡рд┐рд╡рд┐рдз рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рдкреНрд▓реЗрдЯрдлрд░реНрдорд╣рд░реВ рд░ рдЕрдкрд░реЗрдЯрд┐рдЩ рдкреНрд░рдгрд╛рд▓реАрд╣рд░реВрдорд╛ рд▓рдЧрд╛рддрд╛рд░ рдЪрд▓реНрди рд╕рдХреНрд╖рдо рдмрдирд╛рдЙрдБрдЫ:

**рд╕рд╛рд░реНрд╡рднреМрдорд┐рдХ рдкрд░рд┐рдирд┐рдпреЛрдЬрди**: ONNX Runtimeрд▓реЗ Windows, Linux, macOS, iOS, рд░ Android рдкреНрд▓реЗрдЯрдлрд░реНрдорд╣рд░реВрдорд╛ SLM рдПрдЬреЗрдиреНрдЯ рд╡реНрдпрд╡рд╣рд╛рд░рдХреЛ рдирд┐рд░рдиреНрддрд░рддрд╛ рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдЧрд░реНрджрдЫред рдпреЛ рдХреНрд░рд╕-рдкреНрд▓реНрдпрд╛рдЯрдлрд░реНрдо рдЕрдиреБрдХреВрд▓рддрд╛рд▓реЗ рд╡рд┐рдХрд╛рд╕рдХрд░реНрддрд╛рд╣рд░реВрд▓рд╛рдИ рдПрдХрдкрдЯрдХ рд▓реЗрдЦреНрди рд░ рд╕рдмреИ рдард╛рдЙрдБрдорд╛ рдкрд░рд┐рдирд┐рдпреЛрдЬрди рдЧрд░реНрди рд╕рдХреНрд╖рдо рдмрдирд╛рдЙрдБрдЫ, рдмрд╣реБ-рдкреНрд▓реНрдпрд╛рдЯрдлрд░реНрдо рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рд╡рд┐рдХрд╛рд╕ рд░ рдорд░реНрдорддрд╕рдореНрднрд╛рд░рдХреЛ рдУрднрд░рд╣реЗрдбрд▓рд╛рдИ рдЙрд▓реНрд▓реЗрдЦрдиреАрдп рд░реВрдкрдорд╛ рдХрдо рдЧрд░реНрджрдЫред

**рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рдПрдХреНрд╕реЗрд▓реЗрд░реЗрд╢рди рд╡рд┐рдХрд▓реНрдкрд╣рд░реВ**: рдлреНрд░реЗрдорд╡рд░реНрдХрд▓реЗ CPU (Intel, AMD, ARM), GPU (NVIDIA CUDA, AMD ROCm), рд░ рд╡рд┐рд╢реЗрд╖ рдПрдХреНрд╕реЗрд▓реЗрд░реЗрдЯрд░рд╣рд░реВ (Intel VPU, Qualcomm NPU) рд╕рд╣рд┐рдд рд╡рд┐рднрд┐рдиреНрди рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рдХрдиреНрдлрд┐рдЧрд░реЗрд╕рдирд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЕрдиреБрдХреВрд▓рд┐рдд рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди рдкреНрд░рджрд╛рдпрдХрд╣рд░реВ рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫред SLM рдПрдЬреЗрдиреНрдЯрд╣рд░реВрд▓реЗ рдХреЛрдб рдкрд░рд┐рд╡рд░реНрддрди рдмрд┐рдирд╛ рдиреИ рдЙрдкрд▓рдмреНрдз рд╕рдмреИрднрдиреНрджрд╛ рд░рд╛рдореНрд░реЛ рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рд░реВрдкрдорд╛ рдЙрдкрдпреЛрдЧ рдЧрд░реНрди рд╕рдХреНрдЫрдиреНред

**рдЙрддреНрдкрд╛рджрди-рддрдпрд╛рд░ рд╕реБрд╡рд┐рдзрд╛рд╣рд░реВ**: ONNX Runtimeрд▓реЗ рдЙрддреНрдкрд╛рджрди рдПрдЬреЗрдиреНрдЯ рдкрд░рд┐рдирд┐рдпреЛрдЬрдирдХрд╛ рд▓рд╛рдЧрд┐ рдЖрд╡рд╢реНрдпрдХ рдЙрджреНрдпрдо-рдЧреНрд░реЗрдб рд╕реБрд╡рд┐рдзрд╛рд╣рд░реВ рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫ рдЬрд╕рдорд╛ рдЫрд┐рдЯреЛ рдЕрдиреБрдорд╛рдирдХреЛ рд▓рд╛рдЧрд┐ рдЧреНрд░рд╛рдл рдЕрдиреБрдХреВрд▓рди, рд╕реНрд░реЛрдд-рд╕реАрдорд┐рдд рд╡рд╛рддрд╛рд╡рд░рдгрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдореЗрдореЛрд░реА рд╡реНрдпрд╡рд╕реНрдерд╛рдкрди, рд░ рдкреНрд░рджрд░реНрд╢рди рд╡рд┐рд╢реНрд▓реЗрд╖рдгрдХрд╛ рд▓рд╛рдЧрд┐ рд╡реНрдпрд╛рдкрдХ рдкреНрд░реЛрдлрд╛рдЗрд▓рд┐рдЩ рдЙрдкрдХрд░рдгрд╣рд░реВ рд╕рдорд╛рд╡реЗрд╢ рдЫрдиреНред рдлреНрд░реЗрдорд╡рд░реНрдХрд▓реЗ рд▓рдЪрд┐рд▓реЛ рдПрдХреАрдХрд░рдгрдХреЛ рд▓рд╛рдЧрд┐ Python рд░ C++ API рд╕рдорд░реНрдерди рдЧрд░реНрджрдЫред
- рдорд╛рдЗрдХреНрд░реЛрд╕рдлреНрдЯ рдПрдЬреЗрдиреНрдЯ рдлреНрд░реЗрдорд╡рд░реНрдХ рдПрдХреАрдХрд░рдг рдкрд░реАрдХреНрд╖рдг рдЧрд░реНрдиреБрд╣реЛрд╕реН  
- рдЕрдлрд▓рд╛рдЗрди рдЕрдкрд░реЗрд╢рди рдХреНрд╖рдорддрд╛рд╣рд░реВ рдкреНрд░рдорд╛рдгрд┐рдд рдЧрд░реНрдиреБрд╣реЛрд╕реН  
- рдлреЗрд▓рдУрднрд░ рдкрд░рд┐рджреГрд╢реНрдпрд╣рд░реВ рд░ рддреНрд░реБрдЯрд┐ рд╣реНрдпрд╛рдиреНрдбрд▓рд┐рдЩ рдкрд░реАрдХреНрд╖рдг рдЧрд░реНрдиреБрд╣реЛрд╕реН  
- рдЕрдиреНрдд-рджреЗрдЦрд┐-рдЕрдиреНрдд рдПрдЬреЗрдиреНрдЯ рд╡рд░реНрдХрдлреНрд▓реЛрд╣рд░реВ рдкреНрд░рдорд╛рдгрд┐рдд рдЧрд░реНрдиреБрд╣реЛрд╕реН  

**Foundry Local рд╕рдБрдЧ рддреБрд▓рдирд╛**:

| рд╡рд┐рд╢реЗрд╖рддрд╛ | Foundry Local | Ollama |
|---------|---------------|--------|
| **рд▓рдХреНрд╖рд┐рдд рдкреНрд░рдпреЛрдЧ рдХреЗрд╕** | рдЙрджреНрдпрдо рдЙрддреНрдкрд╛рджрди | рд╡рд┐рдХрд╛рд╕ рд░ рд╕рдореБрджрд╛рдп |
| **рдореЛрдбреЗрд▓ рдЗрдХреЛрд╕рд┐рд╕реНрдЯрдо** | рдорд╛рдЗрдХреНрд░реЛрд╕рдлреНрдЯ-рдХреНрдпреБрд░реЗрдЯреЗрдб | рд╡рд┐рд╕реНрддреГрдд рд╕рдореБрджрд╛рдп |
| **рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рдЕрдкреНрдЯрд┐рдорд╛рдЗрдЬреЗрд╕рди** | рд╕реНрд╡рдЪрд╛рд▓рд┐рдд (CUDA/NPU/CPU) | рдореНрдпрд╛рдиреБрдЕрд▓ рдХрдиреНрдлрд┐рдЧрд░реЗрд╕рди |
| **рдЙрджреНрдпрдо рд╡рд┐рд╢реЗрд╖рддрд╛рд╣рд░реВ** | рдмрд┐рд▓реНрдЯ-рдЗрди рдирд┐рдЧрд░рд╛рдиреА, рд╕реБрд░рдХреНрд╖рд╛ | рд╕рд╛рдореБрджрд╛рдпрд┐рдХ рдЙрдкрдХрд░рдгрд╣рд░реВ |
| **рдбрд┐рдкреНрд▓реЛрдпрдореЗрдиреНрдЯ рдЬрдЯрд┐рд▓рддрд╛** | рд╕рд░рд▓ (winget install) | рд╕рд░рд▓ (curl install) |
| **API рдЕрдиреБрдХреВрд▓рддрд╛** | OpenAI + рд╡рд┐рд╕реНрддрд╛рд░рд╣рд░реВ | OpenAI рдорд╛рдирдХ |
| **рд╕рдкреЛрд░реНрдЯ** | рдорд╛рдЗрдХреНрд░реЛрд╕рдлреНрдЯ рдЖрдзрд┐рдХрд╛рд░рд┐рдХ | рд╕рд╛рдореБрджрд╛рдпрд┐рдХ-рдЪрд╛рд▓рд┐рдд |
| **рдЙрддреНрддрдо рд▓рд╛рдЧрд┐** | рдЙрддреНрдкрд╛рджрди рдПрдЬреЗрдиреНрдЯрд╣рд░реВ | рдкреНрд░реЛрдЯреЛрдЯрд╛рдЗрдкрд┐рдЩ, рдЕрдиреБрд╕рдиреНрдзрд╛рди |

**Ollama рдЪрдпрди рдЧрд░реНрдиреЗ рд╕рдордп**:
- **рд╡рд┐рдХрд╛рд╕ рд░ рдкреНрд░реЛрдЯреЛрдЯрд╛рдЗрдкрд┐рдЩ**: рд╡рд┐рднрд┐рдиреНрди рдореЛрдбреЗрд▓рд╣рд░реВрд╕рдБрдЧ рдЫрд┐рдЯреЛ рдкреНрд░рдпреЛрдЧ  
- **рд╕рд╛рдореБрджрд╛рдпрд┐рдХ рдореЛрдбреЗрд▓рд╣рд░реВ**: рдирд╡реАрдирддрдо рд╕рд╛рдореБрджрд╛рдпрд┐рдХ рдпреЛрдЧрджрд╛рди рдореЛрдбреЗрд▓рд╣рд░реВрдорд╛ рдкрд╣реБрдБрдЪ  
- **рд╢реИрдХреНрд╖рд┐рдХ рдкреНрд░рдпреЛрдЧ**: AI рдПрдЬреЗрдиреНрдЯ рд╡рд┐рдХрд╛рд╕ рд╕рд┐рдХреНрди рд░ рд╕рд┐рдХрд╛рдЙрди  
- **рдЕрдиреБрд╕рдиреНрдзрд╛рди рдкрд░рд┐рдпреЛрдЬрдирд╛рд╣рд░реВ**: рд╡рд┐рд╡рд┐рдз рдореЛрдбреЗрд▓ рдкрд╣реБрдБрдЪ рдЖрд╡рд╢реНрдпрдХ рдкрд░реНрдиреЗ рд╢реИрдХреНрд╖рд┐рдХ рдЕрдиреБрд╕рдиреНрдзрд╛рди  
- **рдХрд╕реНрдЯрдо рдореЛрдбреЗрд▓рд╣рд░реВ**: рдХрд╕реНрдЯрдо рдлрд╛рдЗрди-рдЯреНрдпреБрди рдЧрд░рд┐рдПрдХреЛ рдореЛрдбреЗрд▓рд╣рд░реВ рдирд┐рд░реНрдорд╛рдг рд░ рдкрд░реАрдХреНрд╖рдг  

### VLLM: рдЙрдЪреНрдЪ-рдкреНрд░рджрд░реНрд╢рди SLM рдПрдЬреЗрдиреНрдЯ рдЗрдиреНрдлрд░реЗрдиреНрд╕

VLLM (рдмрд╣реБрдд рдареВрд▓реЛ рднрд╛рд╖рд╛ рдореЛрдбреЗрд▓ рдЗрдиреНрдлрд░реЗрдиреНрд╕) рдЙрдЪреНрдЪ-рдереНрд░реБрдкреБрдЯ, рдореЗрдореЛрд░реА-рдХреБрд╢рд▓ рдЗрдиреНрдлрд░реЗрдиреНрд╕ рдЗрдиреНрдЬрд┐рди рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫ, рд╡рд┐рд╢реЗрд╖ рд░реВрдкрдорд╛ рдЙрддреНрдкрд╛рджрди SLM рдбрд┐рдкреНрд▓реЛрдпрдореЗрдиреНрдЯрд╣рд░реВрдорд╛ рд╕реНрдХреЗрд▓рдорд╛ рдЕрдиреБрдХреВрд▓рд┐рддред Foundry Local рд▓реЗ рдкреНрд░рдпреЛрдЧрдХреЛ рд╕рдЬрд┐рд▓реЛрдкрдирдорд╛ рдзреНрдпрд╛рди рдХреЗрдиреНрджреНрд░рд┐рдд рдЧрд░реНрджрд╛ рд░ Ollama рд▓реЗ рд╕рд╛рдореБрджрд╛рдпрд┐рдХ рдореЛрдбреЗрд▓рд╣рд░реВрдорд╛ рдЬреЛрдб рджрд┐рдБрджрд╛, VLLM рдЙрдЪреНрдЪ-рдкреНрд░рджрд░реНрд╢рди рдкрд░рд┐рджреГрд╢реНрдпрд╣рд░реВрдорд╛ рдЙрддреНрдХреГрд╖реНрдЯ рдЫ рдЬрд╕рд▓реЗ рдЕрдзрд┐рдХрддрдо рдереНрд░реБрдкреБрдЯ рд░ рдХреБрд╢рд▓ рд╕реНрд░реЛрдд рдЙрдкрдпреЛрдЧ рдЖрд╡рд╢реНрдпрдХ рдЫред

**рдореБрдЦреНрдп рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░ рд░ рд╡рд┐рд╢реЗрд╖рддрд╛рд╣рд░реВ**:
- **PagedAttention**: рдзреНрдпрд╛рди рдЧрдгрдирд╛рдХреЛ рд▓рд╛рдЧрд┐ рдХреНрд░рд╛рдиреНрддрд┐рдХрд╛рд░реА рдореЗрдореЛрд░реА рд╡реНрдпрд╡рд╕реНрдерд╛рдкрди  
- **Dynamic Batching**: рдЗрд╖реНрдЯрддрдо рдереНрд░реБрдкреБрдЯрдХреЛ рд▓рд╛рдЧрд┐ рдмреБрджреНрдзрд┐рдорд╛рдиреА рдЕрдиреБрд░реЛрдз рдмреНрдпрд╛рдЪрд┐рдЩ  
- **GPU рдЕрдкреНрдЯрд┐рдорд╛рдЗрдЬреЗрд╕рди**: рдЙрдиреНрдирдд CUDA рдХрд░реНрдиреЗрд▓рд╣рд░реВ рд░ рдЯреЗрдиреНрд╕рд░ рд╕рдорд╛рдирд╛рдиреНрддрд░рддрд╛ рд╕рдорд░реНрдерди  
- **OpenAI рдЕрдиреБрдХреВрд▓рддрд╛**: рд╕рд╣рдЬ рдПрдХреАрдХрд░рдгрдХреЛ рд▓рд╛рдЧрд┐ рдкреВрд░реНрдг API рдЕрдиреБрдХреВрд▓рддрд╛  
- **Speculative Decoding**: рдЙрдиреНрдирдд рдЗрдиреНрдлрд░реЗрдиреНрд╕ рдПрдХреНрд╕реЗрд▓реЗрд░реЗрд╢рди рдкреНрд░рд╡рд┐рдзрд┐рд╣рд░реВ  
- **Quantization Support**: рдореЗрдореЛрд░реА рджрдХреНрд╖рддрд╛рдХреЛ рд▓рд╛рдЧрд┐ INT4, INT8, рд░ FP16 рдХреНрд╡рд╛рдиреНрдЯрд╛рдЗрдЬреЗрд╕рди  

#### рд╕реНрдерд╛рдкрдирд╛ рд░ рд╕реЗрдЯрдЕрдк

**рд╕реНрдерд╛рдкрдирд╛ рд╡рд┐рдХрд▓реНрдкрд╣рд░реВ**:  
```bash
# Standard installation
pip install vllm

# With additional dependencies for agent frameworks
pip install vllm[agent] openai

# Docker deployment for production
docker pull vllm/vllm-openai:latest

# From source for latest features
git clone https://github.com/vllm-project/vllm.git
cd vllm
pip install -e .
```
  
**рдПрдЬреЗрдиреНрдЯ рд╡рд┐рдХрд╛рд╕рдХреЛ рд▓рд╛рдЧрд┐ рдЫрд┐рдЯреЛ рд╕реБрд░реБ**:  
```bash
# Start VLLM server with SLM model
python -m vllm.entrypoints.openai.api_server \
    --model microsoft/Phi-3.5-mini-instruct \
    --trust-remote-code \
    --max-model-len 4096 \
    --gpu-memory-utilization 0.8

# Alternative: Start with Qwen2.5 for lightweight agents
python -m vllm.entrypoints.openai.api_server \
    --model Qwen/Qwen2.5-0.5B-Instruct \
    --trust-remote-code \
    --max-model-len 2048 \
    --tensor-parallel-size 1

# Test API endpoint
curl http://localhost:8000/v1/models

# Test chat completion
curl http://localhost:8000/v1/chat/completions \
    -H "Content-Type: application/json" \
    -d '{
        "model": "microsoft/Phi-3.5-mini-instruct",
        "messages": [{"role": "user", "content": "Hello!"}]
    }'
```
  

#### рдПрдЬреЗрдиреНрдЯ рдлреНрд░реЗрдорд╡рд░реНрдХ рдПрдХреАрдХрд░рдг

**VLLM рдорд╛рдЗрдХреНрд░реЛрд╕рдлреНрдЯ рдПрдЬреЗрдиреНрдЯ рдлреНрд░реЗрдорд╡рд░реНрдХрд╕рдБрдЧ**:  
```python
from microsoft_agent_framework import Agent, Config
import openai
import subprocess
import time
import requests
from typing import Optional, Dict, Any

class VLLMManager:
    def __init__(self, model_name: str, 
                 host: str = "localhost", 
                 port: int = 8000,
                 gpu_memory_utilization: float = 0.8,
                 max_model_len: int = 4096):
        self.model_name = model_name
        self.host = host
        self.port = port
        self.base_url = f"http://{host}:{port}"
        self.gpu_memory_utilization = gpu_memory_utilization
        self.max_model_len = max_model_len
        self.process = None
        self.client = None
        
    def start_server(self) -> bool:
        """Start VLLM server with optimized settings for agents."""
        try:
            cmd = [
                "python", "-m", "vllm.entrypoints.openai.api_server",
                "--model", self.model_name,
                "--host", self.host,
                "--port", str(self.port),
                "--gpu-memory-utilization", str(self.gpu_memory_utilization),
                "--max-model-len", str(self.max_model_len),
                "--trust-remote-code",
                "--disable-log-requests",  # Reduce logging for agents
                "--served-model-name", self.get_served_model_name()
            ]
            
            self.process = subprocess.Popen(cmd, 
                stdout=subprocess.PIPE, 
                stderr=subprocess.PIPE)
            
            # Wait for server to start
            max_retries = 30
            for _ in range(max_retries):
                if self.health_check():
                    self.client = openai.OpenAI(base_url=f"{self.base_url}/v1")
                    return True
                time.sleep(2)
                
            return False
            
        except Exception as e:
            print(f"Failed to start VLLM server: {e}")
            return False
    
    def get_served_model_name(self) -> str:
        """Get a clean model name for serving."""
        return self.model_name.replace("/", "--")
    
    def health_check(self) -> bool:
        """Check if VLLM server is healthy."""
        try:
            response = requests.get(f"{self.base_url}/health", timeout=5)
            return response.status_code == 200
        except:
            return False
    
    def get_openai_client(self) -> openai.OpenAI:
        """Get OpenAI-compatible client for VLLM."""
        if not self.client:
            self.client = openai.OpenAI(base_url=f"{self.base_url}/v1")
        return self.client
    
    def get_model_info(self) -> Dict[str, Any]:
        """Get model information and statistics."""
        try:
            response = requests.get(f"{self.base_url}/v1/models")
            if response.status_code == 200:
                return response.json()
        except:
            pass
        return {}
    
    def shutdown(self):
        """Shutdown VLLM server."""
        if self.process:
            self.process.terminate()
            self.process.wait()

# Initialize VLLM for high-performance agents
vllm_manager = VLLMManager("microsoft/Phi-3.5-mini-instruct")
if vllm_manager.start_server():
    print("VLLM server started successfully")
    
    # Configure agent with VLLM backend
    agent_config = Config(
        name="vllm-performance-agent",
        model_provider="vllm",
        model_id=vllm_manager.get_served_model_name(),
        endpoint=f"{vllm_manager.base_url}/v1",
        api_key="none"  # VLLM doesn't require API key
    )
    
    agent = Agent(config=agent_config)
else:
    print("Failed to start VLLM server")
```
  
**рдЙрдЪреНрдЪ-рдереНрд░реБрдкреБрдЯ рдорд▓реНрдЯрд┐-рдПрдЬреЗрдиреНрдЯ рд╕реЗрдЯрдЕрдк**:  
```python
import asyncio
from concurrent.futures import ThreadPoolExecutor
from microsoft_agent_framework import Agent, Config
import openai

class VLLMHighThroughputManager:
    def __init__(self):
        self.model_configs = {
            "lightweight": {
                "model": "Qwen/Qwen2.5-0.5B-Instruct",
                "port": 8000,
                "max_model_len": 2048,
                "gpu_memory_utilization": 0.3
            },
            "balanced": {
                "model": "microsoft/Phi-3.5-mini-instruct",
                "port": 8001,
                "max_model_len": 4096,
                "gpu_memory_utilization": 0.5
            },
            "capable": {
                "model": "meta-llama/Llama-3.2-3B-Instruct",
                "port": 8002,
                "max_model_len": 8192,
                "gpu_memory_utilization": 0.7
            }
        }
        self.managers = {}
        self.agents = {}
        self.client_pool = {}
        
    async def initialize_all_models(self):
        """Initialize all VLLM models in parallel."""
        initialization_tasks = []
        
        for category, config in self.model_configs.items():
            task = self._initialize_model(category, config)
            initialization_tasks.append(task)
        
        results = await asyncio.gather(*initialization_tasks, return_exceptions=True)
        
        successful_inits = 0
        for i, result in enumerate(results):
            category = list(self.model_configs.keys())[i]
            if isinstance(result, Exception):
                print(f"Failed to initialize {category}: {result}")
            else:
                successful_inits += 1
                print(f"Successfully initialized {category} model")
        
        return successful_inits
    
    async def _initialize_model(self, category: str, config: Dict[str, Any]):
        """Initialize a single VLLM model instance."""
        manager = VLLMManager(
            model_name=config["model"],
            port=config["port"],
            max_model_len=config["max_model_len"],
            gpu_memory_utilization=config["gpu_memory_utilization"]
        )
        
        # Start server in thread to avoid blocking
        loop = asyncio.get_event_loop()
        with ThreadPoolExecutor() as executor:
            success = await loop.run_in_executor(executor, manager.start_server)
        
        if success:
            self.managers[category] = manager
            
            # Create agent
            agent_config = Config(
                name=f"vllm-{category}-agent",
                model_provider="vllm",
                model_id=manager.get_served_model_name(),
                endpoint=f"{manager.base_url}/v1",
                api_key="none"
            )
            
            self.agents[category] = Agent(config=agent_config)
            
            # Create client pool for high throughput
            self.client_pool[category] = [
                openai.OpenAI(base_url=f"{manager.base_url}/v1")
                for _ in range(5)  # 5 clients per model for parallelism
            ]
            
            return True
        else:
            raise Exception(f"Failed to start VLLM server for {category}")
    
    def get_optimal_agent(self, request_complexity: str, current_load: Dict[str, int]) -> str:
        """Select optimal agent based on request complexity and current load."""
        complexity_mapping = {
            "simple": "lightweight",
            "moderate": "balanced", 
            "complex": "capable"
        }
        
        preferred_category = complexity_mapping.get(request_complexity, "balanced")
        
        # Check if preferred agent is available and not overloaded
        if (preferred_category in self.agents and 
            current_load.get(preferred_category, 0) < 10):  # Max 10 concurrent per agent
            return preferred_category
        
        # Fallback to least loaded available agent
        available_agents = [(cat, load) for cat, load in current_load.items() 
                          if cat in self.agents and load < 10]
        
        if available_agents:
            return min(available_agents, key=lambda x: x[1])[0]
        
        return "balanced"  # Default fallback
    
    async def process_batch_requests(self, requests: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Process multiple requests in parallel for maximum throughput."""
        current_load = {cat: 0 for cat in self.agents.keys()}
        tasks = []
        
        for request in requests:
            # Determine optimal agent
            complexity = request.get("complexity", "moderate")
            agent_category = self.get_optimal_agent(complexity, current_load)
            current_load[agent_category] += 1
            
            # Create processing task
            task = self._process_single_request(request, agent_category)
            tasks.append(task)
        
        # Process all requests in parallel
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Format results
        formatted_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                formatted_results.append({
                    "request_id": requests[i].get("id", i),
                    "status": "error",
                    "error": str(result)
                })
            else:
                formatted_results.append(result)
        
        return formatted_results
    
    async def _process_single_request(self, request: Dict[str, Any], agent_category: str) -> Dict[str, Any]:
        """Process a single request with the specified agent."""
        start_time = time.time()
        
        try:
            agent = self.agents[agent_category]
            response = await agent.chat_async(request["message"])
            
            processing_time = time.time() - start_time
            
            return {
                "request_id": request.get("id"),
                "status": "success",
                "response": response,
                "agent_used": agent_category,
                "processing_time": processing_time
            }
            
        except Exception as e:
            return {
                "request_id": request.get("id"),
                "status": "error",
                "error": str(e),
                "agent_used": agent_category,
                "processing_time": time.time() - start_time
            }

# High-throughput usage example
throughput_manager = VLLMHighThroughputManager()

# Initialize all models
initialized_count = await throughput_manager.initialize_all_models()
print(f"Initialized {initialized_count} models")

# Process batch requests
batch_requests = [
    {"id": 1, "message": "Simple question", "complexity": "simple"},
    {"id": 2, "message": "Complex analysis needed", "complexity": "complex"},
    {"id": 3, "message": "Moderate difficulty task", "complexity": "moderate"}
]

results = await throughput_manager.process_batch_requests(batch_requests)
for result in results:
    print(f"Request {result['request_id']}: {result['status']} in {result.get('processing_time', 0):.2f}s")
```
  

#### рдЙрддреНрдкрд╛рджрди рдбрд┐рдкреНрд▓реЛрдпрдореЗрдиреНрдЯ рдврд╛рдБрдЪрд╛рд╣рд░реВ

**рдЙрджреНрдпрдо VLLM рдЙрддреНрдкрд╛рджрди рд╕реЗрд╡рд╛**:  
```python
import asyncio
import logging
import time
from typing import Dict, List, Optional
from dataclasses import dataclass
from microsoft_agent_framework import Agent, Config
import uvicorn
from fastapi import FastAPI, HTTPException, BackgroundTasks
from pydantic import BaseModel

@dataclass
class VLLMServerConfig:
    model_name: str
    port: int
    gpu_memory_utilization: float
    max_model_len: int
    tensor_parallel_size: int = 1
    quantization: Optional[str] = None

class AgentRequest(BaseModel):
    message: str
    agent_type: str = "general"
    priority: str = "normal"
    timeout: int = 30

class VLLMProductionService:
    def __init__(self, server_configs: Dict[str, VLLMServerConfig]):
        self.server_configs = server_configs
        self.managers = {}
        self.agents = {}
        self.metrics = {
            "requests_processed": 0,
            "requests_failed": 0,
            "total_processing_time": 0,
            "agent_usage": {name: 0 for name in server_configs.keys()},
            "throughput_per_minute": 0
        }
        self.request_queue = asyncio.Queue(maxsize=1000)
        self.processing_workers = []
        self.app = FastAPI(title="VLLM Agent Service")
        self._setup_routes()
        
    async def initialize_production_environment(self):
        """Initialize all VLLM servers for production."""
        logging.info("Initializing VLLM production environment...")
        
        initialization_tasks = []
        for name, config in self.server_configs.items():
            task = self._initialize_server(name, config)
            initialization_tasks.append(task)
        
        results = await asyncio.gather(*initialization_tasks, return_exceptions=True)
        
        successful_servers = 0
        for i, result in enumerate(results):
            server_name = list(self.server_configs.keys())[i]
            if isinstance(result, Exception):
                logging.error(f"Failed to initialize {server_name}: {result}")
            else:
                successful_servers += 1
                logging.info(f"Successfully initialized {server_name}")
        
        if successful_servers == 0:
            raise Exception("No VLLM servers could be initialized")
        
        # Start processing workers
        self.processing_workers = [
            asyncio.create_task(self._processing_worker(i))
            for i in range(min(4, successful_servers))  # 4 workers max
        ]
        
        logging.info(f"Production environment ready with {successful_servers} servers")
        return successful_servers
    
    async def _initialize_server(self, name: str, config: VLLMServerConfig):
        """Initialize a single VLLM server."""
        manager = VLLMManager(
            model_name=config.model_name,
            port=config.port,
            gpu_memory_utilization=config.gpu_memory_utilization,
            max_model_len=config.max_model_len
        )
        
        # Add quantization if specified
        if config.quantization:
            # This would be added to the manager's start command
            pass
        
        success = manager.start_server()
        if success:
            self.managers[name] = manager
            
            # Create production agent
            agent_config = Config(
                name=f"vllm-production-{name}",
                model_provider="vllm",
                model_id=manager.get_served_model_name(),
                endpoint=f"{manager.base_url}/v1",
                api_key="none",
                timeout=30.0
            )
            
            agent = Agent(config=agent_config)
            
            # Add production tools
            self._add_production_tools(agent, name)
            
            self.agents[name] = agent
            return True
        else:
            raise Exception(f"Failed to start VLLM server for {name}")
    
    def _add_production_tools(self, agent: Agent, server_type: str):
        """Add production tools based on server type."""
        if server_type == "customer_service":
            @agent.tool
            def escalate_to_human(issue: str, customer_id: str) -> str:
                """Escalate complex issues to human agents."""
                return f"Escalated issue for customer {customer_id}: {issue}"
            
            @agent.tool
            def lookup_order_status(order_id: str) -> dict:
                """Look up order status from production database."""
                # Production database lookup
                return {"order_id": order_id, "status": "shipped", "eta": "2 days"}
        
        elif server_type == "technical_support":
            @agent.tool
            def run_system_diagnostics(system_id: str) -> dict:
                """Run comprehensive system diagnostics."""
                return {"system_id": system_id, "status": "healthy", "issues": []}
            
            @agent.tool
            def create_incident_report(description: str, severity: str) -> str:
                """Create incident report in production system."""
                incident_id = f"INC-{hash(description) % 100000:05d}"
                return f"Created incident {incident_id} with severity {severity}"
    
    def _setup_routes(self):
        """Set up FastAPI routes for production service."""
        @self.app.post("/chat")
        async def chat_endpoint(request: AgentRequest, background_tasks: BackgroundTasks):
            try:
                # Add request to queue
                await self.request_queue.put({
                    "request": request,
                    "timestamp": time.time(),
                    "future": asyncio.Future()
                })
                
                # Wait for processing (with timeout)
                result = await asyncio.wait_for(
                    self._wait_for_result(request),
                    timeout=request.timeout
                )
                
                return result
                
            except asyncio.TimeoutError:
                raise HTTPException(status_code=408, detail="Request timeout")
            except Exception as e:
                raise HTTPException(status_code=500, detail=str(e))
        
        @self.app.get("/health")
        async def health_endpoint():
            return await self.get_health_status()
        
        @self.app.get("/metrics")
        async def metrics_endpoint():
            return self.get_production_metrics()
    
    async def _processing_worker(self, worker_id: int):
        """Background worker for processing agent requests."""
        logging.info(f"Starting processing worker {worker_id}")
        
        while True:
            try:
                # Get request from queue
                queue_item = await self.request_queue.get()
                request_data = queue_item["request"]
                request_future = queue_item["future"]
                
                # Select appropriate agent
                agent_name = self._select_agent(request_data.agent_type)
                
                if agent_name not in self.agents:
                    request_future.set_exception(Exception(f"Agent {agent_name} not available"))
                    continue
                
                # Process request
                start_time = time.time()
                try:
                    agent = self.agents[agent_name]
                    response = await agent.chat_async(request_data.message)
                    
                    processing_time = time.time() - start_time
                    
                    # Update metrics
                    self.metrics["requests_processed"] += 1
                    self.metrics["total_processing_time"] += processing_time
                    self.metrics["agent_usage"][agent_name] += 1
                    
                    result = {
                        "response": response,
                        "agent_used": agent_name,
                        "processing_time": processing_time,
                        "worker_id": worker_id
                    }
                    
                    request_future.set_result(result)
                    
                except Exception as e:
                    self.metrics["requests_failed"] += 1
                    request_future.set_exception(e)
                
                finally:
                    self.request_queue.task_done()
                    
            except Exception as e:
                logging.error(f"Worker {worker_id} error: {e}")
                await asyncio.sleep(1)
    
    def _select_agent(self, agent_type: str) -> str:
        """Select appropriate agent based on request type."""
        agent_mapping = {
            "customer_service": "customer_service",
            "technical": "technical_support",
            "general": "general_purpose"
        }
        
        return agent_mapping.get(agent_type, "general_purpose")
    
    async def _wait_for_result(self, request: AgentRequest):
        """Wait for request processing to complete."""
        # This is simplified - in production you'd track futures properly
        await asyncio.sleep(0.1)  # Placeholder
        return {"response": "Processed", "status": "success"}
    
    async def get_health_status(self) -> dict:
        """Get comprehensive health status of all services."""
        health_status = {
            "overall_status": "healthy",
            "servers": {},
            "queue_size": self.request_queue.qsize(),
            "active_workers": len([w for w in self.processing_workers if not w.done()]),
            "timestamp": time.time()
        }
        
        unhealthy_servers = 0
        for name, manager in self.managers.items():
            try:
                is_healthy = manager.health_check()
                health_status["servers"][name] = {
                    "status": "healthy" if is_healthy else "unhealthy",
                    "endpoint": manager.base_url,
                    "model": manager.model_name
                }
                if not is_healthy:
                    unhealthy_servers += 1
            except Exception as e:
                health_status["servers"][name] = {
                    "status": "error",
                    "error": str(e)
                }
                unhealthy_servers += 1
        
        if unhealthy_servers > 0:
            health_status["overall_status"] = "degraded" if unhealthy_servers < len(self.managers) else "unhealthy"
        
        return health_status
    
    def get_production_metrics(self) -> dict:
        """Get production performance metrics."""
        total_requests = self.metrics["requests_processed"] + self.metrics["requests_failed"]
        avg_processing_time = (
            self.metrics["total_processing_time"] / self.metrics["requests_processed"]
            if self.metrics["requests_processed"] > 0 else 0
        )
        
        success_rate = (
            self.metrics["requests_processed"] / total_requests * 100
            if total_requests > 0 else 0
        )
        
        return {
            "total_requests": total_requests,
            "successful_requests": self.metrics["requests_processed"],
            "failed_requests": self.metrics["requests_failed"],
            "success_rate_percent": success_rate,
            "average_processing_time_seconds": avg_processing_time,
            "agent_usage_distribution": self.metrics["agent_usage"],
            "queue_size": self.request_queue.qsize()
        }
    
    async def start_production_server(self, host: str = "0.0.0.0", port: int = 8080):
        """Start the production FastAPI server."""
        config = uvicorn.Config(
            self.app,
            host=host,
            port=port,
            log_level="info",
            workers=1  # Single worker for simplicity
        )
        server = uvicorn.Server(config)
        await server.serve()

# Production deployment example
production_configs = {
    "customer_service": VLLMServerConfig(
        model_name="microsoft/Phi-3.5-mini-instruct",
        port=8000,
        gpu_memory_utilization=0.4,
        max_model_len=4096
    ),
    "technical_support": VLLMServerConfig(
        model_name="meta-llama/Llama-3.2-3B-Instruct",
        port=8001,
        gpu_memory_utilization=0.6,
        max_model_len=8192
    ),
    "general_purpose": VLLMServerConfig(
        model_name="Qwen/Qwen2.5-1.5B-Instruct",
        port=8002,
        gpu_memory_utilization=0.3,
        max_model_len=2048
    )
}

production_service = VLLMProductionService(production_configs)

# Initialize and start production service
# await production_service.initialize_production_environment()
# await production_service.start_production_server()
```
  

#### рдЙрджреНрдпрдо рд╡рд┐рд╢реЗрд╖рддрд╛рд╣рд░реВ рд░ рдирд┐рдЧрд░рд╛рдиреА

**рдЙрдиреНрдирдд VLLM рдкреНрд░рджрд░реНрд╢рди рдирд┐рдЧрд░рд╛рдиреА**:  
```python
import psutil
import nvidia_ml_py3 as nvml
from dataclasses import dataclass
from typing import List, Dict, Optional
import json
import asyncio

@dataclass
class PerformanceMetrics:
    timestamp: float
    requests_per_second: float
    average_latency_ms: float
    gpu_utilization_percent: float
    gpu_memory_used_gb: float
    cpu_utilization_percent: float
    memory_used_gb: float
    queue_length: int
    active_requests: int

class VLLMAdvancedMonitoring:
    def __init__(self, vllm_managers: Dict[str, VLLMManager]):
        self.managers = vllm_managers
        self.metrics_history = []
        self.alert_thresholds = {
            "gpu_utilization_max": 95,
            "gpu_memory_max_gb": 10,
            "latency_max_ms": 3000,
            "queue_length_max": 50,
            "error_rate_max_percent": 10
        }
        
        # Initialize NVIDIA ML for GPU monitoring
        try:
            nvml.nvmlInit()
            self.gpu_monitoring_available = True
            self.gpu_count = nvml.nvmlDeviceGetCount()
        except:
            self.gpu_monitoring_available = False
            self.gpu_count = 0
    
    async def collect_comprehensive_metrics(self) -> Dict[str, PerformanceMetrics]:
        """Collect detailed performance metrics for all VLLM instances."""
        all_metrics = {}
        
        for name, manager in self.managers.items():
            try:
                metrics = await self._collect_single_instance_metrics(name, manager)
                all_metrics[name] = metrics
            except Exception as e:
                logging.error(f"Failed to collect metrics for {name}: {e}")
                # Create error metrics
                all_metrics[name] = PerformanceMetrics(
                    timestamp=time.time(),
                    requests_per_second=0,
                    average_latency_ms=0,
                    gpu_utilization_percent=0,
                    gpu_memory_used_gb=0,
                    cpu_utilization_percent=0,
                    memory_used_gb=0,
                    queue_length=0,
                    active_requests=0
                )
        
        return all_metrics
    
    async def _collect_single_instance_metrics(self, name: str, manager: VLLMManager) -> PerformanceMetrics:
        """Collect metrics for a single VLLM instance."""
        timestamp = time.time()
        
        # Get VLLM-specific metrics via API
        vllm_stats = await self._get_vllm_stats(manager)
        
        # Get system metrics
        cpu_percent = psutil.cpu_percent(interval=0.1)
        memory_info = psutil.virtual_memory()
        memory_used_gb = memory_info.used / (1024**3)
        
        # Get GPU metrics if available
        gpu_utilization = 0
        gpu_memory_used = 0
        
        if self.gpu_monitoring_available and self.gpu_count > 0:
            try:
                # Assuming first GPU for simplicity
                handle = nvml.nvmlDeviceGetHandleByIndex(0)
                gpu_util = nvml.nvmlDeviceGetUtilizationRates(handle)
                gpu_utilization = gpu_util.gpu
                
                gpu_mem = nvml.nvmlDeviceGetMemoryInfo(handle)
                gpu_memory_used = gpu_mem.used / (1024**3)
                
            except Exception as e:
                logging.warning(f"GPU monitoring failed: {e}")
        
        return PerformanceMetrics(
            timestamp=timestamp,
            requests_per_second=vllm_stats.get("requests_per_second", 0),
            average_latency_ms=vllm_stats.get("average_latency_ms", 0),
            gpu_utilization_percent=gpu_utilization,
            gpu_memory_used_gb=gpu_memory_used,
            cpu_utilization_percent=cpu_percent,
            memory_used_gb=memory_used_gb,
            queue_length=vllm_stats.get("queue_length", 0),
            active_requests=vllm_stats.get("active_requests", 0)
        )
    
    async def _get_vllm_stats(self, manager: VLLMManager) -> dict:
        """Get VLLM-specific statistics via API calls."""
        try:
            # Test inference to measure latency
            start_time = time.time()
            client = manager.get_openai_client()
            
            response = await asyncio.wait_for(
                asyncio.to_thread(
                    client.chat.completions.create,
                    model=manager.get_served_model_name(),
                    messages=[{"role": "user", "content": "ping"}],
                    max_tokens=1
                ),
                timeout=5.0
            )
            
            latency_ms = (time.time() - start_time) * 1000
            
            return {
                "average_latency_ms": latency_ms,
                "requests_per_second": 1000 / latency_ms if latency_ms > 0 else 0,
                "queue_length": 0,  # Would need to be exposed by VLLM
                "active_requests": 1  # Approximation
            }
            
        except Exception as e:
            logging.warning(f"Failed to get VLLM stats: {e}")
            return {
                "average_latency_ms": 0,
                "requests_per_second": 0,
                "queue_length": 0,
                "active_requests": 0
            }
    
    def generate_performance_report(self, time_window_minutes: int = 60) -> dict:
        """Generate comprehensive performance report."""
        cutoff_time = time.time() - (time_window_minutes * 60)
        recent_metrics = [
            metrics for metrics in self.metrics_history
            if any(m.timestamp > cutoff_time for m in metrics.values())
        ]
        
        if not recent_metrics:
            return {"error": "No recent metrics available"}
        
        report = {
            "time_window_minutes": time_window_minutes,
            "total_samples": len(recent_metrics),
            "instances": {}
        }
        
        # Analyze each instance
        for instance_name in self.managers.keys():
            instance_metrics = [
                metrics[instance_name] for metrics in recent_metrics
                if instance_name in metrics
            ]
            
            if instance_metrics:
                report["instances"][instance_name] = {
                    "avg_latency_ms": sum(m.average_latency_ms for m in instance_metrics) / len(instance_metrics),
                    "max_latency_ms": max(m.average_latency_ms for m in instance_metrics),
                    "avg_gpu_utilization": sum(m.gpu_utilization_percent for m in instance_metrics) / len(instance_metrics),
                    "avg_requests_per_second": sum(m.requests_per_second for m in instance_metrics) / len(instance_metrics),
                    "max_queue_length": max(m.queue_length for m in instance_metrics),
                    "availability_percent": (len(instance_metrics) / len(recent_metrics)) * 100
                }
        
        return report
    
    async def auto_scaling_recommendations(self) -> List[dict]:
        """Generate auto-scaling recommendations based on performance metrics."""
        recommendations = []
        
        if not self.metrics_history:
            return recommendations
        
        latest_metrics = self.metrics_history[-1]
        
        for instance_name, metrics in latest_metrics.items():
            # High latency recommendation
            if metrics.average_latency_ms > self.alert_thresholds["latency_max_ms"]:
                recommendations.append({
                    "instance": instance_name,
                    "type": "scale_up",
                    "reason": f"High latency: {metrics.average_latency_ms:.0f}ms",
                    "suggestion": "Consider adding tensor parallelism or increasing GPU memory"
                })
            
            # High GPU utilization recommendation
            if metrics.gpu_utilization_percent > self.alert_thresholds["gpu_utilization_max"]:
                recommendations.append({
                    "instance": instance_name,
                    "type": "scale_out",
                    "reason": f"High GPU utilization: {metrics.gpu_utilization_percent:.1f}%",
                    "suggestion": "Consider adding additional GPU instances"
                })
            
            # Low utilization recommendation
            if (metrics.gpu_utilization_percent < 20 and 
                metrics.requests_per_second < 1):
                recommendations.append({
                    "instance": instance_name,
                    "type": "scale_down",
                    "reason": f"Low utilization: {metrics.gpu_utilization_percent:.1f}% GPU, {metrics.requests_per_second:.1f} RPS",
                    "suggestion": "Consider consolidating workloads or reducing resources"
                })
        
        return recommendations

# Advanced monitoring setup
monitoring = VLLMAdvancedMonitoring({
    "customer_service": vllm_manager,
    # Add other managers as needed
})

async def advanced_monitoring_loop():
    """Advanced monitoring with auto-scaling recommendations."""
    while True:
        try:
            # Collect metrics
            metrics = await monitoring.collect_comprehensive_metrics()
            monitoring.metrics_history.append(metrics)
            
            # Keep only last 1000 entries
            if len(monitoring.metrics_history) > 1000:
                monitoring.metrics_history = monitoring.metrics_history[-1000:]
            
            # Generate recommendations every 5 minutes
            if len(monitoring.metrics_history) % 10 == 0:  # Every 10th collection (5 minutes if collecting every 30s)
                recommendations = await monitoring.auto_scaling_recommendations()
                
                if recommendations:
                    logging.info(f"Auto-scaling recommendations: {recommendations}")
            
            # Generate performance report every hour
            if len(monitoring.metrics_history) % 120 == 0:  # Every 120th collection (1 hour)
                report = monitoring.generate_performance_report(60)
                logging.info(f"Performance report: {json.dumps(report, indent=2)}")
            
        except Exception as e:
            logging.error(f"Advanced monitoring error: {e}")
        
        await asyncio.sleep(30)  # Collect metrics every 30 seconds

# Start advanced monitoring
# asyncio.create_task(advanced_monitoring_loop())
```
  

#### рдЙрдиреНрдирдд рдХрдиреНрдлрд┐рдЧрд░реЗрд╕рди рд░ рдЕрдкреНрдЯрд┐рдорд╛рдЗрдЬреЗрд╕рди

**рдЙрддреНрдкрд╛рджрди VLLM рдХрдиреНрдлрд┐рдЧрд░реЗрд╕рди рдЯреЗрдореНрдкреНрд▓реЗрдЯрд╣рд░реВ**:  
```python
from enum import Enum
from typing import Dict, Any

class DeploymentScenario(Enum):
    DEVELOPMENT = "development"
    STAGING = "staging"
    PRODUCTION_LOW = "production_low"
    PRODUCTION_HIGH = "production_high"
    ENTERPRISE = "enterprise"

class VLLMConfigTemplates:
    """Production-ready VLLM configuration templates."""
    
    @staticmethod
    def get_config_template(scenario: DeploymentScenario) -> Dict[str, Any]:
        """Get optimized configuration for deployment scenario."""
        
        templates = {
            DeploymentScenario.DEVELOPMENT: {
                "gpu_memory_utilization": 0.6,
                "max_model_len": 2048,
                "tensor_parallel_size": 1,
                "pipeline_parallel_size": 1,
                "quantization": None,
                "enable_prefix_caching": False,
                "max_num_seqs": 32,
                "max_num_batched_tokens": 2048
            },
            
            DeploymentScenario.STAGING: {
                "gpu_memory_utilization": 0.8,
                "max_model_len": 4096,
                "tensor_parallel_size": 1,
                "pipeline_parallel_size": 1,
                "quantization": "awq",
                "enable_prefix_caching": True,
                "max_num_seqs": 64,
                "max_num_batched_tokens": 4096
            },
            
            DeploymentScenario.PRODUCTION_LOW: {
                "gpu_memory_utilization": 0.85,
                "max_model_len": 4096,
                "tensor_parallel_size": 1,
                "pipeline_parallel_size": 1,
                "quantization": "awq",
                "enable_prefix_caching": True,
                "max_num_seqs": 128,
                "max_num_batched_tokens": 8192,
                "enable_chunked_prefill": True
            },
            
            DeploymentScenario.PRODUCTION_HIGH: {
                "gpu_memory_utilization": 0.9,
                "max_model_len": 8192,
                "tensor_parallel_size": 2,
                "pipeline_parallel_size": 1,
                "quantization": "awq",
                "enable_prefix_caching": True,
                "max_num_seqs": 256,
                "max_num_batched_tokens": 16384,
                "enable_chunked_prefill": True,
                "speculative_model": "small_draft_model"
            },
            
            DeploymentScenario.ENTERPRISE: {
                "gpu_memory_utilization": 0.95,
                "max_model_len": 16384,
                "tensor_parallel_size": 4,
                "pipeline_parallel_size": 2,
                "quantization": "awq",
                "enable_prefix_caching": True,
                "max_num_seqs": 512,
                "max_num_batched_tokens": 32768,
                "enable_chunked_prefill": True,
                "speculative_model": "optimized_draft_model",
                "guided_decoding_backend": "outlines"
            }
        }
        
        return templates[scenario]
    
    @staticmethod
    def generate_vllm_command(model_name: str, 
                             scenario: DeploymentScenario,
                             port: int = 8000,
                             host: str = "0.0.0.0") -> List[str]:
        """Generate optimized VLLM command for deployment scenario."""
        
        config = VLLMConfigTemplates.get_config_template(scenario)
        
        cmd = [
            "python", "-m", "vllm.entrypoints.openai.api_server",
            "--model", model_name,
            "--host", host,
            "--port", str(port),
            "--gpu-memory-utilization", str(config["gpu_memory_utilization"]),
            "--max-model-len", str(config["max_model_len"]),
            "--tensor-parallel-size", str(config["tensor_parallel_size"]),
            "--max-num-seqs", str(config["max_num_seqs"]),
            "--max-num-batched-tokens", str(config["max_num_batched_tokens"]),
            "--trust-remote-code",
            "--disable-log-requests"
        ]
        
        # Add optional parameters
        if config.get("quantization"):
            cmd.extend(["--quantization", config["quantization"]])
        
        if config.get("enable_prefix_caching"):
            cmd.append("--enable-prefix-caching")
        
        if config.get("enable_chunked_prefill"):
            cmd.append("--enable-chunked-prefill")
        
        if config.get("pipeline_parallel_size", 1) > 1:
            cmd.extend(["--pipeline-parallel-size", str(config["pipeline_parallel_size"])])
        
        if config.get("speculative_model"):
            cmd.extend(["--speculative-model", config["speculative_model"]])
        
        return cmd

# Usage examples
dev_cmd = VLLMConfigTemplates.generate_vllm_command(
    "microsoft/Phi-3.5-mini-instruct",
    DeploymentScenario.DEVELOPMENT,
    port=8000
)

prod_cmd = VLLMConfigTemplates.generate_vllm_command(
    "microsoft/Phi-3.5-mini-instruct",
    DeploymentScenario.PRODUCTION_HIGH,
    port=8001
)

print(f"Development command: {' '.join(dev_cmd)}")
print(f"Production command: {' '.join(prod_cmd)}")
```
  
**VLLM рдХреЛ рд▓рд╛рдЧрд┐ рдЙрддреНрдкрд╛рджрди рдбрд┐рдкреНрд▓реЛрдпрдореЗрдиреНрдЯ рдЪреЗрдХрд▓рд┐рд╕реНрдЯ**:

тЬЕ **рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рдЕрдкреНрдЯрд┐рдорд╛рдЗрдЬреЗрд╕рди**:  
- рдорд▓реНрдЯрд┐-GPU рд╕реЗрдЯрдЕрдкрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЯреЗрдиреНрд╕рд░ рд╕рдорд╛рдирд╛рдиреНрддрд░рддрд╛ рдХрдиреНрдлрд┐рдЧрд░ рдЧрд░реНрдиреБрд╣реЛрд╕реН  
- рдореЗрдореЛрд░реА рджрдХреНрд╖рддрд╛рдХреЛ рд▓рд╛рдЧрд┐ рдХреНрд╡рд╛рдиреНрдЯрд╛рдЗрдЬреЗрд╕рди (AWQ/GPTQ) рд╕рдХреНрд╖рдо рдЧрд░реНрдиреБрд╣реЛрд╕реН  
- GPU рдореЗрдореЛрд░реА рдЙрдкрдпреЛрдЧрдХреЛ рд▓рд╛рдЧрд┐ рдЗрд╖реНрдЯрддрдо рд╕реЗрдЯ рдЧрд░реНрдиреБрд╣реЛрд╕реН (85-95%)  
- рдереНрд░реБрдкреБрдЯрдХреЛ рд▓рд╛рдЧрд┐ рдЙрдкрдпреБрдХреНрдд рдмреНрдпрд╛рдЪ рд╕рд╛рдЗрдЬрд╣рд░реВ рдХрдиреНрдлрд┐рдЧрд░ рдЧрд░реНрдиреБрд╣реЛрд╕реН  

тЬЕ **рдкреНрд░рджрд░реНрд╢рди рдЯреНрдпреБрдирд┐рдЩ**:  
- рджреЛрд╣реЛрд░рд┐рдиреЗ рдХреНрд╡реЗрд░реАрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдкреНрд░рд┐рдлрд┐рдХреНрд╕ рдХреНрдпрд╛рд╕рд┐рдЩ рд╕рдХреНрд╖рдо рдЧрд░реНрдиреБрд╣реЛрд╕реН  
- рд▓рд╛рдореЛ рдЕрдиреБрдХреНрд░рдорд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЪрдЩреНрдХ рдЧрд░рд┐рдПрдХреЛ рдкреНрд░рд┐рдлрд┐рд▓ рдХрдиреНрдлрд┐рдЧрд░ рдЧрд░реНрдиреБрд╣реЛрд╕реН  
- рдЫрд┐рдЯреЛ рдЗрдиреНрдлрд░реЗрдиреНрд╕рдХреЛ рд▓рд╛рдЧрд┐ рд╕реНрдкреЗрдХреБрд▓реЗрдЯрд┐рдн рдбрд┐рдХреЛрдбрд┐рдЩ рд╕реЗрдЯ рдЧрд░реНрдиреБрд╣реЛрд╕реН  
- рд╣рд╛рд░реНрдбрд╡реЗрдпрд░рдХреЛ рдЖрдзрд╛рд░рдорд╛ max_num_seqs рдЕрдиреБрдХреВрд▓рд┐рдд рдЧрд░реНрдиреБрд╣реЛрд╕реН  

тЬЕ **рдЙрддреНрдкрд╛рджрди рд╡рд┐рд╢реЗрд╖рддрд╛рд╣рд░реВ**:  
- рд╕реНрд╡рд╛рд╕реНрдереНрдп рдирд┐рдЧрд░рд╛рдиреА рд░ рдореЗрдЯреНрд░рд┐рдХреНрд╕ рд╕рдЩреНрдХрд▓рди рд╕реЗрдЯ рдЧрд░реНрдиреБрд╣реЛрд╕реН  
- рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рдкреБрдирдГ рд╕реБрд░реБ рд░ рдлреЗрд▓рдУрднрд░ рдХрдиреНрдлрд┐рдЧрд░ рдЧрд░реНрдиреБрд╣реЛрд╕реН  
- рдЕрдиреБрд░реЛрдз рдХреНрдпреБрдЗрдЩ рд░ рд▓реЛрдб рдмреНрдпрд╛рд▓реЗрдиреНрд╕рд┐рдЩ рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди рдЧрд░реНрдиреБрд╣реЛрд╕реН  
- рд╡реНрдпрд╛рдкрдХ рд▓рдЧрд┐рдЩ рд░ рдЕрд▓рд░реНрдЯрд┐рдЩ рд╕реЗрдЯ рдЧрд░реНрдиреБрд╣реЛрд╕реН  

тЬЕ **рд╕реБрд░рдХреНрд╖рд╛ рд░ рд╡рд┐рд╢реНрд╡рд╕рдиреАрдпрддрд╛**:  
- рдлрд╛рдпрд░рд╡рд╛рд▓ рдирд┐рдпрдорд╣рд░реВ рд░ рдкрд╣реБрдБрдЪ рдирд┐рдпрдиреНрддреНрд░рдгрд╣рд░реВ рдХрдиреНрдлрд┐рдЧрд░ рдЧрд░реНрдиреБрд╣реЛрд╕реН  
- API рджрд░ рд╕реАрдорд┐рддрддрд╛ рд░ рдкреНрд░рдорд╛рдгреАрдХрд░рдг рд╕реЗрдЯ рдЧрд░реНрдиреБрд╣реЛрд╕реН  
- рдЧреНрд░реЗрд╕рдлреБрд▓ рд╢рдЯрдбрд╛рдЙрди рд░ рд╕рдлрд╛рдЗ рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди рдЧрд░реНрдиреБрд╣реЛрд╕реН  
- рдмреНрдпрд╛рдХрдЕрдк рд░ рдкреНрд░рдХреЛрдк рдкреБрдирдГрдкреНрд░рд╛рдкреНрддрд┐ рдХрдиреНрдлрд┐рдЧрд░ рдЧрд░реНрдиреБрд╣реЛрд╕реН  

тЬЕ **рдПрдХреАрдХрд░рдг рдкрд░реАрдХреНрд╖рдг**:  
- рдорд╛рдЗрдХреНрд░реЛрд╕рдлреНрдЯ рдПрдЬреЗрдиреНрдЯ рдлреНрд░реЗрдорд╡рд░реНрдХ рдПрдХреАрдХрд░рдг рдкрд░реАрдХреНрд╖рдг рдЧрд░реНрдиреБрд╣реЛрд╕реН  
- рдЙрдЪреНрдЪ-рдереНрд░реБрдкреБрдЯ рдкрд░рд┐рджреГрд╢реНрдпрд╣рд░реВ рдкреНрд░рдорд╛рдгрд┐рдд рдЧрд░реНрдиреБрд╣реЛрд╕реН  
- рдлреЗрд▓рдУрднрд░ рд░ рд░рд┐рдХрднрд░реА рдкреНрд░рдХреНрд░рд┐рдпрд╛рд╣рд░реВ рдкрд░реАрдХреНрд╖рдг рдЧрд░реНрдиреБрд╣реЛрд╕реН  
- рд▓реЛрдб рдЕрдиреНрддрд░реНрдЧрдд рдкреНрд░рджрд░реНрд╢рди рдмреЗрдВрдЪрдорд╛рд░реНрдХ рдЧрд░реНрдиреБрд╣реЛрд╕реН  

**рдЕрдиреНрдп рд╕рдорд╛рдзрд╛рдирд╣рд░реВрд╕рдБрдЧ рддреБрд▓рдирд╛**:

| рд╡рд┐рд╢реЗрд╖рддрд╛ | VLLM | Foundry Local | Ollama |
|---------|------|---------------|--------|
| **рд▓рдХреНрд╖рд┐рдд рдкреНрд░рдпреЛрдЧ рдХреЗрд╕** | рдЙрдЪреНрдЪ-рдереНрд░реБрдкреБрдЯ рдЙрддреНрдкрд╛рджрди | рдЙрджреНрдпрдо рдкреНрд░рдпреЛрдЧрдХреЛ рд╕рдЬрд┐рд▓реЛрдкрди | рд╡рд┐рдХрд╛рд╕ рд░ рд╕рдореБрджрд╛рдп |
| **рдкреНрд░рджрд░реНрд╢рди** | рдЕрдзрд┐рдХрддрдо рдереНрд░реБрдкреБрдЯ | рд╕рдиреНрддреБрд▓рд┐рдд | рд░рд╛рдореНрд░реЛ |
| **рдореЗрдореЛрд░реА рджрдХреНрд╖рддрд╛** | PagedAttention рдЕрдкреНрдЯрд┐рдорд╛рдЗрдЬреЗрд╕рди | рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рдЕрдкреНрдЯрд┐рдорд╛рдЗрдЬреЗрд╕рди | рдорд╛рдирдХ |
| **рд╕реЗрдЯрдЕрдк рдЬрдЯрд┐рд▓рддрд╛** | рдЙрдЪреНрдЪ (рдзреЗрд░реИ рдкреНрдпрд╛рд░рд╛рдорд┐рдЯрд░рд╣рд░реВ) | рдХрдо (рд╕реНрд╡рдЪрд╛рд▓рд┐рдд) | рдХрдо (рд╕рд░рд▓) |
| **рд╕реНрдХреЗрд▓реЗрдмрд┐рд▓рд┐рдЯреА** | рдЙрддреНрдХреГрд╖реНрдЯ (рдЯреЗрдиреНрд╕рд░/рдкрд╛рдЗрдкрд▓рд╛рдЗрди рд╕рдорд╛рдирд╛рдиреНрддрд░) | рд░рд╛рдореНрд░реЛ | рд╕реАрдорд┐рдд |
| **рдХреНрд╡рд╛рдиреНрдЯрд╛рдЗрдЬреЗрд╕рди** | рдЙрдиреНрдирдд (AWQ, GPTQ, FP8) | рд╕реНрд╡рдЪрд╛рд▓рд┐рдд | рдорд╛рдирдХ GGUF |
| **рдЙрджреНрдпрдо рд╡рд┐рд╢реЗрд╖рддрд╛рд╣рд░реВ** | рдХрд╕реНрдЯрдо рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди рдЖрд╡рд╢реНрдпрдХ | рдмрд┐рд▓реНрдЯ-рдЗрди | рд╕рд╛рдореБрджрд╛рдпрд┐рдХ рдЙрдкрдХрд░рдгрд╣рд░реВ |
| **рдЙрддреНрддрдо рд▓рд╛рдЧрд┐** | рдЙрдЪреНрдЪ-рд╕реНрдХреЗрд▓ рдЙрддреНрдкрд╛рджрди рдПрдЬреЗрдиреНрдЯрд╣рд░реВ | рдЙрджреНрдпрдо рдЙрддреНрдкрд╛рджрди | рд╡рд┐рдХрд╛рд╕ |

**VLLM рдЪрдпрди рдЧрд░реНрдиреЗ рд╕рдордп**:
- **рдЙрдЪреНрдЪ-рдереНрд░реБрдкреБрдЯ рдЖрд╡рд╢реНрдпрдХрддрд╛рд╣рд░реВ**: рдкреНрд░рддрд┐ рд╕реЗрдХреЗрдиреНрдб рд╕рдпреМрдВ рдЕрдиреБрд░реЛрдзрд╣рд░реВ рдкреНрд░рд╢реЛрдзрди  
- **рдареВрд▓реЛ-рд╕реНрдХреЗрд▓ рдбрд┐рдкреНрд▓реЛрдпрдореЗрдиреНрдЯрд╣рд░реВ**: рдорд▓реНрдЯрд┐-GPU, рдорд▓реНрдЯрд┐-рдиреЛрдб рдбрд┐рдкреНрд▓реЛрдпрдореЗрдиреНрдЯрд╣рд░реВ  
- **рдкреНрд░рджрд░реНрд╢рди рдорд╣рддреНрддреНрд╡рдкреВрд░реНрдг**: рд╕реНрдХреЗрд▓рдорд╛ рдЙрдк-рд╕реЗрдХреЗрдиреНрдб рдкреНрд░рддрд┐рдХреНрд░рд┐рдпрд╛ рд╕рдордп  
- **рдЙрдиреНрдирдд рдЕрдкреНрдЯрд┐рдорд╛рдЗрдЬреЗрд╕рди**: рдХрд╕реНрдЯрдо рдХреНрд╡рд╛рдиреНрдЯрд╛рдЗрдЬреЗрд╕рди рд░ рдмреНрдпрд╛рдЪрд┐рдЩ рдЖрд╡рд╢реНрдпрдХ  
- **рд╕реНрд░реЛрдд рджрдХреНрд╖рддрд╛**: рдорд╣рдБрдЧреЛ GPU рд╣рд╛рд░реНрдбрд╡реЗрдпрд░рдХреЛ рдЕрдзрд┐рдХрддрдо рдЙрдкрдпреЛрдЧ  

## рд╡рд╛рд╕реНрддрд╡рд┐рдХ-рд╡рд┐рд╢реНрд╡ SLM рдПрдЬреЗрдиреНрдЯ рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╣рд░реВ

### рдЧреНрд░рд╛рд╣рдХ рд╕реЗрд╡рд╛ SLM рдПрдЬреЗрдиреНрдЯрд╣рд░реВ  
- **SLM рдХреНрд╖рдорддрд╛**: рдЦрд╛рддрд╛ рдЦреЛрдЬреА, рдкрд╛рд╕рд╡рд░реНрдб рд░рд┐рд╕реЗрдЯ, рдЕрд░реНрдбрд░ рд╕реНрдерд┐рддрд┐ рдЬрд╛рдБрдЪ  
- **рд▓рд╛рдЧрдд рд▓рд╛рднрд╣рд░реВ**: LLM рдПрдЬреЗрдиреНрдЯрд╣рд░реВрдХреЛ рддреБрд▓рдирд╛рдорд╛ рдЗрдиреНрдлрд░реЗрдиреНрд╕ рд▓рд╛рдЧрддрдорд╛ 10x рдХрдореА  
- **рдкреНрд░рджрд░реНрд╢рди**: рдирд┐рдпрдорд┐рдд рдХреНрд╡реЗрд░реАрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рд╕реНрдерд┐рд░ рдЧреБрдгрд╕реНрддрд░рдХреЛ рд╕рд╛рде рдЫрд┐рдЯреЛ рдкреНрд░рддрд┐рдХреНрд░рд┐рдпрд╛ рд╕рдордп  

### рд╡реНрдпрд╛рдкрд╛рд░ рдкреНрд░рдХреНрд░рд┐рдпрд╛ SLM рдПрдЬреЗрдиреНрдЯрд╣рд░реВ  
- **рдЗрдирднреНрд╡рд╛рдЗрд╕ рдкреНрд░рд╢реЛрдзрди рдПрдЬреЗрдиреНрдЯрд╣рд░реВ**: рдбрд╛рдЯрд╛ рдирд┐рдХрд╛рд▓реНрдиреБрд╣реЛрд╕реН, рдЬрд╛рдирдХрд╛рд░реА рдкреНрд░рдорд╛рдгрд┐рдд рдЧрд░реНрдиреБрд╣реЛрд╕реН, рд╕реНрд╡реАрдХреГрддрд┐рдХреЛ рд▓рд╛рдЧрд┐ рд░реБрдЯ рдЧрд░реНрдиреБрд╣реЛрд╕реН  
- **рдЗрдореЗрд▓ рд╡реНрдпрд╡рд╕реНрдерд╛рдкрди рдПрдЬреЗрдиреНрдЯрд╣рд░реВ**: рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рд░реВрдкрдорд╛ рд╡рд░реНрдЧреАрдХрд░рдг, рдкреНрд░рд╛рдердорд┐рдХрддрд╛, рдкреНрд░рддрд┐рдХреНрд░рд┐рдпрд╛ рдбреНрд░рд╛рдлреНрдЯ рдЧрд░реНрдиреБрд╣реЛрд╕реН  
- **рд╢реЗрдбреНрдпреБрд▓рд┐рдЩ рдПрдЬреЗрдиреНрдЯрд╣рд░реВ**: рдмреИрдардХрд╣рд░реВ рд╕рдордиреНрд╡рдп рдЧрд░реНрдиреБрд╣реЛрд╕реН, рдХреНрдпрд╛рд▓реЗрдиреНрдбрд░рд╣рд░реВ рд╡реНрдпрд╡рд╕реНрдерд╛рдкрди рдЧрд░реНрдиреБрд╣реЛрд╕реН, рд░рд┐рдорд╛рдЗрдиреНрдбрд░рд╣рд░реВ рдкрдард╛рдЙрдиреБрд╣реЛрд╕реН  

### рд╡реНрдпрдХреНрддрд┐рдЧрдд SLM рдбрд┐рдЬрд┐рдЯрд▓ рд╕рд╣рд╛рдпрдХрд╣рд░реВ  
- **рдХрд╛рд░реНрдп рд╡реНрдпрд╡рд╕реНрдерд╛рдкрди рдПрдЬреЗрдиреНрдЯрд╣рд░реВ**: рдХрд╛рд░реНрдпрд╣рд░реВ рд╕рд┐рд░реНрдЬрдирд╛ рдЧрд░реНрдиреБрд╣реЛрд╕реН, рдЕрдкрдбреЗрдЯ рдЧрд░реНрдиреБрд╣реЛрд╕реН, рдХреБрд╢рд▓рддрд╛рдкреВрд░реНрд╡рдХ рдЯреБ-рдбреБ рд╕реВрдЪреАрд╣рд░реВ рд╡реНрдпрд╡рд╕реНрдерд┐рдд рдЧрд░реНрдиреБрд╣реЛрд╕реН  
- **рд╕реВрдЪрдирд╛ рд╕рдЩреНрдХрд▓рди рдПрдЬреЗрдиреНрдЯрд╣рд░реВ**: рд╡рд┐рд╖рдпрд╣рд░реВ рдЕрдиреБрд╕рдиреНрдзрд╛рди рдЧрд░реНрдиреБрд╣реЛрд╕реН, рд╕реНрдерд╛рдиреАрдп рд░реВрдкрдорд╛ рдирд┐рд╖реНрдХрд░реНрд╖рд╣рд░реВ рд╕рдВрдХреНрд╖реЗрдк рдЧрд░реНрдиреБрд╣реЛрд╕реН  
- **рд╕рдЮреНрдЪрд╛рд░ рдПрдЬреЗрдиреНрдЯрд╣рд░реВ**: рдЗрдореЗрд▓, рд╕рдиреНрджреЗрд╢рд╣рд░реВ, рд╕рд╛рдорд╛рдЬрд┐рдХ рдорд┐рдбрд┐рдпрд╛ рдкреЛрд╕реНрдЯрд╣рд░реВ рдирд┐рдЬреА рд░реВрдкрдорд╛ рдбреНрд░рд╛рдлреНрдЯ рдЧрд░реНрдиреБрд╣реЛрд╕реН  

### рд╡реНрдпрд╛рдкрд╛рд░ рд░ рд╡рд┐рддреНрддреАрдп SLM рдПрдЬреЗрдиреНрдЯрд╣рд░реВ  
- **рдмрдЬрд╛рд░ рдирд┐рдЧрд░рд╛рдиреА рдПрдЬреЗрдиреНрдЯрд╣рд░реВ**: рдореВрд▓реНрдпрд╣рд░реВ рдЯреНрд░реНрдпрд╛рдХ рдЧрд░реНрдиреБрд╣реЛрд╕реН, рд╡рд╛рд╕реНрддрд╡рд┐рдХ рд╕рдордпрдорд╛ рдкреНрд░рд╡реГрддреНрддрд┐рд╣рд░реВ рдкрд╣рд┐рдЪрд╛рди рдЧрд░реНрдиреБрд╣реЛрд╕реН  
- **рд░рд┐рдкреЛрд░реНрдЯ рдЙрддреНрдкрд╛рджрди рдПрдЬреЗрдиреНрдЯрд╣рд░реВ**: рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рд░реВрдкрдорд╛ рджреИрдирд┐рдХ/рд╕рд╛рдкреНрддрд╛рд╣рд┐рдХ рд╕рд╛рд░рд╛рдВрд╢рд╣рд░реВ рд╕рд┐рд░реНрдЬрдирд╛ рдЧрд░реНрдиреБрд╣реЛрд╕реН  
- **рдЬреЛрдЦрд┐рдо рдореВрд▓реНрдпрд╛рдЩреНрдХрди рдПрдЬреЗрдиреНрдЯрд╣рд░реВ**: рд╕реНрдерд╛рдиреАрдп рдбрд╛рдЯрд╛рдХреЛ рдкреНрд░рдпреЛрдЧ рдЧрд░реЗрд░ рдкреЛрд░реНрдЯрдлреЛрд▓рд┐рдпреЛ рд╕реНрдерд┐рддрд┐ рдореВрд▓реНрдпрд╛рдЩреНрдХрди рдЧрд░реНрдиреБрд╣реЛрд╕реН  

### рд╕реНрд╡рд╛рд╕реНрдереНрдп рд╕реЗрд╡рд╛ рд╕рдорд░реНрдерди SLM рдПрдЬреЗрдиреНрдЯрд╣рд░реВ  
- **рд░реЛрдЧреА рд╢реЗрдбреНрдпреБрд▓рд┐рдЩ рдПрдЬреЗрдиреНрдЯрд╣рд░реВ**: рдЕрдкреЛрдЗрдиреНрдЯрдореЗрдиреНрдЯрд╣рд░реВ рд╕рдордиреНрд╡рдп рдЧрд░реНрдиреБрд╣реЛрд╕реН, рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рд░рд┐рдорд╛рдЗрдиреНрдбрд░рд╣рд░реВ рдкрдард╛рдЙрдиреБрд╣реЛрд╕реН  
- **рдбрдХреБрдореЗрдиреНрдЯреЗрд╕рди рдПрдЬреЗрдиреНрдЯрд╣рд░реВ**: рд╕реНрдерд╛рдиреАрдп рд░реВрдкрдорд╛ рдореЗрдбрд┐рдХрд▓ рд╕рд╛рд░рд╛рдВрд╢рд╣рд░реВ, рд░рд┐рдкреЛрд░реНрдЯрд╣рд░реВ рд╕рд┐рд░реНрдЬрдирд╛ рдЧрд░реНрдиреБрд╣реЛрд╕реН  
- **рдкреНрд░рд┐рд╕реНрдХреНрд░рд┐рдкреНрд╢рди рд╡реНрдпрд╡рд╕реНрдерд╛рдкрди рдПрдЬреЗрдиреНрдЯрд╣рд░реВ**: рд░рд┐рдлрд┐рд▓рд╣рд░реВ рдЯреНрд░реНрдпрд╛рдХ рдЧрд░реНрдиреБрд╣реЛрд╕реН, рдирд┐рдЬреА рд░реВрдкрдорд╛ рдЕрдиреНрддрд░рдХреНрд░рд┐рдпрд╛рд╣рд░реВ рдЬрд╛рдБрдЪ рдЧрд░реНрдиреБрд╣реЛрд╕реН  

## рдорд╛рдЗрдХреНрд░реЛрд╕рдлреНрдЯ рдПрдЬреЗрдиреНрдЯ рдлреНрд░реЗрдорд╡рд░реНрдХ: рдЙрддреНрдкрд╛рджрди-рддрдпрд╛рд░ рдПрдЬреЗрдиреНрдЯ рд╡рд┐рдХрд╛рд╕

### рдЕрд╡рд▓реЛрдХрди рд░ рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░

рдорд╛рдЗрдХреНрд░реЛрд╕рдлреНрдЯ рдПрдЬреЗрдиреНрдЯ рдлреНрд░реЗрдорд╡рд░реНрдХрд▓реЗ AI рдПрдЬреЗрдиреНрдЯрд╣рд░реВ рдирд┐рд░реНрдорд╛рдг, рдбрд┐рдкреНрд▓реЛрдп, рд░ рд╡реНрдпрд╡рд╕реНрдерд╛рдкрди рдЧрд░реНрдирдХрд╛ рд▓рд╛рдЧрд┐ рд╡реНрдпрд╛рдкрдХ, рдЙрджреНрдпрдо-рдЧреНрд░реЗрдб рдкреНрд▓реЗрдЯрдлрд░реНрдо рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫ рдЬрд╕рд▓реЗ рдХреНрд▓рд╛рдЙрдб рд░ рдЕрдлрд▓рд╛рдЗрди рдПрдЬ рд╡рд╛рддрд╛рд╡рд░рдгрд╣рд░реВрдорд╛ рд╕рдЮреНрдЪрд╛рд▓рди рдЧрд░реНрди рд╕рдХреНрдЫред рдлреНрд░реЗрдорд╡рд░реНрдХ рд╡рд┐рд╢реЗрд╖ рд░реВрдкрдорд╛ рд╕рд╛рдиреЛ рднрд╛рд╖рд╛ рдореЛрдбреЗрд▓рд╣рд░реВ рд░ рдПрдЬ рдХрдореНрдкреНрдпреБрдЯрд┐рдЩ рдкрд░рд┐рджреГрд╢реНрдпрд╣рд░реВрд╕рдБрдЧ рдХрд╛рдо рдЧрд░реНрди рдбрд┐рдЬрд╛рдЗрди рдЧрд░рд┐рдПрдХреЛ рдЫ, рдЬрд╕рд▓реЗ рдЧреЛрдкрдиреАрдпрддрд╛-рд╕рдВрд╡реЗрджрдирд╢реАрд▓ рд░ рд╕реНрд░реЛрдд-рд╕реАрдорд┐рдд рдбрд┐рдкреНрд▓реЛрдпрдореЗрдиреНрдЯрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЖрджрд░реНрд╢ рдмрдирд╛рдЙрдБрдЫред

**рдореБрдЦреНрдп рдлреНрд░реЗрдорд╡рд░реНрдХ рдШрдЯрдХрд╣рд░реВ**:
- **рдПрдЬреЗрдиреНрдЯ рд░рдирдЯрд╛рдЗрдо**: рдПрдЬ рдЙрдкрдХрд░рдгрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЕрдиреБрдХреВрд▓рд┐рдд рд╣рд▓реНрдХрд╛ рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди рд╡рд╛рддрд╛рд╡рд░рдг  
- **рдЯреВрд▓ рдПрдХреАрдХрд░рдг рдкреНрд░рдгрд╛рд▓реА**: рдмрд╛рд╣реНрдп рд╕реЗрд╡рд╛рд╣рд░реВ рд░ API рд╣рд░реВрд╕рдБрдЧ рдЬрдбрд╛рди рдЧрд░реНрдирдХреЛ рд▓рд╛рдЧрд┐ рд╡рд┐рд╕реНрддрд╛рд░рдпреЛрдЧреНрдп рдкреНрд▓рдЧрдЗрди рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░  
- **рд░рд╛рдЬреНрдп рд╡реНрдпрд╡рд╕реНрдерд╛рдкрди**: рд╕рддреНрд░рд╣рд░реВрдорд╛ рд╕реНрдерд╛рдпреА рдПрдЬреЗрдиреНрдЯ рдореЗрдореЛрд░реА рд░ рд╕рдиреНрджрд░реНрдн рд╣реНрдпрд╛рдиреНрдбрд▓рд┐рдЩ  
- **рд╕реБрд░рдХреНрд╖рд╛ рддрд╣**: рдЙрджреНрдпрдо рдбрд┐рдкреНрд▓реЛрдпрдореЗрдиреНрдЯрдХреЛ рд▓рд╛рдЧрд┐ рдмрд┐рд▓реНрдЯ-рдЗрди рд╕реБрд░рдХреНрд╖рд╛ рдирд┐рдпрдиреНрддреНрд░рдгрд╣рд░реВ  
- **рдЕрд░реНрдХреЗрд╕реНрдЯреНрд░реЗрд╕рди рдЗрдиреНрдЬрд┐рди**: рдорд▓реНрдЯрд┐-рдПрдЬреЗрдиреНрдЯ рд╕рдордиреНрд╡рдп рд░ рд╡рд░реНрдХрдлреНрд▓реЛ рд╡реНрдпрд╡рд╕реНрдерд╛рдкрди  

### рдПрдЬ рдбрд┐рдкреНрд▓реЛрдпрдореЗрдиреНрдЯрдХрд╛ рд▓рд╛рдЧрд┐ рдкреНрд░рдореБрдЦ рд╡рд┐рд╢реЗрд╖рддрд╛рд╣рд░реВ

**рдЕрдлрд▓рд╛рдЗрди-рдкреНрд░рдердо рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░**: рдорд╛рдЗрдХреНрд░реЛрд╕рдлреНрдЯ рдПрдЬреЗрдиреНрдЯ рдлреНрд░реЗрдорд╡рд░реНрдХ рдЕрдлрд▓рд╛рдЗрди-рдкреНрд░рдердо рд╕рд┐рджреНрдзрд╛рдиреНрддрд╣рд░реВрд╕рдБрдЧ рдбрд┐рдЬрд╛рдЗрди рдЧрд░рд┐рдПрдХреЛ рдЫ, рдЬрд╕рд▓реЗ рдПрдЬреЗрдиреНрдЯрд╣рд░реВрд▓рд╛рдИ рдирд┐рд░рдиреНрддрд░ рдЗрдиреНрдЯрд░рдиреЗрдЯ рдЬрдбрд╛рди рдмрд┐рдирд╛ рдкреНрд░рднрд╛рд╡рдХрд╛рд░реА рд░реВрдкрдорд╛ рд╕рдЮреНрдЪрд╛рд▓рди рдЧрд░реНрди рд╕рдХреНрд╖рдо рдмрдирд╛рдЙрдБрдЫред рдпрд╕рдорд╛ рд╕реНрдерд╛рдиреАрдп рдореЛрдбреЗрд▓ рдЗрдиреНрдлрд░реЗрдиреНрд╕, рдХреНрдпрд╛рд╕ рдЧрд░рд┐рдПрдХреЛ рдЬреНрдЮрд╛рди рдЖрдзрд╛рд░рд╣рд░реВ, рдЕрдлрд▓рд╛рдЗрди рдЯреВрд▓ рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди, рд░ рдХреНрд▓рд╛рдЙрдб рд╕реЗрд╡рд╛рд╣рд░реВ рдЕрдиреБрдкрд▓рдмреНрдз рд╣реБрдБрджрд╛ рдЧреНрд░реЗрд╕рдлреБрд▓ рдбрд┐рдЧреНрд░реЗрдбреЗрд╕рди рд╕рдорд╛рд╡реЗрд╢ рдЫред

**рд╕реНрд░реЛрдд рдЕрдкреНрдЯрд┐рдорд╛рдЗрдЬреЗрд╕рди**: рдлреНрд░реЗрдорд╡рд░реНрдХрд▓реЗ рд╕рд╛рдирд╛ рднрд╛рд╖рд╛ рдореЛрдбреЗрд▓рд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рдореЗрдореЛрд░реА рдЕрдкреНрдЯрд┐рдорд╛рдЗрдЬреЗрд╕рди, рдПрдЬ рдЙрдкрдХрд░рдгрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ CPU/GPU рд▓реЛрдб рдмреНрдпрд╛рд▓реЗрдиреНрд╕рд┐рдЩ, рдЙрдкрд▓рдмреНрдз рд╕реНрд░реЛрддрд╣рд░реВрдХреЛ рдЖрдзрд╛рд░рдорд╛ рдЕрдиреБрдХреВрд▓рди рдореЛрдбреЗрд▓ рдЪрдпрди, рд░ рдореЛрдмрд╛рдЗрд▓ рдбрд┐рдкреНрд▓реЛрдпрдореЗрдиреНрдЯрдХреЛ рд▓рд╛рдЧрд┐ рдкрд╛рд╡рд░-рдХреБрд╢рд▓ рдЗрдиреНрдлрд░реЗрдиреНрд╕ рдврд╛рдБрдЪрд╛рд╣рд░реВрдХреЛ рд╕рд╛рде рдмреБрджреНрдзрд┐рдорд╛рдиреА рд╕реНрд░реЛрдд рд╡реНрдпрд╡рд╕реНрдерд╛рдкрди рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫред

**рд╕реБрд░рдХреНрд╖рд╛ рд░ рдЧреЛрдкрдиреАрдпрддрд╛**: рдЙрджреНрдпрдо-рдЧреНрд░реЗрдб рд╕реБрд░рдХреНрд╖рд╛ рд╡рд┐рд╢реЗрд╖рддрд╛рд╣рд░реВрдорд╛ рдЧреЛрдкрдиреАрдпрддрд╛ рдХрд╛рдпрдо рд░рд╛рдЦреНрди рд╕реНрдерд╛рдиреАрдп рдбрд╛рдЯрд╛ рдкреНрд░рд╢реЛрдзрди, рдПрдиреНрдХреНрд░рд┐рдкреНрдЯреЗрдб рдПрдЬреЗрдиреНрдЯ рд╕рдЮреНрдЪрд╛рд░ рдЪреНрдпрд╛рдирд▓рд╣рд░реВ, рдПрдЬреЗрдиреНрдЯ рдХреНрд╖рдорддрд╛рд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рднреВрдорд┐рдХрд╛-рдЖрдзрд╛рд░рд┐рдд рдкрд╣реБрдБрдЪ рдирд┐рдпрдиреНрддреНрд░рдгрд╣рд░реВ, рд░ рдЕрдиреБрдкрд╛рд▓рди рдЖрд╡рд╢реНрдпрдХрддрд╛рд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЕрдбрд┐рдЯ рд▓рдЧрд┐рдЩ рд╕рдорд╛рд╡реЗрд╢ рдЫред

### Foundry Local рд╕рдБрдЧ рдПрдХреАрдХрд░рдг

рдорд╛рдЗрдХреНрд░реЛрд╕рдлреНрдЯ рдПрдЬреЗрдиреНрдЯ рдлреНрд░реЗрдорд╡рд░реНрдХрд▓реЗ Foundry Local рд╕рдБрдЧ рд╕рд╣рдЬ рд░реВрдкрдорд╛ рдПрдХреАрдХреГрдд рднрдПрд░ рдкреВрд░реНрдг рдПрдЬ AI рд╕рдорд╛рдзрд╛рди рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫ:

**рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рдореЛрдбреЗрд▓ рдбрд┐рд╕реНрдХрднрд░реА**: рдлреНрд░реЗрдорд╡рд░реНрдХрд▓реЗ рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рд░реВрдкрдорд╛ Foundry Local рдЙрджрд╛рд╣рд░рдгрд╣рд░реВ рдкрддреНрддрд╛ рд▓рдЧрд╛рдЙрдБрдЫ, рдЙрдкрд▓рдмреНрдз SLM рдореЛрдбреЗрд▓рд╣рд░реВрдорд╛ рдЬрдбрд╛рди рдЧрд░реНрджрдЫ, рд░ рдПрдЬреЗрдиреНрдЯ рдЖрд╡рд╢реНрдпрдХрддрд╛рд╣рд░реВ рд░ рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рдХреНрд╖рдорддрд╛рд╣рд░реВрдХреЛ рдЖрдзрд╛рд░рдорд╛ рдЗрд╖реНрдЯрддрдо рдореЛрдбреЗрд▓рд╣рд░реВ рдЪрдпрди рдЧрд░реНрджрдЫред

**рдбрд╛рдпрдирд╛рдорд┐рдХ рдореЛрдбреЗрд▓ рд▓реЛрдбрд┐рдЩ**: рдПрдЬреЗрдиреНрдЯрд╣рд░реВрд▓реЗ рд╡рд┐рд╢рд┐рд╖реНрдЯ рдХрд╛рд░реНрдпрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рд╡рд┐рднрд┐рдиреНрди SLM рд╣рд░реВрд▓рд╛рдИ рдбрд╛рдпрдирд╛рдорд┐рдХ рд░реВрдкрдорд╛ рд▓реЛрдб рдЧрд░реНрди рд╕рдХреНрдЫрдиреН, рдЬрд╕рд▓реЗ рдорд▓реНрдЯрд┐-рдореЛрдбреЗрд▓ рдПрдЬреЗрдиреНрдЯ рдкреНрд░рдгрд╛рд▓реАрд╣рд░реВ рд╕рдХреНрд╖рдо рдмрдирд╛рдЙрдБрдЫ рдЬрд╣рд╛рдБ рд╡рд┐рднрд┐рдиреНрди рдореЛрдбреЗрд▓рд╣рд░реВрд▓реЗ рд╡рд┐рднрд┐рдиреНрди рдкреНрд░рдХрд╛рд░рдХрд╛ рдЕрдиреБрд░реЛрдзрд╣рд░реВ рд╣реНрдпрд╛рдиреНрдбрд▓ рдЧрд░реНрдЫрдиреН, рд░ рдЙрдкрд▓рдмреНрдзрддрд╛ рд░ рдкреНрд░рджрд░реНрд╢рдирдХреЛ рдЖрдзрд╛рд░рдорд╛ рдореЛрдбреЗрд▓рд╣рд░реВ рдмреАрдЪ рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рдлреЗрд▓рдУрднрд░ред

**рдкреНрд░рджрд░реНрд╢рди рдЕрдкреНрдЯрд┐рдорд╛рдЗрдЬреЗрд╕рди**: рдПрдХреАрдХреГрдд рдХреНрдпрд╛рд╕рд┐рдЩ рдореЗрдХрд╛рдирд┐рдЬреНрдорд╣рд░реВрд▓реЗ рдореЛрдбреЗрд▓ рд▓реЛрдбрд┐рдЩ рд╕рдордп рдШрдЯрд╛рдЙрдБрдЫ, рдХрдиреЗрдХреНрд╢рди рдкреВрд▓рд┐рдЩрд▓реЗ Foundry Local рдорд╛ API рдХрд▓рд╣рд░реВ рдЕрдиреБрдХреВрд▓рд┐рдд рдЧрд░реНрджрдЫ, рд░ рдмреБрджреНрдзрд┐рдорд╛рдиреА рдмреНрдпрд╛рдЪрд┐рдЩрд▓реЗ рдзреЗрд░реИ рдПрдЬреЗрдиреНрдЯ рдЕрдиреБрд░реЛрдзрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдереНрд░реБрдкреБрдЯ рд╕реБрдзрд╛рд░ рдЧрд░реНрджрдЫред

### рдорд╛рдЗрдХреНрд░реЛрд╕рдлреНрдЯ рдПрдЬреЗрдиреНрдЯ рдлреНрд░реЗрдорд╡рд░реНрдХрд╕рдБрдЧ рдПрдЬреЗрдиреНрдЯ рдирд┐рд░реНрдорд╛рдг

#### рдПрдЬреЗрдиреНрдЯ рдкрд░рд┐рднрд╛рд╖рд╛ рд░ рдХрдиреНрдлрд┐рдЧрд░реЗрд╕рди

```python
from microsoft_agent_framework import Agent, Tool, Config
from foundry_local import FoundryLocalManager

# Configure agent with Foundry Local integration
config = Config(
    name="customer-service-agent",
    model_provider="foundry-local",
    model_alias="phi-4-mini",
    max_tokens=512,
    temperature=0.1,
    offline_mode=True
)

# Initialize Foundry Local connection
foundry = FoundryLocalManager("phi-4-mini")

# Create agent instance
agent = Agent(
    config=config,
    model_endpoint=foundry.endpoint,
    api_key=foundry.api_key
)
```
  
#### рдПрдЬ рдкрд░рд┐рджреГрд╢реНрдпрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЯреВрд▓ рдПрдХреАрдХрд░рдг

```python
# Define tools for offline operation
@agent.tool
def lookup_customer_info(customer_id: str) -> dict:
    """Look up customer information from local database."""
    # Local database query - works offline
    return local_db.get_customer(customer_id)

@agent.tool
def create_support_ticket(issue: str, priority: str) -> str:
    """Create a support ticket in local system."""
    # Local ticket creation with sync when online
    ticket_id = local_system.create_ticket(issue, priority)
    return f"Ticket {ticket_id} created successfully"

@agent.tool
def schedule_callback(customer_id: str, preferred_time: str) -> str:
    """Schedule a callback for the customer."""
    # Local scheduling with calendar integration
    return local_calendar.schedule(customer_id, preferred_time)
```
  
#### рдорд▓реНрдЯрд┐-рдПрдЬреЗрдиреНрдЯ рдЕрд░реНрдХреЗрд╕реНрдЯреНрд░реЗрд╕рди

```python
from microsoft_agent_framework import AgentOrchestrator

# Create specialized agents for different domains
scheduling_agent = Agent(
    config=Config(
        name="scheduling-agent",
        model_alias="qwen2.5-0.5b",  # Lightweight for simple tasks
        specialized_for="scheduling"
    )
)

technical_support_agent = Agent(
    config=Config(
        name="technical-agent",
        model_alias="phi-4-mini",  # More capable for complex issues
        specialized_for="technical_support"
    )
)

# Orchestrate multiple agents
orchestrator = AgentOrchestrator([
    scheduling_agent,
    technical_support_agent
])

# Route requests based on intent
result = orchestrator.process_request(
    "I need to schedule a callback for a technical issue",
    routing_strategy="intent-based"
)
```
  

### рдЙрдиреНрдирдд рдПрдЬ рдбрд┐рдкреНрд▓реЛрдпрдореЗрдиреНрдЯ рдврд╛рдБрдЪрд╛рд╣рд░реВ

#### рд╣рд╛рдЗрд░рд╛рд░реНрдХрд┐рдХрд▓ рдПрдЬреЗрдиреНрдЯ рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░

**рд╕реНрдерд╛рдиреАрдп рдПрдЬреЗрдиреНрдЯ рдХреНрд▓рд╕реНрдЯрд░рд╣рд░реВ**: рдкреНрд░рддреНрдпреЗрдХ рд╡рд┐рд╢рд┐рд╖реНрдЯ рдХрд╛рд░реНрдпрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЕрдиреБрдХреВрд▓рд┐рдд рдПрдЬ рдЙрдкрдХрд░рдгрд╣рд░реВрдорд╛ рдзреЗрд░реИ рд╡рд┐рд╢реЗрд╖ SLM рдПрдЬреЗрдиреНрдЯрд╣рд░реВ рдбрд┐рдкреНрд▓реЛрдп рдЧрд░реНрдиреБрд╣реЛрд╕реНред рд╕рд░рд▓ рд░реБрдЯрд┐рдЩ рд░ рд╢реЗрдбреНрдпреБрд▓рд┐рдЩрдХреЛ рд▓рд╛рдЧрд┐ Qwen2.5-0.5B рдЬрд╕реНрддрд╛ рд╣рд▓реНрдХрд╛ рдореЛрдбреЗрд▓рд╣рд░реВ рдкреНрд░рдпреЛрдЧ рдЧрд░реНрдиреБрд╣реЛрд╕реН, рдЧреНрд░рд╛рд╣рдХ рд╕реЗрд╡рд╛ рд░ рдбрдХреБрдореЗрдиреНрдЯреЗрд╕рдирдХреЛ рд▓рд╛рдЧрд┐ Phi-4-Mini рдЬрд╕реНрддрд╛ рдордзреНрдпрдо рдореЛрдбреЗрд▓рд╣рд░реВ, рд░ рдЬрдЯрд┐рд▓ рддрд░реНрдХрдХреЛ рд▓рд╛рдЧрд┐ рдареВрд▓реЛ рдореЛрдбреЗрд▓рд╣рд░реВ рдЬрдм рд╕реНрд░реЛрддрд╣рд░реВ рдЙрдкрд▓рдмреНрдз рдЫрдиреНред

**рдПрдЬ-рджреЗрдЦрд┐-рдХреНрд▓рд╛рдЙрдб рд╕рдордиреНрд╡рдп**: рд╕реНрдерд╛рдиреАрдп рдПрдЬреЗрдиреНрдЯрд╣рд░реВрд▓реЗ рдирд┐рдпрдорд┐рдд рдХрд╛рд░реНрдпрд╣рд░реВ рд╣реНрдпрд╛рдиреНрдбрд▓ рдЧрд░реНрдиреЗ, рдХреНрд▓рд╛рдЙрдб рдПрдЬреЗрдиреНрдЯрд╣рд░реВрд▓реЗ рдЬрдЯрд┐рд▓ рддрд░реНрдХ рдкреНрд░рджрд╛рди рдЧрд░реНрдиреЗ рдЬрдм рдЬрдбрд╛рди рдЙрдкрд▓рдмреНрдз рд╣реБрдиреНрдЫ, рд░ рдПрдЬ рд░ рдХреНрд▓рд╛рдЙрдб рдкреНрд░рд╢реЛрдзрди рдмреАрдЪрдХреЛ рд╕рд╣рдЬ рд╣рд╕реНрддрд╛рдиреНрддрд░рдгрд▓реЗ рдирд┐рд░рдиреНрддрд░рддрд╛ рдХрд╛рдпрдо рд░рд╛рдЦреНрдиреЗред

#### рдбрд┐рдкреНрд▓реЛрдпрдореЗрдиреНрдЯ рдХрдиреНрдлрд┐рдЧрд░реЗрд╕рдирд╣рд░реВ

**рдПрдХрд▓ рдЙрдкрдХрд░рдг рдбрд┐рдкреНрд▓реЛрдпрдореЗрдиреНрдЯ**:  
```yaml
deployment:
  type: single-device
  hardware: edge-device
  models:
    - alias: "phi-4-mini"
      primary: true
      tasks: ["conversation", "reasoning"]
    - alias: "qwen2.5-0.5b"
      secondary: true
      tasks: ["routing", "classification"]
  agents:
    - name: "primary-agent"
      model: "phi-4-mini"
      tools: ["database", "calendar", "email"]
```
  
**рд╡рд┐рддрд░рд┐рдд рдПрдЬ рдбрд┐рдкреНрд▓реЛрдпрдореЗрдиреНрдЯ**:  
```yaml
deployment:
  type: distributed-edge
  nodes:
    - id: "edge-1"
      agents: ["customer-service", "scheduling"]
      models: ["phi-4-mini"]
    - id: "edge-2"
      agents: ["technical-support", "documentation"]
      models: ["qwen2.5-coder-0.5b"]
  coordination:
    load_balancing: true
    failover: automatic
```
  

### рдПрдЬ рдПрдЬреЗрдиреНрдЯрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдкреНрд░рджрд░реНрд╢рди рдЕрдкреНрдЯрд┐рдорд╛рдЗрдЬреЗрд╕рди

#### рдореЛрдбреЗрд▓ рдЪрдпрди рд░рдгрдиреАрддрд┐рд╣рд░реВ

**рдХрд╛рд░реНрдп-рдЖрдзрд╛рд░рд┐рдд рдореЛрдбреЗрд▓ рдЕрд╕рд╛рдЗрдирдореЗрдиреНрдЯ**: рдорд╛рдЗрдХреНрд░реЛрд╕рдлреНрдЯ рдПрдЬреЗрдиреНрдЯ рдлреНрд░реЗрдорд╡рд░реНрдХрд▓реЗ рдХрд╛рд░реНрдп рдЬрдЯрд┐рд▓рддрд╛ рд░ рдЖрд╡рд╢реНрдпрдХрддрд╛рд╣рд░реВрдХреЛ рдЖрдзрд╛рд░рдорд╛ рдмреБрджреНрдзрд┐рдорд╛рдиреА рдореЛрдбреЗрд▓ рдЪрдпрди рд╕рдХреНрд╖рдо рдЧрд░реНрджрдЫ:

- **рд╕рд░рд▓ рдХрд╛рд░реНрдпрд╣рд░реВ** (Q&A, рд░реБрдЯрд┐рдЩ): Qwen2.5-0.5B (500MB, <100ms рдкреНрд░рддрд┐рдХреНрд░рд┐рдпрд╛)  
- **рдордзреНрдпрдо рдХрд╛рд░реНрдпрд╣рд░реВ** (рдЧреНрд░рд╛рд╣рдХ рд╕реЗрд╡рд╛, рд╢реЗрдбреНрдпреБрд▓рд┐рдЩ): Phi-4-Mini (2.4GB, 200-500ms рдкреНрд░рддрд┐рдХреНрд░рд┐рдпрд╛)  
- **рдЬрдЯрд┐рд▓ рдХрд╛рд░реНрдпрд╣рд░реВ** (рдкреНрд░рд╛рд╡рд┐рдзрд┐рдХ рд╡рд┐рд╢реНрд▓реЗрд╖рдг, рдпреЛрдЬрдирд╛): Phi-4 (7GB, 1-3s рдкреНрд░рддрд┐рдХреНрд░рд┐рдпрд╛ рдЬрдм рд╕реНрд░реЛрддрд╣рд░реВ рдЙрдкрд▓рдмреНрдз рдЫрдиреН)  

**рдбрд╛рдпрдирд╛рдорд┐рдХ рдореЛрдбреЗрд▓ рд╕реНрд╡рд┐рдЪрд┐рдЩ**: рдПрдЬреЗрдиреНрдЯрд╣рд░реВрд▓реЗ рд╣рд╛рд▓рдХреЛ рдкреНрд░рдгрд╛рд▓реА рд▓реЛрдб, рдХрд╛рд░реНрдп рдЬрдЯрд┐рд▓рддрд╛ рдореВрд▓реНрдпрд╛рдЩреНрдХрди, рдкреНрд░рдпреЛрдЧрдХрд░реНрддрд╛ рдкреНрд░рд╛рдердорд┐рдХрддрд╛ рд╕реНрддрд░рд╣рд░реВ, рд░ рдЙрдкрд▓рдмреНрдз рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рд╕реНрд░реЛрддрд╣рд░реВрдХреЛ рдЖрдзрд╛рд░рдорд╛ рдореЛрдбреЗрд▓рд╣рд░реВ рдмреАрдЪ рд╕реНрд╡рд┐рдЪ рдЧрд░реНрди рд╕рдХреНрдЫрдиреНред

#### рдореЗрдореЛрд░реА рд░ рд╕реНрд░реЛрдд рд╡реНрдпрд╡рд╕реНрдерд╛рдкрди

```python
# Configure resource constraints for edge deployment
resource_config = ResourceConfig(
    max_memory_usage="4GB",
    max_concurrent_agents=3,
    model_cache_size="2GB",
    auto_unload_idle_models=True,
    power_management=True
)

agent = Agent(
    config=config,
    resource_limits=resource_config
)
```
  

### рдЙрджреНрдпрдо рдПрдХреАрдХрд░рдг рдврд╛рдБрдЪрд╛рд╣рд░реВ

#### рд╕реБрд░рдХреНрд╖рд╛ рд░ рдЕрдиреБрдкрд╛рд▓рди

**рд╕реНрдерд╛рдиреАрдп рдбрд╛рдЯрд╛ рдкреНрд░рд╢реЛрдзрди**: рд╕рдмреИ рдПрдЬреЗрдиреНрдЯ рдкреНрд░рд╢реЛрдзрди рд╕реНрдерд╛рдиреАрдп рд░реВрдкрдорд╛ рд╣реБрдиреНрдЫ, рдЬрд╕рд▓реЗ рд╕рдВрд╡реЗрджрдирд╢реАрд▓ рдбрд╛рдЯрд╛ рдХрд╣рд┐рд▓реНрдпреИ рдПрдЬ рдЙрдкрдХрд░рдгрдмрд╛рдЯ рдмрд╛рд╣рд┐рд░ рдЬрд╛рдиреНрди рд╕рдХреНрджреИрдиред рдпрд╕рдорд╛ рдЧреНрд░рд╛рд╣рдХ рдЬрд╛рдирдХрд╛рд░реА рд╕рдВрд░рдХреНрд╖рдг, рд╕реНрд╡рд╛рд╕реНрдереНрдп рд╕реЗрд╡рд╛ рдПрдЬреЗрдиреНрдЯрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ HIPAA рдЕрдиреБрдкрд╛рд▓рди, рдмреИрдВрдХрд┐рдЩ рдПрдЬреЗрдиреНрдЯрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рд╡рд┐рддреНрддреАрдп рдбрд╛рдЯрд╛ рд╕реБрд░рдХреНрд╖рд╛, рд░ рдпреБрд░реЛрдкреЗрд▓реА рдбрд┐рдкреНрд▓реЛрдпрдореЗрдиреНрдЯрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ GDPR рдЕрдиреБрдкрд╛рд▓рди рд╕рдорд╛рд╡реЗрд╢ рдЫред

**рдкрд╣реБрдВрдЪ рдирд┐рдпрдиреНрддреНрд░рдг**: рднреВрдорд┐рдХрд╛-рдЖрдзрд╛рд░рд┐рдд рдЕрдиреБрдорддрд┐рд╣рд░реВрд▓реЗ рдЙрдкрдХрд░рдгрд╣рд░реВрдорд╛ рдПрдЬреЗрдиреНрдЯрд╣рд░реВрд▓реЗ рдкрд╣реБрдБрдЪ рдЧрд░реНрди рд╕рдХреНрдиреЗ рдирд┐рдпрдиреНрддреНрд░рдг рдЧрд░реНрджрдЫ, рдПрдЬреЗрдиреНрдЯ рдЕрдиреНрддрд░рдХреНрд░рд┐рдпрд╛рдХреЛ рд▓рд╛рдЧрд┐ рдкреНрд░рдпреЛрдЧрдХрд░реНрддрд╛ рдкреНрд░рдорд╛рдгреАрдХрд░рдг, рд░ рдПрдЬреЗрдиреНрдЯрдХрд╛ рд╕рдмреИ рдХрд╛рд░реНрдпрд╣рд░реВ рд░ рдирд┐рд░реНрдгрдпрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЕрдбрд┐рдЯ рдЯреНрд░реЗрд▓рд╣рд░реВред

#### рдирд┐рдЧрд░рд╛рдиреА рд░ рдЕрд╡рд▓реЛрдХрдиреАрдпрддрд╛

```python
from microsoft_agent_framework import AgentMonitor

# Set up monitoring for edge agents
monitor = AgentMonitor(
    metrics=["response_time", "success_rate", "resource_usage"],
    alerts=[
        {"metric": "response_time", "threshold": "2s", "action": "scale_down_model"},
        {"metric": "memory_usage", "threshold": "80%", "action": "unload_idle_agents"}
    ],
    local_storage=True  # Store metrics locally for offline operation
)

agent.add_monitor(monitor)
```
  

### рд╡рд╛рд╕реНрддрд╡рд┐рдХ-рд╡рд┐рд╢реНрд╡ рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди рдЙрджрд╛рд╣рд░рдгрд╣рд░реВ

#### рд░рд┐рдЯреЗрд▓ рдПрдЬ
**рдПрдЬреЗрдиреНрдЯ рдкрд░рд┐рдирд┐рдпреЛрдЬрдирдХреЛ рд▓рд╛рдЧрд┐ рдлреНрд░реЗрдорд╡рд░реНрдХ рдЪрдпрди**: рд▓рдХреНрд╖реНрдп рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рд░ рдПрдЬреЗрдиреНрдЯ рдЖрд╡рд╢реНрдпрдХрддрд╛рд╣рд░реВрдХреЛ рдЖрдзрд╛рд░рдорд╛ рдЕрдиреБрдХреВрд▓рди рдлреНрд░реЗрдорд╡рд░реНрдХрд╣рд░реВ рдЪрдпрди рдЧрд░реНрдиреБрд╣реЛрд╕реНред CPU-рдЕрдиреБрдХреВрд▓рд┐рдд рдПрдЬреЗрдиреНрдЯ рдкрд░рд┐рдирд┐рдпреЛрдЬрдирдХреЛ рд▓рд╛рдЧрд┐ Llama.cpp рдкреНрд░рдпреЛрдЧ рдЧрд░реНрдиреБрд╣реЛрд╕реН, Apple Silicon рдПрдЬреЗрдиреНрдЯ рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ Apple MLX рдкреНрд░рдпреЛрдЧ рдЧрд░реНрдиреБрд╣реЛрд╕реН, рд░ рдХреНрд░рд╕-рдкреНрд▓реНрдпрд╛рдЯрдлрд░реНрдо рдПрдЬреЗрдиреНрдЯ рдЕрдиреБрдХреВрд▓рддрд╛рдХреЛ рд▓рд╛рдЧрд┐ ONNX рдкреНрд░рдпреЛрдЧ рдЧрд░реНрдиреБрд╣реЛрд╕реНред

## рд╡реНрдпрд╛рд╡рд╣рд╛рд░рд┐рдХ SLM рдПрдЬреЗрдиреНрдЯ рд░реВрдкрд╛рдиреНрддрд░рдг рд░ рдкреНрд░рдпреЛрдЧрдХрд╛ рдХреЗрд╕рд╣рд░реВ

### рд╡рд╛рд╕реНрддрд╡рд┐рдХ рд╕рдВрд╕рд╛рд░рдорд╛ рдПрдЬреЗрдиреНрдЯ рдкрд░рд┐рдирд┐рдпреЛрдЬрди рдкрд░рд┐рджреГрд╢реНрдпрд╣рд░реВ

**рдореЛрдмрд╛рдЗрд▓ рдПрдЬреЗрдиреНрдЯ рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╣рд░реВ**: Q4_K рдлрд░реНрдореНрдпрд╛рдЯрд╣рд░реВ рдиреНрдпреВрдирддрдо рдореЗрдореЛрд░реА рдЦрдкрддрдХрд╛ рд╕рд╛рде рд╕реНрдорд╛рд░реНрдЯрдлреЛрди рдПрдЬреЗрдиреНрдЯ рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╣рд░реВрдорд╛ рдЙрддреНрдХреГрд╖реНрдЯ рдЫрдиреН, рдЬрдмрдХрд┐ Q8_0 рдЯреНрдпрд╛рдмреНрд▓реЗрдЯ-рдЖрдзрд╛рд░рд┐рдд рдПрдЬреЗрдиреНрдЯ рдкреНрд░рдгрд╛рд▓реАрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рд╕рдиреНрддреБрд▓рд┐рдд рдкреНрд░рджрд░реНрд╢рди рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫред Q5_K рдлрд░реНрдореНрдпрд╛рдЯрд╣рд░реВрд▓реЗ рдореЛрдмрд╛рдЗрд▓ рдЙрддреНрдкрд╛рджрдХрддрд╛ рдПрдЬреЗрдиреНрдЯрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЙрдЪреНрдЪ рдЧреБрдгрд╕реНрддрд░ рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫред

**рдбреЗрд╕реНрдХрдЯрдк рд░ рдПрдЬ рдПрдЬреЗрдиреНрдЯ рдХрдореНрдкреНрдпреБрдЯрд┐рдЩ**: Q5_K рдбреЗрд╕реНрдХрдЯрдк рдПрдЬреЗрдиреНрдЯ рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЙрддреНрдХреГрд╖реНрдЯ рдкреНрд░рджрд░реНрд╢рди рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫ, Q8_0 рд╡рд░реНрдХрд╕реНрдЯреЗрд╢рди рдПрдЬреЗрдиреНрдЯ рд╡рд╛рддрд╛рд╡рд░рдгрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЙрдЪреНрдЪ-рдЧреБрдгрд╕реНрддрд░рдХреЛ рдЗрдирдлрд░реЗрдиреНрд╕ рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫ, рд░ Q4_K рдПрдЬ рдПрдЬреЗрдиреНрдЯ рдЙрдкрдХрд░рдгрд╣рд░реВрдорд╛ рдХреБрд╢рд▓ рдкреНрд░рд╢реЛрдзрди рд╕рдХреНрд╖рдо рдЧрд░реНрджрдЫред

**рдЕрдиреБрд╕рдиреНрдзрд╛рди рд░ рдкреНрд░рдпреЛрдЧрд╛рддреНрдордХ рдПрдЬреЗрдиреНрдЯрд╣рд░реВ**: рдЙрдиреНрдирдд рдХреНрд╡рд╛рдиреНрдЯрд╛рдЗрдЬреЗрд╕рди рдлрд░реНрдореНрдпрд╛рдЯрд╣рд░реВрд▓реЗ рд╢реИрдХреНрд╖рд┐рдХ рдЕрдиреБрд╕рдиреНрдзрд╛рди рд░ рдЕрддреНрдпрдзрд┐рдХ рд╕реНрд░реЛрдд рд╕реАрдорд┐рддрддрд╛рд╕рд╣рд┐рддрдХреЛ рдкреНрд░рдорд╛рдг-рдЕрд╡рдзрд╛рд░рдгрд╛ рдПрдЬреЗрдиреНрдЯ рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЕрд▓реНрдЯреНрд░рд╛-рд▓реЛ рдкреНрд░реЗрд╕рд┐рдЬрди рдПрдЬреЗрдиреНрдЯ рдЗрдирдлрд░реЗрдиреНрд╕рдХреЛ рдЕрдиреНрд╡реЗрд╖рдг рд╕рдХреНрд╖рдо рдЧрд░реНрджрдЫред

### SLM рдПрдЬреЗрдиреНрдЯ рдкреНрд░рджрд░реНрд╢рди рдмреЗрдВрдЪрдорд╛рд░реНрдХрд╣рд░реВ

**рдПрдЬреЗрдиреНрдЯ рдЗрдирдлрд░реЗрдиреНрд╕ рдЧрддрд┐**: Q4_K рдореЛрдмрд╛рдЗрд▓ CPUs рдорд╛ рд╕рдмреИрднрдиреНрджрд╛ рдЫрд┐рдЯреЛ рдПрдЬреЗрдиреНрдЯ рдкреНрд░рддрд┐рдХреНрд░рд┐рдпрд╛ рд╕рдордп рдкреНрд░рд╛рдкреНрдд рдЧрд░реНрджрдЫ, Q5_K рд╕рд╛рдорд╛рдиреНрдп рдПрдЬреЗрдиреНрдЯ рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рд╕рдиреНрддреБрд▓рд┐рдд рдЧрддрд┐-рдЧреБрдгрд╕реНрддрд░ рдЕрдиреБрдкрд╛рдд рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫ, Q8_0 рдЬрдЯрд┐рд▓ рдПрдЬреЗрдиреНрдЯ рдХрд╛рд░реНрдпрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЙрдЪреНрдЪ рдЧреБрдгрд╕реНрддрд░ рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫ, рд░ рдкреНрд░рдпреЛрдЧрд╛рддреНрдордХ рдлрд░реНрдореНрдпрд╛рдЯрд╣рд░реВрд▓реЗ рд╡рд┐рд╢реЗрд╖ рдПрдЬреЗрдиреНрдЯ рд╣рд╛рд░реНрдбрд╡реЗрдпрд░рдХреЛ рд▓рд╛рдЧрд┐ рдЕрдзрд┐рдХрддрдо рдереНрд░реБрдкреБрдЯ рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫред

**рдПрдЬреЗрдиреНрдЯ рдореЗрдореЛрд░реА рдЖрд╡рд╢реНрдпрдХрддрд╛рд╣рд░реВ**: рдПрдЬреЗрдиреНрдЯрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдХреНрд╡рд╛рдиреНрдЯрд╛рдЗрдЬреЗрд╕рди рд╕реНрддрд░рд╣рд░реВ Q2_K (рд╕рд╛рдиреЛ рдПрдЬреЗрдиреНрдЯ рдореЛрдбреЗрд▓рд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ 500MB рднрдиреНрджрд╛ рдХрдо) рджреЗрдЦрд┐ Q8_0 (рдореВрд▓ рдЖрдХрд╛рд░рдХреЛ рд▓рдЧрднрдЧ 50%) рд╕рдореНрдо рд╣реБрдиреНрдЫрдиреН, рд░ рдкреНрд░рдпреЛрдЧрд╛рддреНрдордХ рдХрдиреНрдлрд┐рдЧрд░реЗрд╕рдирд╣рд░реВрд▓реЗ рд╕реНрд░реЛрдд-рд╕реАрдорд┐рдд рдПрдЬреЗрдиреНрдЯ рд╡рд╛рддрд╛рд╡рд░рдгрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЕрдзрд┐рдХрддрдо рдХрдореНрдкреНрд░реЗрд╕рди рдкреНрд░рд╛рдкреНрдд рдЧрд░реНрджрдЫред

## SLM рдПрдЬреЗрдиреНрдЯрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЪреБрдиреМрддреАрд╣рд░реВ рд░ рд╡рд┐рдЪрд╛рд░рд╣рд░реВ

### рдПрдЬреЗрдиреНрдЯ рдкреНрд░рдгрд╛рд▓реАрд╣рд░реВрдорд╛ рдкреНрд░рджрд░реНрд╢рди рд╡реНрдпрд╛рдкрд╛рд░-рд╕рдореНрдЭреМрддрд╛

SLM рдПрдЬреЗрдиреНрдЯ рдкрд░рд┐рдирд┐рдпреЛрдЬрдирд▓реЗ рдореЛрдбреЗрд▓ рдЖрдХрд╛рд░, рдПрдЬреЗрдиреНрдЯ рдкреНрд░рддрд┐рдХреНрд░рд┐рдпрд╛ рдЧрддрд┐, рд░ рдЖрдЙрдЯрдкреБрдЯ рдЧреБрдгрд╕реНрддрд░ рдмреАрдЪрдХреЛ рд╡реНрдпрд╛рдкрд╛рд░-рд╕рдореНрдЭреМрддрд╛рдХреЛ рд╕рд╛рд╡рдзрд╛рдиреАрдкреВрд░реНрд╡рдХ рд╡рд┐рдЪрд╛рд░ рд╕рдорд╛рд╡реЗрд╢ рдЧрд░реНрджрдЫред рдЬрдмрдХрд┐ Q4_K рдореЛрдмрд╛рдЗрд▓ рдПрдЬреЗрдиреНрдЯрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЕрд╕рд╛рдзрд╛рд░рдг рдЧрддрд┐ рд░ рджрдХреНрд╖рддрд╛ рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫ, Q8_0 рдЬрдЯрд┐рд▓ рдПрдЬреЗрдиреНрдЯ рдХрд╛рд░реНрдпрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЙрдЪреНрдЪ рдЧреБрдгрд╕реНрддрд░ рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫред Q5_K рдЕрдзрд┐рдХрд╛рдВрд╢ рд╕рд╛рдорд╛рдиреНрдп рдПрдЬреЗрдиреНрдЯ рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЙрдкрдпреБрдХреНрдд рдордзреНрдп рдорд╛рд░реНрдЧ рдмрдирд╛рдЙрдБрдЫред

### SLM рдПрдЬреЗрдиреНрдЯрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рдЕрдиреБрдХреВрд▓рддрд╛

рд╡рд┐рднрд┐рдиреНрди рдПрдЬ рдЙрдкрдХрд░рдгрд╣рд░реВрдорд╛ SLM рдПрдЬреЗрдиреНрдЯ рдкрд░рд┐рдирд┐рдпреЛрдЬрдирдХреЛ рд▓рд╛рдЧрд┐ рд╡рд┐рднрд┐рдиреНрди рдХреНрд╖рдорддрд╛рд╣рд░реВ рдЫрдиреНред Q4_K рд╕рд╛рдзрд╛рд░рдг рдПрдЬреЗрдиреНрдЯрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЖрдзрд╛рд░рднреВрдд рдкреНрд░реЛрд╕реЗрд╕рд░рд╣рд░реВрдорд╛ рдХреБрд╢рд▓рддрд╛рдкреВрд░реНрд╡рдХ рдЪрд▓реНрдЫ, Q5_K рд╕рдиреНрддреБрд▓рд┐рдд рдПрдЬреЗрдиреНрдЯ рдкреНрд░рджрд░реНрд╢рдирдХреЛ рд▓рд╛рдЧрд┐ рдордзреНрдпрдо рдХрдореНрдкреНрдпреБрдЯреЗрд╢рдирд▓ рд╕реНрд░реЛрддрд╣рд░реВ рдЖрд╡рд╢реНрдпрдХ рдЫ, рд░ Q8_0 рдЙрдиреНрдирдд рдПрдЬреЗрдиреНрдЯ рдХреНрд╖рдорддрд╛рд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЙрдЪреНрдЪ-рдЕрдиреНрдд рд╣рд╛рд░реНрдбрд╡реЗрдпрд░рдмрд╛рдЯ рд▓рд╛рднрд╛рдиреНрд╡рд┐рдд рд╣реБрдиреНрдЫред

### SLM рдПрдЬреЗрдиреНрдЯ рдкреНрд░рдгрд╛рд▓реАрд╣рд░реВрдорд╛ рд╕реБрд░рдХреНрд╖рд╛ рд░ рдЧреЛрдкрдиреАрдпрддрд╛

SLM рдПрдЬреЗрдиреНрдЯрд╣рд░реВрд▓реЗ рдЧреЛрдкрдиреАрдпрддрд╛ рдмрдврд╛рдЙрди рд╕реНрдерд╛рдиреАрдп рдкреНрд░рд╢реЛрдзрди рд╕рдХреНрд╖рдо рдЧрд░реЗ рдкрдирд┐, рдПрдЬреЗрдиреНрдЯ рдореЛрдбреЗрд▓рд╣рд░реВ рд░ рдбреЗрдЯрд╛ рдПрдЬ рд╡рд╛рддрд╛рд╡рд░рдгрд╣рд░реВрдорд╛ рд╕реБрд░рдХреНрд╖рд┐рдд рдЧрд░реНрди рдЙрдЪрд┐рдд рд╕реБрд░рдХреНрд╖рд╛ рдЙрдкрд╛рдпрд╣рд░реВ рд▓рд╛рдЧреВ рдЧрд░реНрдиреБрдкрд░реНрдЫред рдпреЛ рд╡рд┐рд╢реЗрд╖ рдЧрд░реА рдЙрдЪреНрдЪ-рдЧреБрдгрд╕реНрддрд░рдХреЛ рдПрдЬреЗрдиреНрдЯ рдлрд░реНрдореНрдпрд╛рдЯрд╣рд░реВ рдЙрджреНрдпрдо рд╡рд╛рддрд╛рд╡рд░рдгрд╣рд░реВрдорд╛ рдкрд░рд┐рдирд┐рдпреЛрдЬрди рдЧрд░реНрджрд╛ рд╡рд╛ рд╕рдВрд╡реЗрджрдирд╢реАрд▓ рдбреЗрдЯрд╛ рд╣реНрдпрд╛рдиреНрдбрд▓ рдЧрд░реНрдиреЗ рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╣рд░реВрдорд╛ рдХрдореНрдкреНрд░реЗрд╕реНрдб рдПрдЬреЗрдиреНрдЯ рдлрд░реНрдореНрдпрд╛рдЯрд╣рд░реВ рдкрд░рд┐рдирд┐рдпреЛрдЬрди рдЧрд░реНрджрд╛ рдорд╣рддреНрддреНрд╡рдкреВрд░реНрдг рдЫред

## SLM рдПрдЬреЗрдиреНрдЯ рд╡рд┐рдХрд╛рд╕рдорд╛ рднрд╡рд┐рд╖реНрдпрдХрд╛ рдкреНрд░рд╡реГрддреНрддрд┐рд╣рд░реВ

SLM рдПрдЬреЗрдиреНрдЯ рдкрд░рд┐рджреГрд╢реНрдп рдХрдореНрдкреНрд░реЗрд╕рди рдкреНрд░рд╡рд┐рдзрд┐рд╣рд░реВ, рдЕрдиреБрдХреВрд▓рди рд╡рд┐рдзрд┐рд╣рд░реВ, рд░ рдПрдЬ рдкрд░рд┐рдирд┐рдпреЛрдЬрди рд░рдгрдиреАрддрд┐рд╣рд░реВрдХреЛ рдкреНрд░рдЧрддрд┐рд╕рдБрдЧ рд╡рд┐рдХрд╕рд┐рдд рд╣реБрдБрджреИрдЫред рднрд╡рд┐рд╖реНрдпрдХрд╛ рд╡рд┐рдХрд╛рд╕рд╣рд░реВрдорд╛ рдПрдЬреЗрдиреНрдЯ рдореЛрдбреЗрд▓рд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЕрдзрд┐рдХ рдХреБрд╢рд▓ рдХреНрд╡рд╛рдиреНрдЯрд╛рдЗрдЬреЗрд╕рди рдПрд▓реНрдЧреЛрд░рд┐рджрдорд╣рд░реВ, рдПрдЬреЗрдиреНрдЯ рд╡рд░реНрдХрдлреНрд▓реЛрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рд╕реБрдзрд╛рд░рд┐рдПрдХреЛ рдХрдореНрдкреНрд░реЗрд╕рди рд╡рд┐рдзрд┐рд╣рд░реВ, рд░ рдПрдЬреЗрдиреНрдЯ рдкреНрд░рд╢реЛрдзрдирдХреЛ рд▓рд╛рдЧрд┐ рдПрдЬ рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рдПрдХреНрд╕реЗрд▓реЗрд░реЗрдЯрд░рд╣рд░реВрд╕рдБрдЧ рд░рд╛рдореНрд░реЛ рдПрдХреАрдХрд░рдг рд╕рдорд╛рд╡реЗрд╢ рдЫред

**SLM рдПрдЬреЗрдиреНрдЯрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдмрдЬрд╛рд░ рднрд╡рд┐рд╖реНрдпрд╡рд╛рдгреАрд╣рд░реВ**: рд╣рд╛рд▓рдХреЛ рдЕрдиреБрд╕рдиреНрдзрд╛рди рдЕрдиреБрд╕рд╛рд░, рдПрдЬреЗрдиреНрдЯ-рд╕рдВрдЪрд╛рд▓рд┐рдд рд╕реНрд╡рдЪрд╛рд▓рдирд▓реЗ 2027 рд╕рдореНрдордорд╛ рдЙрджреНрдпрдо рд╡рд░реНрдХрдлреНрд▓реЛрд╣рд░реВрдорд╛ рджреЛрд╣реЛрд░рд┐рдиреЗ рд╕рдВрдЬреНрдЮрд╛рдирд╛рддреНрдордХ рдХрд╛рд░реНрдпрд╣рд░реВрдХреЛ 40тАУ60% рд╣рдЯрд╛рдЙрди рд╕рдХреНрдЫ, SLMs рд▓реЗ рд▓рд╛рдЧрдд рджрдХреНрд╖рддрд╛ рд░ рдкрд░рд┐рдирд┐рдпреЛрдЬрди рд▓рдЪрд┐рд▓реЛрддрд╛рдХрд╛ рдХрд╛рд░рдг рдпреЛ рд░реВрдкрд╛рдиреНрддрд░рдгрдХреЛ рдиреЗрддреГрддреНрд╡ рдЧрд░реНрдиреЗрдЫрдиреНред

**SLM рдПрдЬреЗрдиреНрдЯрд╣рд░реВрдорд╛ рдкреНрд░рд╡рд┐рдзрд┐ рдкреНрд░рд╡реГрддреНрддрд┐рд╣рд░реВ**:
- **рд╡рд┐рд╢реЗрд╖ SLM рдПрдЬреЗрдиреНрдЯрд╣рд░реВ**: рд╡рд┐рд╢реЗрд╖ рдПрдЬреЗрдиреНрдЯ рдХрд╛рд░реНрдпрд╣рд░реВ рд░ рдЙрджреНрдпреЛрдЧрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд рдбреЛрдореЗрди-рд╡рд┐рд╢рд┐рд╖реНрдЯ рдореЛрдбреЗрд▓рд╣рд░реВ
- **рдПрдЬ рдПрдЬреЗрдиреНрдЯ рдХрдореНрдкреНрдпреБрдЯрд┐рдЩ**: рд╕реБрдзрд╛рд░рд┐рдПрдХреЛ рдЧреЛрдкрдиреАрдпрддрд╛ рд░ рдХрдо рд╡рд┐рд▓рдореНрдмрддрд╛рд╕рд╣рд┐рддрдХреЛ рдЙрдкрдХрд░рдгрдорд╛ рдЖрдзрд╛рд░рд┐рдд рдПрдЬреЗрдиреНрдЯ рдХреНрд╖рдорддрд╛рд╣рд░реВ
- **рдПрдЬреЗрдиреНрдЯ рд╕рдордиреНрд╡рдп**: рдЧрддрд┐рд╢реАрд▓ рд░реБрдЯрд┐рдЩ рд░ рд▓реЛрдб рдмреНрдпрд╛рд▓реЗрдиреНрд╕рд┐рдЩрдХреЛ рд╕рд╛рде рдзреЗрд░реИ SLM рдПрдЬреЗрдиреНрдЯрд╣рд░реВ рдмреАрдЪрдХреЛ рд░рд╛рдореНрд░реЛ рд╕рдордиреНрд╡рдп
- **рд▓реЛрдХрддрд╛рдиреНрддреНрд░рд┐рдХрд░рдг**: SLM рд▓рдЪрд┐рд▓реЛрддрд╛рд▓реЗ рд╕рдВрдЧрдардирд╣рд░реВрдорд╛ рдПрдЬреЗрдиреНрдЯ рд╡рд┐рдХрд╛рд╕рдорд╛ рд╡реНрдпрд╛рдкрдХ рд╕рд╣рднрд╛рдЧрд┐рддрд╛ рд╕рдХреНрд╖рдо рдЧрд░реНрджрдЫ

## SLM рдПрдЬреЗрдиреНрдЯрд╣рд░реВрд╕рдБрдЧ рд╕реБрд░реБ рдЧрд░реНрджреИ

### рдЪрд░рдг 1: рдорд╛рдЗрдХреНрд░реЛрд╕рдлреНрдЯ рдПрдЬреЗрдиреНрдЯ рдлреНрд░реЗрдорд╡рд░реНрдХ рд╡рд╛рддрд╛рд╡рд░рдг рд╕реЗрдЯ рдЕрдк рдЧрд░реНрдиреБрд╣реЛрд╕реН

**рдЖрд╡рд╢реНрдпрдХрддрд╛рд╣рд░реВ рд╕реНрдерд╛рдкрдирд╛ рдЧрд░реНрдиреБрд╣реЛрд╕реН**:
```bash
# Install Microsoft Agent Framework
pip install microsoft-agent-framework

# Install Foundry Local SDK for edge deployment
pip install foundry-local-sdk

# Install additional dependencies for edge agents
pip install openai asyncio
```

**Foundry Local рдЖрд░рдореНрдн рдЧрд░реНрдиреБрд╣реЛрд╕реН**:
```bash
# Start Foundry Local service
foundry service start

# Load default model for agent development
foundry model run phi-4-mini
```

### рдЪрд░рдг 2: рдПрдЬреЗрдиреНрдЯ рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЖрдлреНрдиреЛ SLM рдЪрдпрди рдЧрд░реНрдиреБрд╣реЛрд╕реН
рдорд╛рдЗрдХреНрд░реЛрд╕рдлреНрдЯ рдПрдЬреЗрдиреНрдЯ рдлреНрд░реЗрдорд╡рд░реНрдХрдХрд╛ рд▓рд╛рдЧрд┐ рд▓реЛрдХрдкреНрд░рд┐рдп рд╡рд┐рдХрд▓реНрдкрд╣рд░реВ:
- **Microsoft Phi-4 Mini (3.8B)**: рд╕рдиреНрддреБрд▓рд┐рдд рдкреНрд░рджрд░реНрд╢рдирдХрд╛ рд╕рд╛рде рд╕рд╛рдорд╛рдиреНрдп рдПрдЬреЗрдиреНрдЯ рдХрд╛рд░реНрдпрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЙрддреНрдХреГрд╖реНрдЯ
- **Qwen2.5-0.5B (0.5B)**: рд╕рд╛рдзрд╛рд░рдг рд░реБрдЯрд┐рдЩ рд░ рд╡рд░реНрдЧреАрдХрд░рдг рдПрдЬреЗрдиреНрдЯрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЕрддрд┐-рдХреБрд╢рд▓
- **Qwen2.5-Coder-0.5B (0.5B)**: рдХреЛрдб-рд╕рдореНрдмрдиреНрдзрд┐рдд рдПрдЬреЗрдиреНрдЯ рдХрд╛рд░реНрдпрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рд╡рд┐рд╢реЗрд╖
- **Phi-4 (7B)**: рд╕реНрд░реЛрддрд╣рд░реВ рдЙрдкрд▓рдмреНрдз рд╣реБрдБрджрд╛ рдЬрдЯрд┐рд▓ рдПрдЬ рдкрд░рд┐рджреГрд╢реНрдпрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдЙрдиреНрдирдд рддрд░реНрдХ

### рдЪрд░рдг 3: рдорд╛рдЗрдХреНрд░реЛрд╕рдлреНрдЯ рдПрдЬреЗрдиреНрдЯ рдлреНрд░реЗрдорд╡рд░реНрдХрд╕рдБрдЧ рдЖрдлреНрдиреЛ рдкрд╣рд┐рд▓реЛ рдПрдЬреЗрдиреНрдЯ рд╕рд┐рд░реНрдЬрдирд╛ рдЧрд░реНрдиреБрд╣реЛрд╕реН

**рдЖрдзрд╛рд░рднреВрдд рдПрдЬреЗрдиреНрдЯ рд╕реЗрдЯрдЕрдк**:
```python
from microsoft_agent_framework import Agent, Config
from foundry_local import FoundryLocalManager

# Initialize Foundry Local connection
foundry = FoundryLocalManager("phi-4-mini")

# Create agent configuration
config = Config(
    name="my-first-agent",
    model_provider="foundry-local",
    model_alias="phi-4-mini",
    offline_mode=True
)

# Create and configure agent
agent = Agent(
    config=config,
    model_endpoint=foundry.endpoint,
    api_key=foundry.api_key
)

# Define a simple tool
@agent.tool
def get_current_time() -> str:
    """Get the current time."""
    from datetime import datetime
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

# Test the agent
response = agent.chat("What time is it?")
print(response)
```

### рдЪрд░рдг 4: рдПрдЬреЗрдиреНрдЯрдХреЛ рджрд╛рдпрд░рд╛ рд░ рдЖрд╡рд╢реНрдпрдХрддрд╛рд╣рд░реВ рдкрд░рд┐рднрд╛рд╖рд┐рдд рдЧрд░реНрдиреБрд╣реЛрд╕реН
рдорд╛рдЗрдХреНрд░реЛрд╕рдлреНрдЯ рдПрдЬреЗрдиреНрдЯ рдлреНрд░реЗрдорд╡рд░реНрдХ рдкреНрд░рдпреЛрдЧ рдЧрд░реЗрд░ рдХреЗрдиреНрджреНрд░рд┐рдд, рд░рд╛рдореНрд░реЛрд╕рдБрдЧ рдкрд░рд┐рднрд╛рд╖рд┐рдд рдПрдЬреЗрдиреНрдЯ рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╣рд░реВрдмрд╛рдЯ рд╕реБрд░реБ рдЧрд░реНрдиреБрд╣реЛрд╕реН:
- **рдПрдХрд▓ рдбреЛрдореЗрди рдПрдЬреЗрдиреНрдЯрд╣рд░реВ**: рдЧреНрд░рд╛рд╣рдХ рд╕реЗрд╡рд╛ рд╡рд╛ рддрд╛рд▓рд┐рдХрд╛ рдмрдирд╛рдЙрдиреЗ рд╡рд╛ рдЕрдиреБрд╕рдиреНрдзрд╛рди
- **рд╕реНрдкрд╖реНрдЯ рдПрдЬреЗрдиреНрдЯ рдЙрджреНрджреЗрд╢реНрдпрд╣рд░реВ**: рдПрдЬреЗрдиреНрдЯ рдкреНрд░рджрд░реНрд╢рдирдХрд╛ рд▓рд╛рдЧрд┐ рд╡рд┐рд╢рд┐рд╖реНрдЯ, рдорд╛рдкрдирдпреЛрдЧреНрдп рд▓рдХреНрд╖реНрдпрд╣рд░реВ
- **рд╕реАрдорд┐рдд рдЙрдкрдХрд░рдг рдПрдХреАрдХрд░рдг**: рдкреНрд░рд╛рд░рдореНрднрд┐рдХ рдПрдЬреЗрдиреНрдЯ рдкрд░рд┐рдирд┐рдпреЛрдЬрдирдХреЛ рд▓рд╛рдЧрд┐ рдЕрдзрд┐рдХрддрдо 3-5 рдЙрдкрдХрд░рдгрд╣рд░реВ
- **рдкрд░рд┐рднрд╛рд╖рд┐рдд рдПрдЬреЗрдиреНрдЯ рд╕реАрдорд╛рд╣рд░реВ**: рдЬрдЯрд┐рд▓ рдкрд░рд┐рджреГрд╢реНрдпрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рд╕реНрдкрд╖реНрдЯ рд╡реГрджреНрдзрд┐ рдорд╛рд░реНрдЧрд╣рд░реВ
- **рдПрдЬ-рдкреНрд░рдердо рдбрд┐рдЬрд╛рдЗрди**: рдЕрдлрд▓рд╛рдЗрди рдХрд╛рд░реНрдпрдХреНрд╖рдорддрд╛ рд░ рд╕реНрдерд╛рдиреАрдп рдкреНрд░рд╢реЛрдзрдирд▓рд╛рдИ рдкреНрд░рд╛рдердорд┐рдХрддрд╛ рджрд┐рдиреБрд╣реЛрд╕реН

### рдЪрд░рдг 5: рдорд╛рдЗрдХреНрд░реЛрд╕рдлреНрдЯ рдПрдЬреЗрдиреНрдЯ рдлреНрд░реЗрдорд╡рд░реНрдХрд╕рдБрдЧ рдПрдЬ рдкрд░рд┐рдирд┐рдпреЛрдЬрди рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди рдЧрд░реНрдиреБрд╣реЛрд╕реН

**рд╕реНрд░реЛрдд рдХрдиреНрдлрд┐рдЧрд░реЗрд╕рди**:
```python
from microsoft_agent_framework import ResourceConfig

# Configure for edge deployment
resource_config = ResourceConfig(
    max_memory_usage="2GB",
    max_concurrent_agents=2,
    model_cache_size="1GB",
    auto_unload_idle_models=True,
    power_management=True
)

agent = Agent(
    config=config,
    resource_limits=resource_config
)
```

**рдПрдЬ рдПрдЬреЗрдиреНрдЯрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рд╕реБрд░рдХреНрд╖рд╛ рдЙрдкрд╛рдпрд╣рд░реВ рдкрд░рд┐рдирд┐рдпреЛрдЬрди рдЧрд░реНрдиреБрд╣реЛрд╕реН**:
- **рд╕реНрдерд╛рдиреАрдп рдЗрдирдкреБрдЯ рдорд╛рдиреНрдпрддрд╛**: рдХреНрд▓рд╛рдЙрдб рдирд┐рд░реНрднрд░рддрд╛рд╣рд░реВ рдмрд┐рдирд╛ рдЕрдиреБрд░реЛрдзрд╣рд░реВ рдЬрд╛рдБрдЪ рдЧрд░реНрдиреБрд╣реЛрд╕реН
- **рдЕрдлрд▓рд╛рдЗрди рдЖрдЙрдЯрдкреБрдЯ рдлрд┐рд▓реНрдЯрд░рд┐рдЩ**: рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдЧрд░реНрдиреБрд╣реЛрд╕реН рдХрд┐ рдкреНрд░рддрд┐рдХреНрд░рд┐рдпрд╛рд╣рд░реВ рд╕реНрдерд╛рдиреАрдп рд░реВрдкрдорд╛ рдЧреБрдгрд╕реНрддрд░ рдорд╛рдкрджрдгреНрдбрд╣рд░реВ рдкреВрд░рд╛ рдЧрд░реНрдЫрдиреН
- **рдПрдЬ рд╕реБрд░рдХреНрд╖рд╛ рдирд┐рдпрдиреНрддреНрд░рдгрд╣рд░реВ**: рдЗрдиреНрдЯрд░рдиреЗрдЯ рдХрдиреЗрдХреНрдЯрд┐рд╡рд┐рдЯреА рдЖрд╡рд╢реНрдпрдХ рдмрд┐рдирд╛ рд╕реБрд░рдХреНрд╖рд╛ рд▓рд╛рдЧреВ рдЧрд░реНрдиреБрд╣реЛрд╕реН
- **рд╕реНрдерд╛рдиреАрдп рдЕрдиреБрдЧрдорди**: рдкреНрд░рджрд░реНрд╢рди рдЯреНрд░реНрдпрд╛рдХ рдЧрд░реНрдиреБрд╣реЛрд╕реН рд░ рдПрдЬ рдЯреЗрд▓рд┐рдореЗрдЯреНрд░реА рдкреНрд░рдпреЛрдЧ рдЧрд░реЗрд░ рд╕рдорд╕реНрдпрд╛рд╣рд░реВрд▓рд╛рдИ рдЭрдгреНрдбрд╛ рд▓рдЧрд╛рдЙрдиреБрд╣реЛрд╕реН

### рдЪрд░рдг 6: рдПрдЬ рдПрдЬреЗрдиреНрдЯ рдкреНрд░рджрд░реНрд╢рди рдорд╛рдкрди рд░ рдЕрдиреБрдХреВрд▓рди рдЧрд░реНрдиреБрд╣реЛрд╕реН
- **рдПрдЬреЗрдиреНрдЯ рдХрд╛рд░реНрдп рдкреВрд░рд╛ рджрд░рд╣рд░реВ**: рдЕрдлрд▓рд╛рдЗрди рдкрд░рд┐рджреГрд╢реНрдпрд╣рд░реВрдорд╛ рд╕рдлрд▓рддрд╛ рджрд░рд╣рд░реВ рдЕрдиреБрдЧрдорди рдЧрд░реНрдиреБрд╣реЛрд╕реН
- **рдПрдЬреЗрдиреНрдЯ рдкреНрд░рддрд┐рдХреНрд░рд┐рдпрд╛ рд╕рдордпрд╣рд░реВ**: рдПрдЬ рдкрд░рд┐рдирд┐рдпреЛрдЬрдирдХреЛ рд▓рд╛рдЧрд┐ рдЙрдк-рд╕реЗрдХреЗрдиреНрдб рдкреНрд░рддрд┐рдХреНрд░рд┐рдпрд╛ рд╕рдордп рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдЧрд░реНрдиреБрд╣реЛрд╕реН
- **рд╕реНрд░реЛрдд рдЙрдкрдпреЛрдЧ**: рдПрдЬ рдЙрдкрдХрд░рдгрд╣рд░реВрдорд╛ рдореЗрдореЛрд░реА, CPU, рд░ рдмреНрдпрд╛рдЯреНрд░реА рдкреНрд░рдпреЛрдЧ рдЯреНрд░реНрдпрд╛рдХ рдЧрд░реНрдиреБрд╣реЛрд╕реН
- **рд▓рд╛рдЧрдд рджрдХреНрд╖рддрд╛**: рдХреНрд▓рд╛рдЙрдб-рдЖрдзрд╛рд░рд┐рдд рд╡рд┐рдХрд▓реНрдкрд╣рд░реВрд╕рдБрдЧ рдПрдЬ рдкрд░рд┐рдирд┐рдпреЛрдЬрди рд▓рд╛рдЧрдд рддреБрд▓рдирд╛ рдЧрд░реНрдиреБрд╣реЛрд╕реН
- **рдЕрдлрд▓рд╛рдЗрди рд╡рд┐рд╢реНрд╡рд╕рдиреАрдпрддрд╛**: рдиреЗрдЯрд╡рд░реНрдХ рдЖрдЙрдЯреЗрдЬрдХреЛ рд╕рдордпрдорд╛ рдПрдЬреЗрдиреНрдЯ рдкреНрд░рджрд░реНрд╢рди рдорд╛рдкрди рдЧрд░реНрдиреБрд╣реЛрд╕реН

## SLM рдПрдЬреЗрдиреНрдЯ рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрдирдХрд╛ рд▓рд╛рдЧрд┐ рдореБрдЦреНрдп рдирд┐рд╖реНрдХрд░реНрд╖рд╣рд░реВ

1. **рдПрдЬреЗрдиреНрдЯрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ SLM рдкрд░реНрдпрд╛рдкреНрдд рдЫрдиреН**: рдЕрдзрд┐рдХрд╛рдВрд╢ рдПрдЬреЗрдиреНрдЯ рдХрд╛рд░реНрдпрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐, рд╕рд╛рдирд╛ рдореЛрдбреЗрд▓рд╣рд░реВрд▓реЗ рдареВрд▓рд╛ рдореЛрдбреЗрд▓рд╣рд░реВ рдЬрд╕реНрддреИ рдкреНрд░рджрд░реНрд╢рди рдЧрд░реНрдЫрдиреН рдЬрдмрдХрд┐ рдорд╣рддреНрддреНрд╡рдкреВрд░реНрдг рдлрд╛рдЗрджрд╛рд╣рд░реВ рдкреНрд░рджрд╛рди рдЧрд░реНрджреИ
2. **рдПрдЬреЗрдиреНрдЯрд╣рд░реВрдорд╛ рд▓рд╛рдЧрдд рджрдХреНрд╖рддрд╛**: SLM рдПрдЬреЗрдиреНрдЯрд╣рд░реВ рдЪрд▓рд╛рдЙрди 10-30x рд╕рд╕реНрддреЛ, рд╡реНрдпрд╛рдкрдХ рдкрд░рд┐рдирд┐рдпреЛрдЬрдирдХреЛ рд▓рд╛рдЧрд┐ рдЖрд░реНрдерд┐рдХ рд░реВрдкрдорд╛ рд╡реНрдпрд╡рд╣рд╛рд░реНрдп рдмрдирд╛рдЙрдБрджреИ
3. **рдПрдЬреЗрдиреНрдЯрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рд╡рд┐рд╢реЗрд╖рдЬреНрдЮрддрд╛ рдХрд╛рдо рдЧрд░реНрдЫ**: рд╡рд┐рд╢реЗрд╖ рд░реВрдкрдорд╛ рдЯреНрдпреБрди рдЧрд░рд┐рдПрдХреЛ SLMs рдЕрдХреНрд╕рд░ рд╡рд┐рд╢рд┐рд╖реНрдЯ рдПрдЬреЗрдиреНрдЯ рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╣рд░реВрдорд╛ рд╕рд╛рдорд╛рдиреНрдп рдЙрджреНрджреЗрд╢реНрдп LLMs рднрдиреНрджрд╛ рд░рд╛рдореНрд░реЛ рдкреНрд░рджрд░реНрд╢рди рдЧрд░реНрдЫ
4. **рд╣рд╛рдЗрдмреНрд░рд┐рдб рдПрдЬреЗрдиреНрдЯ рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░**: рдирд┐рдпрдорд┐рдд рдПрдЬреЗрдиреНрдЯ рдХрд╛рд░реНрдпрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ SLMs рдкреНрд░рдпреЛрдЧ рдЧрд░реНрдиреБрд╣реЛрд╕реН, рдЬрдЯрд┐рд▓ рддрд░реНрдХрдХреЛ рд▓рд╛рдЧрд┐ рдЖрд╡рд╢реНрдпрдХ рдкрд░реНрджрд╛ LLMs рдкреНрд░рдпреЛрдЧ рдЧрд░реНрдиреБрд╣реЛрд╕реН
5. **рдорд╛рдЗрдХреНрд░реЛрд╕рдлреНрдЯ рдПрдЬреЗрдиреНрдЯ рдлреНрд░реЗрдорд╡рд░реНрдХ рдЙрддреНрдкрд╛рджрди рдкрд░рд┐рдирд┐рдпреЛрдЬрди рд╕рдХреНрд╖рдо рдЧрд░реНрджрдЫ**: рдПрдЬ рдПрдЬреЗрдиреНрдЯрд╣рд░реВ рдирд┐рд░реНрдорд╛рдг, рдкрд░рд┐рдирд┐рдпреЛрдЬрди, рд░ рд╡реНрдпрд╡рд╕реНрдерд╛рдкрдирдХрд╛ рд▓рд╛рдЧрд┐ рдЙрджреНрдпрдо-рдЧреНрд░реЗрдб рдЙрдкрдХрд░рдгрд╣рд░реВ рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫ
6. **рдПрдЬ-рдкреНрд░рдердо рдбрд┐рдЬрд╛рдЗрди рд╕рд┐рджреНрдзрд╛рдиреНрддрд╣рд░реВ**: рд╕реНрдерд╛рдиреАрдп рдкреНрд░рд╢реЛрдзрдирд╕рд╣рд┐рдд рдЕрдлрд▓рд╛рдЗрди-рд╕рдХреНрд╖рдо рдПрдЬреЗрдиреНрдЯрд╣рд░реВрд▓реЗ рдЧреЛрдкрдиреАрдпрддрд╛ рд░ рд╡рд┐рд╢реНрд╡рд╕рдиреАрдпрддрд╛ рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдЧрд░реНрджрдЫ
7. **Foundry Local рдПрдХреАрдХрд░рдг**: рдорд╛рдЗрдХреНрд░реЛрд╕рдлреНрдЯ рдПрдЬреЗрдиреНрдЯ рдлреНрд░реЗрдорд╡рд░реНрдХ рд░ рд╕реНрдерд╛рдиреАрдп рдореЛрдбреЗрд▓ рдЗрдирдлрд░реЗрдиреНрд╕ рдмреАрдЪрдХреЛ рд╕рд╣рдЬ рдХрдиреЗрдХреНрд╢рди
8. **рднрд╡рд┐рд╖реНрдп SLM рдПрдЬреЗрдиреНрдЯрд╣рд░реВ рд╣реБрдиреН**: рдЙрддреНрдкрд╛рджрди рдлреНрд░реЗрдорд╡рд░реНрдХрд╣рд░реВрд╕рд╣рд┐рдд рд╕рд╛рдирд╛ рднрд╛рд╖рд╛ рдореЛрдбреЗрд▓рд╣рд░реВ рдПрдЬреЗрдиреНрдЯрд┐рдХ AI рдХреЛ рднрд╡рд┐рд╖реНрдп рд╣реБрдиреН, рд▓реЛрдХрддрд╛рдиреНрддреНрд░рд┐рдХ рд░ рдХреБрд╢рд▓ рдПрдЬреЗрдиреНрдЯ рдкрд░рд┐рдирд┐рдпреЛрдЬрди рд╕рдХреНрд╖рдо рдЧрд░реНрджреИ

## рд╕рдиреНрджрд░реНрднрд╣рд░реВ рд░ рдердк рдкрдврд╛рдЗ

### рдХреЛрд░ рдЕрдиреБрд╕рдиреНрдзрд╛рди рдкрддреНрд░рд╣рд░реВ рд░ рдкреНрд░рдХрд╛рд╢рдирд╣рд░реВ

#### AI рдПрдЬреЗрдиреНрдЯрд╣рд░реВ рд░ рдПрдЬреЗрдиреНрдЯрд┐рдХ рдкреНрд░рдгрд╛рд▓реАрд╣рд░реВ
- **"рднрд╛рд╖рд╛ рдПрдЬреЗрдиреНрдЯрд╣рд░реВ рдЕрдиреБрдХреВрд▓рдирдпреЛрдЧреНрдп рдЧреНрд░рд╛рдлрд╣рд░реВрдХрд╛ рд░реВрдкрдорд╛"** (2024) - рдПрдЬреЗрдиреНрдЯ рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░ рд░ рдЕрдиреБрдХреВрд▓рди рд░рдгрдиреАрддрд┐рд╣рд░реВрдорд╛ рдЖрдзрд╛рд░рднреВрдд рдЕрдиреБрд╕рдиреНрдзрд╛рди
  - рд▓реЗрдЦрдХрд╣рд░реВ: Wenyue Hua, Lishan Yang, рдЖрджрд┐ред
  - рд▓рд┐рдВрдХ: https://arxiv.org/abs/2402.16823
  - рдореБрдЦреНрдп рдЬрд╛рдирдХрд╛рд░реА: рдЧреНрд░рд╛рдл-рдЖрдзрд╛рд░рд┐рдд рдПрдЬреЗрдиреНрдЯ рдбрд┐рдЬрд╛рдЗрди рд░ рдЕрдиреБрдХреВрд▓рди рд░рдгрдиреАрддрд┐рд╣рд░реВ

- **"рдареВрд▓рд╛ рднрд╛рд╖рд╛ рдореЛрдбреЗрд▓ рдЖрдзрд╛рд░рд┐рдд рдПрдЬреЗрдиреНрдЯрд╣рд░реВрдХреЛ рдЙрджрдп рд░ рд╕рдореНрднрд╛рд╡рдирд╛"** (2023)
  - рд▓реЗрдЦрдХрд╣рд░реВ: Zhiheng Xi, Wenxiang Chen, рдЖрджрд┐ред
  - рд▓рд┐рдВрдХ: https://arxiv.org/abs/2309.07864
  - рдореБрдЦреНрдп рдЬрд╛рдирдХрд╛рд░реА: LLM-рдЖрдзрд╛рд░рд┐рдд рдПрдЬреЗрдиреНрдЯ рдХреНрд╖рдорддрд╛рд╣рд░реВ рд░ рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╣рд░реВрдХреЛ рд╡реНрдпрд╛рдкрдХ рд╕рд░реНрд╡реЗрдХреНрд╖рдг

- **"рднрд╛рд╖рд╛ рдПрдЬреЗрдиреНрдЯрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рд╕рдВрдЬреНрдЮрд╛рдирд╛рддреНрдордХ рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░рд╣рд░реВ"** (2024)
  - рд▓реЗрдЦрдХрд╣рд░реВ: Theodore Sumers, Shunyu Yao, рдЖрджрд┐ред
  - рд▓рд┐рдВрдХ: https://arxiv.org/abs/2309.02427
  - рдореБрдЦреНрдп рдЬрд╛рдирдХрд╛рд░реА: рдмреБрджреНрдзрд┐рдорд╛рди рдПрдЬреЗрдиреНрдЯрд╣рд░реВ рдбрд┐рдЬрд╛рдЗрди рдЧрд░реНрди рд╕рдВрдЬреНрдЮрд╛рдирд╛рддреНрдордХ рдлреНрд░реЗрдорд╡рд░реНрдХрд╣рд░реВ

#### рд╕рд╛рдирд╛ рднрд╛рд╖рд╛ рдореЛрдбреЗрд▓рд╣рд░реВ рд░ рдЕрдиреБрдХреВрд▓рди
- **"Phi-3 рдкреНрд░рд╛рд╡рд┐рдзрд┐рдХ рд░рд┐рдкреЛрд░реНрдЯ: рддрдкрд╛рдИрдВрдХреЛ рдлреЛрдирдорд╛ рд╕реНрдерд╛рдиреАрдп рд░реВрдкрдорд╛ рдЕрддреНрдпрдзрд┐рдХ рд╕рдХреНрд╖рдо рднрд╛рд╖рд╛ рдореЛрдбреЗрд▓"** (2024)
  - рд▓реЗрдЦрдХрд╣рд░реВ: рдорд╛рдЗрдХреНрд░реЛрд╕рдлреНрдЯ рдЕрдиреБрд╕рдиреНрдзрд╛рди рдЯреЛрд▓реА
  - рд▓рд┐рдВрдХ: https://arxiv.org/abs/2404.14219
  - рдореБрдЦреНрдп рдЬрд╛рдирдХрд╛рд░реА: SLM рдбрд┐рдЬрд╛рдЗрди рд╕рд┐рджреНрдзрд╛рдиреНрддрд╣рд░реВ рд░ рдореЛрдмрд╛рдЗрд▓ рдкрд░рд┐рдирд┐рдпреЛрдЬрди рд░рдгрдиреАрддрд┐рд╣рд░реВ

- **"Qwen2.5 рдкреНрд░рд╛рд╡рд┐рдзрд┐рдХ рд░рд┐рдкреЛрд░реНрдЯ"** (2024)
  - рд▓реЗрдЦрдХрд╣рд░реВ: Alibaba Cloud Team
  - рд▓рд┐рдВрдХ: https://arxiv.org/abs/2407.10671
  - рдореБрдЦреНрдп рдЬрд╛рдирдХрд╛рд░реА: рдЙрдиреНрдирдд SLM рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдкреНрд░рд╡рд┐рдзрд┐рд╣рд░реВ рд░ рдкреНрд░рджрд░реНрд╢рди рдЕрдиреБрдХреВрд▓рди

- **"TinyLlama: рдПрдХ рдЦреБрд▓рд╛-рд╕реНрд░реЛрдд рд╕рд╛рдиреЛ рднрд╛рд╖рд╛ рдореЛрдбреЗрд▓"** (2024)
  - рд▓реЗрдЦрдХрд╣рд░реВ: Peiyuan Zhang, Guangtao Zeng, рдЖрджрд┐ред
  - рд▓рд┐рдВрдХ: https://arxiv.org/abs/2401.02385
  - рдореБрдЦреНрдп рдЬрд╛рдирдХрд╛рд░реА: рдЕрддрд┐-рд╕рдВрдХреНрд╖рд┐рдкреНрдд рдореЛрдбреЗрд▓ рдбрд┐рдЬрд╛рдЗрди рд░ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рджрдХреНрд╖рддрд╛

### рдЖрдзрд┐рдХрд╛рд░рд┐рдХ рджрд╕реНрддрд╛рд╡реЗрдЬрд╣рд░реВ рд░ рдлреНрд░реЗрдорд╡рд░реНрдХрд╣рд░реВ

#### рдорд╛рдЗрдХреНрд░реЛрд╕рдлреНрдЯ рдПрдЬреЗрдиреНрдЯ рдлреНрд░реЗрдорд╡рд░реНрдХ
- **рдЖрдзрд┐рдХрд╛рд░рд┐рдХ рджрд╕реНрддрд╛рд╡реЗрдЬ**: https://docs.microsoft.com/en-us/azure/ai-services/agents/
- **GitHub рд░рд┐рдкреЛрдЬрд┐рдЯрд░реА**: https://github.com/microsoft/agent-framework

#### Foundry Local
- **рдкреНрд░рд╛рдердорд┐рдХ рд░рд┐рдкреЛрдЬрд┐рдЯрд░реА**: https://github.com/microsoft/foundry-local
- **рджрд╕реНрддрд╛рд╡реЗрдЬ**: https://github.com/microsoft/foundry-local/blob/main/docs/README.md


#### VLLM
- **рдореБрдЦреНрдп рд░рд┐рдкреЛрдЬрд┐рдЯрд░реА**: https://github.com/vllm-project/vllm
- **рджрд╕реНрддрд╛рд╡реЗрдЬ**: https://docs.vllm.ai/


#### Ollama
- **рдЖрдзрд┐рдХрд╛рд░рд┐рдХ рд╡реЗрдмрд╕рд╛рдЗрдЯ**: https://ollama.ai/
- **GitHub рд░рд┐рдкреЛрдЬрд┐рдЯрд░реА**: https://github.com/ollama/ollama

### рдореЛрдбреЗрд▓ рдЕрдиреБрдХреВрд▓рди рдлреНрд░реЗрдорд╡рд░реНрдХрд╣рд░реВ

#### Llama.cpp
- **рд░рд┐рдкреЛрдЬрд┐рдЯрд░реА**: https://github.com/ggml-org/llama.cpp


#### рдорд╛рдЗрдХреНрд░реЛрд╕рдлреНрдЯ Olive
- **рджрд╕реНрддрд╛рд╡реЗрдЬ**: https://microsoft.github.io/Olive/
- **GitHub рд░рд┐рдкреЛрдЬрд┐рдЯрд░реА**: https://github.com/microsoft/Olive

#### OpenVINO
- **рдЖрдзрд┐рдХрд╛рд░рд┐рдХ рд╕рд╛рдЗрдЯ**: https://docs.openvino.ai/

#### Apple MLX
- **рд░рд┐рдкреЛрдЬрд┐рдЯрд░реА**: https://github.com/ml-explore/mlx

### рдЙрджреНрдпреЛрдЧ рд░рд┐рдкреЛрд░реНрдЯрд╣рд░реВ рд░ рдмрдЬрд╛рд░ рд╡рд┐рд╢реНрд▓реЗрд╖рдг

#### AI рдПрдЬреЗрдиреНрдЯ рдмрдЬрд╛рд░ рдЕрдиреБрд╕рдиреНрдзрд╛рди
- **"AI рдПрдЬреЗрдиреНрдЯрд╣рд░реВрдХреЛ рдЕрд╡рд╕реНрдерд╛ 2025"** - McKinsey Global Institute
  - рд▓рд┐рдВрдХ: https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/ai-agents-2025
  - рдореБрдЦреНрдп рдЬрд╛рдирдХрд╛рд░реА: рдмрдЬрд╛рд░ рдкреНрд░рд╡реГрддреНрддрд┐рд╣рд░реВ рд░ рдЙрджреНрдпрдо рдЕрдкрдирд╛рдЙрдиреЗ рдврд╛рдБрдЪрд╛рд╣рд░реВ

#### рдкреНрд░рд╛рд╡рд┐рдзрд┐рдХ рдмреЗрдВрдЪрдорд╛рд░реНрдХрд╣рд░реВ

- **"рдПрдЬ AI рдЗрдирдлрд░реЗрдиреНрд╕ рдмреЗрдВрдЪрдорд╛рд░реНрдХрд╣рд░реВ"** - MLPerf
  - рд▓рд┐рдВрдХ: https://mlcommons.org/en/inference-edge/
  - рдореБрдЦреНрдп рдЬрд╛рдирдХрд╛рд░реА: рдПрдЬ рдкрд░рд┐рдирд┐рдпреЛрдЬрдирдХреЛ рд▓рд╛рдЧрд┐ рдорд╛рдирдХреАрдХреГрдд рдкреНрд░рджрд░реНрд╢рди рдореЗрдЯреНрд░рд┐рдХреНрд╕

### рдорд╛рдирдХрд╣рд░реВ рд░ рд╡рд┐рд╢рд┐рд╖реНрдЯрддрд╛рд╣рд░реВ

#### рдореЛрдбреЗрд▓ рдлрд░реНрдореНрдпрд╛рдЯрд╣рд░реВ рд░ рдорд╛рдирдХрд╣рд░реВ
- **ONNX (Open Neural Network Exchange)**: https://onnx.ai/
  - рдЕрдиреНрддрд░рд╕рдЮреНрдЪрд╛рд▓рдирдХрд╛ рд▓рд╛рдЧрд┐ рдХреНрд░рд╕-рдкреНрд▓реНрдпрд╛рдЯрдлрд░реНрдо рдореЛрдбреЗрд▓ рдлрд░реНрдореНрдпрд╛рдЯ
- **GGUF рд╡рд┐рд╢рд┐рд╖реНрдЯрддрд╛**: https://github.com/ggerganov/ggml/blob/master/docs/gguf.md
  - CPU рдЗрдирдлрд░реЗрдиреНрд╕рдХрд╛ рд▓рд╛рдЧрд┐ рдХреНрд╡рд╛рдиреНрдЯрд╛рдЗрдЬреНрдб рдореЛрдбреЗрд▓ рдлрд░реНрдореНрдпрд╛рдЯ
- **OpenAI API рд╡рд┐рд╢рд┐рд╖реНрдЯрддрд╛**: https://platform.openai.com/docs/api-reference
  - рднрд╛рд╖рд╛ рдореЛрдбреЗрд▓ рдПрдХреАрдХрд░рдгрдХрд╛ рд▓рд╛рдЧрд┐ рдорд╛рдирдХ API рдлрд░реНрдореНрдпрд╛рдЯ

#### рд╕реБрд░рдХреНрд╖рд╛ рд░ рдЕрдиреБрдкрд╛рд▓рди
- **NIST AI рдЬреЛрдЦрд┐рдо рд╡реНрдпрд╡рд╕реНрдерд╛рдкрди рдлреНрд░реЗрдорд╡рд░реНрдХ**: https://www.nist.gov/itl/ai-risk-management-framework
- **ISO/IEC 23053:2022 - AI рдкреНрд░рдгрд╛рд▓реАрд╣рд░реВ**: AI рдкреНрд░рдгрд╛рд▓реАрд╣рд░реВ рд░ рд╕реБрд░рдХреНрд╖рд╛ рдлреНрд░реЗрдорд╡рд░реНрдХ
- **IEEE AI рдХрд╛ рд▓рд╛рдЧрд┐ рдорд╛рдирдХрд╣рд░реВ**: https://standards.ieee.org/industry-connections/ai/

SLM-рд╕рдВрдЪрд╛рд▓рд┐рдд рдПрдЬреЗрдиреНрдЯрд╣рд░реВрдХреЛ рддрд░реНрдлрдХреЛ рдкрд░рд┐рд╡рд░реНрддрдирд▓реЗ AI рдкрд░рд┐рдирд┐рдпреЛрдЬрдирд▓рд╛рдИ рд╣реЗрд░реНрдиреЗ рддрд░рд┐рдХрд╛рдорд╛ рдореМрд▓рд┐рдХ рдкрд░рд┐рд╡рд░реНрддрдирдХреЛ рдкреНрд░рддрд┐рдирд┐рдзрд┐рддреНрд╡ рдЧрд░реНрджрдЫред рдорд╛рдЗрдХреНрд░реЛрд╕рдлреНрдЯ рдПрдЬреЗрдиреНрдЯ рдлреНрд░реЗрдорд╡рд░реНрдХ, рд╕реНрдерд╛рдиреАрдп рдкреНрд▓реЗрдЯрдлрд░реНрдорд╣рд░реВ рд░ рдХреБрд╢рд▓ рд╕рд╛рдирд╛ рднрд╛рд╖рд╛ рдореЛрдбреЗрд▓рд╣рд░реВрд╕рдБрдЧ рдорд┐рд▓реЗрд░, рдПрдЬ рд╡рд╛рддрд╛рд╡рд░рдгрд╣рд░реВрдорд╛ рдкреНрд░рднрд╛рд╡рдХрд╛рд░реА рд░реВрдкрдорд╛ рд╕рдЮреНрдЪрд╛рд▓рди рдЧрд░реНрдиреЗ рдЙрддреНрдкрд╛рджрди-рддрдпрд╛рд░ рдПрдЬреЗрдиреНрдЯрд╣рд░реВ рдирд┐рд░реНрдорд╛рдг рдЧрд░реНрдирдХреЛ рд▓рд╛рдЧрд┐ рдкреВрд░реНрдг рд╕рдорд╛рдзрд╛рди рдкреНрд░рджрд╛рди рдЧрд░реНрджрдЫред рджрдХреНрд╖рддрд╛, рд╡рд┐рд╢реЗрд╖рдЬреНрдЮрддрд╛, рд░ рд╡реНрдпрд╛рд╡рд╣рд╛рд░рд┐рдХ рдЙрдкрдпреЛрдЧрдорд╛ рдзреНрдпрд╛рди рдХреЗрдиреНрджреНрд░рд┐рдд рдЧрд░реЗрд░, рдпреЛ рдкреНрд░рд╡рд┐рдзрд┐ рд╕реНрдЯреНрдпрд╛рдХрд▓реЗ AI рдПрдЬреЗрдиреНрдЯрд╣рд░реВрд▓рд╛рдИ рд╡рд╛рд╕реНрддрд╡рд┐рдХ рд╕рдВрд╕рд╛рд░рдХрд╛ рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╣рд░реВрдорд╛ рдЕрдзрд┐рдХ рдкрд╣реБрдБрдЪрдпреЛрдЧреНрдп, рдХрд┐рдлрд╛рдпрддреА, рд░ рдкреНрд░рднрд╛рд╡рдХрд╛рд░реА рдмрдирд╛рдЙрдБрдЫред

рдЬрд╕рд░реА рд╣рд╛рдореА 2025 рд╕рдореНрдо рдЕрдЧрд╛рдбрд┐ рдмрдвреНрдЫреМрдВ, рдмрдвреНрджреЛ рд╕рдХреНрд╖рдо рд╕рд╛рдирд╛ рдореЛрдбреЗрд▓рд╣рд░реВрдХреЛ рд╕рдВрдпреЛрдЬрди, рдорд╛рдЗрдХреНрд░реЛрд╕рдлреНрдЯ рдПрдЬреЗрдиреНрдЯ рдлреНрд░реЗрдорд╡рд░реНрдХ рдЬрд╕реНрддрд╛ рдкрд░рд┐рд╖реНрдХреГрдд рдПрдЬреЗрдиреНрдЯ рдлреНрд░реЗрдорд╡рд░реНрдХрд╣рд░реВ, рд░ рдмрд▓рд┐рдпреЛ рдПрдЬ рдкрд░рд┐рдирд┐рдпреЛрдЬрди рдкреНрд▓реЗрдЯрдлрд░реНрдорд╣рд░реВрд▓реЗ рд╕реНрд╡рд╛рдпрддреНрдд рдкреНрд░рдгрд╛рд▓реАрд╣рд░реВрдХреЛ рд▓рд╛рдЧрд┐ рдирдпрд╛рдБ рд╕рдореНрднрд╛рд╡рдирд╛рд╣рд░реВ рдЕрдирд▓рдХ рдЧрд░реНрдиреЗрдЫ рдЬрд╕рд▓реЗ рдЧреЛрдкрдиреАрдпрддрд╛ рдХрд╛рдпрдо рд░рд╛рдЦреНрджреИ, рд▓рд╛рдЧрдд рдШрдЯрд╛рдЙрдБрджреИ, рд░ рдЙрддреНрдХреГрд╖реНрдЯ рдкреНрд░рдпреЛрдЧрдХрд░реНрддрд╛ рдЕрдиреБрднрд╡рд╣рд░реВ рдкреНрд░рджрд╛рди рдЧрд░реНрджреИ рдПрдЬ рдЙрдкрдХрд░рдгрд╣рд░реВрдорд╛ рдХреБрд╢рд▓рддрд╛рдкреВрд░реНрд╡рдХ рд╕рдЮреНрдЪрд╛рд▓рди рдЧрд░реНрди рд╕рдХреНрдЫред

**рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрдирдХрд╛ рд▓рд╛рдЧрд┐ рдЖрдЧрд╛рдореА рдХрджрдорд╣рд░реВ**:
1. **рдлрдЩреНрд╕рди рдХрд▓рд┐рдЩ рдЕрдиреНрд╡реЗрд╖рдг рдЧрд░реНрдиреБрд╣реЛрд╕реН**: SLMs рдХрд╕рд░реА рдЙрдкрдХрд░рдг рдПрдХреАрдХрд░рдг рд░ рд╕рдВрд░рдЪрд┐рдд рдЖрдЙрдЯрдкреБрдЯрд╣рд░реВ рд╣реНрдпрд╛рдиреНрдбрд▓ рдЧрд░реНрдЫрдиреН рд╕рд┐рдХреНрдиреБрд╣реЛрд╕реН
2. **рдореЛрдбреЗрд▓ рдХрдиреНрдХреНрд╕

---

**рдЕрд╕реНрд╡реАрдХрд░рдг**:  
рдпреЛ рджрд╕реНрддрд╛рд╡реЗрдЬрд╝ AI рдЕрдиреБрд╡рд╛рдж рд╕реЗрд╡рд╛ [Co-op Translator](https://github.com/Azure/co-op-translator) рдкреНрд░рдпреЛрдЧ рдЧрд░реЗрд░ рдЕрдиреБрд╡рд╛рдж рдЧрд░рд┐рдПрдХреЛ рдЫред рд╣рд╛рдореА рд╢реБрджреНрдзрддрд╛рдХреЛ рд▓рд╛рдЧрд┐ рдкреНрд░рдпрд╛рд╕ рдЧрд░реНрдЫреМрдВ, рддрд░ рдХреГрдкрдпрд╛ рдзреНрдпрд╛рди рджрд┐рдиреБрд╣реЛрд╕реН рдХрд┐ рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рдЕрдиреБрд╡рд╛рджрд╣рд░реВрдорд╛ рддреНрд░реБрдЯрд┐рд╣рд░реВ рд╡рд╛ рдЕрд╢реБрджреНрдзрддрд╛рд╣рд░реВ рд╣реБрди рд╕рдХреНрдЫред рдпрд╕рдХреЛ рдореВрд▓ рднрд╛рд╖рд╛ рдорд╛ рд░рд╣реЗрдХреЛ рдореВрд▓ рджрд╕реНрддрд╛рд╡реЗрдЬрд╝рд▓рд╛рдИ рдЖрдзрд┐рдХрд╛рд░рд┐рдХ рд╕реНрд░реЛрдд рдорд╛рдирд┐рдиреБрдкрд░реНрдЫред рдорд╣рддреНрд╡рдкреВрд░реНрдг рдЬрд╛рдирдХрд╛рд░реАрдХреЛ рд▓рд╛рдЧрд┐, рд╡реНрдпрд╛рд╡рд╕рд╛рдпрд┐рдХ рдорд╛рдирд╡ рдЕрдиреБрд╡рд╛рдж рд╕рд┐рдлрд╛рд░рд┐рд╕ рдЧрд░рд┐рдиреНрдЫред рдпрд╕ рдЕрдиреБрд╡рд╛рджрдХреЛ рдкреНрд░рдпреЛрдЧрдмрд╛рдЯ рдЙрддреНрдкрдиреНрди рд╣реБрдиреЗ рдХреБрдиреИ рдкрдирд┐ рдЧрд▓рддрдлрд╣рдореА рд╡рд╛ рдЧрд▓рдд рд╡реНрдпрд╛рдЦреНрдпрд╛рдХреЛ рд▓рд╛рдЧрд┐ рд╣рд╛рдореА рдЬрд┐рдореНрдореЗрд╡рд╛рд░ рд╣реБрдиреЗрдЫреИрдиреМрдВред