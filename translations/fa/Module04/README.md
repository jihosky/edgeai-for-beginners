<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e8d157e0a282083a1e1c7bb5dda28646",
  "translation_date": "2025-10-30T10:59:49+00:00",
  "source_file": "Module04/README.md",
  "language_code": "fa"
}
-->
# فصل ۰۴: تبدیل فرمت مدل و کوانتیزاسیون - مرور فصل

ظهور EdgeAI تبدیل فرمت مدل و کوانتیزاسیون را به فناوری‌های ضروری برای پیاده‌سازی قابلیت‌های پیشرفته یادگیری ماشین بر روی دستگاه‌های با منابع محدود تبدیل کرده است. این فصل جامع راهنمای کاملی برای درک، پیاده‌سازی و بهینه‌سازی مدل‌ها برای سناریوهای استقرار در لبه ارائه می‌دهد.

## 📚 ساختار فصل و مسیر یادگیری

این فصل به هفت بخش پیشرفته تقسیم شده است که هر کدام بر اساس بخش قبلی بنا شده‌اند تا درک جامعی از بهینه‌سازی مدل برای محاسبات لبه ایجاد کنند:

---

## [بخش ۱: اصول تبدیل فرمت مدل و کوانتیزاسیون](./01.Introduce.md)

### 🎯 مرور کلی
این بخش پایه‌ای چارچوب نظری برای بهینه‌سازی مدل در محیط‌های محاسبات لبه را ایجاد می‌کند و مرزهای کوانتیزاسیون از دقت ۱ بیت تا ۸ بیت و استراتژی‌های کلیدی تبدیل فرمت را پوشش می‌دهد.

**موضوعات کلیدی:**
- چارچوب طبقه‌بندی دقت (دقت فوق‌العاده پایین، پایین، متوسط)
- مزایا و موارد استفاده از فرمت‌های GGUF و ONNX
- مزایای کوانتیزاسیون برای کارایی عملیاتی و انعطاف‌پذیری استقرار
- مقایسه معیارهای عملکرد و ردپای حافظه

**نتایج یادگیری:**
- درک مرزهای کوانتیزاسیون و طبقه‌بندی‌ها
- شناسایی تکنیک‌های مناسب تبدیل فرمت
- یادگیری استراتژی‌های پیشرفته بهینه‌سازی برای استقرار در لبه

---

## [بخش ۲: راهنمای پیاده‌سازی Llama.cpp](./02.Llamacpp.md)

### 🎯 مرور کلی
یک آموزش جامع برای پیاده‌سازی Llama.cpp، یک چارچوب قدرتمند C++ که امکان استنتاج مدل‌های زبان بزرگ را با حداقل تنظیمات در پیکربندی‌های سخت‌افزاری متنوع فراهم می‌کند.

**موضوعات کلیدی:**
- نصب در پلتفرم‌های ویندوز، macOS و لینوکس
- تبدیل فرمت GGUF و سطوح مختلف کوانتیزاسیون (Q2_K تا Q8_0)
- شتاب سخت‌افزاری با CUDA، Metal، OpenCL و Vulkan
- یکپارچه‌سازی با پایتون و استراتژی‌های استقرار تولید

**نتایج یادگیری:**
- تسلط بر نصب چندپلتفرمی و ساخت از منبع
- پیاده‌سازی تکنیک‌های کوانتیزاسیون و بهینه‌سازی مدل
- استقرار مدل‌ها در حالت سرور با یکپارچه‌سازی REST API

---

## [بخش ۳: مجموعه بهینه‌سازی Microsoft Olive](./03.MicrosoftOlive.md)

### 🎯 مرور کلی
بررسی Microsoft Olive، یک ابزار بهینه‌سازی مدل آگاه به سخت‌افزار با بیش از ۴۰ مؤلفه بهینه‌سازی داخلی، طراحی شده برای استقرار مدل‌های سطح سازمانی در پلتفرم‌های سخت‌افزاری متنوع.

**موضوعات کلیدی:**
- ویژگی‌های خودکار بهینه‌سازی با کوانتیزاسیون پویا و ایستا
- هوش آگاه به سخت‌افزار برای استقرار در CPU، GPU و NPU
- پشتیبانی از مدل‌های محبوب (Llama، Phi، Qwen، Gemma) به صورت آماده
- یکپارچه‌سازی سازمانی با Azure ML و جریان‌های کاری تولید

**نتایج یادگیری:**
- استفاده از بهینه‌سازی خودکار برای معماری‌های مختلف مدل
- پیاده‌سازی استراتژی‌های استقرار چندپلتفرمی
- ایجاد جریان‌های کاری بهینه‌سازی آماده برای سازمان

---

## [بخش ۴: مجموعه بهینه‌سازی OpenVINO Toolkit](./04.openvino.md)

### 🎯 مرور کلی
بررسی جامع ابزار OpenVINO اینتل، یک پلتفرم متن‌باز برای استقرار راه‌حل‌های هوش مصنوعی با عملکرد بالا در محیط‌های ابری، محلی و لبه با قابلیت‌های پیشرفته فشرده‌سازی شبکه عصبی (NNCF).

**موضوعات کلیدی:**
- استقرار چندپلتفرمی با شتاب سخت‌افزاری (CPU، GPU، VPU، شتاب‌دهنده‌های هوش مصنوعی)
- چارچوب فشرده‌سازی شبکه عصبی (NNCF) برای کوانتیزاسیون و هرس پیشرفته
- OpenVINO GenAI برای بهینه‌سازی و استقرار مدل‌های زبان بزرگ
- قابلیت‌های سرور مدل سطح سازمانی و استراتژی‌های استقرار مقیاس‌پذیر

**نتایج یادگیری:**
- تسلط بر جریان‌های کاری تبدیل و بهینه‌سازی مدل OpenVINO
- پیاده‌سازی تکنیک‌های پیشرفته کوانتیزاسیون با NNCF
- استقرار مدل‌های بهینه‌سازی شده در پلتفرم‌های سخت‌افزاری متنوع با سرور مدل

---

## [بخش ۵: بررسی عمیق چارچوب Apple MLX](./05.AppleMLX.md)

### 🎯 مرور کلی
پوشش جامع Apple MLX، یک چارچوب انقلابی که به طور خاص برای یادگیری ماشین کارآمد بر روی Apple Silicon طراحی شده است، با تأکید بر قابلیت‌های مدل‌های زبان بزرگ و استقرار محلی.

**موضوعات کلیدی:**
- مزایای معماری حافظه یکپارچه و Metal Performance Shaders
- پشتیبانی از مدل‌های LLaMA، Mistral، Phi-3، Qwen و Code Llama
- تنظیم دقیق LoRA برای سفارشی‌سازی کارآمد مدل
- یکپارچه‌سازی Hugging Face و پشتیبانی از کوانتیزاسیون (۴ بیت و ۸ بیت)

**نتایج یادگیری:**
- تسلط بر بهینه‌سازی Apple Silicon برای استقرار مدل‌های زبان بزرگ
- پیاده‌سازی تکنیک‌های تنظیم دقیق و سفارشی‌سازی مدل
- ساخت برنامه‌های هوش مصنوعی سازمانی با ویژگی‌های پیشرفته حفظ حریم خصوصی

---

## [بخش ۶: ترکیب جریان کاری توسعه Edge AI](./06.workflow-synthesis.md)

### 🎯 مرور کلی
ترکیب جامع تمام چارچوب‌های بهینه‌سازی در جریان‌های کاری یکپارچه، ماتریس‌های تصمیم‌گیری و بهترین روش‌ها برای استقرار آماده تولید Edge AI در پلتفرم‌ها و موارد استفاده متنوع از جمله موبایل، دسکتاپ و محیط‌های ابری.

**موضوعات کلیدی:**
- معماری جریان کاری یکپارچه که چندین چارچوب بهینه‌سازی را ادغام می‌کند
- درخت‌های تصمیم‌گیری انتخاب چارچوب و تحلیل مصالحه‌های عملکرد
- اعتبارسنجی آمادگی تولید و استراتژی‌های استقرار جامع
- استراتژی‌های آینده‌نگر برای سخت‌افزارهای نوظهور و معماری‌های مدل

**نتایج یادگیری:**
- تسلط بر انتخاب سیستماتیک چارچوب بر اساس نیازها و محدودیت‌ها
- پیاده‌سازی جریان‌های کاری Edge AI آماده تولید با نظارت جامع
- طراحی جریان‌های کاری قابل تطبیق که با فناوری‌ها و نیازهای نوظهور تکامل می‌یابند

---

## [بخش ۷: مجموعه بهینه‌سازی Qualcomm QNN](./07.QualcommQNN.md)

### 🎯 مرور کلی
بررسی جامع Qualcomm QNN (شبکه عصبی Qualcomm)، یک چارچوب استنتاج هوش مصنوعی یکپارچه که برای بهره‌گیری از معماری محاسبات ناهمگن Qualcomm شامل Hexagon NPU، Adreno GPU و Kryo CPU برای حداکثر عملکرد و کارایی انرژی در دستگاه‌های موبایل و لبه طراحی شده است.

**موضوعات کلیدی:**
- محاسبات ناهمگن با دسترسی یکپارچه به NPU، GPU و CPU
- بهینه‌سازی آگاه به سخت‌افزار برای پلتفرم‌های Snapdragon با توزیع هوشمند بار کاری
- تکنیک‌های پیشرفته کوانتیزاسیون (INT8، INT16، دقت مختلط) برای استقرار موبایل
- استنتاج کارآمد از نظر انرژی بهینه شده برای دستگاه‌های باتری‌دار و برنامه‌های کاربردی بلادرنگ

**نتایج یادگیری:**
- تسلط بر شتاب سخت‌افزاری Qualcomm برای استقرار هوش مصنوعی موبایل
- پیاده‌سازی استراتژی‌های بهینه‌سازی کارآمد از نظر انرژی برای محاسبات لبه
- استقرار مدل‌های آماده تولید در اکوسیستم Qualcomm با عملکرد بهینه

---

## 🎯 نتایج یادگیری فصل

با تکمیل این فصل جامع، خوانندگان به دست خواهند آورد:

### **تسلط فنی**
- درک عمیق مرزهای کوانتیزاسیون و کاربردهای عملی
- تجربه عملی با چندین چارچوب بهینه‌سازی
- مهارت‌های استقرار تولید برای محیط‌های محاسبات لبه

### **درک استراتژیک**
- توانایی انتخاب بهینه‌سازی آگاه به سخت‌افزار
- تصمیم‌گیری آگاهانه در مورد مصالحه‌های عملکرد
- استراتژی‌های استقرار و نظارت آماده سازمان

### **معیارهای عملکرد**

| چارچوب | کوانتیزاسیون | استفاده از حافظه | بهبود سرعت | مورد استفاده |
|--------|--------------|------------------|------------|--------------|
| Llama.cpp | Q4_K_M | ~۴ گیگابایت | ۲-۳ برابر | استقرار چندپلتفرمی |
| Olive | INT4 | کاهش ۶۰-۷۵٪ | ۲-۶ برابر | جریان‌های کاری سازمانی |
| OpenVINO | INT8/INT4 | کاهش ۵۰-۷۵٪ | ۲-۵ برابر | بهینه‌سازی سخت‌افزار اینتل |
| QNN | INT8/INT4 | کاهش ۵۰-۸۰٪ | ۵-۱۵ برابر | موبایل/لبه Qualcomm |
| MLX | ۴ بیت | ~۴ گیگابایت | ۲-۴ برابر | بهینه‌سازی Apple Silicon |

## 🚀 گام‌های بعدی و کاربردهای پیشرفته

این فصل پایه کاملی برای:
- توسعه مدل‌های سفارشی برای حوزه‌های خاص
- تحقیق در بهینه‌سازی Edge AI
- توسعه برنامه‌های کاربردی هوش مصنوعی تجاری
- استقرار Edge AI سازمانی در مقیاس بزرگ

دانش حاصل از این هفت بخش یک جعبه‌ابزار جامع برای پیمایش در چشم‌انداز به سرعت در حال تحول بهینه‌سازی و استقرار مدل‌های Edge AI ارائه می‌دهد.

---

**سلب مسئولیت**:  
این سند با استفاده از سرویس ترجمه هوش مصنوعی [Co-op Translator](https://github.com/Azure/co-op-translator) ترجمه شده است. در حالی که ما تلاش می‌کنیم دقت را حفظ کنیم، لطفاً توجه داشته باشید که ترجمه‌های خودکار ممکن است شامل خطاها یا نادرستی‌ها باشند. سند اصلی به زبان اصلی آن باید به عنوان منبع معتبر در نظر گرفته شود. برای اطلاعات حیاتی، ترجمه حرفه‌ای انسانی توصیه می‌شود. ما مسئولیتی در قبال سوء تفاهم‌ها یا تفسیرهای نادرست ناشی از استفاده از این ترجمه نداریم.