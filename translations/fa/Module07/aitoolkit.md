<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "efb0e70d6e87d0795f4d381c3bc99074",
  "translation_date": "2025-10-21T06:50:53+00:00",
  "source_file": "Module07/aitoolkit.md",
  "language_code": "fa"
}
-->
# ابزار هوش مصنوعی برای Visual Studio Code - راهنمای توسعه هوش مصنوعی در Edge

## مقدمه

به راهنمای جامع استفاده از ابزار هوش مصنوعی برای Visual Studio Code در توسعه هوش مصنوعی در Edge خوش آمدید. با حرکت هوش مصنوعی از محاسبات متمرکز ابری به دستگاه‌های توزیع‌شده در Edge، توسعه‌دهندگان به ابزارهای قدرتمند و یکپارچه‌ای نیاز دارند که بتوانند چالش‌های خاص استقرار در Edge را مدیریت کنند - از محدودیت‌های منابع گرفته تا نیازهای عملکرد آفلاین.

ابزار هوش مصنوعی برای Visual Studio Code این فاصله را پر می‌کند و یک محیط توسعه کامل را برای ساخت، آزمایش و بهینه‌سازی برنامه‌های هوش مصنوعی که به طور کارآمد بر روی دستگاه‌های Edge اجرا می‌شوند، فراهم می‌کند. چه در حال توسعه برای حسگرهای IoT، دستگاه‌های موبایل، سیستم‌های تعبیه‌شده یا سرورهای Edge باشید، این ابزار کل جریان کاری توسعه شما را در محیط آشنای VS Code ساده می‌کند.

این راهنما شما را با مفاهیم اساسی، ابزارها و بهترین روش‌ها برای استفاده از ابزار هوش مصنوعی در پروژه‌های هوش مصنوعی Edge، از انتخاب اولیه مدل تا استقرار در تولید، آشنا می‌کند.

## نمای کلی

ابزار هوش مصنوعی برای Visual Studio Code یک افزونه قدرتمند است که توسعه عامل‌ها و ایجاد برنامه‌های هوش مصنوعی را ساده می‌کند. این ابزار قابلیت‌های جامعی برای کاوش، ارزیابی و استقرار مدل‌های هوش مصنوعی از طیف گسترده‌ای از ارائه‌دهندگان - از جمله Anthropic، OpenAI، GitHub، Google - ارائه می‌دهد و در عین حال از اجرای مدل‌های محلی با استفاده از ONNX و Ollama پشتیبانی می‌کند.

آنچه ابزار هوش مصنوعی را متمایز می‌کند، رویکرد جامع آن به کل چرخه توسعه هوش مصنوعی است. برخلاف ابزارهای سنتی توسعه هوش مصنوعی که بر جنبه‌های خاص تمرکز دارند، ابزار هوش مصنوعی یک محیط یکپارچه ارائه می‌دهد که کشف مدل، آزمایش، توسعه عامل، ارزیابی و استقرار را پوشش می‌دهد - همه در محیط آشنای VS Code.

این پلتفرم به طور خاص برای نمونه‌سازی سریع و استقرار تولید طراحی شده است، با ویژگی‌هایی مانند تولید درخواست، شروع سریع، ادغام‌های بی‌وقفه ابزار MCP (پروتکل زمینه مدل) و قابلیت‌های ارزیابی گسترده. برای توسعه هوش مصنوعی در Edge، این بدان معناست که می‌توانید برنامه‌های هوش مصنوعی را برای سناریوهای استقرار در Edge به طور کارآمد توسعه دهید، آزمایش کنید و بهینه‌سازی کنید، در حالی که کل جریان کاری توسعه را در VS Code حفظ می‌کنید.

## اهداف یادگیری

در پایان این راهنما، شما قادر خواهید بود:

### مهارت‌های اصلی
- **نصب و پیکربندی** ابزار هوش مصنوعی برای Visual Studio Code برای جریان‌های کاری توسعه هوش مصنوعی در Edge
- **پیمایش و استفاده** از رابط ابزار هوش مصنوعی، از جمله کاتالوگ مدل، Playground و سازنده عامل
- **انتخاب و ارزیابی** مدل‌های هوش مصنوعی مناسب برای استقرار در Edge بر اساس عملکرد و محدودیت‌های منابع
- **تبدیل و بهینه‌سازی** مدل‌ها با استفاده از فرمت ONNX و تکنیک‌های کمینه‌سازی برای دستگاه‌های Edge

### مهارت‌های توسعه هوش مصنوعی در Edge
- **طراحی و پیاده‌سازی** برنامه‌های هوش مصنوعی در Edge با استفاده از محیط توسعه یکپارچه
- **آزمایش مدل** در شرایط مشابه Edge با استفاده از استنتاج محلی و نظارت بر منابع
- **ایجاد و سفارشی‌سازی** عامل‌های هوش مصنوعی بهینه‌شده برای سناریوهای استقرار در Edge
- **ارزیابی عملکرد مدل** با استفاده از معیارهای مرتبط با محاسبات در Edge (تاخیر، استفاده از حافظه، دقت)

### بهینه‌سازی و استقرار
- **اعمال تکنیک‌های کمینه‌سازی و هرس** برای کاهش اندازه مدل در حالی که عملکرد قابل قبول حفظ می‌شود
- **بهینه‌سازی مدل‌ها** برای پلتفرم‌های سخت‌افزاری خاص در Edge از جمله شتاب‌دهنده‌های CPU، GPU و NPU
- **اجرای بهترین روش‌ها** برای توسعه هوش مصنوعی در Edge از جمله مدیریت منابع و استراتژی‌های جایگزین
- **آماده‌سازی مدل‌ها و برنامه‌ها** برای استقرار تولید در دستگاه‌های Edge

### مفاهیم پیشرفته هوش مصنوعی در Edge
- **ادغام با چارچوب‌های هوش مصنوعی در Edge** از جمله ONNX Runtime، Windows ML و TensorFlow Lite
- **اجرای معماری‌های چندمدلی** و سناریوهای یادگیری فدرال برای محیط‌های Edge
- **رفع مشکلات رایج هوش مصنوعی در Edge** از جمله محدودیت‌های حافظه، سرعت استنتاج و سازگاری سخت‌افزار
- **طراحی استراتژی‌های نظارت و ثبت** برای برنامه‌های هوش مصنوعی در Edge در تولید

### کاربرد عملی
- **ساخت راه‌حل‌های جامع هوش مصنوعی در Edge** از انتخاب مدل تا استقرار
- **نمایش مهارت** در جریان‌های کاری توسعه خاص Edge و تکنیک‌های بهینه‌سازی
- **اعمال مفاهیم آموخته‌شده** به موارد استفاده واقعی هوش مصنوعی در Edge از جمله IoT، موبایل و برنامه‌های تعبیه‌شده
- **ارزیابی و مقایسه** استراتژی‌های مختلف استقرار هوش مصنوعی در Edge و مزایا و معایب آن‌ها

## ویژگی‌های کلیدی برای توسعه هوش مصنوعی در Edge

### 1. کاتالوگ مدل و کشف
- **پشتیبانی چند ارائه‌دهنده**: مرور و دسترسی به مدل‌های هوش مصنوعی از Anthropic، OpenAI، GitHub، Google و سایر ارائه‌دهندگان
- **ادغام مدل محلی**: کشف ساده مدل‌های ONNX و Ollama برای استقرار در Edge
- **مدل‌های GitHub**: ادغام مستقیم با میزبانی مدل‌های GitHub برای دسترسی ساده‌تر
- **مقایسه مدل‌ها**: مقایسه مدل‌ها به صورت کنار هم برای یافتن تعادل بهینه برای محدودیت‌های دستگاه‌های Edge

### 2. Playground تعاملی
- **محیط آزمایش تعاملی**: آزمایش سریع قابلیت‌های مدل در یک محیط کنترل‌شده
- **پشتیبانی چندحالتی**: آزمایش با تصاویر، متن و ورودی‌های دیگر معمول در سناریوهای Edge
- **آزمایش بلادرنگ**: بازخورد فوری در مورد پاسخ‌ها و عملکرد مدل
- **بهینه‌سازی پارامترها**: تنظیم دقیق پارامترهای مدل برای نیازهای استقرار در Edge

### 3. سازنده درخواست (عامل)
- **تولید زبان طبیعی**: تولید درخواست‌های شروع‌کننده با استفاده از توضیحات زبان طبیعی
- **بهبود تدریجی**: بهبود درخواست‌ها بر اساس پاسخ‌ها و عملکرد مدل
- **تجزیه وظایف**: تقسیم وظایف پیچیده با زنجیره‌سازی درخواست‌ها و خروجی‌های ساختاریافته
- **پشتیبانی از متغیرها**: استفاده از متغیرها در درخواست‌ها برای رفتار پویا عامل
- **تولید کد تولیدی**: تولید کد آماده تولید برای توسعه سریع برنامه

### 4. اجرای دسته‌ای و ارزیابی
- **آزمایش چندمدلی**: اجرای چندین درخواست به طور همزمان در مدل‌های انتخاب‌شده
- **آزمایش کارآمد در مقیاس**: آزمایش ورودی‌ها و تنظیمات مختلف به صورت کارآمد
- **موارد آزمایش سفارشی**: اجرای عامل‌ها با موارد آزمایش برای اعتبارسنجی عملکرد
- **مقایسه عملکرد**: مقایسه نتایج در مدل‌ها و تنظیمات مختلف

### 5. ارزیابی مدل با مجموعه داده‌ها
- **معیارهای استاندارد**: آزمایش مدل‌های هوش مصنوعی با استفاده از ارزیابی‌کننده‌های داخلی (امتیاز F1، ارتباط، شباهت، انسجام)
- **ارزیابی‌کننده‌های سفارشی**: ایجاد معیارهای ارزیابی خود برای موارد استفاده خاص
- **ادغام مجموعه داده‌ها**: آزمایش مدل‌ها در برابر مجموعه داده‌های جامع
- **اندازه‌گیری عملکرد**: کمی‌سازی عملکرد مدل برای تصمیمات استقرار در Edge

### 6. قابلیت‌های تنظیم دقیق
- **سفارشی‌سازی مدل**: سفارشی‌سازی مدل‌ها برای موارد استفاده و حوزه‌های خاص
- **انطباق تخصصی**: انطباق مدل‌ها با حوزه‌ها و نیازهای تخصصی
- **بهینه‌سازی Edge**: تنظیم دقیق مدل‌ها به طور خاص برای محدودیت‌های استقرار در Edge
- **آموزش خاص حوزه**: ایجاد مدل‌هایی که برای موارد استفاده خاص در Edge طراحی شده‌اند

### 7. ادغام ابزار MCP
- **اتصال ابزار خارجی**: اتصال عامل‌ها به ابزارهای خارجی از طریق سرورهای پروتکل زمینه مدل
- **اقدامات واقعی**: فعال‌سازی عامل‌ها برای پرسش از پایگاه‌های داده، دسترسی به API‌ها یا اجرای منطق سفارشی
- **سرورهای MCP موجود**: استفاده از ابزارها از طریق پروتکل‌های فرمان (stdio) یا HTTP (رویدادهای ارسال‌شده توسط سرور)
- **توسعه MCP سفارشی**: ساخت و ایجاد سرورهای MCP جدید با آزمایش در سازنده عامل

### 8. توسعه و آزمایش عامل
- **پشتیبانی از فراخوانی توابع**: فعال‌سازی عامل‌ها برای فراخوانی توابع خارجی به صورت پویا
- **آزمایش یکپارچه‌سازی بلادرنگ**: آزمایش یکپارچه‌سازی‌ها با اجراهای بلادرنگ و استفاده از ابزارها
- **نسخه‌بندی عامل‌ها**: کنترل نسخه برای عامل‌ها با قابلیت‌های مقایسه نتایج ارزیابی
- **اشکال‌زدایی و ردیابی**: قابلیت‌های ردیابی و اشکال‌زدایی محلی برای توسعه عامل

## جریان کاری توسعه هوش مصنوعی در Edge

### مرحله 1: کشف و انتخاب مدل
1. **کاتالوگ مدل را مرور کنید**: از کاتالوگ مدل برای یافتن مدل‌های مناسب برای استقرار در Edge استفاده کنید
2. **مقایسه عملکرد**: مدل‌ها را بر اساس اندازه، دقت و سرعت استنتاج ارزیابی کنید
3. **آزمایش محلی**: از مدل‌های Ollama یا ONNX برای آزمایش محلی قبل از استقرار در Edge استفاده کنید
4. **ارزیابی نیازهای منابع**: نیازهای حافظه و محاسباتی برای دستگاه‌های هدف در Edge را تعیین کنید

### مرحله 2: بهینه‌سازی مدل
1. **تبدیل به ONNX**: مدل‌های انتخاب‌شده را به فرمت ONNX برای سازگاری با Edge تبدیل کنید
2. **اعمال کمینه‌سازی**: اندازه مدل را از طریق کمینه‌سازی INT8 یا INT4 کاهش دهید
3. **بهینه‌سازی سخت‌افزار**: برای سخت‌افزار هدف در Edge (ARM، x86، شتاب‌دهنده‌های تخصصی) بهینه‌سازی کنید
4. **اعتبارسنجی عملکرد**: اطمینان حاصل کنید که مدل‌های بهینه‌شده دقت قابل قبول را حفظ می‌کنند

### مرحله 3: توسعه برنامه
1. **طراحی عامل**: از سازنده عامل برای ایجاد عامل‌های هوش مصنوعی بهینه‌شده برای Edge استفاده کنید
2. **مهندسی درخواست**: درخواست‌هایی را توسعه دهید که به طور مؤثر با مدل‌های کوچک‌تر در Edge کار کنند
3. **آزمایش یکپارچه‌سازی**: عامل‌ها را در شرایط شبیه‌سازی‌شده Edge آزمایش کنید
4. **تولید کد**: کد تولیدی بهینه‌شده برای استقرار در Edge تولید کنید

### مرحله 4: ارزیابی و آزمایش
1. **ارزیابی دسته‌ای**: تنظیمات مختلف را آزمایش کنید تا تنظیمات بهینه برای Edge را پیدا کنید
2. **پروفایل عملکرد**: سرعت استنتاج، استفاده از حافظه و دقت را تحلیل کنید
3. **شبیه‌سازی Edge**: در شرایط مشابه محیط استقرار هدف در Edge آزمایش کنید
4. **آزمایش فشار**: عملکرد را تحت شرایط بار مختلف ارزیابی کنید

### مرحله 5: آماده‌سازی برای استقرار
1. **بهینه‌سازی نهایی**: بهینه‌سازی‌های نهایی را بر اساس نتایج آزمایش اعمال کنید
2. **بسته‌بندی استقرار**: مدل‌ها و کد را برای استقرار در Edge بسته‌بندی کنید
3. **مستندسازی**: نیازها و تنظیمات استقرار را مستند کنید
4. **راه‌اندازی نظارت**: نظارت و ثبت برای استقرار در Edge را آماده کنید

## مخاطبان هدف برای توسعه هوش مصنوعی در Edge

### توسعه‌دهندگان هوش مصنوعی در Edge
- توسعه‌دهندگان برنامه که دستگاه‌های Edge و راه‌حل‌های IoT مبتنی بر هوش مصنوعی ایجاد می‌کنند
- توسعه‌دهندگان سیستم‌های تعبیه‌شده که قابلیت‌های هوش مصنوعی را در دستگاه‌های با منابع محدود ادغام می‌کنند
- توسعه‌دهندگان موبایل که برنامه‌های هوش مصنوعی در دستگاه را برای گوشی‌های هوشمند و تبلت‌ها ایجاد می‌کنند

### مهندسان هوش مصنوعی در Edge
- مهندسان هوش مصنوعی که مدل‌ها را برای استقرار در Edge بهینه‌سازی می‌کنند و خطوط استنتاج را مدیریت می‌کنند
- مهندسان DevOps که مدل‌های هوش مصنوعی را در زیرساخت توزیع‌شده Edge مستقر و مدیریت می‌کنند
- مهندسان عملکرد که بارهای کاری هوش مصنوعی را برای محدودیت‌های سخت‌افزاری در Edge بهینه‌سازی می‌کنند

### پژوهشگران و مربیان
- پژوهشگران هوش مصنوعی که مدل‌ها و الگوریتم‌های کارآمد برای محاسبات در Edge توسعه می‌دهند
- مربیان که مفاهیم هوش مصنوعی در Edge را آموزش می‌دهند و تکنیک‌های بهینه‌سازی را نشان می‌دهند
- دانشجویان که درباره چالش‌ها و راه‌حل‌های استقرار هوش مصنوعی در Edge یاد می‌گیرند

## موارد استفاده هوش مصنوعی در Edge

### دستگاه‌های هوشمند IoT
- **تشخیص تصویر بلادرنگ**: استقرار مدل‌های بینایی کامپیوتری بر روی دوربین‌ها و حسگرهای IoT
- **پردازش صوتی**: اجرای تشخیص گفتار و پردازش زبان طبیعی بر روی بلندگوهای هوشمند
- **نگهداری پیش‌بینی‌کننده**: اجرای مدل‌های تشخیص ناهنجاری بر روی دستگاه‌های صنعتی Edge
- **نظارت بر محیط زیست**: استقرار مدل‌های تحلیل داده‌های حسگر برای برنامه‌های محیطی

### برنامه‌های موبایل و تعبیه‌شده
- **ترجمه در دستگاه**: اجرای مدل‌های ترجمه زبان که به صورت آفلاین کار می‌کنند
- **واقعیت افزوده**: استقرار تشخیص و ردیابی اشیاء بلادرنگ برای برنامه‌های AR
- **نظارت بر سلامت**: اجرای مدل‌های تحلیل سلامت بر روی دستگاه‌های پوشیدنی و تجهیزات پزشکی
- **سیستم‌های خودمختار**: اجرای مدل‌های تصمیم‌گیری برای پهپادها، ربات‌ها و وسایل نقلیه

### زیرساخت محاسباتی در Edge
- **مراکز داده Edge**: استقرار مدل‌های هوش مصنوعی در مراکز داده Edge برای برنامه‌های کم‌تاخیر
- **ادغام CDN**: ادغام قابلیت‌های پردازش هوش مصنوعی در شبکه‌های تحویل محتوا
- **Edge 5G**: استفاده از محاسبات Edge 5G برای برنامه‌های مبتنی بر هوش مصنوعی
- **محاسبات مه**: اجرای پردازش هوش مصنوعی در محیط‌های محاسبات مه

## نصب و راه‌اندازی

### نصب افزونه
افزونه ابزار هوش مصنوعی را مستقیماً از بازار Visual Studio Code نصب کنید:

**شناسه افزونه**: `ms-windows-ai-studio.windows-ai-studio`

**روش‌های نصب**:
1. **بازار VS Code**: در نمای Extensions به دنبال "AI Toolkit" بگردید
2. **خط فرمان**: `code --install-extension ms-windows-ai-studio.windows-ai-studio`
3. **نصب مستقیم**: دانلود از [بازار VS Code](https://marketplace.visualstudio.com/items?itemName=ms-windows-ai-studio.windows-ai-studio)

### پیش‌نیازها برای توسعه هوش مصنوعی در Edge
- **Visual Studio Code**: نسخه آخر توصیه می‌شود
- **محیط پایتون**: پایتون 3.8+ با کتابخانه‌های هوش مصنوعی مورد نیاز
- **ONNX Runtime** (اختیاری): برای استنتاج مدل‌های ONNX
- **Ollama** (اختیاری): برای سرویس‌دهی مدل‌های محلی
- **ابزارهای شتاب‌دهنده سخت‌افزاری**: CUDA، OpenVINO یا شتاب‌دهنده‌های خاص پلتفرم

### پیکربندی اولیه
1. **فعال‌سازی افزونه**: VS Code را باز کنید و مطمئن شوید ابزار هوش مصنوعی در نوار فعالیت ظاهر می‌شود
2. **تنظیم ارائه‌دهنده مدل**: دسترسی به GitHub، OpenAI، Anthropic یا سایر ارائه‌دهندگان مدل را پیکربندی کنید
3. **محیط محلی**: محیط پایتون را تنظیم کنید و بسته‌های مورد نیاز را نصب کنید
4. **شتاب‌دهنده سخت‌افزاری**: شتاب‌دهنده GPU/NPU را در صورت موجود بودن پیکربندی کنید
5. **ادغام MCP**: در صورت نیاز سرورهای پروتکل زمینه مدل را تنظیم کنید

### چک‌لیست تنظیم اولیه
- [ ] افزونه ابزار هوش مصنوعی نصب و فعال شده است
- [ ] کاتالوگ مدل قابل دسترسی و مدل‌ها قابل کشف هستند
- [ ] Playground برای آزمایش مدل‌ها فعال است
- [ ] سازنده عامل برای توسعه درخواست‌ها قابل دسترسی است
- [ ] محیط توسعه محلی پیکربندی شده است
-
2. تولید درخواست‌های اولیه با استفاده از توضیحات زبان طبیعی  
3. تکرار و بهبود درخواست‌ها بر اساس پاسخ‌های مدل  
4. ادغام ابزارهای MCP برای افزایش قابلیت‌های عامل  

#### مرحله 3: آزمایش و ارزیابی  
1. از **Bulk Run** برای آزمایش چندین درخواست در مدل‌های انتخاب‌شده استفاده کنید  
2. عوامل را با موارد آزمایشی اجرا کنید تا عملکرد آن‌ها را تأیید کنید  
3. دقت و عملکرد را با استفاده از معیارهای داخلی یا سفارشی ارزیابی کنید  
4. مدل‌ها و تنظیمات مختلف را مقایسه کنید  

#### مرحله 4: تنظیم دقیق و بهینه‌سازی  
1. مدل‌ها را برای موارد استفاده خاص سفارشی کنید  
2. تنظیمات دقیق مرتبط با حوزه را اعمال کنید  
3. برای محدودیت‌های استقرار در لبه بهینه‌سازی کنید  
4. نسخه‌بندی و مقایسه تنظیمات مختلف عامل  

#### مرحله 5: آماده‌سازی برای استقرار  
1. کد آماده تولید را با استفاده از Agent Builder تولید کنید  
2. اتصالات سرور MCP را برای استفاده در تولید تنظیم کنید  
3. بسته‌های استقرار را برای دستگاه‌های لبه آماده کنید  
4. معیارهای نظارت و ارزیابی را پیکربندی کنید  

## نمونه‌هایی برای ابزار هوش مصنوعی  

نمونه‌های ما را امتحان کنید  
[نمونه‌های ابزار هوش مصنوعی](https://github.com/Azure-Samples/AI_Toolkit_Samples) برای کمک به توسعه‌دهندگان و محققان در کشف و اجرای راه‌حل‌های هوش مصنوعی طراحی شده‌اند.  

نمونه‌های ما شامل موارد زیر هستند:  

کد نمونه: مثال‌های از پیش ساخته‌شده برای نشان دادن قابلیت‌های هوش مصنوعی، مانند آموزش، استقرار یا ادغام مدل‌ها در برنامه‌ها.  
مستندات: راهنماها و آموزش‌هایی برای کمک به کاربران در درک ویژگی‌های ابزار هوش مصنوعی و نحوه استفاده از آن‌ها.  
پیش‌نیازها  

- Visual Studio Code  
- ابزار هوش مصنوعی برای Visual Studio Code  
- توکن دسترسی شخصی دقیق GitHub (PAT)  
- Foundry Local  

## بهترین روش‌ها برای توسعه هوش مصنوعی در لبه  

### انتخاب مدل  
- **محدودیت‌های اندازه**: مدل‌هایی را انتخاب کنید که در محدودیت‌های حافظه دستگاه‌های هدف قرار گیرند  
- **سرعت استنتاج**: مدل‌هایی را با زمان استنتاج سریع برای برنامه‌های بلادرنگ اولویت دهید  
- **معاوضه‌های دقت**: دقت مدل را با محدودیت‌های منابع متعادل کنید  
- **سازگاری فرمت**: فرمت‌های ONNX یا بهینه‌شده برای سخت‌افزار را برای استقرار در لبه ترجیح دهید  

### تکنیک‌های بهینه‌سازی  
- **کوانتیزاسیون**: از کوانتیزاسیون INT8 یا INT4 برای کاهش اندازه مدل و بهبود سرعت استفاده کنید  
- **هرس کردن**: پارامترهای غیرضروری مدل را حذف کنید تا نیازهای محاسباتی کاهش یابد  
- **انتقال دانش**: مدل‌های کوچک‌تر ایجاد کنید که عملکرد مدل‌های بزرگ‌تر را حفظ کنند  
- **شتاب سخت‌افزاری**: از NPUs، GPUs یا شتاب‌دهنده‌های تخصصی در صورت موجود بودن استفاده کنید  

### جریان کاری توسعه  
- **آزمایش تکراری**: در شرایط مشابه لبه در طول توسعه به طور مکرر آزمایش کنید  
- **نظارت بر عملکرد**: استفاده از منابع و سرعت استنتاج را به طور مداوم نظارت کنید  
- **کنترل نسخه**: نسخه‌های مدل و تنظیمات بهینه‌سازی را پیگیری کنید  
- **مستندسازی**: تمام تصمیمات بهینه‌سازی و معاوضه‌های عملکرد را مستند کنید  

### ملاحظات استقرار  
- **نظارت بر منابع**: حافظه، CPU و مصرف برق را در تولید نظارت کنید  
- **استراتژی‌های جایگزین**: مکانیزم‌های جایگزین برای خرابی مدل پیاده‌سازی کنید  
- **مکانیزم‌های به‌روزرسانی**: برای به‌روزرسانی مدل‌ها و مدیریت نسخه برنامه‌ریزی کنید  
- **امنیت**: اقدامات امنیتی مناسب برای برنامه‌های هوش مصنوعی در لبه اجرا کنید  

## ادغام با چارچوب‌های هوش مصنوعی در لبه  

### ONNX Runtime  
- **استقرار چندپلتفرمی**: مدل‌های ONNX را در پلتفرم‌های مختلف لبه مستقر کنید  
- **بهینه‌سازی سخت‌افزاری**: از بهینه‌سازی‌های سخت‌افزاری خاص ONNX Runtime استفاده کنید  
- **پشتیبانی موبایل**: از ONNX Runtime Mobile برای برنامه‌های گوشی‌های هوشمند و تبلت‌ها استفاده کنید  
- **ادغام IoT**: مدل‌ها را در دستگاه‌های IoT با توزیع‌های سبک ONNX Runtime مستقر کنید  

### Windows ML  
- **دستگاه‌های ویندوز**: برای دستگاه‌های لبه مبتنی بر ویندوز و رایانه‌های شخصی بهینه‌سازی کنید  
- **شتاب NPU**: از واحدهای پردازش عصبی در دستگاه‌های ویندوز استفاده کنید  
- **DirectML**: از DirectML برای شتاب GPU در پلتفرم‌های ویندوز استفاده کنید  
- **ادغام UWP**: با برنامه‌های Universal Windows Platform ادغام کنید  

### TensorFlow Lite  
- **بهینه‌سازی موبایل**: مدل‌های TensorFlow Lite را در دستگاه‌های موبایل و تعبیه‌شده مستقر کنید  
- **نمایندگان سخت‌افزاری**: از نمایندگان سخت‌افزاری تخصصی برای شتاب‌دهی استفاده کنید  
- **کنترل‌کننده‌های کوچک**: مدل‌ها را با استفاده از TensorFlow Lite Micro در کنترل‌کننده‌های کوچک مستقر کنید  
- **پشتیبانی چندپلتفرمی**: مدل‌ها را در سیستم‌های Android، iOS و Linux تعبیه‌شده مستقر کنید  

### Azure IoT Edge  
- **ترکیب ابر-لبه**: آموزش در ابر را با استنتاج در لبه ترکیب کنید  
- **استقرار ماژول**: مدل‌های هوش مصنوعی را به عنوان ماژول‌های IoT Edge مستقر کنید  
- **مدیریت دستگاه**: دستگاه‌های لبه و به‌روزرسانی مدل‌ها را از راه دور مدیریت کنید  
- **تله‌متری**: داده‌های عملکرد و معیارهای مدل را از استقرارهای لبه جمع‌آوری کنید  

## سناریوهای پیشرفته هوش مصنوعی در لبه  

### استقرار چندمدلی  
- **مجموعه مدل‌ها**: چندین مدل را برای بهبود دقت یا افزونگی مستقر کنید  
- **آزمایش A/B**: مدل‌های مختلف را به طور همزمان در دستگاه‌های لبه آزمایش کنید  
- **انتخاب پویا**: مدل‌ها را بر اساس شرایط فعلی دستگاه انتخاب کنید  
- **اشتراک منابع**: استفاده از منابع را در مدل‌های مستقر شده بهینه کنید  

### یادگیری فدرال  
- **آموزش توزیع‌شده**: مدل‌ها را در چندین دستگاه لبه آموزش دهید  
- **حفظ حریم خصوصی**: داده‌های آموزشی را محلی نگه دارید و بهبودهای مدل را به اشتراک بگذارید  
- **یادگیری مشارکتی**: به دستگاه‌ها اجازه دهید از تجربیات جمعی یاد بگیرند  
- **هماهنگی لبه-ابر**: یادگیری را بین دستگاه‌های لبه و زیرساخت ابر هماهنگ کنید  

### پردازش بلادرنگ  
- **پردازش جریان**: داده‌های پیوسته را در دستگاه‌های لبه پردازش کنید  
- **استنتاج با تأخیر کم**: برای حداقل تأخیر استنتاج بهینه‌سازی کنید  
- **پردازش دسته‌ای**: دسته‌های داده را به طور کارآمد در دستگاه‌های لبه پردازش کنید  
- **پردازش تطبیقی**: پردازش را بر اساس قابلیت‌های فعلی دستگاه تنظیم کنید  

## رفع اشکال توسعه هوش مصنوعی در لبه  

### مشکلات رایج  
- **محدودیت‌های حافظه**: مدل برای حافظه دستگاه هدف بسیار بزرگ است  
- **سرعت استنتاج**: استنتاج مدل برای نیازهای بلادرنگ بسیار کند است  
- **کاهش دقت**: بهینه‌سازی دقت مدل را به طور غیرقابل قبول کاهش می‌دهد  
- **سازگاری سخت‌افزاری**: مدل با سخت‌افزار هدف سازگار نیست  

### استراتژی‌های اشکال‌زدایی  
- **پروفایل عملکرد**: از ویژگی‌های ردیابی ابزار هوش مصنوعی برای شناسایی گلوگاه‌ها استفاده کنید  
- **نظارت بر منابع**: حافظه و استفاده از CPU را در طول توسعه نظارت کنید  
- **آزمایش تدریجی**: بهینه‌سازی‌ها را به صورت تدریجی آزمایش کنید تا مشکلات را جدا کنید  
- **شبیه‌سازی سخت‌افزار**: از ابزارهای توسعه برای شبیه‌سازی سخت‌افزار هدف استفاده کنید  

### راه‌حل‌های بهینه‌سازی  
- **کوانتیزاسیون بیشتر**: تکنیک‌های کوانتیزاسیون تهاجمی‌تر را اعمال کنید  
- **معماری مدل**: معماری‌های مدل مختلف بهینه‌شده برای لبه را در نظر بگیرید  
- **بهینه‌سازی پیش‌پردازش**: پیش‌پردازش داده‌ها را برای محدودیت‌های لبه بهینه کنید  
- **بهینه‌سازی استنتاج**: از بهینه‌سازی‌های استنتاج خاص سخت‌افزار استفاده کنید  

## منابع و مراحل بعدی  

### مستندات رسمی  
- [مستندات توسعه‌دهنده ابزار هوش مصنوعی](https://aka.ms/AIToolkit/doc)  
- [راهنمای نصب و راه‌اندازی](https://code.visualstudio.com/docs/intelligentapps/overview#_install-and-setup)  
- [مستندات برنامه‌های هوشمند VS Code](https://code.visualstudio.com/docs/intelligentapps)  
- [مستندات پروتکل زمینه مدل (MCP)](https://modelcontextprotocol.io/)  

### جامعه و پشتیبانی  
- [مخزن GitHub ابزار هوش مصنوعی](https://github.com/microsoft/vscode-ai-toolkit)  
- [مشکلات و درخواست‌های ویژگی GitHub](https://aka.ms/AIToolkit/feedback)  
- [جامعه Discord Azure AI Foundry](https://aka.ms/azureaifoundry/discord)  
- [بازار افزونه‌های VS Code](https://marketplace.visualstudio.com/items?itemName=ms-windows-ai-studio.windows-ai-studio)  

### منابع فنی  
- [مستندات ONNX Runtime](https://onnxruntime.ai/)  
- [مستندات Ollama](https://ollama.ai/)  
- [مستندات Windows ML](https://docs.microsoft.com/en-us/windows/ai/)  
- [مستندات Azure AI Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/)  

### مسیرهای یادگیری  
- [دوره اصول هوش مصنوعی در لبه](../Module01/README.md)  
- [راهنمای مدل‌های زبان کوچک](../Module02/README.md)  
- [استراتژی‌های استقرار در لبه](../Module03/README.md)  
- [توسعه هوش مصنوعی در لبه ویندوز](./windowdeveloper.md)  

### منابع اضافی  
- **آمار مخزن**: بیش از 1.8k ستاره، بیش از 150 فورک، بیش از 18 مشارکت‌کننده  
- **مجوز**: مجوز MIT  
- **امنیت**: سیاست‌های امنیتی مایکروسافت اعمال می‌شود  
- **تله‌متری**: تنظیمات تله‌متری VS Code رعایت می‌شود  

## نتیجه‌گیری  

ابزار هوش مصنوعی برای Visual Studio Code یک پلتفرم جامع برای توسعه مدرن هوش مصنوعی است که قابلیت‌های توسعه عامل را به صورت ساده ارائه می‌دهد و به ویژه برای برنامه‌های هوش مصنوعی در لبه ارزشمند است. با کاتالوگ گسترده مدل که از ارائه‌دهندگانی مانند Anthropic، OpenAI، GitHub و Google پشتیبانی می‌کند، همراه با اجرای محلی از طریق ONNX و Ollama، این ابزار انعطاف‌پذیری لازم برای سناریوهای مختلف استقرار در لبه را فراهم می‌کند.  

قدرت این ابزار در رویکرد یکپارچه آن نهفته است—از کشف مدل و آزمایش در Playground گرفته تا توسعه پیشرفته عامل با Prompt Builder، قابلیت‌های ارزیابی جامع و ادغام بی‌دردسر ابزار MCP. برای توسعه‌دهندگان هوش مصنوعی در لبه، این به معنای نمونه‌سازی سریع و آزمایش عوامل هوش مصنوعی قبل از استقرار در لبه است، با توانایی تکرار سریع و بهینه‌سازی برای محیط‌های محدود منابع.  

مزایای کلیدی برای توسعه هوش مصنوعی در لبه شامل موارد زیر است:  
- **آزمایش سریع**: مدل‌ها و عوامل را سریعاً قبل از تعهد به استقرار در لبه آزمایش کنید  
- **انعطاف‌پذیری چند ارائه‌دهنده**: به مدل‌ها از منابع مختلف دسترسی پیدا کنید تا راه‌حل‌های بهینه لبه را پیدا کنید  
- **توسعه محلی**: با ONNX و Ollama برای توسعه آفلاین و حفظ حریم خصوصی آزمایش کنید  
- **آمادگی تولید**: کد آماده تولید ایجاد کنید و با ابزارهای خارجی از طریق MCP ادغام کنید  
- **ارزیابی جامع**: از معیارهای داخلی و سفارشی برای اعتبارسنجی عملکرد هوش مصنوعی در لبه استفاده کنید  

همان‌طور که هوش مصنوعی به سمت سناریوهای استقرار در لبه حرکت می‌کند، ابزار هوش مصنوعی برای VS Code محیط توسعه و جریان کاری مورد نیاز برای ساخت، آزمایش و بهینه‌سازی برنامه‌های هوشمند برای محیط‌های محدود منابع را فراهم می‌کند. چه در حال توسعه راه‌حل‌های IoT، برنامه‌های هوش مصنوعی موبایل یا سیستم‌های هوشمند تعبیه‌شده باشید، مجموعه ویژگی‌های جامع این ابزار و جریان کاری یکپارچه از کل چرخه توسعه هوش مصنوعی در لبه پشتیبانی می‌کند.  

با توسعه مداوم و یک جامعه فعال (بیش از 1.8k ستاره در GitHub)، ابزار هوش مصنوعی همچنان در خط مقدم ابزارهای توسعه هوش مصنوعی قرار دارد و به طور مداوم برای پاسخگویی به نیازهای توسعه‌دهندگان مدرن هوش مصنوعی که برای سناریوهای استقرار در لبه می‌سازند، تکامل می‌یابد.  

[Next Foundry Local](./foundrylocal.md)  

---

**سلب مسئولیت**:  
این سند با استفاده از سرویس ترجمه هوش مصنوعی [Co-op Translator](https://github.com/Azure/co-op-translator) ترجمه شده است. در حالی که ما تلاش می‌کنیم دقت را حفظ کنیم، لطفاً توجه داشته باشید که ترجمه‌های خودکار ممکن است شامل خطاها یا نادرستی‌ها باشند. سند اصلی به زبان اصلی آن باید به عنوان منبع معتبر در نظر گرفته شود. برای اطلاعات حیاتی، ترجمه حرفه‌ای انسانی توصیه می‌شود. ما مسئولیتی در قبال سوء تفاهم‌ها یا تفسیرهای نادرست ناشی از استفاده از این ترجمه نداریم.