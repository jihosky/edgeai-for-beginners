<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "76b134be93f45283a2df8f8a93717d06",
  "translation_date": "2025-10-17T10:00:04+00:00",
  "source_file": "Module01/01.EdgeAIFundamentals.md",
  "language_code": "sw"
}
-->
# Sehemu ya 1: Misingi ya EdgeAI

EdgeAI inawakilisha mabadiliko makubwa katika utekelezaji wa akili bandia, ikileta uwezo wa AI moja kwa moja kwenye vifaa vya pembezoni badala ya kutegemea tu usindikaji wa wingu. Ni muhimu kuelewa jinsi EdgeAI inavyowezesha usindikaji wa AI wa ndani kwenye vifaa vyenye rasilimali ndogo huku ikidumisha utendaji mzuri na kushughulikia changamoto kama faragha, ucheleweshaji, na uwezo wa kufanya kazi bila mtandao.

## Utangulizi

Katika somo hili, tutachunguza EdgeAI na dhana zake za msingi. Tutajadili mtazamo wa jadi wa kompyuta ya AI, changamoto za kompyuta ya pembezoni, teknolojia muhimu zinazowezesha EdgeAI, na matumizi ya vitendo katika sekta mbalimbali.

## Malengo ya Kujifunza

Mwisho wa somo hili, utaweza:

- Kuelewa tofauti kati ya mbinu za AI zinazotegemea wingu na EdgeAI.
- Kutambua teknolojia muhimu zinazowezesha usindikaji wa AI kwenye vifaa vya pembezoni.
- Kutambua faida na mapungufu ya utekelezaji wa EdgeAI.
- Kutumia maarifa ya EdgeAI katika hali halisi na matumizi.

## Kuelewa Mtazamo wa Jadi wa Kompyuta ya AI

Kwa kawaida, programu za AI zinazozalisha hutegemea miundombinu ya kompyuta yenye utendaji wa juu kuendesha mifano mikubwa ya lugha (LLMs) kwa ufanisi. Mashirika kwa kawaida huweka mifano hii kwenye makundi ya GPU katika mazingira ya wingu, yakipata uwezo wake kupitia interface za API.

Mfumo huu wa kati unafanya kazi vizuri kwa programu nyingi lakini una mapungufu ya asili linapokuja suala la hali za kompyuta ya pembezoni. Mbinu ya kawaida inahusisha kutuma maswali ya mtumiaji kwa seva za mbali, kuyachakata kwa kutumia vifaa vyenye nguvu, na kurudisha matokeo kupitia mtandao. Ingawa njia hii hutoa ufikiaji wa mifano ya hali ya juu, inaunda utegemezi wa muunganisho wa mtandao, inaleta wasiwasi wa ucheleweshaji, na inazua masuala ya faragha wakati data nyeti inapaswa kutumwa kwa seva za nje.

Kuna dhana kadhaa za msingi tunazohitaji kuelewa tunapofanya kazi na mtazamo wa jadi wa kompyuta ya AI, ambazo ni:

- **☁️ Usindikaji Unaotegemea Wingu**: Mifano ya AI inaendeshwa kwenye miundombinu ya seva yenye rasilimali za juu za kompyuta.
- **🔌 Ufikiaji Kupitia API**: Programu zinapata uwezo wa AI kupitia miito ya API ya mbali badala ya usindikaji wa ndani.
- **🎛️ Usimamizi wa Mifano wa Kati**: Mifano inahifadhiwa na kusasishwa kwa pamoja, kuhakikisha uthabiti lakini inahitaji muunganisho wa mtandao.
- **📈 Uwezo wa Kuongeza Rasilimali**: Miundombinu ya wingu inaweza kupanuka kwa nguvu kushughulikia mahitaji tofauti ya kompyuta.

## Changamoto ya Kompyuta ya Pembezoni

Vifaa vya pembezoni kama kompyuta ndogo, simu za mkononi, na vifaa vya Mtandao wa Vitu (IoT) kama Raspberry Pi na NVIDIA Orin Nano vina vikwazo vya kipekee vya kompyuta. Vifaa hivi kwa kawaida vina nguvu ndogo ya usindikaji, kumbukumbu, na rasilimali za nishati ikilinganishwa na miundombinu ya kituo cha data.

Kuendesha LLM za jadi kwenye vifaa kama hivyo kihistoria imekuwa changamoto kutokana na vikwazo hivi vya vifaa. Hata hivyo, hitaji la usindikaji wa AI ya pembezoni limekuwa muhimu zaidi katika hali mbalimbali. Fikiria hali ambapo muunganisho wa mtandao hauaminiki au haupatikani, kama vile maeneo ya viwanda ya mbali, magari yanayosafiri, au maeneo yenye mtandao hafifu. Zaidi ya hayo, programu zinazohitaji viwango vya juu vya usalama, kama vile vifaa vya matibabu, mifumo ya kifedha, au programu za serikali, zinaweza kuhitaji kuchakata data nyeti kwa ndani ili kudumisha faragha na mahitaji ya kufuata sheria.

### Vikwazo Muhimu vya Kompyuta ya Pembezoni

Mazingira ya kompyuta ya pembezoni yanakabiliwa na vikwazo kadhaa vya msingi ambavyo suluhisho za jadi za AI zinazotegemea wingu hazikumbani:

- **Nguvu Ndogo ya Usindikaji**: Vifaa vya pembezoni kwa kawaida vina cores chache za CPU na kasi ya chini ya saa ikilinganishwa na vifaa vya daraja la seva.
- **Vikwazo vya Kumbukumbu**: RAM inayopatikana na uwezo wa kuhifadhi ni mdogo sana kwenye vifaa vya pembezoni.
- **Vikwazo vya Nishati**: Vifaa vinavyotumia betri vinapaswa kusawazisha utendaji na matumizi ya nishati kwa uendeshaji wa muda mrefu.
- **Usimamizi wa Joto**: Miundo midogo inazuia uwezo wa kupoza, ikiongeza athari kwa utendaji endelevu chini ya mzigo.

## EdgeAI ni Nini?

### Dhana: Ufafanuzi wa Edge AI

Edge AI inahusu uwekaji na utekelezaji wa algoriti za akili bandia moja kwa moja kwenye vifaa vya pembezoni—vifaa vya kimwili vilivyo karibu na "pembeni" ya mtandao, karibu na mahali data inazalishwa na kukusanywa. Vifaa hivi ni pamoja na simu za mkononi, sensa za IoT, kamera za kisasa, magari yanayojiendesha, vifaa vinavyovaliwa, na vifaa vya viwandani. Tofauti na mifumo ya jadi ya AI inayotegemea seva za wingu kwa usindikaji, Edge AI inaleta akili moja kwa moja kwenye chanzo cha data.

Kwa msingi wake, Edge AI inahusu kuhamisha usindikaji wa AI kutoka vituo vya data vya kati na kuusambaza kwenye mtandao mkubwa wa vifaa vinavyounda mfumo wetu wa kidijitali. Hii inawakilisha mabadiliko ya kimsingi katika jinsi mifumo ya AI inavyoundwa na kutekelezwa.

Nguzo muhimu za dhana ya Edge AI ni pamoja na:

- **Usindikaji wa Karibu**: Usindikaji unafanyika karibu kimwili na mahali data inatoka.
- **Akili Iliyosambazwa**: Uwezo wa kufanya maamuzi unasambazwa kwenye vifaa vingi.
- **Udhibiti wa Data**: Taarifa zinabaki chini ya udhibiti wa ndani, mara nyingi hazitoki kwenye kifaa.
- **Uendeshaji wa Kujitegemea**: Vifaa vinaweza kufanya kazi kwa akili bila kuhitaji muunganisho wa mara kwa mara.
- **AI Iliyopachikwa**: Akili inakuwa uwezo wa ndani wa vifaa vya kila siku.

### Muonekano wa Usanifu wa Edge AI

```
┌─────────────────────────────────────────────────────────────────────┐
│                         TRADITIONAL AI ARCHITECTURE                 │
└─────────────────────────────────────────────────────────────────────┘
                                  │
┌──────────────┐   Data Transfer  ┌───────────────┐   API Response   ┌───────────┐
│ Edge Devices ├─────────────────>│ Cloud Servers │────────────────> │ End Users │
└──────────────┘                  └───────────────┘                  └───────────┘
     Data                         Model Inference                     Results
   Collection                     High Latency
                                  High Bandwidth
                                  Privacy Concerns
                               
┌─────────────────────────────────────────────────────────────────────┐
│                            EDGE AI ARCHITECTURE                     │
└─────────────────────────────────────────────────────────────────────┘
                                  │
┌────────────────────────────────────────────────────┐   Direct Response  ┌───────────┐
│              Edge Devices with Embedded AI         │───────────────────>│ End Users │
│  ┌─────────┐  ┌───────────────┐  ┌──────────────┐  │                    └───────────┘
│  │ Sensors │─>│ SLM Inference │─>│ Local Action │  │
│  └─────────┘  └───────────────┘  └──────────────┘  │
└────────────────────────────────────────────────────┘
     Data         Low Latency       Immediate
   Collection     Processing        Response
                  No Data Transfer
                  Enhanced Privacy
```

EdgeAI inawakilisha mabadiliko makubwa katika utekelezaji wa akili bandia, ikileta uwezo wa AI moja kwa moja kwenye vifaa vya pembezoni badala ya kutegemea tu usindikaji wa wingu. Mbinu hii inaruhusu mifano ya AI kuendeshwa kwa ndani kwenye vifaa vyenye rasilimali ndogo za kompyuta, ikitoa uwezo wa utambuzi wa wakati halisi bila kuhitaji muunganisho wa mtandao wa mara kwa mara.

EdgeAI inajumuisha teknolojia na mbinu mbalimbali zilizoundwa ili kufanya mifano ya AI kuwa bora zaidi na inayofaa kwa uwekaji kwenye vifaa vyenye rasilimali ndogo. Lengo ni kudumisha utendaji mzuri huku ikipunguza kwa kiasi kikubwa mahitaji ya kompyuta na kumbukumbu ya mifano ya AI.

Hebu tuangalie mbinu za msingi zinazowezesha utekelezaji wa EdgeAI kwenye aina tofauti za vifaa na matumizi.

### Kanuni za Msingi za EdgeAI

EdgeAI imejengwa juu ya kanuni kadhaa za msingi zinazoitofautisha na AI inayotegemea wingu:

- **Usindikaji wa Ndani**: Utambuzi wa AI unafanyika moja kwa moja kwenye kifaa cha pembezoni bila kuhitaji muunganisho wa nje.
- **Uboreshaji wa Rasilimali**: Mifano imeboreshwa mahsusi kwa vikwazo vya vifaa vya lengo.
- **Utendaji wa Wakati Halisi**: Usindikaji unafanyika kwa ucheleweshaji mdogo kwa programu nyeti kwa wakati.
- **Faragha kwa Muundo**: Data nyeti inabaki kwenye kifaa, ikiboresha usalama na kufuata sheria.

## Teknolojia Muhimu Zinazowezesha EdgeAI

### Upunguzaji wa Mfano

Moja ya mbinu muhimu zaidi katika EdgeAI ni upunguzaji wa mfano. Mchakato huu unahusisha kupunguza usahihi wa vigezo vya mfano, kwa kawaida kutoka kwa namba za kuelea za biti 32 hadi namba za biti 8 au hata fomati za usahihi wa chini zaidi. Ingawa kupunguzwa huku kwa usahihi kunaweza kuonekana kuwa na wasiwasi, utafiti umeonyesha kuwa mifano mingi ya AI inaweza kudumisha utendaji wake hata kwa usahihi uliopunguzwa kwa kiasi kikubwa.

Upunguzaji hufanya kazi kwa kuonyesha anuwai ya maadili ya kuelea kwa seti ndogo ya maadili ya kidhahania. Kwa mfano, badala ya kutumia biti 32 kuwakilisha kila parameter, upunguzaji unaweza kutumia biti 8 tu, na kusababisha kupunguzwa kwa mahitaji ya kumbukumbu kwa mara 4 na mara nyingi kusababisha nyakati za utambuzi wa haraka.

```python
# Example: PyTorch model quantization 
import torch

# Load a pre-trained model
model = torch.load('large_model.pth')

# Quantize the model to INT8
quantized_model = torch.quantization.quantize_dynamic(
    model,  # model to quantize
    {torch.nn.Linear, torch.nn.Conv2d},  # layers to quantize
    dtype=torch.qint8  # quantization data type
)

# Save the quantized model
torch.save(quantized_model, 'quantized_model.pth')

# Memory usage comparison
original_size = model.size()
quantized_size = quantized_model.size()
print(f"Memory reduction: {original_size / quantized_size:.2f}x")
```

Mbinu tofauti za upunguzaji ni pamoja na:

- **Upunguzaji Baada ya Mafunzo (PTQ)**: Inatumika baada ya mafunzo ya mfano bila kuhitaji mafunzo upya.
- **Mafunzo Yenye Uelewa wa Upunguzaji (QAT)**: Inajumuisha athari za upunguzaji wakati wa mafunzo kwa usahihi bora.
- **Upunguzaji wa Kawaida**: Unapunguza uzito hadi int8 lakini huhesabu uanzishaji kwa nguvu.
- **Upunguzaji wa Kawaida Kabisa**: Unahesabu mapema vigezo vyote vya upunguzaji kwa uzito na uanzishaji.

Kwa uwekaji wa EdgeAI, kuchagua mkakati sahihi wa upunguzaji kunategemea usanifu maalum wa mfano, mahitaji ya utendaji, na uwezo wa vifaa vya lengo.

### Ukandamizaji na Uboreshaji wa Mfano

Zaidi ya upunguzaji, mbinu mbalimbali za ukandamizaji husaidia kupunguza ukubwa wa mfano na mahitaji ya kompyuta. Hizi ni pamoja na:

**Kupunguza**: Mbinu hii huondoa miunganisho au neurons zisizo za lazima kutoka kwa mitandao ya neva. Kwa kutambua na kuondoa vigezo vinavyotoa mchango mdogo kwa utendaji wa mfano, kupunguza kunaweza kupunguza ukubwa wa mfano kwa kiasi kikubwa huku ukidumisha usahihi.

```python
# Example: Neural network pruning in TensorFlow
import tensorflow as tf
import tensorflow_model_optimization as tfmot

# Define the model
model = tf.keras.Sequential([
    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

# Apply pruning during training
pruning_schedule = tfmot.sparsity.keras.PolynomialDecay(
    initial_sparsity=0.0,
    final_sparsity=0.5,  # 50% of connections will be pruned
    begin_step=0,
    end_step=10000
)

pruned_model = tfmot.sparsity.keras.prune_low_magnitude(
    model, pruning_schedule=pruning_schedule
)

# Compile the pruned model
pruned_model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# Train the model while pruning
pruned_model.fit(x_train, y_train, epochs=10)

# Convert to a smaller model for deployment
final_model = tfmot.sparsity.keras.strip_pruning(pruned_model)
```

**Uhamishaji wa Maarifa**: Mbinu hii inahusisha kufundisha mfano mdogo wa "mwanafunzi" kuiga tabia ya mfano mkubwa wa "mwalimu". Mfano wa mwanafunzi hujifunza kukadiria matokeo ya mwalimu, mara nyingi kufanikisha utendaji sawa na vigezo vichache sana.

**Uboreshaji wa Usanifu wa Mfano**: Watafiti wameunda usanifu maalum ulioundwa mahsusi kwa uwekaji wa pembezoni, kama vile MobileNets, EfficientNets, na usanifu mwingine mwepesi unaosawazisha utendaji na ufanisi wa kompyuta.

### Mifano Midogo ya Lugha (SLMs)

Mwelekeo unaoibuka katika EdgeAI ni maendeleo ya Mifano Midogo ya Lugha (SLMs). Mifano hii imeundwa kutoka mwanzo kuwa ndogo na bora huku ikitoa uwezo wa maana wa lugha asilia. SLMs hufanikisha hili kupitia chaguo za usanifu wa makini, mbinu bora za mafunzo, na mafunzo yaliyolenga nyanja au kazi maalum.

Tofauti na mbinu za jadi zinazohusisha ukandamizaji wa mifano mikubwa, SLMs mara nyingi hufundishwa na seti ndogo za data na usanifu ulioboreshwa mahsusi kwa uwekaji wa pembezoni. Mbinu hii inaweza kusababisha mifano ambayo si tu ndogo bali pia bora kwa matumizi maalum.

## Uharakishaji wa Vifaa kwa EdgeAI

Vifaa vya kisasa vya pembezoni vinajumuisha vifaa maalum vilivyoundwa kuharakisha mzigo wa kazi wa AI:

### Vitengo vya Usindikaji wa Neva (NPUs)

NPUs ni wasindikaji maalum walioundwa mahsusi kwa hesabu za mitandao ya neva. Chipu hizi zinaweza kufanya kazi za utambuzi wa AI kwa ufanisi zaidi kuliko CPU za jadi, mara nyingi kwa matumizi ya chini ya nishati. Simu za kisasa, kompyuta ndogo, na vifaa vya IoT sasa vinajumuisha NPUs kuwezesha usindikaji wa AI kwenye kifaa.

```csharp
// Example: Using Windows ML to target NPU acceleration in C#
using Microsoft.ML.OnnxRuntime;

// Create session options with NPU provider
var sessionOptions = new SessionOptions();
sessionOptions.AppendExecutionProvider_DmlExecutionProvider();  // DirectML for NPU

// Load the ONNX model
using var session = new InferenceSession("model.onnx", sessionOptions);

// Create input tensor
var inputTensor = new DenseTensor<float>(new[] { 1, 3, 224, 224 });  // Example input shape
var inputs = new List<NamedOnnxValue> { NamedOnnxValue.CreateFromTensor("input", inputTensor) };

// Run inference with NPU acceleration
using var results = session.Run(inputs);
var output = results.First().AsTensor<float>();

// Process output
Console.WriteLine($"Inference result: {output[0]}");
```

Vifaa vyenye NPUs ni pamoja na:

- **Apple**: Chipu za A-series na M-series zenye Neural Engine
- **Qualcomm**: Wasindikaji wa Snapdragon wenye Hexagon DSP/NPU
- **Samsung**: Wasindikaji wa Exynos wenye NPU
- **Intel**: Movidius VPUs na viharakishaji vya Habana Labs
- **Microsoft**: Kompyuta za Windows Copilot+ zenye NPUs

### 🎮 Uharakishaji wa GPU

Ingawa vifaa vya pembezoni vinaweza kuwa na GPU zenye nguvu zinazopatikana katika vituo vya data, vingi bado vinajumuisha GPU zilizojumuishwa au za pekee zinazoweza kuharakisha mzigo wa kazi wa AI. GPU za kisasa za simu na wasindikaji wa picha zilizojumuishwa zinaweza kutoa maboresho makubwa ya utendaji kwa kazi za utambuzi wa AI.

```python
# Example: Using TensorRT for GPU acceleration on edge devices
import tensorrt as trt
import numpy as np

# Create TensorRT logger and builder
TRT_LOGGER = trt.Logger(trt.Logger.WARNING)
builder = trt.Builder(TRT_LOGGER)
network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))
parser = trt.OnnxParser(network, TRT_LOGGER)

# Parse ONNX model
with open('model.onnx', 'rb') as model:
    parser.parse(model.read())

# Configure builder
config = builder.create_builder_config()
config.max_workspace_size = 1 << 28  # 256 MiB
config.set_flag(trt.BuilderFlag.FP16)  # Use FP16 precision for edge GPU

# Build and serialize engine
engine = builder.build_engine(network, config)
with open('model.trt', 'wb') as f:
    f.write(engine.serialize())
```

### Uboreshaji wa CPU

Hata vifaa vyenye CPU pekee vinaweza kufaidika na EdgeAI kupitia utekelezaji ulioboreshwa. CPU za kisasa zinajumuisha maagizo maalum kwa mzigo wa kazi wa AI, na mifumo ya programu imetengenezwa ili kuongeza utendaji wa CPU kwa utambuzi wa AI.

```bash
# Example: Using XNNPACK with TFLite for optimized CPU inference
# Compilation command with XNNPACK acceleration enabled

bazel build -c opt --copt=-O3 --copt=-march=native \
  tensorflow/lite/delegates/xnnpack:libxnnpack_delegate.so

# Convert TensorFlow model to TFLite with optimization
tflite_convert \
  --keras_model_file=model.h5 \
  --output_file=model.tflite \
  --inference_type=FLOAT \
  --experimental_new_converter \
  --experimental_new_quantizer
```

Kwa wahandisi wa programu wanaofanya kazi na EdgeAI, kuelewa jinsi ya kutumia chaguo hizi za uharakishaji wa vifaa ni muhimu kwa kuboresha utendaji wa utambuzi na ufanisi wa nishati kwenye vifaa vya lengo.

## Faida za EdgeAI

### Faragha na Usalama

Moja ya faida kubwa zaidi za EdgeAI ni faragha na usalama ulioboreshwa. Kwa kuchakata data kwa ndani kwenye kifaa, taarifa nyeti hazitoki nje ya udhibiti wa mtumiaji. Hii ni muhimu hasa kwa programu zinazoshughulikia data ya kibinafsi, taarifa za matibabu, au data ya siri ya biashara.

### Kupunguza Ucheleweshaji

EdgeAI huondoa hitaji la kutuma data kwa seva za mbali kwa usindikaji, na hivyo kupunguza ucheleweshaji kwa kiasi kikubwa. Hii ni muhimu kwa programu za wakati halisi kama magari yanayojiendesha, otomatiki ya viwanda, au programu za maingiliano ambapo majibu ya haraka yanahitajika.

### Uwezo wa Kufanya Kazi Bila Mtandao

EdgeAI huwezesha utendaji wa AI hata wakati muunganisho wa mtandao haupatikani. Hii ni muhimu kwa programu katika maeneo ya mbali, wakati wa kusafiri, au katika hali ambapo uaminifu wa mtandao ni suala.

### Ufanisi wa Gharama

Kwa kupunguza utegemezi wa huduma za AI zinazotegemea wingu, EdgeAI inaweza kusaidia kupunguza gharama za uendeshaji, hasa kwa programu zenye viwango vya juu vya matumizi. Mashirika yanaweza kuepuka gharama za API zinazoendelea na kupunguza mahitaji ya bandwidth.

### Uwezo wa Kupanuka

EdgeAI husambaza mzigo wa kompyuta kwenye vifaa vya pembezoni badala ya kuuzingatia katika vituo vya data. Hii inaweza kusaidia kupunguza gharama za miundombinu na kuboresha uwezo wa jumla wa mfumo wa kupanuka.

## Matumizi ya EdgeAI

### Vifaa vya Kisasa na IoT

EdgeAI inawezesha vipengele vingi vya vifaa vya kisasa, kutoka kwa wasaidizi wa sauti wanaoweza kuchakata amri kwa ndani hadi kamera za kisasa zinazoweza kutambua vitu na watu bila kutuma video kwa wingu. Vifaa vya IoT hutumia EdgeAI kwa matengenezo ya utabiri, ufuatiliaji wa mazingira, na kufanya maamuzi kiotomatiki.

### Programu za Simu

Simu za mkononi na vidonge hutumia EdgeAI kwa vipengele mbalimbali, ikiwa ni pamoja na uboreshaji wa picha, tafsiri ya wakati halisi, ukweli ulioboreshwa, na mapendekezo ya kibinafsi. Programu hizi zinanufaika na ucheleweshaji mdogo na faida za faragha za usindikaji wa ndani.

### Matumizi ya Viwanda

Mazingira ya utengenezaji na viwanda hutumia EdgeAI kwa udhibiti wa ubora, matengenezo ya utabiri, na uboreshaji wa mchakato. Programu hizi mara nyingi zinahitaji usindikaji wa wakati halisi na zinaweza kufanya kazi katika mazingira yenye muunganisho mdogo.


- [02: Matumizi ya EdgeAI](02.RealWorldCaseStudies.md)

---

**Kanusho**:  
Hati hii imetafsiriwa kwa kutumia huduma ya kutafsiri ya AI [Co-op Translator](https://github.com/Azure/co-op-translator). Ingawa tunajitahidi kwa usahihi, tafadhali fahamu kuwa tafsiri za kiotomatiki zinaweza kuwa na makosa au kutokuwa sahihi. Hati ya asili katika lugha yake ya asili inapaswa kuzingatiwa kama chanzo cha mamlaka. Kwa taarifa muhimu, tafsiri ya kitaalamu ya binadamu inapendekezwa. Hatutawajibika kwa kutoelewana au tafsiri zisizo sahihi zinazotokana na matumizi ya tafsiri hii.