<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8a7765b85f123e8a62aa3847141ca072",
  "translation_date": "2025-10-30T13:37:21+00:00",
  "source_file": "Module06/03.IntroduceMCP.md",
  "language_code": "vi"
}
-->
# Phần 03 - Tích hợp Giao thức Ngữ cảnh Mô hình (MCP)

## Giới thiệu về MCP (Giao thức Ngữ cảnh Mô hình)

Giao thức Ngữ cảnh Mô hình (MCP) là một tiêu chuẩn mã nguồn mở để kết nối các ứng dụng AI với các hệ thống bên ngoài. Sử dụng MCP, các ứng dụng AI như Claude hoặc ChatGPT có thể kết nối với các nguồn dữ liệu (ví dụ: tệp cục bộ, cơ sở dữ liệu), công cụ (ví dụ: công cụ tìm kiếm, máy tính), và quy trình làm việc (ví dụ: các lời nhắc chuyên biệt)—cho phép chúng truy cập thông tin quan trọng và thực hiện các nhiệm vụ.

Hãy nghĩ về MCP như một **cổng USB-C dành cho các ứng dụng AI**. Cũng giống như USB-C cung cấp một cách kết nối tiêu chuẩn cho các thiết bị điện tử, MCP cung cấp một cách kết nối tiêu chuẩn cho các ứng dụng AI với các hệ thống bên ngoài.

### MCP có thể làm được gì?

MCP mở ra những khả năng mạnh mẽ cho các ứng dụng AI:

- **Trợ lý AI cá nhân hóa**: Các tác nhân có thể truy cập Google Calendar và Notion của bạn, hoạt động như một trợ lý AI cá nhân hóa hơn
- **Tạo mã nâng cao**: Claude Code có thể tạo ra toàn bộ ứng dụng web từ thiết kế Figma
- **Tích hợp dữ liệu doanh nghiệp**: Các chatbot doanh nghiệp có thể kết nối với nhiều cơ sở dữ liệu trong tổ chức, giúp người dùng phân tích dữ liệu thông qua trò chuyện
- **Quy trình sáng tạo**: Các mô hình AI có thể tạo ra thiết kế 3D trên Blender và in chúng bằng máy in 3D
- **Truy cập thông tin thời gian thực**: Kết nối với các nguồn dữ liệu bên ngoài để có thông tin cập nhật
- **Hoạt động đa bước phức tạp**: Thực hiện các quy trình phức tạp kết hợp nhiều công cụ và hệ thống

### Tại sao MCP lại quan trọng?

MCP mang lại lợi ích cho toàn bộ hệ sinh thái:

**Đối với nhà phát triển**: MCP giảm thời gian và độ phức tạp khi xây dựng hoặc tích hợp với một ứng dụng hoặc tác nhân AI.

**Đối với các ứng dụng AI**: MCP cung cấp quyền truy cập vào hệ sinh thái các nguồn dữ liệu, công cụ và ứng dụng, giúp tăng cường khả năng và cải thiện trải nghiệm người dùng cuối.

**Đối với người dùng cuối**: MCP tạo ra các ứng dụng hoặc tác nhân AI có khả năng hơn, có thể truy cập dữ liệu của bạn và thực hiện hành động thay mặt bạn khi cần thiết.

## Mô hình ngôn ngữ nhỏ (SLMs) trong MCP

Mô hình ngôn ngữ nhỏ đại diện cho một cách tiếp cận hiệu quả trong triển khai AI, mang lại nhiều lợi ích:

### Lợi ích của SLMs
- **Hiệu quả tài nguyên**: Yêu cầu tính toán thấp hơn
- **Thời gian phản hồi nhanh hơn**: Giảm độ trễ cho các ứng dụng thời gian thực  
- **Hiệu quả chi phí**: Cần ít cơ sở hạ tầng hơn
- **Bảo mật**: Có thể chạy cục bộ mà không cần truyền dữ liệu
- **Tùy chỉnh**: Dễ dàng tinh chỉnh cho các lĩnh vực cụ thể

### Tại sao SLMs hoạt động tốt với MCP

SLMs kết hợp với MCP tạo ra một sự kết hợp mạnh mẽ, nơi khả năng suy luận của mô hình được tăng cường bởi các công cụ bên ngoài, bù đắp cho số lượng tham số nhỏ hơn bằng cách tăng cường chức năng.

## Tổng quan về Python MCP SDK

Python MCP SDK cung cấp nền tảng để xây dựng các ứng dụng hỗ trợ MCP. SDK bao gồm:

- **Thư viện khách**: Để kết nối với các máy chủ MCP
- **Khung máy chủ**: Để tạo các máy chủ MCP tùy chỉnh
- **Trình xử lý giao thức**: Để quản lý giao tiếp
- **Tích hợp công cụ**: Để thực hiện các chức năng bên ngoài

## Triển khai thực tế: Khách hàng MCP Phi-4

Hãy khám phá một triển khai thực tế sử dụng mô hình mini Phi-4 của Microsoft tích hợp với các khả năng MCP.

### Tổng quan về Kiến trúc MCP

MCP tuân theo kiến trúc **máy khách-máy chủ**, nơi một máy chủ MCP (một ứng dụng AI như Claude Code hoặc Claude Desktop) thiết lập kết nối với một hoặc nhiều máy chủ MCP. Máy chủ MCP thực hiện điều này bằng cách tạo một khách hàng MCP cho mỗi máy chủ MCP.

#### Các thành phần chính

- **Máy chủ MCP**: Ứng dụng AI điều phối và quản lý một hoặc nhiều khách hàng MCP
- **Khách hàng MCP**: Một thành phần duy trì kết nối với máy chủ MCP và nhận ngữ cảnh từ máy chủ MCP để máy chủ MCP sử dụng
- **Máy chủ MCP**: Một chương trình cung cấp ngữ cảnh cho các khách hàng MCP

#### Kiến trúc hai lớp

MCP bao gồm hai lớp riêng biệt:

**Lớp dữ liệu**: Xác định giao thức dựa trên JSON-RPC cho giao tiếp máy khách-máy chủ, bao gồm:
- Quản lý vòng đời (khởi tạo kết nối, đàm phán khả năng)
- Các nguyên thủy cốt lõi (công cụ, tài nguyên, lời nhắc)
- Các tính năng của khách hàng (lấy mẫu, thu thập thông tin, ghi nhật ký)
- Các tính năng tiện ích (thông báo, theo dõi tiến độ)

**Lớp truyền tải**: Xác định các cơ chế và kênh giao tiếp:
- **Truyền tải STDIO**: Sử dụng luồng đầu vào/đầu ra tiêu chuẩn cho các quy trình cục bộ (hiệu suất tối ưu, không có chi phí mạng)
- **Truyền tải HTTP có thể truyền trực tuyến**: Sử dụng HTTP POST với các Sự kiện Được Gửi từ Máy chủ tùy chọn cho các máy chủ từ xa (hỗ trợ xác thực HTTP tiêu chuẩn)

```
┌─────────────────────────────────────┐
│           MCP Host                  │
│     (AI Application)                │
└─────────────────┬───────────────────┘
                  │
┌─────────────────┴───────────────────┐
│         MCP Client 1                │
│  ┌─────────────────────────────────┐ │
│  │        Data Layer               │ │
│  │  ├── Lifecycle Management       │ │
│  │  ├── Primitives (Tools/Resources)│ │
│  │  └── Notifications              │ │
│  └─────────────────────────────────┘ │
│  ┌─────────────────────────────────┐ │
│  │      Transport Layer           │ │
│  │  ├── STDIO Transport           │ │
│  │  └── HTTP Transport            │ │
│  └─────────────────────────────────┘ │
└─────────────────┬───────────────────┘
                  │
┌─────────────────┴───────────────────┐
│         MCP Server 1                │
│    (Local/Remote Context Provider)  │
└─────────────────────────────────────┘
```

### Các nguyên thủy cốt lõi của MCP

MCP định nghĩa các nguyên thủy chỉ định các loại thông tin ngữ cảnh có thể được chia sẻ với các ứng dụng AI và phạm vi các hành động có thể được thực hiện.

#### Nguyên thủy của máy chủ

MCP định nghĩa ba nguyên thủy cốt lõi mà máy chủ có thể cung cấp:

**Công cụ**: Các chức năng có thể thực thi mà các ứng dụng AI có thể gọi để thực hiện hành động
- Ví dụ: thao tác tệp, gọi API, truy vấn cơ sở dữ liệu
- Phương thức: `tools/list`, `tools/call`
- Hỗ trợ khám phá và thực thi động

**Tài nguyên**: Các nguồn dữ liệu cung cấp thông tin ngữ cảnh cho các ứng dụng AI
- Ví dụ: nội dung tệp, bản ghi cơ sở dữ liệu, phản hồi API
- Phương thức: `resources/list`, `resources/read`
- Cho phép truy cập dữ liệu có cấu trúc

**Lời nhắc**: Các mẫu có thể tái sử dụng giúp cấu trúc tương tác với các mô hình ngôn ngữ
- Ví dụ: lời nhắc hệ thống, ví dụ few-shot
- Phương thức: `prompts/list`, `prompts/get`
- Chuẩn hóa các mẫu tương tác AI

#### Nguyên thủy của khách hàng

MCP cũng định nghĩa các nguyên thủy mà khách hàng có thể cung cấp để cho phép tương tác phong phú hơn:

**Lấy mẫu**: Cho phép máy chủ yêu cầu hoàn thành mô hình ngôn ngữ từ ứng dụng AI của khách hàng
- Phương thức: `sampling/complete`
- Cho phép phát triển máy chủ độc lập với mô hình
- Cung cấp quyền truy cập vào mô hình ngôn ngữ của máy chủ

**Thu thập thông tin**: Cho phép máy chủ yêu cầu thông tin bổ sung từ người dùng
- Phương thức: `elicitation/request`
- Cho phép tương tác và xác nhận của người dùng
- Hỗ trợ thu thập thông tin động

**Ghi nhật ký**: Cho phép máy chủ gửi thông báo nhật ký đến khách hàng
- Được sử dụng cho mục đích gỡ lỗi và giám sát
- Cung cấp khả năng hiển thị vào hoạt động của máy chủ

### Vòng đời giao thức MCP

#### Khởi tạo và Đàm phán Khả năng

MCP là một giao thức có trạng thái yêu cầu quản lý vòng đời. Quá trình khởi tạo phục vụ một số mục đích quan trọng:

1. **Đàm phán phiên bản giao thức**: Đảm bảo cả máy khách và máy chủ sử dụng các phiên bản giao thức tương thích (ví dụ: "2025-06-18")
2. **Khám phá khả năng**: Mỗi bên tuyên bố các tính năng và nguyên thủy được hỗ trợ
3. **Trao đổi danh tính**: Cung cấp thông tin nhận dạng và phiên bản

```python
# Example initialization request
{
  "jsonrpc": "2.0",
  "id": 1,
  "method": "initialize",
  "params": {
    "protocolVersion": "2025-06-18",
    "capabilities": {
      "elicitation": {},  # Client supports user interaction
      "sampling": {}      # Client can provide LLM completions
    },
    "clientInfo": {
      "name": "edge-ai-client",
      "version": "1.0.0"
    }
  }
}
```

#### Khám phá và Thực thi Công cụ

Sau khi khởi tạo, khách hàng có thể khám phá và thực thi các công cụ:

```python
# Discover available tools
tools_response = await session.list_tools()

# Execute a tool
result = await session.call_tool(
    "weather_current",
    {
        "location": "San Francisco",
        "units": "imperial"
    }
)
```

#### Thông báo thời gian thực

MCP hỗ trợ thông báo thời gian thực cho các cập nhật động:

```python
# Server sends notification when tools change
{
  "jsonrpc": "2.0",
  "method": "notifications/tools/list_changed"
}

# Client responds by refreshing tool list
await session.list_tools()  # Get updated tools
```

## Bắt đầu: Hướng dẫn từng bước

### Bước 1: Thiết lập môi trường

Cài đặt các phụ thuộc cần thiết:
```bash
pip install fastmcp mcp-python-client openai requests pyautogui Pillow
```

### Bước 2: Cấu hình cơ bản

Thiết lập các biến môi trường của bạn:
```python
# System Configuration
SYSTEM_PROMPT = "You are an AI assistant with some tools."

# Ollama Configuration (Local)
OLLAMA_URL = "http://localhost:11434/api/chat"
OLLAMA_MODEL_ID = "phi4-mini:3.8b-fp16"

# vLLM Configuration (Server)
VLLM_URL = "http://localhost:8000/v1"
VLLM_MODEL_ID = "microsoft/Phi-4-mini-instruct"
```

### Bước 3: Chạy Khách hàng MCP đầu tiên của bạn

**Thiết lập Ollama cơ bản:**
```bash
python ghmodel_mcp_demo.py
```

**Sử dụng Backend vLLM:**
```bash
python ghmodel_mcp_demo.py --env vllm
```

**Kết nối Sự kiện Được Gửi từ Máy chủ:**
```bash
python ghmodel_mcp_demo.py --run sse
```

**Máy chủ MCP tùy chỉnh:**
```bash
python ghmodel_mcp_demo.py --server /path/to/server.py
```

### Bước 4: Sử dụng theo chương trình

```python
import asyncio
from ghmodel_mcp_demo import OllamaClient, Phi4MiniMCPClient

async def automated_interaction():
    # Configure MCP server parameters
    server_params = StdioServerParameters(
        command="npx",
        args=["@playwright/mcp@latest"],
        env=None,
    )
    
    # Create MCP client and process tools
    async with Phi4MiniMCPClient(server_params) as mcp_client:
        tools = await process_mcp_tools(mcp_client)
        llm_client = OllamaClient()
        
        # Generate response with tool capabilities
        response, messages = await llm_client.generate_response(
            "Help me automate a web task",
            tools
        )
        return response

# Execute the automation
result = asyncio.run(automated_interaction())
print(result)
```

## Các tính năng nâng cao

### Hỗ trợ nhiều Backend

Triển khai hỗ trợ cả backend Ollama và vLLM, cho phép bạn lựa chọn dựa trên yêu cầu của mình:

- **Ollama**: Tốt hơn cho phát triển và thử nghiệm cục bộ
- **vLLM**: Tối ưu hóa cho sản xuất và các kịch bản thông lượng cao

### Các giao thức kết nối linh hoạt

Hai chế độ kết nối được hỗ trợ:

**Chế độ STDIO**: Giao tiếp trực tiếp giữa các quy trình
- Độ trễ thấp hơn
- Phù hợp cho các công cụ cục bộ
- Thiết lập đơn giản

**Chế độ SSE**: Truyền trực tuyến dựa trên HTTP
- Có khả năng mạng
- Tốt hơn cho các hệ thống phân tán
- Cập nhật thời gian thực

### Khả năng tích hợp công cụ

Hệ thống có thể tích hợp với nhiều công cụ:
- Tự động hóa web (Playwright)
- Thao tác tệp
- Tương tác API
- Lệnh hệ thống
- Các chức năng tùy chỉnh

## Xử lý lỗi và Thực hành tốt nhất

### Quản lý lỗi toàn diện

Triển khai bao gồm xử lý lỗi mạnh mẽ cho:

**Lỗi kết nối:**
- Sự cố máy chủ MCP
- Hết thời gian mạng
- Vấn đề kết nối

**Lỗi thực thi công cụ:**
- Thiếu công cụ
- Xác thực tham số
- Lỗi thực thi

**Lỗi xử lý phản hồi:**
- Vấn đề phân tích JSON
- Không nhất quán định dạng
- Dị thường phản hồi LLM

### Thực hành tốt nhất

1. **Quản lý tài nguyên**: Sử dụng trình quản lý ngữ cảnh không đồng bộ
2. **Xử lý lỗi**: Triển khai các khối try-catch toàn diện
3. **Ghi nhật ký**: Bật các mức ghi nhật ký phù hợp
4. **Bảo mật**: Xác thực đầu vào và làm sạch đầu ra
5. **Hiệu suất**: Sử dụng kết nối nhóm và bộ nhớ đệm

## Ứng dụng thực tế

### Tự động hóa web
```python
# Example: Automated web testing
async def web_automation_example():
    tools = await setup_playwright_tools()
    response = await llm_client.generate_response(
        "Navigate to example.com and take a screenshot",
        tools
    )
```

### Xử lý dữ liệu
```python
# Example: File analysis
async def data_processing_example():
    tools = await setup_file_tools()
    response = await llm_client.generate_response(
        "Analyze the CSV file and generate a summary report",
        tools
    )
```

### Tích hợp API
```python
# Example: API interactions
async def api_integration_example():
    tools = await setup_api_tools()
    response = await llm_client.generate_response(
        "Fetch weather data and create a forecast summary",
        tools
    )
```

## Tối ưu hóa hiệu suất

### Quản lý bộ nhớ
- Xử lý lịch sử tin nhắn hiệu quả
- Dọn dẹp tài nguyên đúng cách
- Kết nối nhóm

### Tối ưu hóa mạng
- Hoạt động HTTP không đồng bộ
- Thời gian chờ có thể cấu hình
- Khôi phục lỗi một cách nhẹ nhàng

### Xử lý đồng thời
- I/O không chặn
- Thực thi công cụ song song
- Mẫu không đồng bộ hiệu quả

## Cân nhắc về bảo mật

### Bảo vệ dữ liệu
- Quản lý khóa API an toàn
- Xác thực đầu vào
- Làm sạch đầu ra

### Bảo mật mạng
- Hỗ trợ HTTPS
- Mặc định điểm cuối cục bộ
- Xử lý token an toàn

### An toàn thực thi
- Lọc công cụ
- Môi trường được cách ly
- Ghi nhật ký kiểm toán

## Hệ sinh thái MCP và Phát triển

### Phạm vi dự án MCP

Hệ sinh thái Giao thức Ngữ cảnh Mô hình bao gồm một số thành phần chính:

- **[Đặc tả MCP](https://modelcontextprotocol.io/specification/latest)**: Đặc tả chính thức phác thảo các yêu cầu triển khai cho máy khách và máy chủ
- **[SDK MCP](https://modelcontextprotocol.io/docs/sdk)**: SDK cho các ngôn ngữ lập trình khác nhau triển khai MCP
- **Công cụ Phát triển MCP**: Công cụ để phát triển máy chủ và máy khách MCP, bao gồm [MCP Inspector](https://github.com/modelcontextprotocol/inspector)
- **[Triển khai Máy chủ Tham chiếu MCP](https://github.com/modelcontextprotocol/servers)**: Triển khai tham chiếu của các máy chủ MCP

### Bắt đầu với Phát triển MCP

Để bắt đầu xây dựng với MCP:

**Xây dựng Máy chủ**: [Tạo máy chủ MCP](https://modelcontextprotocol.io/docs/develop/build-server) để cung cấp dữ liệu và công cụ của bạn

**Xây dựng Máy khách**: [Phát triển ứng dụng](https://modelcontextprotocol.io/docs/develop/build-client) kết nối với máy chủ MCP

**Học các khái niệm**: [Hiểu các khái niệm cốt lõi](https://modelcontextprotocol.io/docs/learn/architecture) và kiến trúc của MCP

## Kết luận

SLMs tích hợp với MCP đại diện cho một sự thay đổi mô hình trong phát triển ứng dụng AI. Bằng cách kết hợp hiệu quả của các mô hình nhỏ với sức mạnh của các công cụ bên ngoài, các nhà phát triển có thể tạo ra các hệ thống thông minh vừa hiệu quả về tài nguyên vừa có khả năng cao.

Giao thức Ngữ cảnh Mô hình cung cấp một cách tiêu chuẩn hóa để kết nối các ứng dụng AI với các hệ thống bên ngoài, giống như USB-C cung cấp một tiêu chuẩn kết nối phổ biến cho các thiết bị điện tử. Sự tiêu chuẩn hóa này cho phép:

- **Tích hợp liền mạch**: Kết nối các mô hình AI với các nguồn dữ liệu và công cụ đa dạng
- **Phát triển hệ sinh thái**: Xây dựng một lần, sử dụng trên nhiều ứng dụng AI
- **Khả năng nâng cao**: Tăng cường SLMs với chức năng bên ngoài
- **Cập nhật thời gian thực**: Hỗ trợ các ứng dụng AI động, phản hồi nhanh

Những điểm chính:
- MCP là một tiêu chuẩn mở kết nối các ứng dụng AI và hệ thống bên ngoài
- Giao thức hỗ trợ công cụ, tài nguyên, và lời nhắc như các nguyên thủy cốt lõi
- Thông báo thời gian thực cho phép các ứng dụng động, phản hồi nhanh
- Quản lý vòng đời và xử lý lỗi đúng cách là rất cần thiết cho việc sử dụng trong sản xuất
- Hệ sinh thái cung cấp các SDK toàn diện và công cụ phát triển

## Tài liệu tham khảo và Đọc thêm

### Tài liệu chính thức MCP

- **[Trang chính thức Giao thức Ngữ cảnh Mô hình](https://modelcontextprotocol.io/)** - Tài liệu và đặc tả đầy đủ
- **[Hướng dẫn Bắt đầu MCP](https://modelcontextprotocol.io/docs/getting-started/intro)** - Giới thiệu và các khái niệm cốt lõi
- **[Tổng quan Kiến trúc MCP](https://modelcontextprotocol.io/docs/learn/architecture)** - Kiến trúc kỹ thuật chi tiết
- **[Đặc tả MCP](https://modelcontextprotocol.io/specification/latest)** - Đặc tả giao thức chính thức
- **[Tài liệu SDK MCP](https://modelcontextprotocol.io/docs/sdk)** - Hướng dẫn SDK theo ngôn ngữ cụ thể

### Tài nguyên phát triển

- **[MCP cho người mới bắt đầu](https://aka.ms/mcp-for-beginners)** - Hướng dẫn toàn diện cho người mới bắt đầu về Giao thức Ngữ cảnh Mô hình
- **[Tổ chức GitHub MCP](https://github.com/modelcontextprotocol)** - Kho lưu trữ và ví dụ chính thức
- **[Kho lưu trữ Máy chủ MCP](https://github.com/modelcontextprotocol/servers)** - Triển khai máy chủ tham chiếu
- **[MCP Inspector](https://github.com/modelcontextprotocol/inspector)** - Công cụ phát triển và gỡ lỗi
- **[Hướng dẫn Xây dựng Máy chủ MCP](https://modelcontextprotocol.io/docs/develop/build-server)** - Hướng dẫn phát triển máy chủ
- **[Hướng dẫn Xây dựng Máy khách MCP](https://modelcontextprotocol.io/docs/develop/build-client)** - Hướng dẫn phát triển máy khách

### Mô hình Ngôn ngữ Nhỏ và AI Biên

- **[Mô hình Phi của Microsoft](https://aka.ms/ph
- **[Tài liệu Ollama](https://ollama.ai/docs)** - Nền tảng triển khai LLM cục bộ  
- **[Tài liệu vLLM](https://docs.vllm.ai/)** - Dịch vụ LLM hiệu suất cao  

### Tiêu chuẩn kỹ thuật và giao thức  

- **[Đặc tả JSON-RPC 2.0](https://www.jsonrpc.org/)** - Giao thức RPC cơ bản được sử dụng bởi MCP  
- **[JSON Schema](https://json-schema.org/)** - Tiêu chuẩn định nghĩa schema cho các công cụ MCP  
- **[Đặc tả OpenAPI](https://swagger.io/specification/)** - Tiêu chuẩn tài liệu API  
- **[Server-Sent Events (SSE)](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events)** - Tiêu chuẩn web cho cập nhật thời gian thực  

### Phát triển tác nhân AI  

- **[Microsoft Agent Framework](https://github.com/microsoft/agent-framework)** - Phát triển tác nhân sẵn sàng cho sản xuất  
- **[Tài liệu LangChain](https://docs.langchain.com/)** - Khung tích hợp tác nhân và công cụ  
- **[Semantic Kernel](https://learn.microsoft.com/en-us/semantic-kernel/)** - SDK điều phối AI của Microsoft  

### Báo cáo ngành và nghiên cứu  

- **[Thông báo về Giao thức Ngữ cảnh Mô hình của Anthropic](https://www.anthropic.com/news/model-context-protocol)** - Giới thiệu MCP ban đầu  
- **[Khảo sát về Mô hình Ngôn ngữ Nhỏ](https://arxiv.org/abs/2410.20011)** - Khảo sát học thuật về nghiên cứu SLM  
- **[Phân tích thị trường Edge AI](https://www.marketsandmarkets.com/Market-Reports/edge-ai-software-market-74385617.html)** - Xu hướng và dự báo ngành  
- **[Thực hành tốt nhất trong phát triển tác nhân AI](https://arxiv.org/abs/2309.02427)** - Nghiên cứu về kiến trúc tác nhân  

Phần này cung cấp nền tảng để xây dựng các ứng dụng MCP sử dụng SLM của riêng bạn, mở ra các khả năng tự động hóa, xử lý dữ liệu và tích hợp hệ thống thông minh.  

## ➡️ Tiếp theo  

- [Module 7. Các mẫu Edge AI](../Module07/README.md)  

---

**Tuyên bố miễn trừ trách nhiệm**:  
Tài liệu này đã được dịch bằng dịch vụ dịch thuật AI [Co-op Translator](https://github.com/Azure/co-op-translator). Mặc dù chúng tôi cố gắng đảm bảo độ chính xác, xin lưu ý rằng các bản dịch tự động có thể chứa lỗi hoặc không chính xác. Tài liệu gốc bằng ngôn ngữ bản địa nên được coi là nguồn thông tin chính thức. Đối với thông tin quan trọng, nên sử dụng dịch vụ dịch thuật chuyên nghiệp bởi con người. Chúng tôi không chịu trách nhiệm cho bất kỳ sự hiểu lầm hoặc diễn giải sai nào phát sinh từ việc sử dụng bản dịch này.