<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "44bc28c27b993c5fb988791b7a115705",
  "translation_date": "2025-10-30T11:44:50+00:00",
  "source_file": "Module06/01.IntroduceAgent.md",
  "language_code": "bn"
}
-->
# ржПржЖржЗ ржПржЬрзЗржирзНржЯ ржПржмржВ ржЫрзЛржЯ ржнрж╛рж╖рж╛ ржоржбрзЗрж▓: ржПржХржЯрж┐ ржмрж┐рж╕рзНрждрзГржд ржЧрж╛ржЗржб

## ржнрзВржорж┐ржХрж╛

ржПржЗ ржЯрж┐ржЙржЯрзЛрж░рж┐ржпрж╝рж╛рж▓рзЗ, ржЖржорж░рж╛ ржПржЖржЗ ржПржЬрзЗржирзНржЯ ржПржмржВ ржЫрзЛржЯ ржнрж╛рж╖рж╛ ржоржбрзЗрж▓ (SLMs) ржПржмржВ рждрж╛ржжрзЗрж░ ржЙржирзНржиржд ржмрж╛рж╕рзНрждржмрж╛ржпрж╝ржи ржХрзМрж╢рж▓ржЧрзБрж▓рж┐ ржкрзНрж░рж╛ржирзНржд ржХржорзНржкрж┐ржЙржЯрж┐ржВ ржкрж░рж┐ржмрзЗрж╢рзЗрж░ ржЬржирзНржп ржЕржирзНржмрзЗрж╖ржг ржХрж░ржмред ржЖржорж░рж╛ ржПржЬрзЗржирзНржЯрж┐ржХ ржПржЖржЗ-ржПрж░ ржорзМрж▓рж┐ржХ ржзрж╛рж░ржгрж╛, SLM ржЕржкрзНржЯрж┐ржорж╛ржЗржЬрзЗрж╢ржи ржХрзМрж╢рж▓, рж╕рзАржорж┐ржд рж╕ржорзНржкржжржпрзБржХрзНржд ржбрж┐ржнрж╛ржЗрж╕рзЗрж░ ржЬржирзНржп ржмрзНржпржмрж╣рж╛рж░рж┐ржХ рж╕рзНржерж╛ржкржирж╛рж░ ржХрзМрж╢рж▓ ржПржмржВ ржкрзНрж░рзЛржбрж╛ржХрж╢ржи-рж░рзЗржбрж┐ ржПржЬрзЗржирзНржЯ рж╕рж┐рж╕рзНржЯрзЗржо рждрзИрж░рж┐рж░ ржЬржирзНржп Microsoft Agent Framework ржирж┐ржпрж╝рзЗ ржЖрж▓рзЛржЪржирж╛ ржХрж░ржмред

ржХрзГрждрзНрж░рж┐ржо ржмрзБржжрзНржзрж┐ржорждрзНрждрж╛рж░ ржХрзНрж╖рзЗрждрзНрж░ржЯрж┐ рзирзжрзирзл рж╕рж╛рж▓рзЗ ржПржХржЯрж┐ ржорзМрж▓рж┐ржХ ржкрж░рж┐ржмрж░рзНрждржирзЗрж░ ржоржзрзНржп ржжрж┐ржпрж╝рзЗ ржпрж╛ржЪрзНржЫрзЗред рзирзжрзирзй ржЫрж┐рж▓ ржЪрзНржпрж╛ржЯржмржЯрзЗрж░ ржмржЫрж░ ржПржмржВ рзирзжрзирзк-ржП ржХрзЛ-ржкрж╛ржЗрж▓ржЯрзЗрж░ ржЙрждрзНржерж╛ржи ржжрзЗржЦрж╛ ржЧрзЗржЫрзЗ, рзирзжрзирзл ржПржЖржЗ ржПржЬрзЗржирзНржЯрзЗрж░ тАФ ржмрзБржжрзНржзрж┐ржорж╛ржи рж╕рж┐рж╕рзНржЯрзЗржо ржпрж╛ ржЪрж┐ржирзНрждрж╛ ржХрж░рзЗ, ржпрзБржХрзНрждрж┐ ржХрж░рзЗ, ржкрж░рж┐ржХрж▓рзНржкржирж╛ ржХрж░рзЗ, рж╕рж░ржЮрзНржЬрж╛ржо ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗ ржПржмржВ ржирзНржпрзВржирждржо ржорж╛ржиржм ржЗржиржкрзБржЯ ржжрж┐ржпрж╝рзЗ ржХрж╛ржЬ рж╕ржорзНржкрж╛ржжржи ржХрж░рзЗ, ржпрж╛ ржХрзНрж░ржоржмрж░рзНржзржорж╛ржиржнрж╛ржмрзЗ ржжржХрзНрж╖ ржЫрзЛржЯ ржнрж╛рж╖рж╛ ржоржбрзЗрж▓ ржжрзНржмрж╛рж░рж╛ ржЪрж╛рж▓рж┐рждред Microsoft Agent Framework ржЕржлрж▓рж╛ржЗржи ржкрзНрж░рж╛ржирзНржд-ржнрж┐рждрзНрждрж┐ржХ рж╕ржХрзНрж╖ржорждрж╛рж░ рж╕рж╛ржерзЗ ржПржЗ ржмрзБржжрзНржзрж┐ржорж╛ржи рж╕рж┐рж╕рзНржЯрзЗржоржЧрзБрж▓рж┐ рждрзИрж░рж┐рж░ ржЬржирзНржп ржПржХржЯрж┐ рж╢рзАрж░рзНрж╖рж╕рзНржерж╛ржирзАржпрж╝ рж╕ржорж╛ржзрж╛ржи рж╣рж┐рж╕рж╛ржмрзЗ ржЖржмрж┐рж░рзНржнрзВржд рж╣ржпрж╝рзЗржЫрзЗред

## рж╢рзЗржЦрж╛рж░ рж▓ржХрзНрж╖рзНржп

ржПржЗ ржЯрж┐ржЙржЯрзЛрж░рж┐ржпрж╝рж╛рж▓ рж╢рзЗрж╖рзЗ, ржЖржкржирж┐ рж╕ржХрзНрж╖ржо рж╣ржмрзЗржи:

- ЁЯдЦ ржПржЖржЗ ржПржЬрзЗржирзНржЯ ржПржмржВ ржПржЬрзЗржирзНржЯрж┐ржХ рж╕рж┐рж╕рзНржЯрзЗржорзЗрж░ ржорзМрж▓рж┐ржХ ржзрж╛рж░ржгрж╛ ржмрзБржЭрждрзЗ
- ЁЯФм ржПржЬрзЗржирзНржЯрж┐ржХ ржЕрзНржпрж╛ржкрзНрж▓рж┐ржХрзЗрж╢ржирзЗ ржмржбрж╝ ржнрж╛рж╖рж╛ ржоржбрзЗрж▓рзЗрж░ рждрзБрж▓ржирж╛ржпрж╝ ржЫрзЛржЯ ржнрж╛рж╖рж╛ ржоржбрзЗрж▓рзЗрж░ рж╕рзБржмрж┐ржзрж╛ ржЪрж┐рж╣рзНржирж┐ржд ржХрж░рждрзЗ
- ЁЯЪА ржкрзНрж░рж╛ржирзНржд ржХржорзНржкрж┐ржЙржЯрж┐ржВ ржкрж░рж┐ржмрзЗрж╢рзЗрж░ ржЬржирзНржп ржЙржирзНржиржд SLM рж╕рзНржерж╛ржкржирж╛рж░ ржХрзМрж╢рж▓ рж╢рж┐ржЦрждрзЗ
- ЁЯУ▒ ржмрж╛рж╕рзНрждржм-ржЬржЧрждрзЗрж░ ржЕрзНржпрж╛ржкрзНрж▓рж┐ржХрзЗрж╢ржирзЗрж░ ржЬржирзНржп ржмрзНржпржмрж╣рж╛рж░рж┐ржХ SLM-ржЪрж╛рж▓рж┐ржд ржПржЬрзЗржирзНржЯ ржмрж╛рж╕рзНрждржмрж╛ржпрж╝ржи ржХрж░рждрзЗ
- ЁЯПЧя╕П Microsoft Agent Framework ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗ ржкрзНрж░рзЛржбрж╛ржХрж╢ржи-рж░рзЗржбрж┐ ржПржЬрзЗржирзНржЯ рждрзИрж░рж┐ ржХрж░рждрзЗ
- ЁЯМР рж╕рзНржерж╛ржирзАржпрж╝ LLM ржПржмржВ SLM ржЗржирзНржЯрж┐ржЧрзНрж░рзЗрж╢ржирзЗрж░ рж╕рж╛ржерзЗ ржЕржлрж▓рж╛ржЗржи ржкрзНрж░рж╛ржирзНржд-ржнрж┐рждрзНрждрж┐ржХ ржПржЬрзЗржирзНржЯ рж╕рзНржерж╛ржкржи ржХрж░рждрзЗ
- ЁЯФз ржкрзНрж░рж╛ржирзНржд рж╕рзНржерж╛ржкржирж╛рж░ ржЬржирзНржп Foundry Local-ржПрж░ рж╕рж╛ржерзЗ Microsoft Agent Framework ржЗржирзНржЯрж┐ржЧрзНрж░рзЗржЯ ржХрж░рждрзЗ

## ржПржЖржЗ ржПржЬрзЗржирзНржЯ ржмрзЛржЭрж╛: ржнрж┐рждрзНрждрж┐ ржПржмржВ рж╢рзНрж░рзЗржгрзАржмрж┐ржнрж╛ржЧ

### рж╕ржВржЬрзНржЮрж╛ ржПржмржВ ржорзВрж▓ ржзрж╛рж░ржгрж╛

ржПржХржЯрж┐ ржХрзГрждрзНрж░рж┐ржо ржмрзБржжрзНржзрж┐ржорждрзНрждрж╛ (AI) ржПржЬрзЗржирзНржЯ ржПржоржи ржПржХржЯрж┐ рж╕рж┐рж╕рзНржЯрзЗржо ржмрж╛ ржкрзНрж░рзЛржЧрзНрж░рж╛ржоржХрзЗ ржмрзЛржЭрж╛ржпрж╝ ржпрж╛ ржмрзНржпржмрж╣рж╛рж░ржХрж╛рж░рзА ржмрж╛ ржЕржирзНржп рж╕рж┐рж╕рзНржЯрзЗржорзЗрж░ ржкржХрзНрж╖ ржерзЗржХрзЗ рж╕рзНржмржпрж╝ржВржХрзНрж░рж┐ржпрж╝ржнрж╛ржмрзЗ ржХрж╛ржЬ рж╕ржорзНржкрж╛ржжржи ржХрж░рждрзЗ рж╕ржХрзНрж╖ржо рж╣ржпрж╝, рждрж╛рж░ ржХрж░рзНржоржкрзНрж░ржмрж╛рж╣ ржбрж┐ржЬрж╛ржЗржи ржХрж░рзЗ ржПржмржВ ржЙржкрж▓ржмрзНржз рж╕рж░ржЮрзНржЬрж╛ржоржЧрзБрж▓рж┐ ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗред ржРрждрж┐рж╣рзНржпржмрж╛рж╣рзА ржПржЖржЗ-ржПрж░ ржмрж┐ржкрж░рзАрждрзЗ, ржпрж╛ рж╢рзБржзрзБржорж╛рждрзНрж░ ржЖржкржирж╛рж░ ржкрзНрж░рж╢рзНржирзЗрж░ ржЙрждрзНрждрж░ ржжрзЗржпрж╝, ржПржХржЯрж┐ ржПржЬрзЗржирзНржЯ рж╕рзНржмрж╛ржзрзАржиржнрж╛ржмрзЗ ржХрж╛ржЬ ржХрж░рждрзЗ ржкрж╛рж░рзЗ ржПржмржВ рж▓ржХрзНрж╖рзНржп ржЕрж░рзНржЬржи ржХрж░рждрзЗ ржкрж╛рж░рзЗред

### ржПржЬрзЗржирзНржЯ рж╢рзНрж░рзЗржгрзАржмрж┐ржнрж╛ржЧ ржХрж╛ржарж╛ржорзЛ

ржПржЬрзЗржирзНржЯрзЗрж░ рж╕рзАржорж╛ржирж╛ ржмрзЛржЭрж╛ ржмрж┐ржнрж┐ржирзНржи ржХржорзНржкрж┐ржЙржЯрж┐ржВ ржкрж░рж┐рж╕рзНржерж┐рждрж┐рж░ ржЬржирзНржп ржЙржкржпрзБржХрзНржд ржПржЬрзЗржирзНржЯрзЗрж░ ржзрж░ржи ржирж┐рж░рзНржмрж╛ржЪржи ржХрж░рждрзЗ рж╕рж╛рж╣рж╛ржпрзНржп ржХрж░рзЗ:

- **ЁЯФм рж╕рж╛ржзрж╛рж░ржг рж░рж┐ржлрзНрж▓рзЗржХрзНрж╕ ржПржЬрзЗржирзНржЯ**: ржирж┐ржпрж╝ржо-ржнрж┐рждрзНрждрж┐ржХ рж╕рж┐рж╕рзНржЯрзЗржо ржпрж╛ рждрж╛рзОржХрзНрж╖ржгрж┐ржХ ржЙржкрж▓ржмрзНржзрж┐рждрзЗ рж╕рж╛ржбрж╝рж╛ ржжрзЗржпрж╝ (ржерж╛рж░рзНржорзЛрж╕рзНржЯрзНржпрж╛ржЯ, ржорзМрж▓рж┐ржХ ржЕржЯрзЛржорзЗрж╢ржи)
- **ЁЯУ▒ ржоржбрзЗрж▓-ржнрж┐рждрзНрждрж┐ржХ ржПржЬрзЗржирзНржЯ**: рж╕рж┐рж╕рзНржЯрзЗржо ржпрж╛ ржЕржнрзНржпржирзНрждрж░рзАржг ржЕржмрж╕рзНржерж╛ ржПржмржВ рж╕рзНржорзГрждрж┐ ржмржЬрж╛ржпрж╝ рж░рж╛ржЦрзЗ (рж░рзЛржмржЯ ржнрзНржпрж╛ржХрзБржпрж╝рж╛ржо, ржирзЗржнрж┐ржЧрзЗрж╢ржи рж╕рж┐рж╕рзНржЯрзЗржо)
- **тЪЦя╕П рж▓ржХрзНрж╖рзНржп-ржнрж┐рждрзНрждрж┐ржХ ржПржЬрзЗржирзНржЯ**: рж╕рж┐рж╕рзНржЯрзЗржо ржпрж╛ рж▓ржХрзНрж╖рзНржп ржЕрж░рзНржЬржирзЗрж░ ржЬржирзНржп ржХрзНрж░ржо ржкрж░рж┐ржХрж▓рзНржкржирж╛ ржПржмржВ рж╕ржорзНржкрж╛ржжржи ржХрж░рзЗ (рж░рзБржЯ ржкрзНрж▓рзНржпрж╛ржирж╛рж░, ржЯрж╛рж╕рзНржХ рж╢рж┐ржбрж┐ржЙрж▓рж╛рж░)
- **ЁЯза рж╢рзЗржЦрж╛рж░ ржПржЬрзЗржирзНржЯ**: ржЕржнрж┐ржпрзЛржЬрж┐ржд рж╕рж┐рж╕рзНржЯрзЗржо ржпрж╛ рж╕ржоржпрж╝рзЗрж░ рж╕рж╛ржерзЗ ржХрж░рзНржоржХрзНрж╖ржорждрж╛ ржЙржирзНржиржд ржХрж░рзЗ (ржкрзНрж░рж╕рзНрждрж╛ржмржирж╛ рж╕рж┐рж╕рзНржЯрзЗржо, ржмрзНржпржХрзНрждрж┐ржЧржд рж╕рж╣ржХрж╛рж░рзА)

### ржПржЖржЗ ржПржЬрзЗржирзНржЯрзЗрж░ ржорзВрж▓ рж╕рзБржмрж┐ржзрж╛

ржПржЖржЗ ржПржЬрзЗржирзНржЯржЧрзБрж▓рж┐ ржмрзЗрж╢ ржХржпрж╝рзЗржХржЯрж┐ ржорзМрж▓рж┐ржХ рж╕рзБржмрж┐ржзрж╛ ржкрзНрж░ржжрж╛ржи ржХрж░рзЗ ржпрж╛ рждрж╛ржжрзЗрж░ ржкрзНрж░рж╛ржирзНржд ржХржорзНржкрж┐ржЙржЯрж┐ржВ ржЕрзНржпрж╛ржкрзНрж▓рж┐ржХрзЗрж╢ржирзЗрж░ ржЬржирзНржп ржЖржжрж░рзНрж╢ ржХрж░рзЗ рждрзЛрж▓рзЗ:

**ржЕржкрж╛рж░рзЗрж╢ржирж╛рж▓ рж╕рзНржмрж╛ржпрж╝рждрзНрждрж╢рж╛рж╕ржи**: ржПржЬрзЗржирзНржЯржЧрзБрж▓рж┐ рж╕рзНржмрж╛ржзрзАржиржнрж╛ржмрзЗ ржХрж╛ржЬ рж╕ржорзНржкрж╛ржжржи ржХрж░рзЗ, ржпрж╛ рждрж╛ржжрзЗрж░ рж░рж┐ржпрж╝рзЗрж▓-ржЯрж╛ржЗржо ржЕрзНржпрж╛ржкрзНрж▓рж┐ржХрзЗрж╢ржирзЗрж░ ржЬржирзНржп ржЖржжрж░рзНрж╢ ржХрж░рзЗ рждрзЛрж▓рзЗред рждрж╛рж░рж╛ ржирзНржпрзВржирждржо рждрждрзНрждрзНржмрж╛ржмржзрж╛ржирзЗрж░ ржкрзНрж░ржпрж╝рзЛржЬржи рж╣ржпрж╝ ржПржмржВ ржЕржнрж┐ржпрзЛржЬрж┐ржд ржЖржЪрж░ржг ржмржЬрж╛ржпрж╝ рж░рж╛ржЦрзЗ, ржпрж╛ рж╕рзАржорж┐ржд рж╕ржорзНржкржжржпрзБржХрзНржд ржбрж┐ржнрж╛ржЗрж╕рзЗ ржХржо ржЕржкрж╛рж░рзЗрж╢ржирж╛рж▓ ржУржнрж╛рж░рж╣рзЗржб рж╕рж╣ рж╕рзНржерж╛ржкржи рж╕ржХрзНрж╖ржо ржХрж░рзЗред

**рж╕рзНржерж╛ржкржирж╛рж░ ржиржоржирзАржпрж╝рждрж╛**: ржПржЗ рж╕рж┐рж╕рзНржЯрзЗржоржЧрзБрж▓рж┐ ржЗржирзНржЯрж╛рж░ржирзЗржЯ рж╕ржВржпрзЛржЧрзЗрж░ ржкрзНрж░ржпрж╝рзЛржЬржи ржЫрж╛ржбрж╝рж╛ржЗ ржЕржи-ржбрж┐ржнрж╛ржЗрж╕ ржПржЖржЗ рж╕ржХрзНрж╖ржорждрж╛ ржкрзНрж░ржжрж╛ржи ржХрж░рзЗ, рж╕рзНржерж╛ржирзАржпрж╝ ржкрзНрж░ржХрзНрж░рж┐ржпрж╝рж╛ржХрж░ржгрзЗрж░ ржорж╛ржзрзНржпржорзЗ ржЧрзЛржкржирзАржпрж╝рждрж╛ ржПржмржВ ржирж┐рж░рж╛ржкрждрзНрждрж╛ ржЙржирзНржиржд ржХрж░рзЗ, ржбрзЛржорзЗржи-ржирж┐рж░рзНржжрж┐рж╖рзНржЯ ржЕрзНржпрж╛ржкрзНрж▓рж┐ржХрзЗрж╢ржирзЗрж░ ржЬржирзНржп ржХрж╛рж╕рзНржЯржорж╛ржЗржЬ ржХрж░рж╛ ржпрж╛ржпрж╝ ржПржмржВ ржмрж┐ржнрж┐ржирзНржи ржкрзНрж░рж╛ржирзНржд ржХржорзНржкрж┐ржЙржЯрж┐ржВ ржкрж░рж┐ржмрзЗрж╢рзЗрж░ ржЬржирзНржп ржЙржкржпрзБржХрзНрждред

**ржЦрж░ржЪ ржХрж╛рж░рзНржпржХрж╛рж░рж┐рждрж╛**: ржПржЬрзЗржирзНржЯ рж╕рж┐рж╕рзНржЯрзЗржоржЧрзБрж▓рж┐ ржХрзНрж▓рж╛ржЙржб-ржнрж┐рждрзНрждрж┐ржХ рж╕ржорж╛ржзрж╛ржирзЗрж░ рждрзБрж▓ржирж╛ржпрж╝ ржЦрж░ржЪ-ржХрж╛рж░рзНржпржХрж░ рж╕рзНржерж╛ржкржи ржкрзНрж░ржжрж╛ржи ржХрж░рзЗ, ржкрзНрж░рж╛ржирзНржд ржЕрзНржпрж╛ржкрзНрж▓рж┐ржХрзЗрж╢ржирзЗрж░ ржЬржирзНржп ржХржо ржЕржкрж╛рж░рзЗрж╢ржирж╛рж▓ ржЦрж░ржЪ ржПржмржВ ржХржо ржмрзНржпрж╛ржирзНржбржЙржЗрже ржкрзНрж░ржпрж╝рзЛржЬржирзАржпрж╝рждрж╛ рж╕рж╣ред

## ржЙржирзНржиржд ржЫрзЛржЯ ржнрж╛рж╖рж╛ ржоржбрзЗрж▓ ржХрзМрж╢рж▓

### SLM (ржЫрзЛржЯ ржнрж╛рж╖рж╛ ржоржбрзЗрж▓) ржорзМрж▓рж┐ржХ ржмрж┐рж╖ржпрж╝

ржПржХржЯрж┐ ржЫрзЛржЯ ржнрж╛рж╖рж╛ ржоржбрзЗрж▓ (SLM) ржПржХржЯрж┐ ржнрж╛рж╖рж╛ ржоржбрзЗрж▓ ржпрж╛ ржПржХржЯрж┐ рж╕рж╛ржзрж╛рж░ржг ржнрзЛржХрзНрждрж╛ ржЗрж▓рзЗржХржЯрзНрж░ржирж┐ржХ ржбрж┐ржнрж╛ржЗрж╕рзЗ ржлрж┐ржЯ ржХрж░рждрзЗ ржкрж╛рж░рзЗ ржПржмржВ ржПржХржЯрж┐ ржмрзНржпржмрж╣рж╛рж░ржХрж╛рж░рзАрж░ ржПржЬрзЗржирзНржЯрж┐ржХ ржЕржирзБрж░рзЛржз ржкрж░рж┐ржмрзЗрж╢ржи ржХрж░рж╛рж░ рж╕ржоржпрж╝ ржпржерзЗрж╖рзНржЯ ржХржо ржмрж┐рж▓ржорзНржм рж╕рж╣ ржЕржирзБржорж╛ржи ржХрж░рждрзЗ ржкрж╛рж░рзЗред ржмрзНржпржмрж╣рж╛рж░рж┐ржХржнрж╛ржмрзЗ, SLM рж╕рж╛ржзрж╛рж░ржгржд рззрзж ржмрж┐рж▓рж┐ржпрж╝ржирзЗрж░ ржХржо ржкрзНржпрж╛рж░рж╛ржорж┐ржЯрж╛рж░ рж╕рж╣ ржоржбрзЗрж▓ред

**ржлрж░ржорзНржпрж╛ржЯ ржЖржмрж┐рж╖рзНржХрж╛рж░ ржмрзИрж╢рж┐рж╖рзНржЯрзНржп**: SLM ржмрж┐ржнрж┐ржирзНржи ржХрзЛржпрж╝рж╛ржирзНржЯрж╛ржЗржЬрзЗрж╢ржи рж╕рзНрждрж░, ржХрзНрж░рж╕-ржкрзНрж▓рзНржпрж╛ржЯржлрж░рзНржо рж╕рж╛ржоржЮрзНржЬрж╕рзНржп, рж░рж┐ржпрж╝рзЗрж▓-ржЯрж╛ржЗржо ржХрж░рзНржоржХрзНрж╖ржорждрж╛ ржЕржкрзНржЯрж┐ржорж╛ржЗржЬрзЗрж╢ржи ржПржмржВ ржкрзНрж░рж╛ржирзНржд рж╕рзНржерж╛ржкржи рж╕ржХрзНрж╖ржорждрж╛рж░ ржЬржирзНржп ржЙржирзНржиржд рж╕ржорж░рзНржержи ржкрзНрж░ржжрж╛ржи ржХрж░рзЗред ржмрзНржпржмрж╣рж╛рж░ржХрж╛рж░рзАрж░рж╛ рж╕рзНржерж╛ржирзАржпрж╝ ржкрзНрж░ржХрзНрж░рж┐ржпрж╝рж╛ржХрж░ржг ржПржмржВ ржмрзНрж░рж╛ржЙржЬрж╛рж░-ржнрж┐рждрзНрждрж┐ржХ рж╕рзНржерж╛ржкржирж╛рж░ ржЬржирзНржп WebGPU рж╕ржорж░рзНржержирзЗрж░ ржорж╛ржзрзНржпржорзЗ ржЙржирзНржиржд ржЧрзЛржкржирзАржпрж╝рждрж╛ ржЕрзНржпрж╛ржХрзНрж╕рзЗрж╕ ржХрж░рждрзЗ ржкрж╛рж░рзЗржиред

**ржХрзЛржпрж╝рж╛ржирзНржЯрж╛ржЗржЬрзЗрж╢ржи рж╕рзНрждрж░ рж╕ржВржЧрзНрж░рж╣**: ржЬржиржкрзНрж░рж┐ржпрж╝ SLM ржлрж░ржорзНржпрж╛ржЯржЧрзБрж▓рж┐рж░ ржоржзрзНржпрзЗ рж░ржпрж╝рзЗржЫрзЗ Q4_K_M ржорзЛржмрж╛ржЗрж▓ ржЕрзНржпрж╛ржкрзНрж▓рж┐ржХрзЗрж╢ржирзЗ ржнрж╛рж░рж╕рж╛ржорзНржпржкрзВрж░рзНржг ржХржорзНржкрзНрж░рзЗрж╢ржирзЗрж░ ржЬржирзНржп, Q5_K_S рж╕рж┐рж░рж┐ржЬ ржЧрзБржгржорж╛ржи-ржХрзЗржирзНржжрзНрж░рж┐ржХ ржкрзНрж░рж╛ржирзНржд рж╕рзНржерж╛ржкржирж╛рж░ ржЬржирзНржп, Q8_0 рж╢ржХрзНрждрж┐рж╢рж╛рж▓рзА ржкрзНрж░рж╛ржирзНржд ржбрж┐ржнрж╛ржЗрж╕рзЗ ржкрзНрж░рж╛ржпрж╝-ржЖрж╕рж▓ ржирж┐рж░рзНржнрзБрж▓рждрж╛рж░ ржЬржирзНржп ржПржмржВ Q2_K-ржПрж░ ржорждрзЛ ржкрж░рзАржХрзНрж╖рж╛ржорзВрж▓ржХ ржлрж░ржорзНржпрж╛ржЯржЧрзБрж▓рж┐ ржЕрждрж┐-ржХржо рж╕ржорзНржкржж ржкрж░рж┐рж╕рзНржерж┐рждрж┐рж░ ржЬржирзНржпред

### GGUF (ржЬрзЗржирж╛рж░рзЗрж▓ GGML ржЗржЙржирж┐ржнрж╛рж░рзНрж╕рж╛рж▓ ржлрж░ржорзНржпрж╛ржЯ) SLM рж╕рзНржерж╛ржкржирж╛рж░ ржЬржирзНржп

GGUF CPU ржПржмржВ ржкрзНрж░рж╛ржирзНржд ржбрж┐ржнрж╛ржЗрж╕рзЗ ржХрзЛржпрж╝рж╛ржирзНржЯрж╛ржЗржЬржб SLM рж╕рзНржерж╛ржкржирзЗрж░ ржЬржирзНржп ржкрзНрж░рж╛ржержорж┐ржХ ржлрж░ржорзНржпрж╛ржЯ рж╣рж┐рж╕рж╛ржмрзЗ ржХрж╛ржЬ ржХрж░рзЗ, ржмрж┐рж╢рзЗрж╖ржнрж╛ржмрзЗ ржПржЬрзЗржирзНржЯрж┐ржХ ржЕрзНржпрж╛ржкрзНрж▓рж┐ржХрзЗрж╢ржирзЗрж░ ржЬржирзНржп ржЕржкрзНржЯрж┐ржорж╛ржЗржЬ ржХрж░рж╛ рж╣ржпрж╝рзЗржЫрзЗ:

**ржПржЬрзЗржирзНржЯ-ржЕржкрзНржЯрж┐ржорж╛ржЗржЬржб ржмрзИрж╢рж┐рж╖рзНржЯрзНржп**: ржлрж░ржорзНржпрж╛ржЯржЯрж┐ SLM рж░рзВржкрж╛ржирзНрждрж░ ржПржмржВ рж╕рзНржерж╛ржкржирж╛рж░ ржЬржирзНржп ржмрзНржпрж╛ржкржХ рж╕ржВрж╕рзНржерж╛ржи ржкрзНрж░ржжрж╛ржи ржХрж░рзЗ, ржЙржирзНржиржд рж╕рж░ржЮрзНржЬрж╛ржо ржХрж▓рж┐ржВ, ржХрж╛ржарж╛ржорзЛржЧржд ржЖржЙржЯржкрзБржЯ ржкрзНрж░ржЬржирзНржо ржПржмржВ ржорж╛рж▓рзНржЯрж┐-ржЯрж╛рж░рзНржи ржХржерзЛржкржХржержирзЗрж░ ржЬржирзНржп рж╕ржорж░рзНржержи рж╕рж╣ред ржХрзНрж░рж╕-ржкрзНрж▓рзНржпрж╛ржЯржлрж░рзНржо рж╕рж╛ржоржЮрзНржЬрж╕рзНржп ржмрж┐ржнрж┐ржирзНржи ржкрзНрж░рж╛ржирзНржд ржбрж┐ржнрж╛ржЗрж╕рзЗ ржзрж╛рж░рж╛ржмрж╛рж╣рж┐ржХ ржПржЬрзЗржирзНржЯ ржЖржЪрж░ржг ржирж┐рж╢рзНржЪрж┐ржд ржХрж░рзЗред

**ржХрж░рзНржоржХрзНрж╖ржорждрж╛ ржЕржкрзНржЯрж┐ржорж╛ржЗржЬрзЗрж╢ржи**: GGUF ржПржЬрзЗржирзНржЯ ржХрж░рзНржоржкрзНрж░ржмрж╛рж╣рзЗрж░ ржЬржирзНржп ржжржХрзНрж╖ ржорзЗржорж░рж┐ ржмрзНржпржмрж╣рж╛рж░ рж╕ржХрзНрж╖ржо ржХрж░рзЗ, ржорж╛рж▓рзНржЯрж┐-ржПржЬрзЗржирзНржЯ рж╕рж┐рж╕рзНржЯрзЗржорзЗрж░ ржЬржирзНржп ржЧрждрж┐рж╢рзАрж▓ ржоржбрзЗрж▓ рж▓рзЛржбрж┐ржВ рж╕ржорж░рзНржержи ржХрж░рзЗ ржПржмржВ рж░рж┐ржпрж╝рзЗрж▓-ржЯрж╛ржЗржо ржПржЬрзЗржирзНржЯ ржЗржирзНржЯрж╛рж░ржЕрзНржпрж╛ржХрж╢ржирзЗрж░ ржЬржирзНржп ржЕржкрзНржЯрж┐ржорж╛ржЗржЬржб ржЕржирзБржорж╛ржи ржкрзНрж░ржжрж╛ржи ржХрж░рзЗред

### ржкрзНрж░рж╛ржирзНржд-ржЕржкрзНржЯрж┐ржорж╛ржЗржЬржб SLM ржлрзНрж░рзЗржоржУржпрж╝рж╛рж░рзНржХ

#### ржПржЬрзЗржирзНржЯрзЗрж░ ржЬржирзНржп Llama.cpp ржЕржкрзНржЯрж┐ржорж╛ржЗржЬрзЗрж╢ржи

Llama.cpp ржПржЬрзЗржирзНржЯрж┐ржХ SLM рж╕рзНржерж╛ржкржирж╛рж░ ржЬржирзНржп ржмрж┐рж╢рзЗрж╖ржнрж╛ржмрзЗ ржЕржкрзНржЯрж┐ржорж╛ржЗржЬржб ржХрзЛржпрж╝рж╛ржирзНржЯрж╛ржЗржЬрзЗрж╢ржи ржХрзМрж╢рж▓ ржкрзНрж░ржжрж╛ржи ржХрж░рзЗ:

**ржПржЬрзЗржирзНржЯ-ржирж┐рж░рзНржжрж┐рж╖рзНржЯ ржХрзЛржпрж╝рж╛ржирзНржЯрж╛ржЗржЬрзЗрж╢ржи**: ржлрзНрж░рзЗржоржУржпрж╝рж╛рж░рзНржХ Q4_0 (ржорзЛржмрж╛ржЗрж▓ ржПржЬрзЗржирзНржЯ рж╕рзНржерж╛ржкржирж╛рж░ ржЬржирзНржп рзнрзл% ржЖржХрж╛рж░ рж╣рзНрж░рж╛рж╕ рж╕рж╣ ржЕржкрзНржЯрж┐ржорж╛рж▓), Q5_1 (ржкрзНрж░рж╛ржирзНржд ржЕржирзБржорж╛ржирзЗрж░ ржПржЬрзЗржирзНржЯрзЗрж░ ржЬржирзНржп ржЧрзБржгржорж╛ржи-ржХржорзНржкрзНрж░рзЗрж╢ржи ржнрж╛рж░рж╕рж╛ржорзНржп) ржПржмржВ Q8_0 (ржкрзНрж░рзЛржбрж╛ржХрж╢ржи ржПржЬрзЗржирзНржЯ рж╕рж┐рж╕рзНржЯрзЗржорзЗрж░ ржЬржирзНржп ржкрзНрж░рж╛ржпрж╝-ржЖрж╕рж▓ ржЧрзБржгржорж╛ржи) рж╕ржорж░рзНржержи ржХрж░рзЗред ржЙржирзНржиржд ржлрж░ржорзНржпрж╛ржЯржЧрзБрж▓рж┐ ржЪрж░ржо ржкрзНрж░рж╛ржирзНржд ржкрж░рж┐рж╕рзНржерж┐рждрж┐рж░ ржЬржирзНржп ржЕрждрж┐-рж╕ржВржХрзБржЪрж┐ржд ржПржЬрзЗржирзНржЯ рж╕ржХрзНрж╖ржо ржХрж░рзЗред

**ржмрж╛рж╕рзНрждржмрж╛ржпрж╝ржи рж╕рзБржмрж┐ржзрж╛**: SIMD рждрзНржмрж░ржг рж╕рж╣ CPU-ржЕржкрзНржЯрж┐ржорж╛ржЗржЬржб ржЕржирзБржорж╛ржи ржорзЗржорж░рж┐-ржжржХрзНрж╖ ржПржЬрзЗржирзНржЯ ржХрж╛рж░рзНржпржХрж░рзАрждрж╛ ржкрзНрж░ржжрж╛ржи ржХрж░рзЗред x86, ARM ржПржмржВ Apple Silicon ржЖрж░рзНржХрж┐ржЯрзЗржХржЪрж╛рж░рзЗрж░ ржЬрзБржбрж╝рзЗ ржХрзНрж░рж╕-ржкрзНрж▓рзНржпрж╛ржЯржлрж░рзНржо рж╕рж╛ржоржЮрзНржЬрж╕рзНржп рж╕рж╛рж░рзНржмржЬржирзАржи ржПржЬрзЗржирзНржЯ рж╕рзНржерж╛ржкржирж╛рж░ рж╕ржХрзНрж╖ржорждрж╛ рж╕ржХрзНрж╖ржо ржХрж░рзЗред

#### Apple MLX ржлрзНрж░рзЗржоржУржпрж╝рж╛рж░рзНржХ SLM ржПржЬрзЗржирзНржЯрзЗрж░ ржЬржирзНржп

Apple MLX Apple Silicon ржбрж┐ржнрж╛ржЗрж╕рзЗ SLM-ржЪрж╛рж▓рж┐ржд ржПржЬрзЗржирзНржЯрзЗрж░ ржЬржирзНржп ржмрж┐рж╢рзЗрж╖ржнрж╛ржмрзЗ ржбрж┐ржЬрж╛ржЗржи ржХрж░рж╛ ржирзЗржЯрж┐ржн ржЕржкрзНржЯрж┐ржорж╛ржЗржЬрзЗрж╢ржи ржкрзНрж░ржжрж╛ржи ржХрж░рзЗ:

**Apple Silicon ржПржЬрзЗржирзНржЯ ржЕржкрзНржЯрж┐ржорж╛ржЗржЬрзЗрж╢ржи**: ржлрзНрж░рзЗржоржУржпрж╝рж╛рж░рзНржХржЯрж┐ ржорзЗржЯрж╛рж▓ ржкрж╛рж░ржлрж░ржорзНржпрж╛ржирзНрж╕ рж╢рзЗржбрж╛рж░ ржЗржирзНржЯрж┐ржЧрзНрж░рзЗрж╢ржи рж╕рж╣ ржЗржЙржирж┐ржлрж╛ржЗржб ржорзЗржорж░рж┐ ржЖрж░рзНржХрж┐ржЯрзЗржХржЪрж╛рж░, ржПржЬрзЗржирзНржЯ ржЕржирзБржорж╛ржирзЗрж░ ржЬржирзНржп рж╕рзНржмржпрж╝ржВржХрзНрж░рж┐ржпрж╝ ржорж┐рж╢рзНрж░рж┐ржд ржирж┐рж░рзНржнрзБрж▓рждрж╛ ржПржмржВ ржорж╛рж▓рзНржЯрж┐-ржПржЬрзЗржирзНржЯ рж╕рж┐рж╕рзНржЯрзЗржорзЗрж░ ржЬржирзНржп ржЕржкрзНржЯрж┐ржорж╛ржЗржЬржб ржорзЗржорж░рж┐ ржмрзНржпрж╛ржирзНржбржЙржЗрже ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗред M-рж╕рж┐рж░рж┐ржЬ ржЪрж┐ржкрзЗ SLM ржПржЬрзЗржирзНржЯржЧрзБрж▓рж┐ ржЕрж╕рж╛ржзрж╛рж░ржг ржХрж░рзНржоржХрзНрж╖ржорждрж╛ ржжрзЗржЦрж╛ржпрж╝ред

**ржЙржирзНржиржпрж╝ржи ржмрзИрж╢рж┐рж╖рзНржЯрзНржп**: Python ржПржмржВ Swift API рж╕ржорж░рзНржержи рж╕рж╣ ржПржЬрзЗржирзНржЯ-ржирж┐рж░рзНржжрж┐рж╖рзНржЯ ржЕржкрзНржЯрж┐ржорж╛ржЗржЬрзЗрж╢ржи, ржПржЬрзЗржирзНржЯ рж╢рзЗржЦрж╛рж░ ржЬржирзНржп рж╕рзНржмржпрж╝ржВржХрзНрж░рж┐ржпрж╝ ржкрж╛рж░рзНржержХрзНржп ржПржмржВ Apple ржбрзЗржнрзЗрж▓ржкржорзЗржирзНржЯ ржЯрзБрж▓ржЧрзБрж▓рж┐рж░ рж╕рж╛ржерзЗ ржирж┐рж░рзНржмрж┐ржШрзНржи ржЗржирзНржЯрж┐ржЧрзНрж░рзЗрж╢ржи ржмрзНржпрж╛ржкржХ ржПржЬрзЗржирзНржЯ ржЙржирзНржиржпрж╝ржи ржкрж░рж┐ржмрзЗрж╢ ржкрзНрж░ржжрж╛ржи ржХрж░рзЗред

#### ONNX Runtime ржХрзНрж░рж╕-ржкрзНрж▓рзНржпрж╛ржЯржлрж░рзНржо SLM ржПржЬрзЗржирзНржЯрзЗрж░ ржЬржирзНржп

ONNX Runtime ржПржХржЯрж┐ рж╕рж╛рж░рзНржмржЬржирзАржи ржЕржирзБржорж╛ржи ржЗржЮрзНржЬрж┐ржи ржкрзНрж░ржжрж╛ржи ржХрж░рзЗ ржпрж╛ SLM ржПржЬрзЗржирзНржЯржЧрзБрж▓рж┐ржХрзЗ ржмрж┐ржнрж┐ржирзНржи рж╣рж╛рж░рзНржбржУржпрж╝рзНржпрж╛рж░ ржкрзНрж▓рзНржпрж╛ржЯржлрж░рзНржо ржПржмржВ ржЕржкрж╛рж░рзЗржЯрж┐ржВ рж╕рж┐рж╕рзНржЯрзЗржо ржЬрзБржбрж╝рзЗ ржзрж╛рж░рж╛ржмрж╛рж╣рж┐ржХржнрж╛ржмрзЗ ржЪрж╛рж▓рж╛рждрзЗ рж╕ржХрзНрж╖ржо ржХрж░рзЗ:

**рж╕рж╛рж░рзНржмржЬржирзАржи рж╕рзНржерж╛ржкржи**: ONNX Runtime Windows, Linux, macOS, iOS ржПржмржВ Android ржкрзНрж▓рзНржпрж╛ржЯржлрж░рзНржо ржЬрзБржбрж╝рзЗ ржзрж╛рж░рж╛ржмрж╛рж╣рж┐ржХ SLM ржПржЬрзЗржирзНржЯ ржЖржЪрж░ржг ржирж┐рж╢рзНржЪрж┐ржд ржХрж░рзЗред ржПржЗ ржХрзНрж░рж╕-ржкрзНрж▓рзНржпрж╛ржЯржлрж░рзНржо рж╕рж╛ржоржЮрзНржЬрж╕рзНржп ржбрзЗржнрзЗрж▓ржкрж╛рж░ржжрзЗрж░ ржПржХржмрж╛рж░ рж▓рж┐ржЦрждрзЗ ржПржмржВ рж╕рж░рзНржмрждрзНрж░ рж╕рзНржерж╛ржкржи ржХрж░рждрзЗ рж╕ржХрзНрж╖ржо ржХрж░рзЗ, ржорж╛рж▓рзНржЯрж┐-ржкрзНрж▓рзНржпрж╛ржЯржлрж░рзНржо ржЕрзНржпрж╛ржкрзНрж▓рж┐ржХрзЗрж╢ржирзЗрж░ ржЬржирзНржп ржЙржирзНржиржпрж╝ржи ржПржмржВ рж░ржХрзНрж╖ржгрж╛ржмрзЗржХрзНрж╖ржгрзЗрж░ ржУржнрж╛рж░рж╣рзЗржб ржЙрж▓рзНрж▓рзЗржЦржпрзЛржЧрзНржпржнрж╛ржмрзЗ рж╣рзНрж░рж╛рж╕ ржХрж░рзЗред

**рж╣рж╛рж░рзНржбржУржпрж╝рзНржпрж╛рж░ рждрзНржмрж░ржг ржмрж┐ржХрж▓рзНржк**: ржлрзНрж░рзЗржоржУржпрж╝рж╛рж░рзНржХржЯрж┐ ржмрж┐ржнрж┐ржирзНржи рж╣рж╛рж░рзНржбржУржпрж╝рзНржпрж╛рж░ ржХржиржлрж┐ржЧрж╛рж░рзЗрж╢ржирзЗрж░ ржЬржирзНржп ржЕржкрзНржЯрж┐ржорж╛ржЗржЬржб ржПржХрзНрж╕рж┐ржХрж┐ржЙрж╢ржи ржкрзНрж░ржжрж╛ржи ржХрж░рзЗ, ржпрж╛рж░ ржоржзрзНржпрзЗ рж░ржпрж╝рзЗржЫрзЗ CPU (Intel, AMD, ARM), GPU (NVIDIA CUDA, AMD ROCm) ржПржмржВ ржмрж┐рж╢рзЗрж╖рж╛ржпрж╝рж┐ржд ржЕрзНржпрж╛ржХрзНрж╕рж┐рж▓рж╛рж░рзЗржЯрж░ (Intel VPU, Qualcomm NPU)ред SLM ржПржЬрзЗржирзНржЯржЧрзБрж▓рж┐ ржХрзЛржб ржкрж░рж┐ржмрж░рзНрждржи ржЫрж╛ржбрж╝рж╛ржЗ рж╕рзЗрж░рж╛ ржЙржкрж▓ржмрзНржз рж╣рж╛рж░рзНржбржУржпрж╝рзНржпрж╛рж░ ржмрзНржпржмрж╣рж╛рж░ ржХрж░рждрзЗ ржкрж╛рж░рзЗред

**ржкрзНрж░рзЛржбрж╛ржХрж╢ржи-рж░рзЗржбрж┐ ржмрзИрж╢рж┐рж╖рзНржЯрзНржп**: ONNX Runtime ржжрзНрж░рзБржд ржЕржирзБржорж╛ржирзЗрж░ ржЬржирзНржп ржЧрзНрж░рж╛ржл ржЕржкрзНржЯрж┐ржорж╛ржЗржЬрзЗрж╢ржи, рж╕рзАржорж┐ржд рж╕ржорзНржкржж ржкрж░рж┐ржмрзЗрж╢рзЗрж░ ржЬржирзНржп ржорзЗржорж░рж┐ ржмрзНржпржмрж╕рзНржерж╛ржкржирж╛ ржПржмржВ ржХрж░рзНржоржХрзНрж╖ржорждрж╛ ржмрж┐рж╢рзНрж▓рзЗрж╖ржгрзЗрж░ ржЬржирзНржп ржмрзНржпрж╛ржкржХ ржкрзНрж░рзЛржлрж╛ржЗрж▓рж┐ржВ рж╕рж░ржЮрзНржЬрж╛ржо рж╕рж╣ ржкрзНрж░рзЛржбрж╛ржХрж╢ржи ржПржЬрзЗржирзНржЯ рж╕рзНржерж╛ржкржирж╛рж░ ржЬржирзНржп ржкрзНрж░ржпрж╝рзЛржЬржирзАржпрж╝ ржПржирзНржЯрж╛рж░ржкрзНрж░рж╛ржЗржЬ-ржЧрзНрж░рзЗржб ржмрзИрж╢рж┐рж╖рзНржЯрзНржп ржкрзНрж░ржжрж╛ржи ржХрж░рзЗред ржлрзНрж░рзЗржоржУржпрж╝рж╛рж░рзНржХржЯрж┐ Python ржПржмржВ C++ API ржЙржнржпрж╝ржЗ рж╕ржорж░рзНржержи ржХрж░рзЗ ржиржоржирзАржпрж╝ ржЗржирзНржЯрж┐ржЧрзНрж░рзЗрж╢ржирзЗрж░ ржЬржирзНржпред
- ржорж╛ржЗржХрзНрж░рзЛрж╕ржлржЯ ржПржЬрзЗржирзНржЯ ржлрзНрж░рзЗржоржУржпрж╝рж╛рж░рзНржХ ржЗржирзНржЯрж┐ржЧрзНрж░рзЗрж╢ржи ржкрж░рзАржХрзНрж╖рж╛ ржХрж░рзБржи  
- ржЕржлрж▓рж╛ржЗржи ржЕржкрж╛рж░рзЗрж╢ржи рж╕ржХрзНрж╖ржорждрж╛ ржпрж╛ржЪрж╛ржЗ ржХрж░рзБржи  
- ржлрзЗржЗрж▓ржУржнрж╛рж░ ржкрж░рж┐рж╕рзНржерж┐рждрж┐ ржПржмржВ рждрзНрж░рзБржЯрж┐ ржкрж░рж┐ржЪрж╛рж▓ржирж╛ ржкрж░рзАржХрзНрж╖рж╛ ржХрж░рзБржи  
- ржПржЬрзЗржирзНржЯрзЗрж░ рж╕ржорзНржкрзВрж░рзНржг ржХрж╛рж░рзНржпржкрзНрж░ржмрж╛рж╣ ржпрж╛ржЪрж╛ржЗ ржХрж░рзБржи  

**Foundry Local-ржПрж░ рж╕рж╛ржерзЗ рждрзБрж▓ржирж╛**:

| ржмрзИрж╢рж┐рж╖рзНржЯрзНржп | Foundry Local | Ollama |
|---------|---------------|--------|
| **рж▓ржХрзНрж╖рзНржп ржмрзНржпржмрж╣рж╛рж░ ржХрзНрж╖рзЗрждрзНрж░** | ржПржирзНржЯрж╛рж░ржкрзНрж░рж╛ржЗржЬ ржкрзНрж░рзЛржбрж╛ржХрж╢ржи | ржбрзЗржнрзЗрж▓ржкржорзЗржирзНржЯ ржПржмржВ ржХржорж┐ржЙржирж┐ржЯрж┐ |
| **ржоржбрзЗрж▓ ржЗржХрзЛрж╕рж┐рж╕рзНржЯрзЗржо** | ржорж╛ржЗржХрзНрж░рзЛрж╕ржлржЯ-ржХрж┐ржЙрж░рзЗржЯрзЗржб | ржмрж┐рж╕рзНрждрзГржд ржХржорж┐ржЙржирж┐ржЯрж┐ |
| **рж╣рж╛рж░рзНржбржУржпрж╝рзНржпрж╛рж░ ржЕржкрзНржЯрж┐ржорж╛ржЗржЬрзЗрж╢ржи** | рж╕рзНржмржпрж╝ржВржХрзНрж░рж┐ржпрж╝ (CUDA/NPU/CPU) | ржорзНржпрж╛ржирзБржпрж╝рж╛рж▓ ржХржиржлрж┐ржЧрж╛рж░рзЗрж╢ржи |
| **ржПржирзНржЯрж╛рж░ржкрзНрж░рж╛ржЗржЬ ржмрзИрж╢рж┐рж╖рзНржЯрзНржп** | ржмрж┐рж▓рзНржЯ-ржЗржи ржоржирж┐ржЯрж░рж┐ржВ, рж╕рж┐ржХрж┐ржЙрж░рж┐ржЯрж┐ | ржХржорж┐ржЙржирж┐ржЯрж┐ ржЯрзБрж▓рж╕ |
| **ржбрж┐ржкрзНрж▓ржпрж╝ржорзЗржирзНржЯ ржЬржЯрж┐рж▓рждрж╛** | рж╕рж╣ржЬ (winget ржЗржирж╕рзНржЯрж▓) | рж╕рж╣ржЬ (curl ржЗржирж╕рзНржЯрж▓) |
| **API рж╕рж╛ржоржЮрзНржЬрж╕рзНржпрждрж╛** | OpenAI + ржПржХрзНрж╕ржЯрзЗржирж╢ржи | OpenAI рж╕рзНржЯрзНржпрж╛ржирзНржбрж╛рж░рзНржб |
| **рж╕рж╛ржкрзЛрж░рзНржЯ** | ржорж╛ржЗржХрзНрж░рзЛрж╕ржлржЯ ржЕржлрж┐рж╕рж┐ржпрж╝рж╛рж▓ | ржХржорж┐ржЙржирж┐ржЯрж┐-ржбрзНрж░рж┐ржнрзЗржи |
| **рж╕рзЗрж░рж╛ ржмрзНржпржмрж╣рж╛рж░ ржХрзНрж╖рзЗрждрзНрж░** | ржкрзНрж░рзЛржбрж╛ржХрж╢ржи ржПржЬрзЗржирзНржЯ | ржкрзНрж░рзЛржЯрзЛржЯрж╛ржЗржкрж┐ржВ, ржЧржмрзЗрж╖ржгрж╛ |

**ржХржЦржи Ollama ржмрзЗржЫрзЗ ржирзЗржмрзЗржи**:
- **ржбрзЗржнрзЗрж▓ржкржорзЗржирзНржЯ ржПржмржВ ржкрзНрж░рзЛржЯрзЛржЯрж╛ржЗржкрж┐ржВ**: ржмрж┐ржнрж┐ржирзНржи ржоржбрзЗрж▓рзЗрж░ рж╕рж╛ржерзЗ ржжрзНрж░рзБржд ржкрж░рзАржХрзНрж╖рж╛-ржирж┐рж░рзАржХрзНрж╖рж╛  
- **ржХржорж┐ржЙржирж┐ржЯрж┐ ржоржбрзЗрж▓**: рж╕рж░рзНржмрж╢рзЗрж╖ ржХржорж┐ржЙржирж┐ржЯрж┐-ржХржирзНржЯрзНрж░рж┐ржмрж┐ржЙржЯрзЗржб ржоржбрзЗрж▓ржЧрзБрж▓рж┐рждрзЗ ржЕрзНржпрж╛ржХрзНрж╕рзЗрж╕  
- **рж╢рж┐ржХрзНрж╖рж╛ржорзВрж▓ржХ ржмрзНржпржмрж╣рж╛рж░**: AI ржПржЬрзЗржирзНржЯ ржбрзЗржнрзЗрж▓ржкржорзЗржирзНржЯ рж╢рзЗржЦрж╛ ржПржмржВ рж╢рзЗржЦрж╛ржирзЛ  
- **ржЧржмрзЗрж╖ржгрж╛ ржкрзНрж░ржХрж▓рзНржк**: ржмрж┐ржнрж┐ржирзНржи ржоржбрзЗрж▓ ржЕрзНржпрж╛ржХрзНрж╕рзЗрж╕рзЗрж░ ржкрзНрж░ржпрж╝рзЛржЬржирзАржпрж╝ ржПржХрж╛ржбрзЗржорж┐ржХ ржЧржмрзЗрж╖ржгрж╛  
- **ржХрж╛рж╕рзНржЯржо ржоржбрзЗрж▓**: ржХрж╛рж╕рзНржЯржо ржлрж╛ржЗржи-ржЯрж┐ржЙржиржб ржоржбрзЗрж▓ рждрзИрж░рж┐ ржПржмржВ ржкрж░рзАржХрзНрж╖рж╛ ржХрж░рж╛  

### VLLM: ржЙржЪрзНржЪ-ржкрзНрж░ржжрж░рзНрж╢ржи SLM ржПржЬрзЗржирзНржЯ ржЗржиржлрж╛рж░рзЗржирзНрж╕

VLLM (Very Large Language Model inference) ржПржХржЯрж┐ ржЙржЪрзНржЪ-ржерзНрж░рзБржкрзБржЯ, ржорзЗржорзЛрж░рж┐-ржжржХрзНрж╖ ржЗржиржлрж╛рж░рзЗржирзНрж╕ ржЗржЮрзНржЬрж┐ржи ржкрзНрж░ржжрж╛ржи ржХрж░рзЗ ржпрж╛ рж╕рзНржХрзЗрж▓рзЗ ржкрзНрж░рзЛржбрж╛ржХрж╢ржи SLM ржбрж┐ржкрзНрж▓ржпрж╝ржорзЗржирзНржЯрзЗрж░ ржЬржирзНржп ржмрж┐рж╢рзЗрж╖ржнрж╛ржмрзЗ ржЕржкрзНржЯрж┐ржорж╛ржЗржЬ ржХрж░рж╛ рж╣ржпрж╝рзЗржЫрзЗред ржпрзЗржЦрж╛ржирзЗ Foundry Local рж╕рж╣ржЬ ржмрзНржпржмрж╣рж╛рж░рзЗ ржоржирзЛржпрзЛржЧ ржжрзЗржпрж╝ ржПржмржВ Ollama ржХржорж┐ржЙржирж┐ржЯрж┐ ржоржбрзЗрж▓ржЧрзБрж▓рж┐ржХрзЗ ржЧрзБрж░рзБрждрзНржм ржжрзЗржпрж╝, VLLM ржЙржЪрзНржЪ-ржкрзНрж░ржжрж░рзНрж╢ржи ржкрж░рж┐рж╕рзНржерж┐рждрж┐рждрзЗ ржЙрзОржХрзГрж╖рзНржЯ ржпрзЗржЦрж╛ржирзЗ рж╕рж░рзНржмрж╛ржзрж┐ржХ ржерзНрж░рзБржкрзБржЯ ржПржмржВ ржжржХрзНрж╖ рж░рж┐рж╕рзЛрж░рзНрж╕ ржмрзНржпржмрж╣рж╛рж░ ржкрзНрж░ржпрж╝рзЛржЬржиред

**ржорзВрж▓ ржЖрж░рзНржХрж┐ржЯрзЗржХржЪрж╛рж░ ржПржмржВ ржмрзИрж╢рж┐рж╖рзНржЯрзНржп**:
- **PagedAttention**: ржХрж╛рж░рзНржпржХрж░ ржЕрзНржпрж╛ржЯрзЗржирж╢ржи ржЧржгржирж╛рж░ ржЬржирзНржп ржмрж┐ржкрзНрж▓ржмрзА ржорзЗржорзЛрж░рж┐ ржорзНржпрж╛ржирзЗржЬржорзЗржирзНржЯ  
- **Dynamic Batching**: рж╕рж░рзНржмрзЛрждрзНрждржо ржерзНрж░рзБржкрзБржЯрзЗрж░ ржЬржирзНржп ржмрзБржжрзНржзрж┐ржорж╛ржи ржЕржирзБрж░рзЛржз ржмрзНржпрж╛ржЪрж┐ржВ  
- **GPU ржЕржкрзНржЯрж┐ржорж╛ржЗржЬрзЗрж╢ржи**: ржЙржирзНржиржд CUDA ржХрж╛рж░рзНржирзЗрж▓ ржПржмржВ ржЯрзЗржирж╕рж░ ржкрзНржпрж╛рж░рж╛рж▓рзЗрж▓рж┐ржЬржо рж╕рж╛ржкрзЛрж░рзНржЯ  
- **OpenAI рж╕рж╛ржоржЮрзНржЬрж╕рзНржпрждрж╛**: ржирж┐рж░рзНржмрж┐ржШрзНржи ржЗржирзНржЯрж┐ржЧрзНрж░рзЗрж╢ржирзЗрж░ ржЬржирзНржп рж╕ржорзНржкрзВрж░рзНржг API рж╕рж╛ржоржЮрзНржЬрж╕рзНржпрждрж╛  
- **Speculative Decoding**: ржЙржирзНржиржд ржЗржиржлрж╛рж░рзЗржирзНрж╕ рждрзНржмрж░рж╛ржирзНржмрж┐ржд ржХрж░рж╛рж░ ржХрзМрж╢рж▓  
- **Quantization рж╕рж╛ржкрзЛрж░рзНржЯ**: ржорзЗржорзЛрж░рж┐ ржжржХрзНрж╖рждрж╛рж░ ржЬржирзНржп INT4, INT8, ржПржмржВ FP16 ржХрзЛржпрж╝рж╛ржирзНржЯрж╛ржЗржЬрзЗрж╢ржи  

#### ржЗржирж╕рзНржЯрж▓рзЗрж╢ржи ржПржмржВ рж╕рзЗржЯржЖржк

**ржЗржирж╕рзНржЯрж▓рзЗрж╢ржи ржЕржкрж╢ржи**:  
```bash
# Standard installation
pip install vllm

# With additional dependencies for agent frameworks
pip install vllm[agent] openai

# Docker deployment for production
docker pull vllm/vllm-openai:latest

# From source for latest features
git clone https://github.com/vllm-project/vllm.git
cd vllm
pip install -e .
```
  
**ржПржЬрзЗржирзНржЯ ржбрзЗржнрзЗрж▓ржкржорзЗржирзНржЯрзЗрж░ ржЬржирзНржп ржжрзНрж░рзБржд рж╢рзБрж░рзБ**:  
```bash
# Start VLLM server with SLM model
python -m vllm.entrypoints.openai.api_server \
    --model microsoft/Phi-3.5-mini-instruct \
    --trust-remote-code \
    --max-model-len 4096 \
    --gpu-memory-utilization 0.8

# Alternative: Start with Qwen2.5 for lightweight agents
python -m vllm.entrypoints.openai.api_server \
    --model Qwen/Qwen2.5-0.5B-Instruct \
    --trust-remote-code \
    --max-model-len 2048 \
    --tensor-parallel-size 1

# Test API endpoint
curl http://localhost:8000/v1/models

# Test chat completion
curl http://localhost:8000/v1/chat/completions \
    -H "Content-Type: application/json" \
    -d '{
        "model": "microsoft/Phi-3.5-mini-instruct",
        "messages": [{"role": "user", "content": "Hello!"}]
    }'
```
  

#### ржПржЬрзЗржирзНржЯ ржлрзНрж░рзЗржоржУржпрж╝рж╛рж░рзНржХ ржЗржирзНржЯрж┐ржЧрзНрж░рзЗрж╢ржи

**VLLM ржПржмржВ ржорж╛ржЗржХрзНрж░рзЛрж╕ржлржЯ ржПржЬрзЗржирзНржЯ ржлрзНрж░рзЗржоржУржпрж╝рж╛рж░рзНржХ**:  
```python
from microsoft_agent_framework import Agent, Config
import openai
import subprocess
import time
import requests
from typing import Optional, Dict, Any

class VLLMManager:
    def __init__(self, model_name: str, 
                 host: str = "localhost", 
                 port: int = 8000,
                 gpu_memory_utilization: float = 0.8,
                 max_model_len: int = 4096):
        self.model_name = model_name
        self.host = host
        self.port = port
        self.base_url = f"http://{host}:{port}"
        self.gpu_memory_utilization = gpu_memory_utilization
        self.max_model_len = max_model_len
        self.process = None
        self.client = None
        
    def start_server(self) -> bool:
        """Start VLLM server with optimized settings for agents."""
        try:
            cmd = [
                "python", "-m", "vllm.entrypoints.openai.api_server",
                "--model", self.model_name,
                "--host", self.host,
                "--port", str(self.port),
                "--gpu-memory-utilization", str(self.gpu_memory_utilization),
                "--max-model-len", str(self.max_model_len),
                "--trust-remote-code",
                "--disable-log-requests",  # Reduce logging for agents
                "--served-model-name", self.get_served_model_name()
            ]
            
            self.process = subprocess.Popen(cmd, 
                stdout=subprocess.PIPE, 
                stderr=subprocess.PIPE)
            
            # Wait for server to start
            max_retries = 30
            for _ in range(max_retries):
                if self.health_check():
                    self.client = openai.OpenAI(base_url=f"{self.base_url}/v1")
                    return True
                time.sleep(2)
                
            return False
            
        except Exception as e:
            print(f"Failed to start VLLM server: {e}")
            return False
    
    def get_served_model_name(self) -> str:
        """Get a clean model name for serving."""
        return self.model_name.replace("/", "--")
    
    def health_check(self) -> bool:
        """Check if VLLM server is healthy."""
        try:
            response = requests.get(f"{self.base_url}/health", timeout=5)
            return response.status_code == 200
        except:
            return False
    
    def get_openai_client(self) -> openai.OpenAI:
        """Get OpenAI-compatible client for VLLM."""
        if not self.client:
            self.client = openai.OpenAI(base_url=f"{self.base_url}/v1")
        return self.client
    
    def get_model_info(self) -> Dict[str, Any]:
        """Get model information and statistics."""
        try:
            response = requests.get(f"{self.base_url}/v1/models")
            if response.status_code == 200:
                return response.json()
        except:
            pass
        return {}
    
    def shutdown(self):
        """Shutdown VLLM server."""
        if self.process:
            self.process.terminate()
            self.process.wait()

# Initialize VLLM for high-performance agents
vllm_manager = VLLMManager("microsoft/Phi-3.5-mini-instruct")
if vllm_manager.start_server():
    print("VLLM server started successfully")
    
    # Configure agent with VLLM backend
    agent_config = Config(
        name="vllm-performance-agent",
        model_provider="vllm",
        model_id=vllm_manager.get_served_model_name(),
        endpoint=f"{vllm_manager.base_url}/v1",
        api_key="none"  # VLLM doesn't require API key
    )
    
    agent = Agent(config=agent_config)
else:
    print("Failed to start VLLM server")
```
  
**ржЙржЪрзНржЪ-ржерзНрж░рзБржкрзБржЯ ржорж╛рж▓рзНржЯрж┐-ржПржЬрзЗржирзНржЯ рж╕рзЗржЯржЖржк**:  
```python
import asyncio
from concurrent.futures import ThreadPoolExecutor
from microsoft_agent_framework import Agent, Config
import openai

class VLLMHighThroughputManager:
    def __init__(self):
        self.model_configs = {
            "lightweight": {
                "model": "Qwen/Qwen2.5-0.5B-Instruct",
                "port": 8000,
                "max_model_len": 2048,
                "gpu_memory_utilization": 0.3
            },
            "balanced": {
                "model": "microsoft/Phi-3.5-mini-instruct",
                "port": 8001,
                "max_model_len": 4096,
                "gpu_memory_utilization": 0.5
            },
            "capable": {
                "model": "meta-llama/Llama-3.2-3B-Instruct",
                "port": 8002,
                "max_model_len": 8192,
                "gpu_memory_utilization": 0.7
            }
        }
        self.managers = {}
        self.agents = {}
        self.client_pool = {}
        
    async def initialize_all_models(self):
        """Initialize all VLLM models in parallel."""
        initialization_tasks = []
        
        for category, config in self.model_configs.items():
            task = self._initialize_model(category, config)
            initialization_tasks.append(task)
        
        results = await asyncio.gather(*initialization_tasks, return_exceptions=True)
        
        successful_inits = 0
        for i, result in enumerate(results):
            category = list(self.model_configs.keys())[i]
            if isinstance(result, Exception):
                print(f"Failed to initialize {category}: {result}")
            else:
                successful_inits += 1
                print(f"Successfully initialized {category} model")
        
        return successful_inits
    
    async def _initialize_model(self, category: str, config: Dict[str, Any]):
        """Initialize a single VLLM model instance."""
        manager = VLLMManager(
            model_name=config["model"],
            port=config["port"],
            max_model_len=config["max_model_len"],
            gpu_memory_utilization=config["gpu_memory_utilization"]
        )
        
        # Start server in thread to avoid blocking
        loop = asyncio.get_event_loop()
        with ThreadPoolExecutor() as executor:
            success = await loop.run_in_executor(executor, manager.start_server)
        
        if success:
            self.managers[category] = manager
            
            # Create agent
            agent_config = Config(
                name=f"vllm-{category}-agent",
                model_provider="vllm",
                model_id=manager.get_served_model_name(),
                endpoint=f"{manager.base_url}/v1",
                api_key="none"
            )
            
            self.agents[category] = Agent(config=agent_config)
            
            # Create client pool for high throughput
            self.client_pool[category] = [
                openai.OpenAI(base_url=f"{manager.base_url}/v1")
                for _ in range(5)  # 5 clients per model for parallelism
            ]
            
            return True
        else:
            raise Exception(f"Failed to start VLLM server for {category}")
    
    def get_optimal_agent(self, request_complexity: str, current_load: Dict[str, int]) -> str:
        """Select optimal agent based on request complexity and current load."""
        complexity_mapping = {
            "simple": "lightweight",
            "moderate": "balanced", 
            "complex": "capable"
        }
        
        preferred_category = complexity_mapping.get(request_complexity, "balanced")
        
        # Check if preferred agent is available and not overloaded
        if (preferred_category in self.agents and 
            current_load.get(preferred_category, 0) < 10):  # Max 10 concurrent per agent
            return preferred_category
        
        # Fallback to least loaded available agent
        available_agents = [(cat, load) for cat, load in current_load.items() 
                          if cat in self.agents and load < 10]
        
        if available_agents:
            return min(available_agents, key=lambda x: x[1])[0]
        
        return "balanced"  # Default fallback
    
    async def process_batch_requests(self, requests: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Process multiple requests in parallel for maximum throughput."""
        current_load = {cat: 0 for cat in self.agents.keys()}
        tasks = []
        
        for request in requests:
            # Determine optimal agent
            complexity = request.get("complexity", "moderate")
            agent_category = self.get_optimal_agent(complexity, current_load)
            current_load[agent_category] += 1
            
            # Create processing task
            task = self._process_single_request(request, agent_category)
            tasks.append(task)
        
        # Process all requests in parallel
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Format results
        formatted_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                formatted_results.append({
                    "request_id": requests[i].get("id", i),
                    "status": "error",
                    "error": str(result)
                })
            else:
                formatted_results.append(result)
        
        return formatted_results
    
    async def _process_single_request(self, request: Dict[str, Any], agent_category: str) -> Dict[str, Any]:
        """Process a single request with the specified agent."""
        start_time = time.time()
        
        try:
            agent = self.agents[agent_category]
            response = await agent.chat_async(request["message"])
            
            processing_time = time.time() - start_time
            
            return {
                "request_id": request.get("id"),
                "status": "success",
                "response": response,
                "agent_used": agent_category,
                "processing_time": processing_time
            }
            
        except Exception as e:
            return {
                "request_id": request.get("id"),
                "status": "error",
                "error": str(e),
                "agent_used": agent_category,
                "processing_time": time.time() - start_time
            }

# High-throughput usage example
throughput_manager = VLLMHighThroughputManager()

# Initialize all models
initialized_count = await throughput_manager.initialize_all_models()
print(f"Initialized {initialized_count} models")

# Process batch requests
batch_requests = [
    {"id": 1, "message": "Simple question", "complexity": "simple"},
    {"id": 2, "message": "Complex analysis needed", "complexity": "complex"},
    {"id": 3, "message": "Moderate difficulty task", "complexity": "moderate"}
]

results = await throughput_manager.process_batch_requests(batch_requests)
for result in results:
    print(f"Request {result['request_id']}: {result['status']} in {result.get('processing_time', 0):.2f}s")
```
  

#### ржкрзНрж░рзЛржбрж╛ржХрж╢ржи ржбрж┐ржкрзНрж▓ржпрж╝ржорзЗржирзНржЯ ржкрзНржпрж╛ржЯрж╛рж░рзНржи

**ржПржирзНржЯрж╛рж░ржкрзНрж░рж╛ржЗржЬ VLLM ржкрзНрж░рзЛржбрж╛ржХрж╢ржи рж╕рж╛рж░рзНржнрж┐рж╕**:  
```python
import asyncio
import logging
import time
from typing import Dict, List, Optional
from dataclasses import dataclass
from microsoft_agent_framework import Agent, Config
import uvicorn
from fastapi import FastAPI, HTTPException, BackgroundTasks
from pydantic import BaseModel

@dataclass
class VLLMServerConfig:
    model_name: str
    port: int
    gpu_memory_utilization: float
    max_model_len: int
    tensor_parallel_size: int = 1
    quantization: Optional[str] = None

class AgentRequest(BaseModel):
    message: str
    agent_type: str = "general"
    priority: str = "normal"
    timeout: int = 30

class VLLMProductionService:
    def __init__(self, server_configs: Dict[str, VLLMServerConfig]):
        self.server_configs = server_configs
        self.managers = {}
        self.agents = {}
        self.metrics = {
            "requests_processed": 0,
            "requests_failed": 0,
            "total_processing_time": 0,
            "agent_usage": {name: 0 for name in server_configs.keys()},
            "throughput_per_minute": 0
        }
        self.request_queue = asyncio.Queue(maxsize=1000)
        self.processing_workers = []
        self.app = FastAPI(title="VLLM Agent Service")
        self._setup_routes()
        
    async def initialize_production_environment(self):
        """Initialize all VLLM servers for production."""
        logging.info("Initializing VLLM production environment...")
        
        initialization_tasks = []
        for name, config in self.server_configs.items():
            task = self._initialize_server(name, config)
            initialization_tasks.append(task)
        
        results = await asyncio.gather(*initialization_tasks, return_exceptions=True)
        
        successful_servers = 0
        for i, result in enumerate(results):
            server_name = list(self.server_configs.keys())[i]
            if isinstance(result, Exception):
                logging.error(f"Failed to initialize {server_name}: {result}")
            else:
                successful_servers += 1
                logging.info(f"Successfully initialized {server_name}")
        
        if successful_servers == 0:
            raise Exception("No VLLM servers could be initialized")
        
        # Start processing workers
        self.processing_workers = [
            asyncio.create_task(self._processing_worker(i))
            for i in range(min(4, successful_servers))  # 4 workers max
        ]
        
        logging.info(f"Production environment ready with {successful_servers} servers")
        return successful_servers
    
    async def _initialize_server(self, name: str, config: VLLMServerConfig):
        """Initialize a single VLLM server."""
        manager = VLLMManager(
            model_name=config.model_name,
            port=config.port,
            gpu_memory_utilization=config.gpu_memory_utilization,
            max_model_len=config.max_model_len
        )
        
        # Add quantization if specified
        if config.quantization:
            # This would be added to the manager's start command
            pass
        
        success = manager.start_server()
        if success:
            self.managers[name] = manager
            
            # Create production agent
            agent_config = Config(
                name=f"vllm-production-{name}",
                model_provider="vllm",
                model_id=manager.get_served_model_name(),
                endpoint=f"{manager.base_url}/v1",
                api_key="none",
                timeout=30.0
            )
            
            agent = Agent(config=agent_config)
            
            # Add production tools
            self._add_production_tools(agent, name)
            
            self.agents[name] = agent
            return True
        else:
            raise Exception(f"Failed to start VLLM server for {name}")
    
    def _add_production_tools(self, agent: Agent, server_type: str):
        """Add production tools based on server type."""
        if server_type == "customer_service":
            @agent.tool
            def escalate_to_human(issue: str, customer_id: str) -> str:
                """Escalate complex issues to human agents."""
                return f"Escalated issue for customer {customer_id}: {issue}"
            
            @agent.tool
            def lookup_order_status(order_id: str) -> dict:
                """Look up order status from production database."""
                # Production database lookup
                return {"order_id": order_id, "status": "shipped", "eta": "2 days"}
        
        elif server_type == "technical_support":
            @agent.tool
            def run_system_diagnostics(system_id: str) -> dict:
                """Run comprehensive system diagnostics."""
                return {"system_id": system_id, "status": "healthy", "issues": []}
            
            @agent.tool
            def create_incident_report(description: str, severity: str) -> str:
                """Create incident report in production system."""
                incident_id = f"INC-{hash(description) % 100000:05d}"
                return f"Created incident {incident_id} with severity {severity}"
    
    def _setup_routes(self):
        """Set up FastAPI routes for production service."""
        @self.app.post("/chat")
        async def chat_endpoint(request: AgentRequest, background_tasks: BackgroundTasks):
            try:
                # Add request to queue
                await self.request_queue.put({
                    "request": request,
                    "timestamp": time.time(),
                    "future": asyncio.Future()
                })
                
                # Wait for processing (with timeout)
                result = await asyncio.wait_for(
                    self._wait_for_result(request),
                    timeout=request.timeout
                )
                
                return result
                
            except asyncio.TimeoutError:
                raise HTTPException(status_code=408, detail="Request timeout")
            except Exception as e:
                raise HTTPException(status_code=500, detail=str(e))
        
        @self.app.get("/health")
        async def health_endpoint():
            return await self.get_health_status()
        
        @self.app.get("/metrics")
        async def metrics_endpoint():
            return self.get_production_metrics()
    
    async def _processing_worker(self, worker_id: int):
        """Background worker for processing agent requests."""
        logging.info(f"Starting processing worker {worker_id}")
        
        while True:
            try:
                # Get request from queue
                queue_item = await self.request_queue.get()
                request_data = queue_item["request"]
                request_future = queue_item["future"]
                
                # Select appropriate agent
                agent_name = self._select_agent(request_data.agent_type)
                
                if agent_name not in self.agents:
                    request_future.set_exception(Exception(f"Agent {agent_name} not available"))
                    continue
                
                # Process request
                start_time = time.time()
                try:
                    agent = self.agents[agent_name]
                    response = await agent.chat_async(request_data.message)
                    
                    processing_time = time.time() - start_time
                    
                    # Update metrics
                    self.metrics["requests_processed"] += 1
                    self.metrics["total_processing_time"] += processing_time
                    self.metrics["agent_usage"][agent_name] += 1
                    
                    result = {
                        "response": response,
                        "agent_used": agent_name,
                        "processing_time": processing_time,
                        "worker_id": worker_id
                    }
                    
                    request_future.set_result(result)
                    
                except Exception as e:
                    self.metrics["requests_failed"] += 1
                    request_future.set_exception(e)
                
                finally:
                    self.request_queue.task_done()
                    
            except Exception as e:
                logging.error(f"Worker {worker_id} error: {e}")
                await asyncio.sleep(1)
    
    def _select_agent(self, agent_type: str) -> str:
        """Select appropriate agent based on request type."""
        agent_mapping = {
            "customer_service": "customer_service",
            "technical": "technical_support",
            "general": "general_purpose"
        }
        
        return agent_mapping.get(agent_type, "general_purpose")
    
    async def _wait_for_result(self, request: AgentRequest):
        """Wait for request processing to complete."""
        # This is simplified - in production you'd track futures properly
        await asyncio.sleep(0.1)  # Placeholder
        return {"response": "Processed", "status": "success"}
    
    async def get_health_status(self) -> dict:
        """Get comprehensive health status of all services."""
        health_status = {
            "overall_status": "healthy",
            "servers": {},
            "queue_size": self.request_queue.qsize(),
            "active_workers": len([w for w in self.processing_workers if not w.done()]),
            "timestamp": time.time()
        }
        
        unhealthy_servers = 0
        for name, manager in self.managers.items():
            try:
                is_healthy = manager.health_check()
                health_status["servers"][name] = {
                    "status": "healthy" if is_healthy else "unhealthy",
                    "endpoint": manager.base_url,
                    "model": manager.model_name
                }
                if not is_healthy:
                    unhealthy_servers += 1
            except Exception as e:
                health_status["servers"][name] = {
                    "status": "error",
                    "error": str(e)
                }
                unhealthy_servers += 1
        
        if unhealthy_servers > 0:
            health_status["overall_status"] = "degraded" if unhealthy_servers < len(self.managers) else "unhealthy"
        
        return health_status
    
    def get_production_metrics(self) -> dict:
        """Get production performance metrics."""
        total_requests = self.metrics["requests_processed"] + self.metrics["requests_failed"]
        avg_processing_time = (
            self.metrics["total_processing_time"] / self.metrics["requests_processed"]
            if self.metrics["requests_processed"] > 0 else 0
        )
        
        success_rate = (
            self.metrics["requests_processed"] / total_requests * 100
            if total_requests > 0 else 0
        )
        
        return {
            "total_requests": total_requests,
            "successful_requests": self.metrics["requests_processed"],
            "failed_requests": self.metrics["requests_failed"],
            "success_rate_percent": success_rate,
            "average_processing_time_seconds": avg_processing_time,
            "agent_usage_distribution": self.metrics["agent_usage"],
            "queue_size": self.request_queue.qsize()
        }
    
    async def start_production_server(self, host: str = "0.0.0.0", port: int = 8080):
        """Start the production FastAPI server."""
        config = uvicorn.Config(
            self.app,
            host=host,
            port=port,
            log_level="info",
            workers=1  # Single worker for simplicity
        )
        server = uvicorn.Server(config)
        await server.serve()

# Production deployment example
production_configs = {
    "customer_service": VLLMServerConfig(
        model_name="microsoft/Phi-3.5-mini-instruct",
        port=8000,
        gpu_memory_utilization=0.4,
        max_model_len=4096
    ),
    "technical_support": VLLMServerConfig(
        model_name="meta-llama/Llama-3.2-3B-Instruct",
        port=8001,
        gpu_memory_utilization=0.6,
        max_model_len=8192
    ),
    "general_purpose": VLLMServerConfig(
        model_name="Qwen/Qwen2.5-1.5B-Instruct",
        port=8002,
        gpu_memory_utilization=0.3,
        max_model_len=2048
    )
}

production_service = VLLMProductionService(production_configs)

# Initialize and start production service
# await production_service.initialize_production_environment()
# await production_service.start_production_server()
```
  

#### ржПржирзНржЯрж╛рж░ржкрзНрж░рж╛ржЗржЬ ржмрзИрж╢рж┐рж╖рзНржЯрзНржп ржПржмржВ ржоржирж┐ржЯрж░рж┐ржВ

**ржЙржирзНржиржд VLLM ржкрж╛рж░ржлрж░ржорзНржпрж╛ржирзНрж╕ ржоржирж┐ржЯрж░рж┐ржВ**:  
```python
import psutil
import nvidia_ml_py3 as nvml
from dataclasses import dataclass
from typing import List, Dict, Optional
import json
import asyncio

@dataclass
class PerformanceMetrics:
    timestamp: float
    requests_per_second: float
    average_latency_ms: float
    gpu_utilization_percent: float
    gpu_memory_used_gb: float
    cpu_utilization_percent: float
    memory_used_gb: float
    queue_length: int
    active_requests: int

class VLLMAdvancedMonitoring:
    def __init__(self, vllm_managers: Dict[str, VLLMManager]):
        self.managers = vllm_managers
        self.metrics_history = []
        self.alert_thresholds = {
            "gpu_utilization_max": 95,
            "gpu_memory_max_gb": 10,
            "latency_max_ms": 3000,
            "queue_length_max": 50,
            "error_rate_max_percent": 10
        }
        
        # Initialize NVIDIA ML for GPU monitoring
        try:
            nvml.nvmlInit()
            self.gpu_monitoring_available = True
            self.gpu_count = nvml.nvmlDeviceGetCount()
        except:
            self.gpu_monitoring_available = False
            self.gpu_count = 0
    
    async def collect_comprehensive_metrics(self) -> Dict[str, PerformanceMetrics]:
        """Collect detailed performance metrics for all VLLM instances."""
        all_metrics = {}
        
        for name, manager in self.managers.items():
            try:
                metrics = await self._collect_single_instance_metrics(name, manager)
                all_metrics[name] = metrics
            except Exception as e:
                logging.error(f"Failed to collect metrics for {name}: {e}")
                # Create error metrics
                all_metrics[name] = PerformanceMetrics(
                    timestamp=time.time(),
                    requests_per_second=0,
                    average_latency_ms=0,
                    gpu_utilization_percent=0,
                    gpu_memory_used_gb=0,
                    cpu_utilization_percent=0,
                    memory_used_gb=0,
                    queue_length=0,
                    active_requests=0
                )
        
        return all_metrics
    
    async def _collect_single_instance_metrics(self, name: str, manager: VLLMManager) -> PerformanceMetrics:
        """Collect metrics for a single VLLM instance."""
        timestamp = time.time()
        
        # Get VLLM-specific metrics via API
        vllm_stats = await self._get_vllm_stats(manager)
        
        # Get system metrics
        cpu_percent = psutil.cpu_percent(interval=0.1)
        memory_info = psutil.virtual_memory()
        memory_used_gb = memory_info.used / (1024**3)
        
        # Get GPU metrics if available
        gpu_utilization = 0
        gpu_memory_used = 0
        
        if self.gpu_monitoring_available and self.gpu_count > 0:
            try:
                # Assuming first GPU for simplicity
                handle = nvml.nvmlDeviceGetHandleByIndex(0)
                gpu_util = nvml.nvmlDeviceGetUtilizationRates(handle)
                gpu_utilization = gpu_util.gpu
                
                gpu_mem = nvml.nvmlDeviceGetMemoryInfo(handle)
                gpu_memory_used = gpu_mem.used / (1024**3)
                
            except Exception as e:
                logging.warning(f"GPU monitoring failed: {e}")
        
        return PerformanceMetrics(
            timestamp=timestamp,
            requests_per_second=vllm_stats.get("requests_per_second", 0),
            average_latency_ms=vllm_stats.get("average_latency_ms", 0),
            gpu_utilization_percent=gpu_utilization,
            gpu_memory_used_gb=gpu_memory_used,
            cpu_utilization_percent=cpu_percent,
            memory_used_gb=memory_used_gb,
            queue_length=vllm_stats.get("queue_length", 0),
            active_requests=vllm_stats.get("active_requests", 0)
        )
    
    async def _get_vllm_stats(self, manager: VLLMManager) -> dict:
        """Get VLLM-specific statistics via API calls."""
        try:
            # Test inference to measure latency
            start_time = time.time()
            client = manager.get_openai_client()
            
            response = await asyncio.wait_for(
                asyncio.to_thread(
                    client.chat.completions.create,
                    model=manager.get_served_model_name(),
                    messages=[{"role": "user", "content": "ping"}],
                    max_tokens=1
                ),
                timeout=5.0
            )
            
            latency_ms = (time.time() - start_time) * 1000
            
            return {
                "average_latency_ms": latency_ms,
                "requests_per_second": 1000 / latency_ms if latency_ms > 0 else 0,
                "queue_length": 0,  # Would need to be exposed by VLLM
                "active_requests": 1  # Approximation
            }
            
        except Exception as e:
            logging.warning(f"Failed to get VLLM stats: {e}")
            return {
                "average_latency_ms": 0,
                "requests_per_second": 0,
                "queue_length": 0,
                "active_requests": 0
            }
    
    def generate_performance_report(self, time_window_minutes: int = 60) -> dict:
        """Generate comprehensive performance report."""
        cutoff_time = time.time() - (time_window_minutes * 60)
        recent_metrics = [
            metrics for metrics in self.metrics_history
            if any(m.timestamp > cutoff_time for m in metrics.values())
        ]
        
        if not recent_metrics:
            return {"error": "No recent metrics available"}
        
        report = {
            "time_window_minutes": time_window_minutes,
            "total_samples": len(recent_metrics),
            "instances": {}
        }
        
        # Analyze each instance
        for instance_name in self.managers.keys():
            instance_metrics = [
                metrics[instance_name] for metrics in recent_metrics
                if instance_name in metrics
            ]
            
            if instance_metrics:
                report["instances"][instance_name] = {
                    "avg_latency_ms": sum(m.average_latency_ms for m in instance_metrics) / len(instance_metrics),
                    "max_latency_ms": max(m.average_latency_ms for m in instance_metrics),
                    "avg_gpu_utilization": sum(m.gpu_utilization_percent for m in instance_metrics) / len(instance_metrics),
                    "avg_requests_per_second": sum(m.requests_per_second for m in instance_metrics) / len(instance_metrics),
                    "max_queue_length": max(m.queue_length for m in instance_metrics),
                    "availability_percent": (len(instance_metrics) / len(recent_metrics)) * 100
                }
        
        return report
    
    async def auto_scaling_recommendations(self) -> List[dict]:
        """Generate auto-scaling recommendations based on performance metrics."""
        recommendations = []
        
        if not self.metrics_history:
            return recommendations
        
        latest_metrics = self.metrics_history[-1]
        
        for instance_name, metrics in latest_metrics.items():
            # High latency recommendation
            if metrics.average_latency_ms > self.alert_thresholds["latency_max_ms"]:
                recommendations.append({
                    "instance": instance_name,
                    "type": "scale_up",
                    "reason": f"High latency: {metrics.average_latency_ms:.0f}ms",
                    "suggestion": "Consider adding tensor parallelism or increasing GPU memory"
                })
            
            # High GPU utilization recommendation
            if metrics.gpu_utilization_percent > self.alert_thresholds["gpu_utilization_max"]:
                recommendations.append({
                    "instance": instance_name,
                    "type": "scale_out",
                    "reason": f"High GPU utilization: {metrics.gpu_utilization_percent:.1f}%",
                    "suggestion": "Consider adding additional GPU instances"
                })
            
            # Low utilization recommendation
            if (metrics.gpu_utilization_percent < 20 and 
                metrics.requests_per_second < 1):
                recommendations.append({
                    "instance": instance_name,
                    "type": "scale_down",
                    "reason": f"Low utilization: {metrics.gpu_utilization_percent:.1f}% GPU, {metrics.requests_per_second:.1f} RPS",
                    "suggestion": "Consider consolidating workloads or reducing resources"
                })
        
        return recommendations

# Advanced monitoring setup
monitoring = VLLMAdvancedMonitoring({
    "customer_service": vllm_manager,
    # Add other managers as needed
})

async def advanced_monitoring_loop():
    """Advanced monitoring with auto-scaling recommendations."""
    while True:
        try:
            # Collect metrics
            metrics = await monitoring.collect_comprehensive_metrics()
            monitoring.metrics_history.append(metrics)
            
            # Keep only last 1000 entries
            if len(monitoring.metrics_history) > 1000:
                monitoring.metrics_history = monitoring.metrics_history[-1000:]
            
            # Generate recommendations every 5 minutes
            if len(monitoring.metrics_history) % 10 == 0:  # Every 10th collection (5 minutes if collecting every 30s)
                recommendations = await monitoring.auto_scaling_recommendations()
                
                if recommendations:
                    logging.info(f"Auto-scaling recommendations: {recommendations}")
            
            # Generate performance report every hour
            if len(monitoring.metrics_history) % 120 == 0:  # Every 120th collection (1 hour)
                report = monitoring.generate_performance_report(60)
                logging.info(f"Performance report: {json.dumps(report, indent=2)}")
            
        except Exception as e:
            logging.error(f"Advanced monitoring error: {e}")
        
        await asyncio.sleep(30)  # Collect metrics every 30 seconds

# Start advanced monitoring
# asyncio.create_task(advanced_monitoring_loop())
```
  

#### ржЙржирзНржиржд ржХржиржлрж┐ржЧрж╛рж░рзЗрж╢ржи ржПржмржВ ржЕржкрзНржЯрж┐ржорж╛ржЗржЬрзЗрж╢ржи

**ржкрзНрж░рзЛржбрж╛ржХрж╢ржи VLLM ржХржиржлрж┐ржЧрж╛рж░рзЗрж╢ржи ржЯрзЗржоржкрзНрж▓рзЗржЯ**:  
```python
from enum import Enum
from typing import Dict, Any

class DeploymentScenario(Enum):
    DEVELOPMENT = "development"
    STAGING = "staging"
    PRODUCTION_LOW = "production_low"
    PRODUCTION_HIGH = "production_high"
    ENTERPRISE = "enterprise"

class VLLMConfigTemplates:
    """Production-ready VLLM configuration templates."""
    
    @staticmethod
    def get_config_template(scenario: DeploymentScenario) -> Dict[str, Any]:
        """Get optimized configuration for deployment scenario."""
        
        templates = {
            DeploymentScenario.DEVELOPMENT: {
                "gpu_memory_utilization": 0.6,
                "max_model_len": 2048,
                "tensor_parallel_size": 1,
                "pipeline_parallel_size": 1,
                "quantization": None,
                "enable_prefix_caching": False,
                "max_num_seqs": 32,
                "max_num_batched_tokens": 2048
            },
            
            DeploymentScenario.STAGING: {
                "gpu_memory_utilization": 0.8,
                "max_model_len": 4096,
                "tensor_parallel_size": 1,
                "pipeline_parallel_size": 1,
                "quantization": "awq",
                "enable_prefix_caching": True,
                "max_num_seqs": 64,
                "max_num_batched_tokens": 4096
            },
            
            DeploymentScenario.PRODUCTION_LOW: {
                "gpu_memory_utilization": 0.85,
                "max_model_len": 4096,
                "tensor_parallel_size": 1,
                "pipeline_parallel_size": 1,
                "quantization": "awq",
                "enable_prefix_caching": True,
                "max_num_seqs": 128,
                "max_num_batched_tokens": 8192,
                "enable_chunked_prefill": True
            },
            
            DeploymentScenario.PRODUCTION_HIGH: {
                "gpu_memory_utilization": 0.9,
                "max_model_len": 8192,
                "tensor_parallel_size": 2,
                "pipeline_parallel_size": 1,
                "quantization": "awq",
                "enable_prefix_caching": True,
                "max_num_seqs": 256,
                "max_num_batched_tokens": 16384,
                "enable_chunked_prefill": True,
                "speculative_model": "small_draft_model"
            },
            
            DeploymentScenario.ENTERPRISE: {
                "gpu_memory_utilization": 0.95,
                "max_model_len": 16384,
                "tensor_parallel_size": 4,
                "pipeline_parallel_size": 2,
                "quantization": "awq",
                "enable_prefix_caching": True,
                "max_num_seqs": 512,
                "max_num_batched_tokens": 32768,
                "enable_chunked_prefill": True,
                "speculative_model": "optimized_draft_model",
                "guided_decoding_backend": "outlines"
            }
        }
        
        return templates[scenario]
    
    @staticmethod
    def generate_vllm_command(model_name: str, 
                             scenario: DeploymentScenario,
                             port: int = 8000,
                             host: str = "0.0.0.0") -> List[str]:
        """Generate optimized VLLM command for deployment scenario."""
        
        config = VLLMConfigTemplates.get_config_template(scenario)
        
        cmd = [
            "python", "-m", "vllm.entrypoints.openai.api_server",
            "--model", model_name,
            "--host", host,
            "--port", str(port),
            "--gpu-memory-utilization", str(config["gpu_memory_utilization"]),
            "--max-model-len", str(config["max_model_len"]),
            "--tensor-parallel-size", str(config["tensor_parallel_size"]),
            "--max-num-seqs", str(config["max_num_seqs"]),
            "--max-num-batched-tokens", str(config["max_num_batched_tokens"]),
            "--trust-remote-code",
            "--disable-log-requests"
        ]
        
        # Add optional parameters
        if config.get("quantization"):
            cmd.extend(["--quantization", config["quantization"]])
        
        if config.get("enable_prefix_caching"):
            cmd.append("--enable-prefix-caching")
        
        if config.get("enable_chunked_prefill"):
            cmd.append("--enable-chunked-prefill")
        
        if config.get("pipeline_parallel_size", 1) > 1:
            cmd.extend(["--pipeline-parallel-size", str(config["pipeline_parallel_size"])])
        
        if config.get("speculative_model"):
            cmd.extend(["--speculative-model", config["speculative_model"]])
        
        return cmd

# Usage examples
dev_cmd = VLLMConfigTemplates.generate_vllm_command(
    "microsoft/Phi-3.5-mini-instruct",
    DeploymentScenario.DEVELOPMENT,
    port=8000
)

prod_cmd = VLLMConfigTemplates.generate_vllm_command(
    "microsoft/Phi-3.5-mini-instruct",
    DeploymentScenario.PRODUCTION_HIGH,
    port=8001
)

print(f"Development command: {' '.join(dev_cmd)}")
print(f"Production command: {' '.join(prod_cmd)}")
```
  
**VLLM-ржПрж░ ржЬржирзНржп ржкрзНрж░рзЛржбрж╛ржХрж╢ржи ржбрж┐ржкрзНрж▓ржпрж╝ржорзЗржирзНржЯ ржЪрзЗржХрж▓рж┐рж╕рзНржЯ**:

тЬЕ **рж╣рж╛рж░рзНржбржУржпрж╝рзНржпрж╛рж░ ржЕржкрзНржЯрж┐ржорж╛ржЗржЬрзЗрж╢ржи**:  
- ржорж╛рж▓рзНржЯрж┐-GPU рж╕рзЗржЯржЖржкрзЗрж░ ржЬржирзНржп ржЯрзЗржирж╕рж░ ржкрзНржпрж╛рж░рж╛рж▓рзЗрж▓рж┐ржЬржо ржХржиржлрж┐ржЧрж╛рж░ ржХрж░рзБржи  
- ржорзЗржорзЛрж░рж┐ ржжржХрзНрж╖рждрж╛рж░ ржЬржирзНржп ржХрзЛржпрж╝рж╛ржирзНржЯрж╛ржЗржЬрзЗрж╢ржи (AWQ/GPTQ) рж╕ржХрзНрж╖ржо ржХрж░рзБржи  
- GPU ржорзЗржорзЛрж░рж┐ ржмрзНржпржмрж╣рж╛рж░ (85-95%) ржЕржкрзНржЯрж┐ржорж╛ржЗржЬ ржХрж░рзБржи  
- ржерзНрж░рзБржкрзБржЯрзЗрж░ ржЬржирзНржп ржЙржкржпрзБржХрзНржд ржмрзНржпрж╛ржЪ рж╕рж╛ржЗржЬ ржХржиржлрж┐ржЧрж╛рж░ ржХрж░рзБржи  

тЬЕ **ржкрж╛рж░ржлрж░ржорзНржпрж╛ржирзНрж╕ ржЯрж┐ржЙржирж┐ржВ**:  
- ржкрзБржирж░рж╛ржмрзГрждрзНржд ржкрзНрж░рж╢рзНржирзЗрж░ ржЬржирзНржп ржкрзНрж░рж┐ржлрж┐ржХрзНрж╕ ржХрзНржпрж╛рж╢рж┐ржВ рж╕ржХрзНрж╖ржо ржХрж░рзБржи  
- ржжрзАрж░рзНржШ рж╕рж┐ржХрзЛржпрж╝рзЗржирзНрж╕рзЗрж░ ржЬржирзНржп ржЪрж╛ржЩрзНржХржб ржкрзНрж░рж┐ржлрж┐рж▓ ржХржиржлрж┐ржЧрж╛рж░ ржХрж░рзБржи  
- ржжрзНрж░рзБржд ржЗржиржлрж╛рж░рзЗржирзНрж╕рзЗрж░ ржЬржирзНржп рж╕рзНржкрзЗржХрзБрж▓рзЗржЯрж┐ржн ржбрж┐ржХрзЛржбрж┐ржВ рж╕рзЗржЯ ржЖржк ржХрж░рзБржи  
- рж╣рж╛рж░рзНржбржУржпрж╝рзНржпрж╛рж░рзЗрж░ ржЙржкрж░ ржнрж┐рждрзНрждрж┐ ржХрж░рзЗ max_num_seqs ржЕржкрзНржЯрж┐ржорж╛ржЗржЬ ржХрж░рзБржи  

тЬЕ **ржкрзНрж░рзЛржбрж╛ржХрж╢ржи ржмрзИрж╢рж┐рж╖рзНржЯрзНржп**:  
- рж╕рзНржмрж╛рж╕рзНржерзНржп ржоржирж┐ржЯрж░рж┐ржВ ржПржмржВ ржорзЗржЯрзНрж░рж┐ржХрзНрж╕ рж╕ржВржЧрзНрж░рж╣ рж╕рзЗржЯ ржЖржк ржХрж░рзБржи  
- рж╕рзНржмржпрж╝ржВржХрзНрж░рж┐ржпрж╝ рж░рж┐рж╕рзНржЯрж╛рж░рзНржЯ ржПржмржВ ржлрзЗржЗрж▓ржУржнрж╛рж░ ржХржиржлрж┐ржЧрж╛рж░ ржХрж░рзБржи  
- ржЕржирзБрж░рзЛржз ржХрж┐ржЙржЗржВ ржПржмржВ рж▓рзЛржб ржмрзНржпрж╛рж▓рзЗржирзНрж╕рж┐ржВ ржмрж╛рж╕рзНрждржмрж╛ржпрж╝ржи ржХрж░рзБржи  
- ржмрзНржпрж╛ржкржХ рж▓ржЧрж┐ржВ ржПржмржВ ржЕрзНржпрж╛рж▓рж╛рж░рзНржЯрж┐ржВ рж╕рзЗржЯ ржЖржк ржХрж░рзБржи  

тЬЕ **ржирж┐рж░рж╛ржкрждрзНрждрж╛ ржПржмржВ ржирж┐рж░рзНржнрж░ржпрзЛржЧрзНржпрждрж╛**:  
- ржлрж╛ржпрж╝рж╛рж░ржУржпрж╝рж╛рж▓ ржирж┐ржпрж╝ржо ржПржмржВ ржЕрзНржпрж╛ржХрзНрж╕рзЗрж╕ ржХржирзНржЯрзНрж░рзЛрж▓ ржХржиржлрж┐ржЧрж╛рж░ ржХрж░рзБржи  
- API рж░рзЗржЯ рж▓рж┐ржорж┐ржЯрж┐ржВ ржПржмржВ ржЕржерзЗржирзНржЯрж┐ржХрзЗрж╢ржи рж╕рзЗржЯ ржЖржк ржХрж░рзБржи  
- ржЧрзНрж░рзЗрж╕ржлрзБрж▓ рж╢рж╛ржЯржбрж╛ржЙржи ржПржмржВ ржХрзНрж▓рж┐ржиржЖржк ржмрж╛рж╕рзНрждржмрж╛ржпрж╝ржи ржХрж░рзБржи  
- ржмрзНржпрж╛ржХржЖржк ржПржмржВ ржбрж┐ржЬрж╛рж╕рзНржЯрж╛рж░ рж░рж┐ржХржнрж╛рж░рж┐ ржХржиржлрж┐ржЧрж╛рж░ ржХрж░рзБржи  

тЬЕ **ржЗржирзНржЯрж┐ржЧрзНрж░рзЗрж╢ржи ржЯрзЗрж╕рзНржЯрж┐ржВ**:  
- ржорж╛ржЗржХрзНрж░рзЛрж╕ржлржЯ ржПржЬрзЗржирзНржЯ ржлрзНрж░рзЗржоржУржпрж╝рж╛рж░рзНржХ ржЗржирзНржЯрж┐ржЧрзНрж░рзЗрж╢ржи ржкрж░рзАржХрзНрж╖рж╛ ржХрж░рзБржи  
- ржЙржЪрзНржЪ-ржерзНрж░рзБржкрзБржЯ ржкрж░рж┐рж╕рзНржерж┐рждрж┐ ржпрж╛ржЪрж╛ржЗ ржХрж░рзБржи  
- ржлрзЗржЗрж▓ржУржнрж╛рж░ ржПржмржВ рж░рж┐ржХржнрж╛рж░рж┐ ржкржжрзНржзрждрж┐ ржкрж░рзАржХрзНрж╖рж╛ ржХрж░рзБржи  
- рж▓рзЛржбрзЗрж░ ржЕржзрзАржирзЗ ржкрж╛рж░ржлрж░ржорзНржпрж╛ржирзНрж╕ ржмрзЗржЮрзНржЪржорж╛рж░рзНржХ ржХрж░рзБржи  

**ржЕржирзНржпрж╛ржирзНржп рж╕ржорж╛ржзрж╛ржирзЗрж░ рж╕рж╛ржерзЗ рждрзБрж▓ржирж╛**:

| ржмрзИрж╢рж┐рж╖рзНржЯрзНржп | VLLM | Foundry Local | Ollama |
|---------|------|---------------|--------|
| **рж▓ржХрзНрж╖рзНржп ржмрзНржпржмрж╣рж╛рж░ ржХрзНрж╖рзЗрждрзНрж░** | ржЙржЪрзНржЪ-ржерзНрж░рзБржкрзБржЯ ржкрзНрж░рзЛржбрж╛ржХрж╢ржи | ржПржирзНржЯрж╛рж░ржкрзНрж░рж╛ржЗржЬ рж╕рж╣ржЬ ржмрзНржпржмрж╣рж╛рж░ | ржбрзЗржнрзЗрж▓ржкржорзЗржирзНржЯ ржПржмржВ ржХржорж┐ржЙржирж┐ржЯрж┐ |
| **ржкрж╛рж░ржлрж░ржорзНржпрж╛ржирзНрж╕** | рж╕рж░рзНржмрж╛ржзрж┐ржХ ржерзНрж░рзБржкрзБржЯ | ржмрзНржпрж╛рж▓рзЗржирзНрж╕ржб | ржнрж╛рж▓рзЛ |
| **ржорзЗржорзЛрж░рж┐ ржжржХрзНрж╖рждрж╛** | PagedAttention ржЕржкрзНржЯрж┐ржорж╛ржЗржЬрзЗрж╢ржи | рж╕рзНржмржпрж╝ржВржХрзНрж░рж┐ржпрж╝ ржЕржкрзНржЯрж┐ржорж╛ржЗржЬрзЗрж╢ржи | рж╕рзНржЯрзНржпрж╛ржирзНржбрж╛рж░рзНржб |
| **рж╕рзЗржЯржЖржк ржЬржЯрж┐рж▓рждрж╛** | ржЙржЪрзНржЪ (ржЕржирзЗржХ ржкрзНржпрж╛рж░рж╛ржорж┐ржЯрж╛рж░) | ржХржо (рж╕рзНржмржпрж╝ржВржХрзНрж░рж┐ржпрж╝) | ржХржо (рж╕рж╣ржЬ) |
| **рж╕рзНржХрзЗрж▓рзЗржмрж┐рж▓рж┐ржЯрж┐** | ржЪржорзОржХрж╛рж░ (ржЯрзЗржирж╕рж░/ржкрж╛ржЗржкрж▓рж╛ржЗржи ржкрзНржпрж╛рж░рж╛рж▓рзЗрж▓) | ржнрж╛рж▓рзЛ | рж╕рзАржорж┐ржд |
| **ржХрзЛржпрж╝рж╛ржирзНржЯрж╛ржЗржЬрзЗрж╢ржи** | ржЙржирзНржиржд (AWQ, GPTQ, FP8) | рж╕рзНржмржпрж╝ржВржХрзНрж░рж┐ржпрж╝ | рж╕рзНржЯрзНржпрж╛ржирзНржбрж╛рж░рзНржб GGUF |
| **ржПржирзНржЯрж╛рж░ржкрзНрж░рж╛ржЗржЬ ржмрзИрж╢рж┐рж╖рзНржЯрзНржп** | ржХрж╛рж╕рзНржЯржо ржЗржоржкрзНрж▓рж┐ржорзЗржирзНржЯрзЗрж╢ржи ржкрзНрж░ржпрж╝рзЛржЬржи | ржмрж┐рж▓рзНржЯ-ржЗржи | ржХржорж┐ржЙржирж┐ржЯрж┐ ржЯрзБрж▓рж╕ |
| **рж╕рзЗрж░рж╛ ржмрзНржпржмрж╣рж╛рж░ ржХрзНрж╖рзЗрждрзНрж░** | ржЙржЪрзНржЪ-рж╕рзНржХрзЗрж▓ ржкрзНрж░рзЛржбрж╛ржХрж╢ржи ржПржЬрзЗржирзНржЯ | ржПржирзНржЯрж╛рж░ржкрзНрж░рж╛ржЗржЬ ржкрзНрж░рзЛржбрж╛ржХрж╢ржи | ржбрзЗржнрзЗрж▓ржкржорзЗржирзНржЯ |

**ржХржЦржи VLLM ржмрзЗржЫрзЗ ржирзЗржмрзЗржи**:
- **ржЙржЪрзНржЪ-ржерзНрж░рзБржкрзБржЯ ржкрзНрж░ржпрж╝рзЛржЬржирзАржпрж╝рждрж╛**: ржкрзНрж░рждрж┐ рж╕рзЗржХрзЗржирзНржбрзЗ рж╢ржд рж╢ржд ржЕржирзБрж░рзЛржз ржкрзНрж░ржХрзНрж░рж┐ржпрж╝рж╛ржХрж░ржг  
- **ржмрзГрж╣рзО-рж╕рзНржХрзЗрж▓ ржбрж┐ржкрзНрж▓ржпрж╝ржорзЗржирзНржЯ**: ржорж╛рж▓рзНржЯрж┐-GPU, ржорж╛рж▓рзНржЯрж┐-ржирзЛржб ржбрж┐ржкрзНрж▓ржпрж╝ржорзЗржирзНржЯ  
- **ржкрж╛рж░ржлрж░ржорзНржпрж╛ржирзНрж╕ ржХрзНрж░рж┐ржЯрж┐ржХрзНржпрж╛рж▓**: рж╕рзНржХрзЗрж▓рзЗ рж╕рж╛ржм-рж╕рзЗржХрзЗржирзНржб рж░рзЗрж╕ржкржирзНрж╕ ржЯрж╛ржЗржо  
- **ржЙржирзНржиржд ржЕржкрзНржЯрж┐ржорж╛ржЗржЬрзЗрж╢ржи**: ржХрж╛рж╕рзНржЯржо ржХрзЛржпрж╝рж╛ржирзНржЯрж╛ржЗржЬрзЗрж╢ржи ржПржмржВ ржмрзНржпрж╛ржЪрж┐ржВржпрж╝рзЗрж░ ржкрзНрж░ржпрж╝рзЛржЬржи  
- **рж░рж┐рж╕рзЛрж░рзНрж╕ ржжржХрзНрж╖рждрж╛**: ржмрзНржпржпрж╝ржмрж╣рзБрж▓ GPU рж╣рж╛рж░рзНржбржУржпрж╝рзНржпрж╛рж░рзЗрж░ рж╕рж░рзНржмрж╛ржзрж┐ржХ ржмрзНржпржмрж╣рж╛рж░  

## ржмрж╛рж╕рзНрждржм-ржЬрзАржмржирзЗрж░ SLM ржПржЬрзЗржирзНржЯ ржЕрзНржпрж╛ржкрзНрж▓рж┐ржХрзЗрж╢ржи

### ржХрж╛рж╕рзНржЯржорж╛рж░ рж╕рж╛рж░рзНржнрж┐рж╕ SLM ржПржЬрзЗржирзНржЯ
- **SLM рж╕ржХрзНрж╖ржорждрж╛**: ржЕрзНржпрж╛ржХрж╛ржЙржирзНржЯ рж▓рзБржХржЖржк, ржкрж╛рж╕ржУржпрж╝рж╛рж░рзНржб рж░рж┐рж╕рзЗржЯ, ржЕрж░рзНржбрж╛рж░ рж╕рзНржЯрзНржпрж╛ржЯрж╛рж╕ ржЪрзЗржХ  
- **ржЦрж░ржЪ рж╕рзБржмрж┐ржзрж╛**: LLM ржПржЬрзЗржирзНржЯрзЗрж░ рждрзБрж▓ржирж╛ржпрж╝ ржЗржиржлрж╛рж░рзЗржирзНрж╕ ржЦрж░ржЪрзЗ 10x рж╣рзНрж░рж╛рж╕  
- **ржкрж╛рж░ржлрж░ржорзНржпрж╛ржирзНрж╕**: рж░рзБржЯрж┐ржи ржкрзНрж░рж╢рзНржирзЗрж░ ржЬржирзНржп ржжрзНрж░рзБржд рж░рзЗрж╕ржкржирзНрж╕ ржЯрж╛ржЗржо ржПржмржВ ржзрж╛рж░рж╛ржмрж╛рж╣рж┐ржХ ржЧрзБржгржорж╛ржи  

### ржмрж┐ржЬржирзЗрж╕ ржкрзНрж░рж╕рзЗрж╕ SLM ржПржЬрзЗржирзНржЯ
- **ржЗржиржнржпрж╝рзЗрж╕ ржкрзНрж░рж╕рзЗрж╕рж┐ржВ ржПржЬрзЗржирзНржЯ**: ржбрзЗржЯрж╛ ржПржХрзНрж╕ржЯрзНрж░рж╛ржХрзНржЯ, рждржерзНржп ржпрж╛ржЪрж╛ржЗ, ржЕржирзБржорзЛржжржирзЗрж░ ржЬржирзНржп рж░рж╛ржЙржЯ  
- **ржЗржорзЗржЗрж▓ ржорзНржпрж╛ржирзЗржЬржорзЗржирзНржЯ ржПржЬрзЗржирзНржЯ**: рж╕рзНржмржпрж╝ржВржХрзНрж░рж┐ржпрж╝ржнрж╛ржмрзЗ рж╢рзНрж░рзЗржгрзАржмржжрзНржз, ржЕржЧрзНрж░рж╛ржзрж┐ржХрж╛рж░ ржирж┐рж░рзНржзрж╛рж░ржг, ржЙрждрзНрждрж░ ржЦрж╕ржбрж╝рж╛ рждрзИрж░рж┐  
- **рж╢рж┐ржбрж┐ржЙрж▓рж┐ржВ ржПржЬрзЗржирзНржЯ**: ржорж┐ржЯрж┐ржВ рж╕ржоржирзНржмржпрж╝, ржХрзНржпрж╛рж▓рзЗржирзНржбрж╛рж░ ржкрж░рж┐ржЪрж╛рж▓ржирж╛, рж░рж┐ржорж╛ржЗржирзНржбрж╛рж░ ржкрж╛ржарж╛ржирзЛ  

### ржмрзНржпржХрзНрждрж┐ржЧржд SLM ржбрж┐ржЬрж┐ржЯрж╛рж▓ ржЕрзНржпрж╛рж╕рж┐рж╕рзНржЯрзНржпрж╛ржирзНржЯ
- **ржЯрж╛рж╕рзНржХ ржорзНржпрж╛ржирзЗржЬржорзЗржирзНржЯ ржПржЬрзЗржирзНржЯ**: ржжржХрзНрж╖рждрж╛рж░ рж╕рж╛ржерзЗ ржЯрзБ-ржбрзБ рж▓рж┐рж╕рзНржЯ рждрзИрж░рж┐, ржЖржкржбрзЗржЯ, рж╕ржВржЧржарж┐ржд  
- **рждржерзНржп рж╕ржВржЧрзНрж░рж╣ ржПржЬрзЗржирзНржЯ**: ржмрж┐рж╖ржпрж╝ ржЧржмрзЗрж╖ржгрж╛, рж╕рзНржерж╛ржирзАржпрж╝ржнрж╛ржмрзЗ рж╕рж╛рж░рж╛ржВрж╢ рждрзИрж░рж┐  
- **ржпрзЛржЧрж╛ржпрзЛржЧ ржПржЬрзЗржирзНржЯ**: ржЗржорзЗржЗрж▓, ржмрж╛рж░рзНрждрж╛, рж╕рзЛрж╢рзНржпрж╛рж▓ ржорж┐ржбрж┐ржпрж╝рж╛ ржкрзЛрж╕рзНржЯ ржЦрж╕ржбрж╝рж╛ рждрзИрж░рж┐  

### ржЯрзНрж░рзЗржбрж┐ржВ ржПржмржВ ржлрж┐ржирж╛ржирзНрж╕рж┐ржпрж╝рж╛рж▓ SLM ржПржЬрзЗржирзНржЯ
- **ржорж╛рж░рзНржХрзЗржЯ ржоржирж┐ржЯрж░рж┐ржВ ржПржЬрзЗржирзНржЯ**: рж░рж┐ржпрж╝рзЗрж▓-ржЯрж╛ржЗржорзЗ ржжрж╛ржо ржЯрзНрж░рзНржпрж╛ржХ ржХрж░рж╛, ржкрзНрж░ржмржгрждрж╛ ржЪрж┐рж╣рзНржирж┐ржд ржХрж░рж╛  
- **рж░рж┐ржкрзЛрж░рзНржЯ ржЬрзЗржирж╛рж░рзЗрж╢ржи ржПржЬрзЗржирзНржЯ**: рж╕рзНржмржпрж╝ржВржХрзНрж░рж┐ржпрж╝ржнрж╛ржмрзЗ ржжрзИржирж┐ржХ/рж╕рж╛ржкрзНрждрж╛рж╣рж┐ржХ рж╕рж╛рж░рж╛ржВрж╢ рждрзИрж░рж┐  
- **рж░рж┐рж╕рзНржХ ржЕрзНржпрж╛рж╕рзЗрж╕ржорзЗржирзНржЯ ржПржЬрзЗржирзНржЯ**: рж╕рзНржерж╛ржирзАржпрж╝ ржбрзЗржЯрж╛ ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗ ржкрзЛрж░рзНржЯржлрзЛрж▓рж┐ржУ ржЕржмрж╕рзНржерж╛ржи ржорзВрж▓рзНржпрж╛ржпрж╝ржи  

### рж╕рзНржмрж╛рж╕рзНржерзНржпрж╕рзЗржмрж╛ рж╕рж╣рж╛ржпрж╝рждрж╛ SLM ржПржЬрзЗржирзНржЯ
- **ржкрзЗрж╢рзЗржирзНржЯ рж╢рж┐ржбрж┐ржЙрж▓рж┐ржВ ржПржЬрзЗржирзНржЯ**: ржЕрзНржпрж╛ржкржпрж╝рзЗржирзНржЯржорзЗржирзНржЯ рж╕ржоржирзНржмржпрж╝, рж╕рзНржмржпрж╝ржВржХрзНрж░рж┐ржпрж╝ рж░рж┐ржорж╛ржЗржирзНржбрж╛рж░ ржкрж╛ржарж╛ржирзЛ  
- **ржбржХрзБржорзЗржирзНржЯрзЗрж╢ржи ржПржЬрзЗржирзНржЯ**: рж╕рзНржерж╛ржирзАржпрж╝ржнрж╛ржмрзЗ ржорзЗржбрж┐ржХрзЗрж▓ рж╕рж╛рж░рж╛ржВрж╢, рж░рж┐ржкрзЛрж░рзНржЯ рждрзИрж░рж┐  
- **ржкрзНрж░рзЗрж╕ржХрзНрж░рж┐ржкрж╢ржи ржорзНржпрж╛ржирзЗржЬржорзЗржирзНржЯ ржПржЬрзЗржирзНржЯ**: рж░рж┐ржлрж┐рж▓ ржЯрзНрж░рзНржпрж╛ржХ ржХрж░рж╛, ржмрзНржпржХрзНрждрж┐ржЧрждржнрж╛ржмрзЗ ржЗржирзНржЯрж╛рж░ржЕрзНржпрж╛ржХрж╢ржи ржЪрзЗржХ ржХрж░рж╛  

## ржорж╛ржЗржХрзНрж░рзЛрж╕ржлржЯ ржПржЬрзЗржирзНржЯ ржлрзНрж░рзЗржоржУржпрж╝рж╛рж░рзНржХ: ржкрзНрж░рзЛржбрж╛ржХрж╢ржи-рж░рзЗржбрж┐ ржПржЬрзЗржирзНржЯ ржбрзЗржнрзЗрж▓ржкржорзЗржирзНржЯ

### ржУржнрж╛рж░ржнрж┐ржЙ ржПржмржВ ржЖрж░рзНржХрж┐ржЯрзЗржХржЪрж╛рж░

ржорж╛ржЗржХрзНрж░рзЛрж╕ржлржЯ ржПржЬрзЗржирзНржЯ ржлрзНрж░рзЗржоржУржпрж╝рж╛рж░рзНржХ ржПржХржЯрж┐ ржмрзНржпрж╛ржкржХ, ржПржирзНржЯрж╛рж░ржкрзНрж░рж╛ржЗржЬ-ржЧрзНрж░рзЗржб ржкрзНрж▓рзНржпрж╛ржЯржлрж░рзНржо ржкрзНрж░ржжрж╛ржи ржХрж░рзЗ ржпрж╛ AI ржПржЬрзЗржирзНржЯ рждрзИрж░рж┐, ржбрж┐ржкрзНрж▓ржпрж╝ ржПржмржВ ржкрж░рж┐ржЪрж╛рж▓ржирж╛ ржХрж░рждрзЗ рж╕ржХрзНрж╖ржо ржпрж╛ ржХрзНрж▓рж╛ржЙржб ржПржмржВ ржЕржлрж▓рж╛ржЗржи ржПржЬ ржЙржнржпрж╝ ржкрж░рж┐ржмрзЗрж╢рзЗ ржХрж╛ржЬ ржХрж░рждрзЗ ржкрж╛рж░рзЗред ржлрзНрж░рзЗржоржУржпрж╝рж╛рж░рзНржХржЯрж┐ ржмрж┐рж╢рзЗрж╖ржнрж╛ржмрзЗ ржЫрзЛржЯ ржнрж╛рж╖рж╛рж░ ржоржбрзЗрж▓ ржПржмржВ ржПржЬ ржХржорзНржкрж┐ржЙржЯрж┐ржВ ржкрж░рж┐рж╕рзНржерж┐рждрж┐рж░ рж╕рж╛ржерзЗ ржирж┐рж░рзНржмрж┐ржШрзНржирзЗ ржХрж╛ржЬ ржХрж░рж╛рж░ ржЬржирзНржп ржбрж┐ржЬрж╛ржЗржи ржХрж░рж╛ рж╣ржпрж╝рзЗржЫрзЗ, ржпрж╛ ржЧрзЛржкржирзАржпрж╝рждрж╛-рж╕ржВржмрзЗржжржирж╢рзАрж▓ ржПржмржВ рж░рж┐рж╕рзЛрж░рзНрж╕-рж╕рзАржорж╛ржмржжрзНржз ржбрж┐ржкрзНрж▓ржпрж╝ржорзЗржирзНржЯрзЗрж░ ржЬржирзНржп ржЖржжрж░рзНрж╢ред

**ржорзВрж▓ ржлрзНрж░рзЗржоржУржпрж╝рж╛рж░рзНржХ ржЙржкрж╛ржжрж╛ржи**:
- **ржПржЬрзЗржирзНржЯ рж░рж╛ржиржЯрж╛ржЗржо**: ржПржЬ ржбрж┐ржнрж╛ржЗрж╕рзЗрж░ ржЬржирзНржп ржЕржкрзНржЯрж┐ржорж╛ржЗржЬ ржХрж░рж╛ рж╣рж╛рж▓ржХрж╛ ржУржЬржирзЗрж░ ржПржХрзНрж╕рж┐ржХрж┐ржЙрж╢ржи ржкрж░рж┐ржмрзЗрж╢  
- **ржЯрзБрж▓ ржЗржирзНржЯрж┐ржЧрзНрж░рзЗрж╢ржи рж╕рж┐рж╕рзНржЯрзЗржо**: ржмрж╛рж╣рзНржпрж┐ржХ ржкрж░рж┐рж╖рзЗржмрж╛ ржПржмржВ API рж╕ржВржпрзЛржЧрзЗрж░ ржЬржирзНржп ржПржХрзНрж╕ржЯрзЗржирж╕рж┐ржмрж▓ ржкрзНрж▓рж╛ржЧржЗржи ржЖрж░рзНржХрж┐ржЯрзЗржХржЪрж╛рж░  
- **рж╕рзНржЯрзЗржЯ ржорзНржпрж╛ржирзЗржЬржорзЗржирзНржЯ**: рж╕рзЗрж╢ржи ржЬрзБржбрж╝рзЗ рж╕рзНржерж╛ржпрж╝рзА ржПржЬрзЗржирзНржЯ ржорзЗржорзЛрж░рж┐ ржПржмржВ ржкрзНрж░рж╕ржЩрзНржЧ ржкрж░рж┐ржЪрж╛рж▓ржирж╛  
- **ржирж┐рж░рж╛ржкрждрзНрждрж╛ рж╕рзНрждрж░**: ржПржирзНржЯрж╛рж░ржкрзНрж░рж╛ржЗржЬ ржбрж┐ржкрзНрж▓ржпрж╝ржорзЗржирзНржЯрзЗрж░ ржЬржирзНржп ржмрж┐рж▓рзНржЯ-ржЗржи рж╕рж┐ржХрж┐ржЙрж░рж┐ржЯрж┐ ржХржирзНржЯрзНрж░рзЛрж▓  
- **ржЕрж░рзНржХрзЗрж╕рзНржЯрзНрж░рзЗрж╢ржи ржЗржЮрзНржЬрж┐ржи**: ржорж╛рж▓рзНржЯрж┐-ржПржЬрзЗржирзНржЯ рж╕ржоржирзНржмржпрж╝ ржПржмржВ ржХрж╛рж░рзНржпржкрзНрж░ржмрж╛рж╣ ржкрж░рж┐ржЪрж╛рж▓ржирж╛  

### ржПржЬ ржбрж┐ржкрзНрж▓ржпрж╝ржорзЗржирзНржЯрзЗрж░ ржЬржирзНржп ржорзВрж▓ ржмрзИрж╢рж┐рж╖рзНржЯрзНржп

**ржЕржлрж▓рж╛ржЗржи-ржкрзНрж░ржержо ржЖрж░рзНржХрж┐ржЯрзЗржХржЪрж╛рж░**: ржорж╛ржЗржХрзНрж░рзЛрж╕ржлржЯ ржПржЬрзЗржирзНржЯ ржлрзНрж░рзЗржоржУржпрж╝рж╛рж░рзНржХ ржЕржлрж▓рж╛ржЗржи-ржкрзНрж░ржержо ржирзАрждрж┐рж░ рж╕рж╛ржерзЗ ржбрж┐ржЬрж╛ржЗржи ржХрж░рж╛ рж╣ржпрж╝рзЗржЫрзЗ, ржпрж╛ ржПржЬрзЗржирзНржЯржжрзЗрж░ ржХрзНрж░ржорж╛ржЧржд ржЗржирзНржЯрж╛рж░ржирзЗржЯ рж╕ржВржпрзЛржЧ ржЫрж╛ржбрж╝рж╛ржЗ ржХрж╛рж░рзНржпржХрж░ржнрж╛ржмрзЗ ржХрж╛ржЬ ржХрж░рждрзЗ рж╕ржХрзНрж╖ржо ржХрж░рзЗред ржПрж░ ржоржзрзНржпрзЗ рж╕рзНржерж╛ржирзАржпрж╝ ржоржбрзЗрж▓ ржЗржиржлрж╛рж░рзЗржирзНрж╕, ржХрзНржпрж╛рж╢ржб ржирж▓рзЗржЬ ржмрзЗрж╕, ржЕржлрж▓рж╛ржЗржи ржЯрзБрж▓ ржПржХрзНрж╕рж┐ржХрж┐ржЙрж╢ржи ржПржмржВ ржХрзНрж▓рж╛ржЙржб ржкрж░рж┐рж╖рзЗржмрж╛ ржЕржирзБржкрж▓ржмрзНржз ржерж╛ржХрж▓рзЗ ржЧрзНрж░рзЗрж╕ржлрзБрж▓ ржбрж┐ржЧрзНрж░рзЗржбрзЗрж╢ржи ржЕржирзНрждрж░рзНржнрзБржХрзНрждред  

**рж░рж┐рж╕рзЛрж░рзНрж╕ ржЕржкрзНржЯрж┐ржорж╛ржЗржЬрзЗрж╢ржи**: ржлрзНрж░рзЗржоржУржпрж╝рж╛рж░рзНржХржЯрж┐ ржмрзБржжрзНржзрж┐ржорж╛ржи рж░рж┐рж╕рзЛрж░рзНрж╕ ржорзНржпрж╛ржирзЗржЬржорзЗржирзНржЯ ржкрзНрж░ржжрж╛ржи ржХрж░рзЗ, SLM-ржПрж░ ржЬржирзНржп рж╕рзНржмржпрж╝ржВржХрзНрж░рж┐ржпрж╝ ржорзЗржорзЛрж░рж┐ ржЕржкрзНржЯрж┐ржорж╛ржЗржЬрзЗрж╢ржи, ржПржЬ ржбрж┐ржнрж╛ржЗрж╕рзЗрж░ ржЬржирзНржп CPU/GPU рж▓рзЛржб ржмрзНржпрж╛рж▓рзЗржирзНрж╕рж┐ржВ, ржЙржкрж▓ржмрзНржз рж░рж┐рж╕рзЛрж░рзНрж╕рзЗрж░ ржЙржкрж░ ржнрж┐рждрзНрждрж┐ ржХрж░рзЗ ржЕржнрж┐ржпрзЛржЬрж┐ржд ржоржбрзЗрж▓ ржирж┐рж░рзНржмрж╛ржЪржи ржПржмржВ ржорзЛржмрж╛ржЗрж▓ ржбрж┐ржкрзНрж▓ржпрж╝ржорзЗржирзНржЯрзЗрж░ ржЬржирзНржп ржкрж╛ржУржпрж╝рж╛рж░-ржжржХрзНрж╖ ржЗржиржлрж╛рж░рзЗржирзНрж╕ ржкрзНржпрж╛ржЯрж╛рж░рзНржиред  

**ржирж┐рж░рж╛ржкрждрзНрждрж╛ ржПржмржВ ржЧрзЛржкржирзАржпрж╝рждрж╛**: ржПржирзНржЯрж╛рж░ржкрзНрж░рж╛ржЗржЬ-ржЧрзНрж░рзЗржб ржирж┐рж░рж╛ржкрждрзНрждрж╛ ржмрзИрж╢рж┐рж╖рзНржЯрзНржпржЧрзБрж▓рж┐рж░ ржоржзрзНржпрзЗ рж░ржпрж╝рзЗржЫрзЗ ржЧрзЛржкржирзАржпрж╝рждрж╛ ржмржЬрж╛ржпрж╝ рж░рж╛ржЦрждрзЗ рж╕рзНржерж╛ржирзАржпрж╝ ржбрзЗржЯрж╛ ржкрзНрж░рж╕рзЗрж╕рж┐ржВ, ржПржиржХрзНрж░рж┐ржкрзНржЯрзЗржб ржПржЬрзЗржирзНржЯ ржпрзЛржЧрж╛ржпрзЛржЧ ржЪрзНржпрж╛ржирзЗрж▓, ржПржЬрзЗржирзНржЯ рж╕ржХрзНрж╖ржорждрж╛рж░ ржЬржирзНржп ржнрзВржорж┐ржХрж╛-ржнрж┐рждрзНрждрж┐ржХ ржЕрзНржпрж╛ржХрзНрж╕рзЗрж╕ ржирж┐ржпрж╝ржирзНрждрзНрж░ржг ржПржмржВ рж╕ржорзНржорждрж┐ ржкрзНрж░ржпрж╝рзЛржЬржирзАржпрж╝рждрж╛рж░ ржЬржирзНржп ржЕржбрж┐ржЯ рж▓ржЧрж┐ржВред  

### Foundry Local-ржПрж░ рж╕рж╛ржерзЗ ржЗржирзНржЯрж┐ржЧрзНрж░рзЗрж╢ржи

ржорж╛ржЗржХрзНрж░рзЛрж╕ржлржЯ ржПржЬрзЗржирзНржЯ ржлрзНрж░рзЗржоржУржпрж╝рж╛рж░рзНржХ Foundry Local-ржПрж░ рж╕рж╛ржерзЗ ржирж┐рж░рзНржмрж┐ржШрзНржирзЗ ржЗржирзНржЯрж┐ржЧрзНрж░рзЗржЯ рж╣ржпрж╝ ржПржмржВ ржПржХржЯрж┐ рж╕ржорзНржкрзВрж░рзНржг ржПржЬ AI рж╕ржорж╛ржзрж╛ржи ржкрзНрж░ржжрж╛ржи ржХрж░рзЗ:

**рж╕рзНржмржпрж╝ржВржХрзНрж░рж┐ржпрж╝ ржоржбрзЗрж▓ ржЖржмрж┐рж╖рзНржХрж╛рж░**: ржлрзНрж░рзЗржоржУржпрж╝рж╛рж░рзНржХржЯрж┐ рж╕рзНржмржпрж╝ржВржХрзНрж░рж┐ржпрж╝ржнрж╛ржмрзЗ Foundry Local ржЗржирж╕рзНржЯрзНржпрж╛ржирзНрж╕ржЧрзБрж▓рж┐ рж╕ржирж╛ржХрзНржд ржХрж░рзЗ ржПржмржВ рж╕ржВржпрзБржХрзНржд ржХрж░рзЗ, ржЙржкрж▓ржмрзНржз SLM ржоржбрзЗрж▓ржЧрзБрж▓рж┐ ржЖржмрж┐рж╖рзНржХрж╛рж░ ржХрж░рзЗ ржПржмржВ ржПржЬрзЗржирзНржЯрзЗрж░ ржкрзНрж░ржпрж╝рзЛржЬржирзАржпрж╝рждрж╛ ржПржмржВ рж╣рж╛рж░рзНржбржУржпрж╝рзНржпрж╛рж░ рж╕ржХрзНрж╖ржорждрж╛рж░ ржЙржкрж░ ржнрж┐рждрзНрждрж┐ ржХрж░рзЗ рж╕рж░рзНржмрзЛрждрзНрждржо ржоржбрзЗрж▓ ржирж┐рж░рзНржмрж╛ржЪржи ржХрж░рзЗред  

**ржбрж╛ржпрж╝ржирж╛ржорж┐ржХ ржоржбрзЗрж▓ рж▓рзЛржбрж┐ржВ**: ржПржЬрзЗржирзНржЯрж░рж╛ ржирж┐рж░рзНржжрж┐рж╖рзНржЯ ржХрж╛ржЬрзЗрж░ ржЬржирзНржп ржмрж┐ржнрж┐ржирзНржи SLM рж╕рзНржерж╛ржирзАржпрж╝ржнрж╛ржмрзЗ рж▓рзЛржб ржХрж░рждрзЗ ржкрж╛рж░рзЗ, ржорж╛рж▓рзНржЯрж┐-ржоржбрзЗрж▓ ржПржЬрзЗржирзНржЯ рж╕рж┐рж╕рзНржЯрзЗржо рж╕ржХрзНрж╖ржо ржХрж░рзЗ ржпрзЗржЦрж╛ржирзЗ ржмрж┐ржнрж┐ржирзНржи ржоржбрзЗрж▓ ржмрж┐ржнрж┐ржирзНржи ржзрж░ржгрзЗрж░ ржЕржирзБрж░рзЛржз ржкрж░рж┐ржЪрж╛рж▓ржирж╛ ржХрж░рзЗ ржПржмржВ ржЙржкрж▓ржмрзНржзрждрж╛ ржПржмржВ ржкрж╛рж░ржлрж░ржорзНржпрж╛ржирзНрж╕рзЗрж░ ржЙржкрж░ ржнрж┐рждрзНрждрж┐ ржХрж░рзЗ ржоржбрзЗрж▓ржЧрзБрж▓рж┐рж░ ржоржзрзНржпрзЗ рж╕рзНржмржпрж╝ржВржХрзНрж░рж┐ржпрж╝ ржлрзЗржЗрж▓ржУржнрж╛рж░ред  

**ржкрж╛рж░ржлрж░ржорзНржпрж╛ржирзНрж╕ ржЕржкрзНржЯрж┐ржорж╛ржЗржЬрзЗрж╢ржи**: ржЗржирзНржЯрж┐ржЧрзНрж░рзЗржЯрзЗржб ржХрзНржпрж╛рж╢рж┐ржВ ржорзЗржХрж╛ржирж┐ржЬржо ржоржбрзЗрж▓ рж▓рзЛржбрж┐ржВ ржЯрж╛ржЗржо рж╣рзНрж░рж╛рж╕ ржХрж░рзЗ, ржХрж╛ржирзЗржХрж╢ржи ржкрзБрж▓рж┐ржВ Foundry Local-ржП API ржХрж▓ ржЕржкрзНржЯрж┐ржорж╛ржЗржЬ ржХрж░рзЗ ржПржмржВ ржмрзБржжрзНржзрж┐ржорж╛ржи ржмрзНржпрж╛ржЪрж┐ржВ ржПржХрж╛ржзрж┐ржХ ржПржЬрзЗржирзНржЯ ржЕржирзБрж░рзЛржзрзЗрж░ ржЬржирзНржп ржерзНрж░рзБржкрзБржЯ ржЙржирзНржиржд ржХрж░рзЗред  

### ржорж╛ржЗржХрзНрж░рзЛрж╕ржлржЯ ржПржЬрзЗржирзНржЯ ржлрзНрж░рзЗржоржУржпрж╝рж╛рж░рзНржХ ржжрж┐ржпрж╝рзЗ ржПржЬрзЗржирзНржЯ рждрзИрж░рж┐

#### ржПржЬрзЗржирзНржЯ рж╕ржВржЬрзНржЮрж╛ ржПржмржВ ржХржиржлрж┐ржЧрж╛рж░рзЗрж╢ржи

```python
from microsoft_agent_framework import Agent, Tool, Config
from foundry_local import FoundryLocalManager

# Configure agent with Foundry Local integration
config = Config(
    name="customer-service-agent",
    model_provider="foundry-local",
    model_alias="phi-4-mini",
    max_tokens=512,
    temperature=0.1,
    offline_mode=True
)

# Initialize Foundry Local connection
foundry = FoundryLocalManager("phi-4-mini")

# Create agent instance
agent = Agent(
    config=config,
    model_endpoint=foundry.endpoint,
    api_key=foundry.api_key
)
```
  
#### ржПржЬ ржЯрзБрж▓ ржЗржирзНржЯрж┐ржЧрзНрж░рзЗрж╢ржи

```python
# Define tools for offline operation
@agent.tool
def lookup_customer_info(customer_id: str) -> dict:
    """Look up customer information from local database."""
    # Local database query - works offline
    return local_db.get_customer(customer_id)

@agent.tool
def create_support_ticket(issue: str, priority: str) -> str:
    """Create a support ticket in local system."""
    # Local ticket creation with sync when online
    ticket_id = local_system.create_ticket(issue, priority)
    return f"Ticket {ticket_id} created successfully"

@agent.tool
def schedule_callback(customer_id: str, preferred_time: str) -> str:
    """Schedule a callback for the customer."""
    # Local scheduling with calendar integration
    return local_calendar.schedule(customer_id, preferred_time)
```
  
#### ржорж╛рж▓рзНржЯрж┐-ржПржЬрзЗржирзНржЯ ржЕрж░рзНржХрзЗрж╕рзНржЯрзНрж░рзЗрж╢ржи

```python
from microsoft_agent_framework import AgentOrchestrator

# Create specialized agents for different domains
scheduling_agent = Agent(
    config=Config(
        name="scheduling-agent",
        model_alias="qwen2.5-0.5b",  # Lightweight for simple tasks
        specialized_for="scheduling"
    )
)

technical_support_agent = Agent(
    config=Config(
        name="technical-agent",
        model_alias="phi-4-mini",  # More capable for complex issues
        specialized_for="technical_support"
    )
)

# Orchestrate multiple agents
orchestrator = AgentOrchestrator([
    scheduling_agent,
    technical_support_agent
])

# Route requests based on intent
result = orchestrator.process_request(
    "I need to schedule a callback for a technical issue",
    routing_strategy="intent-based"
)
```
  

### ржЙржирзНржиржд ржПржЬ ржбрж┐ржкрзНрж▓ржпрж╝ржорзЗржирзНржЯ ржкрзНржпрж╛ржЯрж╛рж░рзНржи

#### рж╣рж╛ржпрж╝рж╛рж░рж╛рж░ржХрж┐ржХрж╛рж▓ ржПржЬрзЗржирзНржЯ ржЖрж░рзНржХрж┐ржЯрзЗржХржЪрж╛рж░

**рж╕рзНржерж╛ржирзАржпрж╝ ржПржЬрзЗржирзНржЯ ржХрзНрж▓рж╛рж╕рзНржЯрж╛рж░**: ржирж┐рж░рзНржжрж┐рж╖рзНржЯ ржХрж╛ржЬрзЗрж░ ржЬржирзНржп ржЕржкрзНржЯрж┐ржорж╛ржЗржЬ ржХрж░рж╛ ржПржХрж╛ржзрж┐ржХ ржмрж┐рж╢рзЗрж╖рж╛ржпрж╝рж┐ржд SLM ржПржЬрзЗржирзНржЯ ржПржЬ ржбрж┐ржнрж╛ржЗрж╕рзЗ ржбрж┐ржкрзНрж▓ржпрж╝ ржХрж░рзБржиред рж╕рж╣ржЬ рж░рж╛ржЙржЯрж┐ржВ ржПржмржВ рж╢рж┐ржбрж┐ржЙрж▓рж┐ржВржпрж╝рзЗрж░ ржЬржирзНржп Qwen2.5-0.5B-ржПрж░ ржорждрзЛ рж╣рж╛рж▓ржХрж╛ ржоржбрзЗрж▓ ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзБржи, ржЧрзНрж░рж╛рж╣ржХ ржкрж░рж┐рж╖рзЗржмрж╛ ржПржмржВ ржбржХрзБржорзЗржирзНржЯрзЗрж╢ржирзЗрж░ ржЬржирзНржп Phi-4-Mini-ржПрж░ ржорждрзЛ ржорж╛ржЭрж╛рж░рж┐ ржоржбрзЗрж▓ ржПржмржВ ржЬржЯрж┐рж▓ ржпрзБржХрзНрждрж┐рж░ ржЬржирзНржп ржмржбрж╝ ржоржбрзЗрж▓ ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзБржи ржпржЦржи рж░рж┐рж╕рзЛрж░рзНрж╕ ржЙржкрж▓ржмрзНржз ржерж╛ржХрзЗред  

**ржПржЬ-ржЯрзБ-ржХрзНрж▓рж╛ржЙржб рж╕ржоржирзНржмржпрж╝**: ржмрзБржжрзНржзрж┐ржорж╛ржи ржПрж╕ржХрзЗрж▓рзЗрж╢ржи ржкрзНржпрж╛ржЯрж╛рж░рзНржи ржмрж╛рж╕рзНрждржмрж╛ржпрж╝ржи ржХрж░рзБржи ржпрзЗржЦрж╛ржирзЗ рж╕рзНржерж╛ржирзАржпрж╝ ржПржЬрзЗржирзНржЯрж░рж╛ рж░рзБржЯрж┐ржи ржХрж╛ржЬ ржкрж░рж┐ржЪрж╛рж▓ржирж╛ ржХрж░рзЗ, ржХрзНрж▓рж╛ржЙржб ржПржЬрзЗржирзНржЯрж░рж╛ рж╕ржВржпрзЛржЧ ржЙржкрж▓ржмрзНржз ржерж╛ржХрж▓рзЗ ржЬржЯрж┐рж▓ ржпрзБржХрзНрждрж┐ ржкрзНрж░ржжрж╛ржи ржХрж░рзЗ ржПржмржВ ржПржЬ ржПржмржВ ржХрзНрж▓рж╛ржЙржб ржкрзНрж░рж╕рзЗрж╕рж┐ржВржпрж╝рзЗрж░ ржоржзрзНржпрзЗ ржирж┐рж░рзНржмрж┐ржШрзНржи рж╣рзНржпрж╛ржирзНржбржЕржл ржзрж╛рж░рж╛ржмрж╛рж╣рж┐ржХрждрж╛ ржмржЬрж╛ржпрж╝ рж░рж╛ржЦрзЗред  

#### ржбрж┐ржкрзНрж▓ржпрж╝ржорзЗржирзНржЯ ржХржиржлрж┐ржЧрж╛рж░рзЗрж╢ржи

**ржПржХржХ ржбрж┐ржнрж╛ржЗрж╕ ржбрж┐ржкрзНрж▓ржпрж╝ржо
**ржПржЬрзЗржирзНржЯ ржбрж┐ржкрзНрж▓ржпрж╝ржорзЗржирзНржЯрзЗрж░ ржЬржирзНржп ржлрзНрж░рзЗржоржУржпрж╝рж╛рж░рзНржХ ржирж┐рж░рзНржмрж╛ржЪржи**: рж▓ржХрзНрж╖рзНржп рж╣рж╛рж░рзНржбржУржпрж╝рзНржпрж╛рж░ ржПржмржВ ржПржЬрзЗржирзНржЯрзЗрж░ ржкрзНрж░ржпрж╝рзЛржЬржирзАржпрж╝рждрж╛рж░ ржЙржкрж░ ржнрж┐рждрзНрждрж┐ ржХрж░рзЗ ржЕржкрзНржЯрж┐ржорж╛ржЗржЬрзЗрж╢ржи ржлрзНрж░рзЗржоржУржпрж╝рж╛рж░рзНржХ ржирж┐рж░рзНржмрж╛ржЪржи ржХрж░рзБржиред CPU-ржЕржкрзНржЯрж┐ржорж╛ржЗржЬржб ржПржЬрзЗржирзНржЯ ржбрж┐ржкрзНрж▓ржпрж╝ржорзЗржирзНржЯрзЗрж░ ржЬржирзНржп Llama.cpp ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзБржи, Apple Silicon ржПржЬрзЗржирзНржЯ ржЕрзНржпрж╛ржкрзНрж▓рж┐ржХрзЗрж╢ржирзЗрж░ ржЬржирзНржп Apple MLX ржПржмржВ ржХрзНрж░рж╕-ржкрзНрж▓рзНржпрж╛ржЯржлрж░рзНржо ржПржЬрзЗржирзНржЯ рж╕рж╛ржоржЮрзНржЬрж╕рзНржпрзЗрж░ ржЬржирзНржп ONNX ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзБржиред

## ржмрж╛рж╕рзНрждржм SLM ржПржЬрзЗржирзНржЯ рж░рзВржкрж╛ржирзНрждрж░ ржПржмржВ ржмрзНржпржмрж╣рж╛рж░ ржХрзНрж╖рзЗрждрзНрж░

### ржмрж╛рж╕рзНрждржм ржЬрзАржмржирзЗрж░ ржПржЬрзЗржирзНржЯ ржбрж┐ржкрзНрж▓ржпрж╝ржорзЗржирзНржЯ ржкрж░рж┐рж╕рзНржерж┐рждрж┐

**ржорзЛржмрж╛ржЗрж▓ ржПржЬрзЗржирзНржЯ ржЕрзНржпрж╛ржкрзНрж▓рж┐ржХрзЗрж╢ржи**: рж╕рзНржорж╛рж░рзНржЯржлрзЛржи ржПржЬрзЗржирзНржЯ ржЕрзНржпрж╛ржкрзНрж▓рж┐ржХрзЗрж╢ржирзЗрж░ ржЬржирзНржп Q4_K ржлрж░ржорзНржпрж╛ржЯ ржХржо ржорзЗржорзЛрж░рж┐ ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗ ржХрж╛рж░рзНржпржХрж░, ржпрзЗржЦрж╛ржирзЗ Q8_0 ржЯрзНржпрж╛ржмрж▓рзЗржЯ-ржнрж┐рждрзНрждрж┐ржХ ржПржЬрзЗржирзНржЯ рж╕рж┐рж╕рзНржЯрзЗржорзЗрж░ ржЬржирзНржп ржнрж╛рж░рж╕рж╛ржорзНржпржкрзВрж░рзНржг ржкрж╛рж░ржлрж░ржорзНржпрж╛ржирзНрж╕ ржкрзНрж░ржжрж╛ржи ржХрж░рзЗред Q5_K ржлрж░ржорзНржпрж╛ржЯ ржорзЛржмрж╛ржЗрж▓ ржкрзНрж░рзЛржбрж╛ржХрзНржЯрж┐ржнрж┐ржЯрж┐ ржПржЬрзЗржирзНржЯрзЗрж░ ржЬржирзНржп ржЙржЪрзНржЪржорж╛ржирзЗрж░ рж╕рзЗржмрж╛ ржкрзНрж░ржжрж╛ржи ржХрж░рзЗред

**ржбрзЗрж╕рзНржХржЯржк ржПржмржВ ржПржЬ ржПржЬрзЗржирзНржЯ ржХржорзНржкрж┐ржЙржЯрж┐ржВ**: ржбрзЗрж╕рзНржХржЯржк ржПржЬрзЗржирзНржЯ ржЕрзНржпрж╛ржкрзНрж▓рж┐ржХрзЗрж╢ржирзЗрж░ ржЬржирзНржп Q5_K рж╕рж░рзНржмрзЛрждрзНрждржо ржкрж╛рж░ржлрж░ржорзНржпрж╛ржирзНрж╕ ржкрзНрж░ржжрж╛ржи ржХрж░рзЗ, ржУржпрж╝рж╛рж░рзНржХрж╕рзНржЯрзЗрж╢ржи ржПржЬрзЗржирзНржЯ ржкрж░рж┐ржмрзЗрж╢рзЗрж░ ржЬржирзНржп Q8_0 ржЙржЪрзНржЪржорж╛ржирзЗрж░ ржЗржиржлрж╛рж░рзЗржирзНрж╕ рж╕рж░ржмрж░рж╛рж╣ ржХрж░рзЗ ржПржмржВ ржПржЬ ржПржЬрзЗржирзНржЯ ржбрж┐ржнрж╛ржЗрж╕рзЗрж░ ржЬржирзНржп Q4_K ржХрж╛рж░рзНржпржХрж░ ржкрзНрж░ржХрзНрж░рж┐ржпрж╝рж╛ржХрж░ржг рж╕ржХрзНрж╖ржо ржХрж░рзЗред

**ржЧржмрзЗрж╖ржгрж╛ ржПржмржВ ржкрж░рзАржХрзНрж╖рж╛ржорзВрж▓ржХ ржПржЬрзЗржирзНржЯ**: ржЙржирзНржиржд ржХрзЛржпрж╝рж╛ржирзНржЯрж╛ржЗржЬрзЗрж╢ржи ржлрж░ржорзНржпрж╛ржЯржЧрзБрж▓рж┐ ржЕрждрзНржпржирзНржд ржХржо ржкрзНрж░рж┐рж╕рж┐рж╢ржи ржПржЬрзЗржирзНржЯ ржЗржиржлрж╛рж░рзЗржирзНрж╕ ржЕржирзНржмрзЗрж╖ржгрзЗрж░ ржЬржирзНржп ржПржХрж╛ржбрзЗржорж┐ржХ ржЧржмрзЗрж╖ржгрж╛ ржПржмржВ ржкрзНрж░рзБржл-ржЕржл-ржХржирж╕рзЗржкрзНржЯ ржПржЬрзЗржирзНржЯ ржЕрзНржпрж╛ржкрзНрж▓рж┐ржХрзЗрж╢ржирзЗрж░ ржЬржирзНржп ржЙржкржпрзЛржЧрзАред

### SLM ржПржЬрзЗржирзНржЯ ржкрж╛рж░ржлрж░ржорзНржпрж╛ржирзНрж╕ ржмрзЗржЮрзНржЪржорж╛рж░рзНржХ

**ржПржЬрзЗржирзНржЯ ржЗржиржлрж╛рж░рзЗржирзНрж╕ ржЧрждрж┐**: ржорзЛржмрж╛ржЗрж▓ CPU-рждрзЗ Q4_K ржжрзНрж░рзБрждрждржо ржПржЬрзЗржирзНржЯ ржкрзНрж░рждрж┐ржХрзНрж░рж┐ржпрж╝рж╛ рж╕ржоржпрж╝ ржЕрж░рзНржЬржи ржХрж░рзЗ, Q5_K рж╕рж╛ржзрж╛рж░ржг ржПржЬрзЗржирзНржЯ ржЕрзНржпрж╛ржкрзНрж▓рж┐ржХрзЗрж╢ржирзЗрж░ ржЬржирзНржп ржЧрждрж┐-ржЧрзБржгржорж╛ржирзЗрж░ ржнрж╛рж░рж╕рж╛ржорзНржп ржкрзНрж░ржжрж╛ржи ржХрж░рзЗ, Q8_0 ржЬржЯрж┐рж▓ ржПржЬрзЗржирзНржЯ ржХрж╛ржЬрзЗрж░ ржЬржирзНржп ржЙржЪрзНржЪржорж╛ржирзЗрж░ рж╕рзЗржмрж╛ ржкрзНрж░ржжрж╛ржи ржХрж░рзЗ ржПржмржВ ржкрж░рзАржХрзНрж╖рж╛ржорзВрж▓ржХ ржлрж░ржорзНржпрж╛ржЯржЧрзБрж▓рж┐ ржмрж┐рж╢рзЗрж╖рж╛ржпрж╝рж┐ржд ржПржЬрзЗржирзНржЯ рж╣рж╛рж░рзНржбржУржпрж╝рзНржпрж╛рж░рзЗрж░ ржЬржирзНржп рж╕рж░рзНржмрж╛ржзрж┐ржХ ржерзНрж░рзБржкрзБржЯ рж╕рж░ржмрж░рж╛рж╣ ржХрж░рзЗред

**ржПржЬрзЗржирзНржЯ ржорзЗржорзЛрж░рж┐ ржкрзНрж░ржпрж╝рзЛржЬржирзАржпрж╝рждрж╛**: ржПржЬрзЗржирзНржЯрзЗрж░ ржЬржирзНржп ржХрзЛржпрж╝рж╛ржирзНржЯрж╛ржЗржЬрзЗрж╢ржи рж╕рзНрждрж░ Q2_K (ржЫрзЛржЯ ржПржЬрзЗржирзНржЯ ржоржбрзЗрж▓рзЗрж░ ржЬржирзНржп рзлрзжрзж ржПржоржмрж┐ ржПрж░ ржирж┐ржЪрзЗ) ржерзЗржХрзЗ Q8_0 (ржорзВрж▓ ржЖржХрж╛рж░рзЗрж░ ржкрзНрж░рж╛ржпрж╝ рзлрзж%) ржкрж░рзНржпржирзНржд ржмрж┐рж╕рзНрждрзГржд, ржпрзЗржЦрж╛ржирзЗ ржкрж░рзАржХрзНрж╖рж╛ржорзВрж▓ржХ ржХржиржлрж┐ржЧрж╛рж░рзЗрж╢ржиржЧрзБрж▓рж┐ рж╕ржорзНржкржж-рж╕рзАржорж╛ржмржжрзНржз ржПржЬрзЗржирзНржЯ ржкрж░рж┐ржмрзЗрж╢рзЗрж░ ржЬржирзНржп рж╕рж░рзНржмрж╛ржзрж┐ржХ ржХржорзНржкрзНрж░рзЗрж╢ржи ржЕрж░рзНржЬржи ржХрж░рзЗред

## SLM ржПржЬрзЗржирзНржЯрзЗрж░ ржЪрзНржпрж╛рж▓рзЗржЮрзНржЬ ржПржмржВ ржмрж┐ржмрзЗржЪржирж╛

### ржПржЬрзЗржирзНржЯ рж╕рж┐рж╕рзНржЯрзЗржорзЗ ржкрж╛рж░ржлрж░ржорзНржпрж╛ржирзНрж╕ ржЯрзНрж░рзЗржб-ржЕржл

SLM ржПржЬрзЗржирзНржЯ ржбрж┐ржкрзНрж▓ржпрж╝ржорзЗржирзНржЯрзЗ ржоржбрзЗрж▓рзЗрж░ ржЖржХрж╛рж░, ржПржЬрзЗржирзНржЯ ржкрзНрж░рждрж┐ржХрзНрж░рж┐ржпрж╝рж╛ ржЧрждрж┐ ржПржмржВ ржЖржЙржЯржкрзБржЯ ржЧрзБржгржорж╛ржирзЗрж░ ржоржзрзНржпрзЗ ржЯрзНрж░рзЗржб-ржЕржлржЧрзБрж▓рж┐ рж╕рж╛ржмржзрж╛ржирзЗ ржмрж┐ржмрзЗржЪржирж╛ ржХрж░рж╛ ржкрзНрж░ржпрж╝рзЛржЬржиред Q4_K ржорзЛржмрж╛ржЗрж▓ ржПржЬрзЗржирзНржЯрзЗрж░ ржЬржирзНржп ржЕрж╕рж╛ржзрж╛рж░ржг ржЧрждрж┐ ржПржмржВ ржжржХрзНрж╖рждрж╛ ржкрзНрж░ржжрж╛ржи ржХрж░рзЗ, Q8_0 ржЬржЯрж┐рж▓ ржПржЬрзЗржирзНржЯ ржХрж╛ржЬрзЗрж░ ржЬржирзНржп ржЙржЪрзНржЪржорж╛ржирзЗрж░ рж╕рзЗржмрж╛ ржкрзНрж░ржжрж╛ржи ржХрж░рзЗред Q5_K ржмрзЗрж╢рж┐рж░ржнрж╛ржЧ рж╕рж╛ржзрж╛рж░ржг ржПржЬрзЗржирзНржЯ ржЕрзНржпрж╛ржкрзНрж▓рж┐ржХрзЗрж╢ржирзЗрж░ ржЬржирзНржп ржПржХржЯрж┐ ржоржзрзНржпржо ржкрже рждрзИрж░рж┐ ржХрж░рзЗред

### SLM ржПржЬрзЗржирзНржЯрзЗрж░ ржЬржирзНржп рж╣рж╛рж░рзНржбржУржпрж╝рзНржпрж╛рж░ рж╕рж╛ржоржЮрзНржЬрж╕рзНржп

ржмрж┐ржнрж┐ржирзНржи ржПржЬ ржбрж┐ржнрж╛ржЗрж╕рзЗрж░ SLM ржПржЬрзЗржирзНржЯ ржбрж┐ржкрзНрж▓ржпрж╝ржорзЗржирзНржЯрзЗрж░ ржЬржирзНржп ржмрж┐ржнрж┐ржирзНржи ржХрзНрж╖ржорждрж╛ рж░ржпрж╝рзЗржЫрзЗред Q4_K рж╕рж╛ржзрж╛рж░ржг ржкрзНрж░рж╕рзЗрж╕рж░рзЗ рж╕рж╣ржЬ ржПржЬрзЗржирзНржЯрзЗрж░ ржЬржирзНржп ржХрж╛рж░рзНржпржХрж░ржнрж╛ржмрзЗ ржЪрж▓рзЗ, Q5_K ржнрж╛рж░рж╕рж╛ржорзНржпржкрзВрж░рзНржг ржПржЬрзЗржирзНржЯ ржкрж╛рж░ржлрж░ржорзНржпрж╛ржирзНрж╕рзЗрж░ ржЬржирзНржп ржорж╛ржЭрж╛рж░рж┐ ржХржорзНржкрж┐ржЙржЯрзЗрж╢ржирж╛рж▓ рж░рж┐рж╕рзЛрж░рзНрж╕ ржкрзНрж░ржпрж╝рзЛржЬржи ржПржмржВ Q8_0 ржЙржирзНржиржд ржПржЬрзЗржирзНржЯ ржХрзНрж╖ржорждрж╛рж░ ржЬржирзНржп ржЙржЪрзНржЪржорж╛ржирзЗрж░ рж╣рж╛рж░рзНржбржУржпрж╝рзНржпрж╛рж░ ржерзЗржХрзЗ ржЙржкржХрзГржд рж╣ржпрж╝ред

### SLM ржПржЬрзЗржирзНржЯ рж╕рж┐рж╕рзНржЯрзЗржорзЗ ржирж┐рж░рж╛ржкрждрзНрждрж╛ ржПржмржВ ржЧрзЛржкржирзАржпрж╝рждрж╛

SLM ржПржЬрзЗржирзНржЯ рж╕рзНржерж╛ржирзАржпрж╝ ржкрзНрж░ржХрзНрж░рж┐ржпрж╝рж╛ржХрж░ржгрзЗрж░ ржорж╛ржзрзНржпржорзЗ ржЙржирзНржиржд ржЧрзЛржкржирзАржпрж╝рждрж╛ рж╕ржХрзНрж╖ржо ржХрж░рзЗ, рждржмрзЗ ржПржЬрзЗржирзНржЯ ржоржбрзЗрж▓ ржПржмржВ ржбрзЗржЯрж╛ рж╕рзБрж░ржХрзНрж╖рж╛рж░ ржЬржирзНржп рж╕ржарж┐ржХ ржирж┐рж░рж╛ржкрждрзНрждрж╛ ржмрзНржпржмрж╕рзНржерж╛ ржкрзНрж░ржпрж╝рзЛржЧ ржХрж░рж╛ ржЖржмрж╢рзНржпржХред ржПржЯрж┐ ржмрж┐рж╢рзЗрж╖ржд ржЧрзБрж░рзБрждрзНржмржкрзВрж░рзНржг ржпржЦржи ржПржирзНржЯрж╛рж░ржкрзНрж░рж╛ржЗржЬ ржкрж░рж┐ржмрзЗрж╢рзЗ ржЙржЪрзНржЪ-ржкрзНрж░рж┐рж╕рж┐рж╢ржи ржПржЬрзЗржирзНржЯ ржлрж░ржорзНржпрж╛ржЯ ржмрж╛ рж╕ржВржХрзНрж╖рзЗржкрж┐ржд ржПржЬрзЗржирзНржЯ ржлрж░ржорзНржпрж╛ржЯржЧрзБрж▓рж┐ рж╕ржВржмрзЗржжржирж╢рзАрж▓ ржбрзЗржЯрж╛ ржкрж░рж┐ржЪрж╛рж▓ржирж╛рж░ ржЕрзНржпрж╛ржкрзНрж▓рж┐ржХрзЗрж╢ржирзЗ ржбрж┐ржкрзНрж▓ржпрж╝ ржХрж░рж╛ рж╣ржпрж╝ред

## SLM ржПржЬрзЗржирзНржЯ ржЙржирзНржиржпрж╝ржирзЗрж░ ржнржмрж┐рж╖рзНржпрзО ржкрзНрж░ржмржгрждрж╛

SLM ржПржЬрзЗржирзНржЯ рж▓рзНржпрж╛ржирзНржбрж╕рзНржХрзЗржк ржХржорзНржкрзНрж░рзЗрж╢ржи ржХрзМрж╢рж▓, ржЕржкрзНржЯрж┐ржорж╛ржЗржЬрзЗрж╢ржи ржкржжрзНржзрждрж┐ ржПржмржВ ржПржЬ ржбрж┐ржкрзНрж▓ржпрж╝ржорзЗржирзНржЯ ржХрзМрж╢рж▓рзЗрж░ ржЕржЧрзНрж░ржЧрждрж┐рж░ рж╕рж╛ржерзЗ ржмрж┐ржХрж╢рж┐ржд рж╣рждрзЗ ржерж╛ржХрзЗред ржнржмрж┐рж╖рзНржпрждрзЗрж░ ржЙржирзНржиржпрж╝ржиржЧрзБрж▓рж┐рж░ ржоржзрзНржпрзЗ рж░ржпрж╝рзЗржЫрзЗ ржПржЬрзЗржирзНржЯ ржоржбрзЗрж▓рзЗрж░ ржЬржирзНржп ржЖрж░ржУ ржХрж╛рж░рзНржпржХрж░ ржХрзЛржпрж╝рж╛ржирзНржЯрж╛ржЗржЬрзЗрж╢ржи ржЕрзНржпрж╛рж▓ржЧрж░рж┐ржжржо, ржПржЬрзЗржирзНржЯ ржУржпрж╝рж╛рж░рзНржХржлрзНрж▓рзЛржЧрзБрж▓рж┐рж░ ржЬржирзНржп ржЙржирзНржиржд ржХржорзНржкрзНрж░рзЗрж╢ржи ржкржжрзНржзрждрж┐ ржПржмржВ ржПржЬрзЗржирзНржЯ ржкрзНрж░ржХрзНрж░рж┐ржпрж╝рж╛ржХрж░ржгрзЗрж░ ржЬржирзНржп ржПржЬ рж╣рж╛рж░рзНржбржУржпрж╝рзНржпрж╛рж░ ржЕрзНржпрж╛ржХрзНрж╕рж┐рж▓рж╛рж░рзЗржЯрж░рзЗрж░ рж╕рж╛ржерзЗ ржЖрж░ржУ ржнрж╛рж▓ ржЗржирзНржЯрж┐ржЧрзНрж░рзЗрж╢ржиред

**SLM ржПржЬрзЗржирзНржЯрзЗрж░ ржЬржирзНржп ржмрж╛ржЬрж╛рж░ ржкрзВрж░рзНржмрж╛ржнрж╛рж╕**: рж╕рж╛ржорзНржкрзНрж░рждрж┐ржХ ржЧржмрзЗрж╖ржгрж╛ ржЕржирзБрж╕рж╛рж░рзЗ, ржПржЬрзЗржирзНржЯ-ржЪрж╛рж▓рж┐ржд ржЕржЯрзЛржорзЗрж╢ржи рзирзжрзирзн рж╕рж╛рж▓рзЗрж░ ржоржзрзНржпрзЗ ржПржирзНржЯрж╛рж░ржкрзНрж░рж╛ржЗржЬ ржУржпрж╝рж╛рж░рзНржХржлрзНрж▓рзЛрждрзЗ рзкрзж-рзмрзж% ржкрзБржирж░рж╛ржмрзГрждрзНрждрж┐ржорзВрж▓ржХ ржХржЧржирж┐ржЯрж┐ржн ржХрж╛ржЬ ржжрзВрж░ ржХрж░рждрзЗ ржкрж╛рж░рзЗ, ржпрзЗржЦрж╛ржирзЗ SLM ржЧрзБрж▓рж┐ рждрж╛ржжрзЗрж░ ржЦрж░ржЪ ржжржХрзНрж╖рждрж╛ ржПржмржВ ржбрж┐ржкрзНрж▓ржпрж╝ржорзЗржирзНржЯ ржиржоржирзАржпрж╝рждрж╛рж░ ржХрж╛рж░ржгрзЗ ржПржЗ рж░рзВржкрж╛ржирзНрждрж░рзЗрж░ ржирзЗрждрзГрждрзНржм ржжрзЗржмрзЗред

**SLM ржПржЬрзЗржирзНржЯрзЗрж░ ржкрзНрж░ржпрзБржХрзНрждрж┐ржЧржд ржкрзНрж░ржмржгрждрж╛**:
- **ржмрж┐рж╢рзЗрж╖рж╛ржпрж╝рж┐ржд SLM ржПржЬрзЗржирзНржЯ**: ржирж┐рж░рзНржжрж┐рж╖рзНржЯ ржПржЬрзЗржирзНржЯ ржХрж╛ржЬ ржПржмржВ рж╢рж┐рж▓рзНржкрзЗрж░ ржЬржирзНржп ржкрзНрж░рж╢рж┐ржХрзНрж╖рж┐ржд ржбрзЛржорзЗржЗржи-ржирж┐рж░рзНржжрж┐рж╖рзНржЯ ржоржбрзЗрж▓
- **ржПржЬ ржПржЬрзЗржирзНржЯ ржХржорзНржкрж┐ржЙржЯрж┐ржВ**: ржЙржирзНржиржд ржЕржи-ржбрж┐ржнрж╛ржЗрж╕ ржПржЬрзЗржирзНржЯ ржХрзНрж╖ржорждрж╛ ржЙржирзНржиржд ржЧрзЛржкржирзАржпрж╝рждрж╛ ржПржмржВ ржХржо рж▓рзЗржЯрзЗржирзНрж╕рж┐ рж╕рж╣
- **ржПржЬрзЗржирзНржЯ ржЕрж░рзНржХрзЗрж╕рзНржЯрзНрж░рзЗрж╢ржи**: ржПржХрж╛ржзрж┐ржХ SLM ржПржЬрзЗржирзНржЯрзЗрж░ ржоржзрзНржпрзЗ ржЖрж░ржУ ржнрж╛рж▓ рж╕ржоржирзНржмржпрж╝, ржбрж╛ржпрж╝ржирж╛ржорж┐ржХ рж░рж╛ржЙржЯрж┐ржВ ржПржмржВ рж▓рзЛржб ржмрзНржпрж╛рж▓рзЗржирзНрж╕рж┐ржВ рж╕рж╣
- **ржЧржгрждржирзНрждрзНрж░рзАржХрж░ржг**: SLM ржПрж░ ржиржоржирзАржпрж╝рждрж╛ ржПржЬрзЗржирзНржЯ ржЙржирзНржиржпрж╝ржирзЗ рж╕ржВрж╕рзНржерж╛ржЧрзБрж▓рж┐рж░ ржоржзрзНржпрзЗ ржмрж┐рж╕рзНрждрзГржд ржЕржВрж╢ржЧрзНрж░рж╣ржг рж╕ржХрзНрж╖ржо ржХрж░рзЗ

## SLM ржПржЬрзЗржирзНржЯ ржжрж┐ржпрж╝рзЗ рж╢рзБрж░рзБ ржХрж░рж╛

### ржзрж╛ржк рзз: Microsoft Agent Framework ржкрж░рж┐ржмрзЗрж╢ рж╕рзЗржЯ ржЖржк ржХрж░рзБржи

**ржбрж┐ржкрзЗржирзНржбрзЗржирзНрж╕рж┐ ржЗржирж╕рзНржЯрж▓ ржХрж░рзБржи**:
```bash
# Install Microsoft Agent Framework
pip install microsoft-agent-framework

# Install Foundry Local SDK for edge deployment
pip install foundry-local-sdk

# Install additional dependencies for edge agents
pip install openai asyncio
```

**Foundry Local ржЗржирж┐рж╢рж┐ржпрж╝рж╛рж▓рж╛ржЗржЬ ржХрж░рзБржи**:
```bash
# Start Foundry Local service
foundry service start

# Load default model for agent development
foundry model run phi-4-mini
```

### ржзрж╛ржк рзи: ржПржЬрзЗржирзНржЯ ржЕрзНржпрж╛ржкрзНрж▓рж┐ржХрзЗрж╢ржирзЗрж░ ржЬржирзНржп ржЖржкржирж╛рж░ SLM ржирж┐рж░рзНржмрж╛ржЪржи ржХрж░рзБржи
Microsoft Agent Framework ржПрж░ ржЬржирзНржп ржЬржиржкрзНрж░рж┐ржпрж╝ ржмрж┐ржХрж▓рзНржк:
- **Microsoft Phi-4 Mini (3.8B)**: рж╕рж╛ржзрж╛рж░ржг ржПржЬрзЗржирзНржЯ ржХрж╛ржЬрзЗрж░ ржЬржирзНржп ржЪржорзОржХрж╛рж░, ржнрж╛рж░рж╕рж╛ржорзНржпржкрзВрж░рзНржг ржкрж╛рж░ржлрж░ржорзНржпрж╛ржирзНрж╕ рж╕рж╣
- **Qwen2.5-0.5B (0.5B)**: рж╕рж╣ржЬ рж░рж╛ржЙржЯрж┐ржВ ржПржмржВ ржХрзНрж▓рж╛рж╕рж┐ржлрж┐ржХрзЗрж╢ржи ржПржЬрзЗржирзНржЯрзЗрж░ ржЬржирзНржп ржЕрждрзНржпржирзНржд ржХрж╛рж░рзНржпржХрж░
- **Qwen2.5-Coder-0.5B (0.5B)**: ржХрзЛржб-рж╕ржорзНржкрж░рзНржХрж┐ржд ржПржЬрзЗржирзНржЯ ржХрж╛ржЬрзЗрж░ ржЬржирзНржп ржмрж┐рж╢рзЗрж╖рж╛ржпрж╝рж┐ржд
- **Phi-4 (7B)**: ржЙржирзНржиржд ржпрзБржХрзНрждрж┐ ржкрзНрж░ржжрж╛ржи ржХрж░рзЗ ржЬржЯрж┐рж▓ ржПржЬ ржкрж░рж┐рж╕рзНржерж┐рждрж┐рж░ ржЬржирзНржп, ржпржЦржи рж╕ржорзНржкржж ржЙржкрж▓ржмрзНржз ржерж╛ржХрзЗ

### ржзрж╛ржк рзй: Microsoft Agent Framework ржжрж┐ржпрж╝рзЗ ржЖржкржирж╛рж░ ржкрзНрж░ржержо ржПржЬрзЗржирзНржЯ рждрзИрж░рж┐ ржХрж░рзБржи

**ржмрзЗрж╕рж┐ржХ ржПржЬрзЗржирзНржЯ рж╕рзЗржЯржЖржк**:
```python
from microsoft_agent_framework import Agent, Config
from foundry_local import FoundryLocalManager

# Initialize Foundry Local connection
foundry = FoundryLocalManager("phi-4-mini")

# Create agent configuration
config = Config(
    name="my-first-agent",
    model_provider="foundry-local",
    model_alias="phi-4-mini",
    offline_mode=True
)

# Create and configure agent
agent = Agent(
    config=config,
    model_endpoint=foundry.endpoint,
    api_key=foundry.api_key
)

# Define a simple tool
@agent.tool
def get_current_time() -> str:
    """Get the current time."""
    from datetime import datetime
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

# Test the agent
response = agent.chat("What time is it?")
print(response)
```

### ржзрж╛ржк рзк: ржПржЬрзЗржирзНржЯрзЗрж░ рж╕рзНржХрзЛржк ржПржмржВ ржкрзНрж░ржпрж╝рзЛржЬржирзАржпрж╝рждрж╛ ржирж┐рж░рзНржзрж╛рж░ржг ржХрж░рзБржи
Microsoft Agent Framework ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗ ржлрзЛржХрж╛рж╕ржб, рж╕рзБрж╕ржВржЬрзНржЮрж╛ржпрж╝рж┐ржд ржПржЬрзЗржирзНржЯ ржЕрзНржпрж╛ржкрзНрж▓рж┐ржХрзЗрж╢ржи ржжрж┐ржпрж╝рзЗ рж╢рзБрж░рзБ ржХрж░рзБржи:
- **ржПржХржХ ржбрзЛржорзЗржЗржи ржПржЬрзЗржирзНржЯ**: ржХрж╛рж╕рзНржЯржорж╛рж░ рж╕рж╛рж░рзНржнрж┐рж╕ ржЕржержмрж╛ рж╢рж┐ржбрж┐ржЙрж▓рж┐ржВ ржЕржержмрж╛ ржЧржмрзЗрж╖ржгрж╛
- **рж╕рзНржкрж╖рзНржЯ ржПржЬрзЗржирзНржЯ ржЙржжрзНржжрзЗрж╢рзНржп**: ржПржЬрзЗржирзНржЯ ржкрж╛рж░ржлрж░ржорзНржпрж╛ржирзНрж╕рзЗрж░ ржЬржирзНржп ржирж┐рж░рзНржжрж┐рж╖рзНржЯ, ржкрж░рж┐ржорж╛ржкржпрзЛржЧрзНржп рж▓ржХрзНрж╖рзНржп
- **рж╕рзАржорж┐ржд ржЯрзБрж▓ ржЗржирзНржЯрж┐ржЧрзНрж░рзЗрж╢ржи**: ржкрзНрж░рж╛ржержорж┐ржХ ржПржЬрзЗржирзНржЯ ржбрж┐ржкрзНрж▓ржпрж╝ржорзЗржирзНржЯрзЗрж░ ржЬржирзНржп рж╕рж░рзНржмрж╛ржзрж┐ржХ рзй-рзлржЯрж┐ ржЯрзБрж▓
- **рж╕ржВржЬрзНржЮрж╛ржпрж╝рж┐ржд ржПржЬрзЗржирзНржЯ рж╕рзАржорж╛ржирж╛**: ржЬржЯрж┐рж▓ ржкрж░рж┐рж╕рзНржерж┐рждрж┐рж░ ржЬржирзНржп рж╕рзНржкрж╖рзНржЯ ржПрж╕ржХрзЗрж▓рзЗрж╢ржи ржкрже
- **ржПржЬ-ржкрзНрж░ржержо ржбрж┐ржЬрж╛ржЗржи**: ржЕржлрж▓рж╛ржЗржи ржХрж╛рж░рзНржпржХрж╛рж░рж┐рждрж╛ ржПржмржВ рж╕рзНржерж╛ржирзАржпрж╝ ржкрзНрж░ржХрзНрж░рж┐ржпрж╝рж╛ржХрж░ржгржХрзЗ ржЕржЧрзНрж░рж╛ржзрж┐ржХрж╛рж░ ржжрж┐ржи

### ржзрж╛ржк рзл: Microsoft Agent Framework ржжрж┐ржпрж╝рзЗ ржПржЬ ржбрж┐ржкрзНрж▓ржпрж╝ржорзЗржирзНржЯ ржмрж╛рж╕рзНрждржмрж╛ржпрж╝ржи ржХрж░рзБржи

**рж░рж┐рж╕рзЛрж░рзНрж╕ ржХржиржлрж┐ржЧрж╛рж░рзЗрж╢ржи**:
```python
from microsoft_agent_framework import ResourceConfig

# Configure for edge deployment
resource_config = ResourceConfig(
    max_memory_usage="2GB",
    max_concurrent_agents=2,
    model_cache_size="1GB",
    auto_unload_idle_models=True,
    power_management=True
)

agent = Agent(
    config=config,
    resource_limits=resource_config
)
```

**ржПржЬ ржПржЬрзЗржирзНржЯрзЗрж░ ржЬржирзНржп ржирж┐рж░рж╛ржкрждрзНрждрж╛ ржмрзНржпржмрж╕рзНржерж╛ ржбрж┐ржкрзНрж▓ржпрж╝ ржХрж░рзБржи**:
- **рж╕рзНржерж╛ржирзАржпрж╝ ржЗржиржкрзБржЯ ржнрзНржпрж╛рж▓рж┐ржбрзЗрж╢ржи**: ржХрзНрж▓рж╛ржЙржб ржирж┐рж░рзНржнрж░рждрж╛ ржЫрж╛ржбрж╝рж╛ржЗ ржЕржирзБрж░рзЛржз ржпрж╛ржЪрж╛ржЗ ржХрж░рзБржи
- **ржЕржлрж▓рж╛ржЗржи ржЖржЙржЯржкрзБржЯ ржлрж┐рж▓рзНржЯрж╛рж░рж┐ржВ**: ржирж┐рж╢рзНржЪрж┐ржд ржХрж░рзБржи ржпрзЗ ржкрзНрж░рждрж┐ржХрзНрж░рж┐ржпрж╝рж╛ржЧрзБрж▓рж┐ рж╕рзНржерж╛ржирзАржпрж╝ржнрж╛ржмрзЗ ржорж╛ржирзЗрж░ ржорж╛ржи ржкрзВрж░ржг ржХрж░рзЗ
- **ржПржЬ ржирж┐рж░рж╛ржкрждрзНрждрж╛ ржирж┐ржпрж╝ржирзНрждрзНрж░ржг**: ржЗржирзНржЯрж╛рж░ржирзЗржЯ рж╕ржВржпрзЛржЧрзЗрж░ ржкрзНрж░ржпрж╝рзЛржЬржи ржЫрж╛ржбрж╝рж╛ржЗ ржирж┐рж░рж╛ржкрждрзНрждрж╛ ржмрж╛рж╕рзНрждржмрж╛ржпрж╝ржи ржХрж░рзБржи
- **рж╕рзНржерж╛ржирзАржпрж╝ ржкрж░рзНржпржмрзЗржХрзНрж╖ржг**: ржкрж╛рж░ржлрж░ржорзНржпрж╛ржирзНрж╕ ржЯрзНрж░рзНржпрж╛ржХ ржХрж░рзБржи ржПржмржВ ржПржЬ ржЯрзЗрж▓рж┐ржорзЗржЯрзНрж░рж┐ ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗ рж╕ржорж╕рзНржпрж╛ржЧрзБрж▓рж┐ ржЪрж┐рж╣рзНржирж┐ржд ржХрж░рзБржи

### ржзрж╛ржк рзм: ржПржЬ ржПржЬрзЗржирзНржЯ ржкрж╛рж░ржлрж░ржорзНржпрж╛ржирзНрж╕ ржкрж░рж┐ржорж╛ржк ржПржмржВ ржЕржкрзНржЯрж┐ржорж╛ржЗржЬ ржХрж░рзБржи
- **ржПржЬрзЗржирзНржЯ ржХрж╛ржЬ рж╕ржорзНржкржирзНржи ржХрж░рж╛рж░ рж╣рж╛рж░**: ржЕржлрж▓рж╛ржЗржи ржкрж░рж┐рж╕рзНржерж┐рждрж┐рждрзЗ рж╕рж╛ржлрж▓рзНржпрзЗрж░ рж╣рж╛рж░ ржкрж░рзНржпржмрзЗржХрзНрж╖ржг ржХрж░рзБржи
- **ржПржЬрзЗржирзНржЯ ржкрзНрж░рждрж┐ржХрзНрж░рж┐ржпрж╝рж╛ рж╕ржоржпрж╝**: ржПржЬ ржбрж┐ржкрзНрж▓ржпрж╝ржорзЗржирзНржЯрзЗрж░ ржЬржирзНржп рж╕рзЗржХрзЗржирзНржбрзЗрж░ ржирж┐ржЪрзЗ ржкрзНрж░рждрж┐ржХрзНрж░рж┐ржпрж╝рж╛ рж╕ржоржпрж╝ ржирж┐рж╢рзНржЪрж┐ржд ржХрж░рзБржи
- **рж░рж┐рж╕рзЛрж░рзНрж╕ ржмрзНржпржмрж╣рж╛рж░**: ржПржЬ ржбрж┐ржнрж╛ржЗрж╕рзЗ ржорзЗржорзЛрж░рж┐, CPU ржПржмржВ ржмрзНржпрж╛ржЯрж╛рж░рж┐ ржмрзНржпржмрж╣рж╛рж░рзЗрж░ ржЯрзНрж░рзНржпрж╛ржХ рж░рж╛ржЦрзБржи
- **ржЦрж░ржЪ ржжржХрзНрж╖рждрж╛**: ржПржЬ ржбрж┐ржкрзНрж▓ржпрж╝ржорзЗржирзНржЯ ржЦрж░ржЪ ржХрзНрж▓рж╛ржЙржб-ржнрж┐рждрзНрждрж┐ржХ ржмрж┐ржХрж▓рзНржкржЧрзБрж▓рж┐рж░ рж╕рж╛ржерзЗ рждрзБрж▓ржирж╛ ржХрж░рзБржи
- **ржЕржлрж▓рж╛ржЗржи ржирж┐рж░рзНржнрж░ржпрзЛржЧрзНржпрждрж╛**: ржирзЗржЯржУржпрж╝рж╛рж░рзНржХ ржмрж┐ржнрзНрж░рж╛ржЯрзЗрж░ рж╕ржоржпрж╝ ржПржЬрзЗржирзНржЯ ржкрж╛рж░ржлрж░ржорзНржпрж╛ржирзНрж╕ ржкрж░рж┐ржорж╛ржк ржХрж░рзБржи

## SLM ржПржЬрзЗржирзНржЯ ржмрж╛рж╕рзНрждржмрж╛ржпрж╝ржирзЗрж░ ржЬржирзНржп ржорзВрж▓ ржмрж┐рж╖рзЯржЧрзБрж▓рзЛ

1. **SLM ржПржЬрзЗржирзНржЯрзЗрж░ ржЬржирзНржп ржпржерзЗрж╖рзНржЯ**: ржмрзЗрж╢рж┐рж░ржнрж╛ржЧ ржПржЬрзЗржирзНржЯ ржХрж╛ржЬрзЗрж░ ржЬржирзНржп ржЫрзЛржЯ ржоржбрзЗрж▓ржЧрзБрж▓рж┐ ржмржбрж╝ржЧрзБрж▓рж┐рж░ ржорждрзЛржЗ ржХрж╛рж░рзНржпржХрж░, ржЙрж▓рзНрж▓рзЗржЦржпрзЛржЧрзНржп рж╕рзБржмрж┐ржзрж╛ ржкрзНрж░ржжрж╛ржи ржХрж░рзЗ
2. **ржПржЬрзЗржирзНржЯрзЗ ржЦрж░ржЪ ржжржХрзНрж╖рждрж╛**: SLM ржПржЬрзЗржирзНржЯ ржЪрж╛рж▓рж╛ржирзЛ рззрзж-рзйрзж ржЧрзБржг рж╕рж╕рзНрждрж╛, ржпрж╛ рждрж╛ржжрзЗрж░ ржмрзНржпрж╛ржкржХ ржбрж┐ржкрзНрж▓ржпрж╝ржорзЗржирзНржЯрзЗрж░ ржЬржирзНржп ржЕрж░рзНржержирзИрждрж┐ржХржнрж╛ржмрзЗ ржХрж╛рж░рзНржпржХрж░ ржХрж░рзЗ рждрзЛрж▓рзЗ
3. **ржПржЬрзЗржирзНржЯрзЗрж░ ржЬржирзНржп ржмрж┐рж╢рзЗрж╖рж╛ржпрж╝ржи ржХрж╛рж░рзНржпржХрж░**: ржирж┐рж░рзНржжрж┐рж╖рзНржЯ ржПржЬрзЗржирзНржЯ ржЕрзНржпрж╛ржкрзНрж▓рж┐ржХрзЗрж╢ржирзЗ ржлрж╛ржЗржи-ржЯрж┐ржЙржиржб SLM рж╕рж╛ржзрж╛рж░ржг ржЙржжрзНржжрзЗрж╢рзНржпрзЗрж░ LLM ржХрзЗ ржЫрж╛ржбрж╝рж┐ржпрж╝рзЗ ржпрж╛ржпрж╝
4. **рж╣рж╛ржЗржмрзНрж░рж┐ржб ржПржЬрзЗржирзНржЯ ржЖрж░рзНржХрж┐ржЯрзЗржХржЪрж╛рж░**: рж░рзБржЯрж┐ржи ржПржЬрзЗржирзНржЯ ржХрж╛ржЬрзЗрж░ ржЬржирзНржп SLM ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзБржи, ржкрзНрж░ржпрж╝рзЛржЬржи рж╣рж▓рзЗ ржЬржЯрж┐рж▓ ржпрзБржХрзНрждрж┐рж░ ржЬржирзНржп LLM ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзБржи
5. **Microsoft Agent Framework ржкрзНрж░рзЛржбрж╛ржХрж╢ржи ржбрж┐ржкрзНрж▓ржпрж╝ржорзЗржирзНржЯ рж╕ржХрзНрж╖ржо ржХрж░рзЗ**: ржПржЬ ржПржЬрзЗржирзНржЯ рждрзИрж░рж┐, ржбрж┐ржкрзНрж▓ржпрж╝ ржПржмржВ ржкрж░рж┐ржЪрж╛рж▓ржирж╛рж░ ржЬржирзНржп ржПржирзНржЯрж╛рж░ржкрзНрж░рж╛ржЗржЬ-ржЧрзНрж░рзЗржб ржЯрзБрж▓ рж╕рж░ржмрж░рж╛рж╣ ржХрж░рзЗ
6. **ржПржЬ-ржкрзНрж░ржержо ржбрж┐ржЬрж╛ржЗржи ржирзАрждрж┐ржорж╛рж▓рж╛**: рж╕рзНржерж╛ржирзАржпрж╝ ржкрзНрж░ржХрзНрж░рж┐ржпрж╝рж╛ржХрж░ржг рж╕рж╣ ржЕржлрж▓рж╛ржЗржи-рж╕ржХрзНрж╖ржо ржПржЬрзЗржирзНржЯ ржЧрзЛржкржирзАржпрж╝рждрж╛ ржПржмржВ ржирж┐рж░рзНржнрж░ржпрзЛржЧрзНржпрждрж╛ ржирж┐рж╢рзНржЪрж┐ржд ржХрж░рзЗ
7. **Foundry Local ржЗржирзНржЯрж┐ржЧрзНрж░рзЗрж╢ржи**: Microsoft Agent Framework ржПржмржВ рж╕рзНржерж╛ржирзАржпрж╝ ржоржбрзЗрж▓ ржЗржиржлрж╛рж░рзЗржирзНрж╕рзЗрж░ ржоржзрзНржпрзЗ ржирж┐рж░рзНржмрж┐ржШрзНржи рж╕ржВржпрзЛржЧ
8. **ржнржмрж┐рж╖рзНржпрзО SLM ржПржЬрзЗржирзНржЯ**: ржкрзНрж░рзЛржбрж╛ржХрж╢ржи ржлрзНрж░рзЗржоржУржпрж╝рж╛рж░рзНржХ рж╕рж╣ ржЫрзЛржЯ ржнрж╛рж╖рж╛рж░ ржоржбрзЗрж▓ржЧрзБрж▓рж┐ ржПржЬрзЗржирзНржЯрж┐ржХ AI ржПрж░ ржнржмрж┐рж╖рзНржпрзО, ржпрж╛ ржЧржгрждржирзНрждрзНрж░рзАржХрж░ржг ржПржмржВ ржХрж╛рж░рзНржпржХрж░ ржПржЬрзЗржирзНржЯ ржбрж┐ржкрзНрж▓ржпрж╝ржорзЗржирзНржЯ рж╕ржХрзНрж╖ржо ржХрж░рзЗ

## рж░рзЗржлрж╛рж░рзЗржирзНрж╕ ржПржмржВ ржЖрж░ржУ ржкржбрж╝рж╛рж╢рзЛржирж╛

### ржорзВрж▓ ржЧржмрзЗрж╖ржгрж╛ ржкрждрзНрж░ ржПржмржВ ржкрзНрж░ржХрж╛рж╢ржирж╛

#### AI ржПржЬрзЗржирзНржЯ ржПржмржВ ржПржЬрзЗржирзНржЯрж┐ржХ рж╕рж┐рж╕рзНржЯрзЗржо
- **"Language Agents as Optimizable Graphs"** (рзирзжрзирзк) - ржПржЬрзЗржирзНржЯ ржЖрж░рзНржХрж┐ржЯрзЗржХржЪрж╛рж░ ржПржмржВ ржЕржкрзНржЯрж┐ржорж╛ржЗржЬрзЗрж╢ржирзЗрж░ ржЙржкрж░ ржорзМрж▓рж┐ржХ ржЧржмрзЗрж╖ржгрж╛
  - рж▓рзЗржЦржХ: Wenyue Hua, Lishan Yang, ржкрзНрж░ржорзБржЦ
  - рж▓рж┐ржЩрзНржХ: https://arxiv.org/abs/2402.16823
  - ржорзВрж▓ ржЕржирзНрждрж░рзНржжрзГрж╖рзНржЯрж┐: ржЧрзНрж░рж╛ржл-ржнрж┐рждрзНрждрж┐ржХ ржПржЬрзЗржирзНржЯ ржбрж┐ржЬрж╛ржЗржи ржПржмржВ ржЕржкрзНржЯрж┐ржорж╛ржЗржЬрзЗрж╢ржи ржХрзМрж╢рж▓

- **"The Rise and Potential of Large Language Model Based Agents"** (рзирзжрзирзй)
  - рж▓рзЗржЦржХ: Zhiheng Xi, Wenxiang Chen, ржкрзНрж░ржорзБржЦ
  - рж▓рж┐ржЩрзНржХ: https://arxiv.org/abs/2309.07864
  - ржорзВрж▓ ржЕржирзНрждрж░рзНржжрзГрж╖рзНржЯрж┐: LLM-ржнрж┐рждрзНрждрж┐ржХ ржПржЬрзЗржирзНржЯрзЗрж░ ржХрзНрж╖ржорждрж╛ ржПржмржВ ржЕрзНржпрж╛ржкрзНрж▓рж┐ржХрзЗрж╢ржирзЗрж░ ржмрзНржпрж╛ржкржХ рж╕ржорзАржХрзНрж╖рж╛

- **"Cognitive Architectures for Language Agents"** (рзирзжрзирзк)
  - рж▓рзЗржЦржХ: Theodore Sumers, Shunyu Yao, ржкрзНрж░ржорзБржЦ
  - рж▓рж┐ржЩрзНржХ: https://arxiv.org/abs/2309.02427
  - ржорзВрж▓ ржЕржирзНрждрж░рзНржжрзГрж╖рзНржЯрж┐: ржмрзБржжрзНржзрж┐ржорж╛ржи ржПржЬрзЗржирзНржЯ ржбрж┐ржЬрж╛ржЗржирзЗрж░ ржЬржирзНржп ржХржЧржирж┐ржЯрж┐ржн ржлрзНрж░рзЗржоржУржпрж╝рж╛рж░рзНржХ

#### ржЫрзЛржЯ ржнрж╛рж╖рж╛рж░ ржоржбрзЗрж▓ ржПржмржВ ржЕржкрзНржЯрж┐ржорж╛ржЗржЬрзЗрж╢ржи
- **"Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone"** (рзирзжрзирзк)
  - рж▓рзЗржЦржХ: Microsoft Research Team
  - рж▓рж┐ржЩрзНржХ: https://arxiv.org/abs/2404.14219
  - ржорзВрж▓ ржЕржирзНрждрж░рзНржжрзГрж╖рзНржЯрж┐: SLM ржбрж┐ржЬрж╛ржЗржи ржирзАрждрж┐ржорж╛рж▓рж╛ ржПржмржВ ржорзЛржмрж╛ржЗрж▓ ржбрж┐ржкрзНрж▓ржпрж╝ржорзЗржирзНржЯ ржХрзМрж╢рж▓

- **"Qwen2.5 Technical Report"** (рзирзжрзирзк)
  - рж▓рзЗржЦржХ: Alibaba Cloud Team
  - рж▓рж┐ржЩрзНржХ: https://arxiv.org/abs/2407.10671
  - ржорзВрж▓ ржЕржирзНрждрж░рзНржжрзГрж╖рзНржЯрж┐: ржЙржирзНржиржд SLM ржкрзНрж░рж╢рж┐ржХрзНрж╖ржг ржХрзМрж╢рж▓ ржПржмржВ ржкрж╛рж░ржлрж░ржорзНржпрж╛ржирзНрж╕ ржЕржкрзНржЯрж┐ржорж╛ржЗржЬрзЗрж╢ржи

- **"TinyLlama: An Open-Source Small Language Model"** (рзирзжрзирзк)
  - рж▓рзЗржЦржХ: Peiyuan Zhang, Guangtao Zeng, ржкрзНрж░ржорзБржЦ
  - рж▓рж┐ржЩрзНржХ: https://arxiv.org/abs/2401.02385
  - ржорзВрж▓ ржЕржирзНрждрж░рзНржжрзГрж╖рзНржЯрж┐: ржЕрждрж┐ржХрзНрж╖рзБржжрзНрж░ ржоржбрзЗрж▓ ржбрж┐ржЬрж╛ржЗржи ржПржмржВ ржкрзНрж░рж╢рж┐ржХрзНрж╖ржгрзЗрж░ ржжржХрзНрж╖рждрж╛

### ржЕржлрж┐рж╕рж┐ржпрж╝рж╛рж▓ ржбржХрзБржорзЗржирзНржЯрзЗрж╢ржи ржПржмржВ ржлрзНрж░рзЗржоржУржпрж╝рж╛рж░рзНржХ

#### Microsoft Agent Framework
- **ржЕржлрж┐рж╕рж┐ржпрж╝рж╛рж▓ ржбржХрзБржорзЗржирзНржЯрзЗрж╢ржи**: https://docs.microsoft.com/en-us/azure/ai-services/agents/
- **GitHub рж░рж┐ржкрзЛржЬрж┐ржЯрж░рж┐**: https://github.com/microsoft/agent-framework

#### Foundry Local
- **ржкрзНрж░рж╛ржЗржорж╛рж░рж┐ рж░рж┐ржкрзЛржЬрж┐ржЯрж░рж┐**: https://github.com/microsoft/foundry-local
- **ржбржХрзБржорзЗржирзНржЯрзЗрж╢ржи**: https://github.com/microsoft/foundry-local/blob/main/docs/README.md


#### VLLM
- **ржорзЗржЗржи рж░рж┐ржкрзЛржЬрж┐ржЯрж░рж┐**: https://github.com/vllm-project/vllm
- **ржбржХрзБржорзЗржирзНржЯрзЗрж╢ржи**: https://docs.vllm.ai/


#### Ollama
- **ржЕржлрж┐рж╕рж┐ржпрж╝рж╛рж▓ ржУржпрж╝рзЗржмрж╕рж╛ржЗржЯ**: https://ollama.ai/
- **GitHub рж░рж┐ржкрзЛржЬрж┐ржЯрж░рж┐**: https://github.com/ollama/ollama

### ржоржбрзЗрж▓ ржЕржкрзНржЯрж┐ржорж╛ржЗржЬрзЗрж╢ржи ржлрзНрж░рзЗржоржУржпрж╝рж╛рж░рзНржХ

#### Llama.cpp
- **рж░рж┐ржкрзЛржЬрж┐ржЯрж░рж┐**: https://github.com/ggml-org/llama.cpp


#### Microsoft Olive
- **ржбржХрзБржорзЗржирзНржЯрзЗрж╢ржи**: https://microsoft.github.io/Olive/
- **GitHub рж░рж┐ржкрзЛржЬрж┐ржЯрж░рж┐**: https://github.com/microsoft/Olive

#### OpenVINO
- **ржЕржлрж┐рж╕рж┐ржпрж╝рж╛рж▓ рж╕рж╛ржЗржЯ**: https://docs.openvino.ai/

#### Apple MLX
- **рж░рж┐ржкрзЛржЬрж┐ржЯрж░рж┐**: https://github.com/ml-explore/mlx

### рж╢рж┐рж▓рзНржк рж░рж┐ржкрзЛрж░рзНржЯ ржПржмржВ ржмрж╛ржЬрж╛рж░ ржмрж┐рж╢рзНрж▓рзЗрж╖ржг

#### AI ржПржЬрзЗржирзНржЯ ржмрж╛ржЬрж╛рж░ ржЧржмрзЗрж╖ржгрж╛
- **"The State of AI Agents 2025"** - McKinsey Global Institute
  - рж▓рж┐ржЩрзНржХ: https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/ai-agents-2025
  - ржорзВрж▓ ржЕржирзНрждрж░рзНржжрзГрж╖рзНржЯрж┐: ржмрж╛ржЬрж╛рж░ ржкрзНрж░ржмржгрждрж╛ ржПржмржВ ржПржирзНржЯрж╛рж░ржкрзНрж░рж╛ржЗржЬ ржЧрзНрж░рж╣ржгрзЗрж░ ржкрзНржпрж╛ржЯрж╛рж░рзНржи

#### ржкрзНрж░ржпрзБржХрзНрждрж┐ржЧржд ржмрзЗржЮрзНржЪржорж╛рж░рзНржХ

- **"Edge AI Inference Benchmarks"** - MLPerf
  - рж▓рж┐ржЩрзНржХ: https://mlcommons.org/en/inference-edge/
  - ржорзВрж▓ ржЕржирзНрждрж░рзНржжрзГрж╖рзНржЯрж┐: ржПржЬ ржбрж┐ржкрзНрж▓ржпрж╝ржорзЗржирзНржЯрзЗрж░ ржЬржирзНржп ржорж╛ржиржХ ржкрж╛рж░ржлрж░ржорзНржпрж╛ржирзНрж╕ ржорзЗржЯрзНрж░рж┐ржХ

### ржорж╛ржи ржПржмржВ рж╕рзНржкрзЗрж╕рж┐ржлрж┐ржХрзЗрж╢ржи

#### ржоржбрзЗрж▓ ржлрж░ржорзНржпрж╛ржЯ ржПржмржВ ржорж╛ржи
- **ONNX (Open Neural Network Exchange)**: https://onnx.ai/
  - ржЖржирзНрждржГржкрж░рж┐ржЪрж╛рж▓ржиржпрзЛржЧрзНржпрждрж╛рж░ ржЬржирзНржп ржХрзНрж░рж╕-ржкрзНрж▓рзНржпрж╛ржЯржлрж░рзНржо ржоржбрзЗрж▓ ржлрж░ржорзНржпрж╛ржЯ
- **GGUF рж╕рзНржкрзЗрж╕рж┐ржлрж┐ржХрзЗрж╢ржи**: https://github.com/ggerganov/ggml/blob/master/docs/gguf.md
  - CPU ржЗржиржлрж╛рж░рзЗржирзНрж╕рзЗрж░ ржЬржирзНржп ржХрзЛржпрж╝рж╛ржирзНржЯрж╛ржЗржЬржб ржоржбрзЗрж▓ ржлрж░ржорзНржпрж╛ржЯ
- **OpenAI API рж╕рзНржкрзЗрж╕рж┐ржлрж┐ржХрзЗрж╢ржи**: https://platform.openai.com/docs/api-reference
  - ржнрж╛рж╖рж╛рж░ ржоржбрзЗрж▓ ржЗржирзНржЯрж┐ржЧрзНрж░рзЗрж╢ржирзЗрж░ ржЬржирзНржп рж╕рзНржЯрзНржпрж╛ржирзНржбрж╛рж░рзНржб API ржлрж░ржорзНржпрж╛ржЯ

#### ржирж┐рж░рж╛ржкрждрзНрждрж╛ ржПржмржВ рж╕ржорзНржорждрж┐
- **NIST AI рж░рж┐рж╕рзНржХ ржорзНржпрж╛ржирзЗржЬржорзЗржирзНржЯ ржлрзНрж░рзЗржоржУржпрж╝рж╛рж░рзНржХ**: https://www.nist.gov/itl/ai-risk

---

**ржЕрж╕рзНржмрзАржХрзГрждрж┐**:  
ржПржЗ ржиржерж┐ржЯрж┐ AI ржЕржирзБржмрж╛ржж ржкрж░рж┐рж╖рзЗржмрж╛ [Co-op Translator](https://github.com/Azure/co-op-translator) ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗ ржЕржирзБржмрж╛ржж ржХрж░рж╛ рж╣ржпрж╝рзЗржЫрзЗред ржЖржорж░рж╛ ржпржерж╛рж╕рж╛ржзрзНржп рж╕ржарж┐ржХрждрж╛рж░ ржЬржирзНржп ржЪрзЗрж╖рзНржЯрж╛ ржХрж░рж┐, рждржмрзЗ ржЕржирзБржЧрзНрж░рж╣ ржХрж░рзЗ ржоржирзЗ рж░рж╛ржЦржмрзЗржи ржпрзЗ рж╕рзНржмржпрж╝ржВржХрзНрж░рж┐ржпрж╝ ржЕржирзБржмрж╛ржжрзЗ рждрзНрж░рзБржЯрж┐ ржмрж╛ ржЕрж╕ржЩрзНржЧрждрж┐ ржерж╛ржХрждрзЗ ржкрж╛рж░рзЗред ржорзВрж▓ ржнрж╛рж╖рж╛ржпрж╝ ржерж╛ржХрж╛ ржиржерж┐ржЯрж┐ржХрзЗ ржкрзНрж░рж╛ржорж╛ржгрж┐ржХ ржЙрзОрж╕ рж╣рж┐рж╕рзЗржмрзЗ ржмрж┐ржмрзЗржЪржирж╛ ржХрж░рж╛ ржЙржЪрж┐рждред ржЧрзБрж░рзБрждрзНржмржкрзВрж░рзНржг рждржерзНржпрзЗрж░ ржЬржирзНржп, ржкрзЗрж╢рж╛ржжрж╛рж░ ржорж╛ржиржм ржЕржирзБржмрж╛ржж рж╕рзБржкрж╛рж░рж┐рж╢ ржХрж░рж╛ рж╣ржпрж╝ред ржПржЗ ржЕржирзБржмрж╛ржж ржмрзНржпржмрж╣рж╛рж░рзЗрж░ ржлрж▓рзЗ ржХрзЛржирзЛ ржнрзБрж▓ ржмрзЛржЭрж╛ржмрзБржЭрж┐ ржмрж╛ ржнрзБрж▓ ржмрзНржпрж╛ржЦрзНржпрж╛ рж╣рж▓рзЗ ржЖржорж░рж╛ ржжрж╛ржпрж╝ржмржжрзНржз ржерж╛ржХржм ржирж╛ред