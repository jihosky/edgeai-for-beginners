<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8a7765b85f123e8a62aa3847141ca072",
  "translation_date": "2025-10-30T13:41:47+00:00",
  "source_file": "Module06/03.IntroduceMCP.md",
  "language_code": "id"
}
-->
# Bagian 03 - Integrasi Model Context Protocol (MCP)

## Pengantar MCP (Model Context Protocol)

Model Context Protocol (MCP) adalah standar open-source untuk menghubungkan aplikasi AI ke sistem eksternal. Dengan MCP, aplikasi AI seperti Claude atau ChatGPT dapat terhubung ke sumber data (misalnya, file lokal, basis data), alat (misalnya, mesin pencari, kalkulator), dan alur kerja (misalnya, prompt khusus)—memungkinkan mereka mengakses informasi penting dan melakukan tugas.

Anggap MCP seperti **port USB-C untuk aplikasi AI**. Sama seperti USB-C menyediakan cara standar untuk menghubungkan perangkat elektronik, MCP menyediakan cara standar untuk menghubungkan aplikasi AI ke sistem eksternal.

### Apa yang Dapat Dimungkinkan oleh MCP?

MCP membuka kemampuan yang kuat untuk aplikasi AI:

- **Asisten AI yang Dipersonalisasi**: Agen dapat mengakses Google Calendar dan Notion Anda, bertindak sebagai asisten AI yang lebih personal
- **Pembuatan Kode Lanjutan**: Claude Code dapat membuat seluruh aplikasi web menggunakan desain Figma
- **Integrasi Data Perusahaan**: Chatbot perusahaan dapat terhubung ke beberapa basis data di seluruh organisasi, memungkinkan pengguna menganalisis data melalui chat
- **Alur Kerja Kreatif**: Model AI dapat membuat desain 3D di Blender dan mencetaknya menggunakan printer 3D
- **Akses Informasi Real-time**: Terhubung ke sumber data eksternal untuk informasi terkini
- **Operasi Multi-langkah yang Kompleks**: Melakukan alur kerja canggih yang menggabungkan beberapa alat dan sistem

### Mengapa MCP Penting?

MCP memberikan manfaat di seluruh ekosistem:

**Untuk Pengembang**: MCP mengurangi waktu dan kompleksitas pengembangan saat membangun atau mengintegrasikan aplikasi atau agen AI.

**Untuk Aplikasi AI**: MCP memberikan akses ke ekosistem sumber data, alat, dan aplikasi yang meningkatkan kemampuan dan pengalaman pengguna akhir.

**Untuk Pengguna Akhir**: MCP menghasilkan aplikasi atau agen AI yang lebih mampu yang dapat mengakses data Anda dan mengambil tindakan atas nama Anda jika diperlukan.

## Small Language Models (SLMs) dalam MCP

Small Language Models mewakili pendekatan yang efisien untuk penerapan AI, menawarkan beberapa keuntungan:

### Keuntungan SLMs
- **Efisiensi Sumber Daya**: Persyaratan komputasi yang lebih rendah
- **Waktu Respons Lebih Cepat**: Latensi yang lebih rendah untuk aplikasi real-time  
- **Efektivitas Biaya**: Kebutuhan infrastruktur minimal
- **Privasi**: Dapat berjalan secara lokal tanpa transmisi data
- **Kustomisasi**: Lebih mudah disesuaikan untuk domain tertentu

### Mengapa SLMs Cocok dengan MCP

SLMs yang dipasangkan dengan MCP menciptakan kombinasi yang kuat di mana kemampuan penalaran model ditingkatkan oleh alat eksternal, mengimbangi jumlah parameter yang lebih kecil melalui fungsionalitas yang ditingkatkan.

## Ikhtisar Python MCP SDK

Python MCP SDK menyediakan dasar untuk membangun aplikasi yang mendukung MCP. SDK mencakup:

- **Library Klien**: Untuk terhubung ke server MCP
- **Kerangka Server**: Untuk membuat server MCP khusus
- **Handler Protokol**: Untuk mengelola komunikasi
- **Integrasi Alat**: Untuk menjalankan fungsi eksternal

## Implementasi Praktis: Klien Phi-4 MCP

Mari kita jelajahi implementasi dunia nyata menggunakan model mini Phi-4 dari Microsoft yang terintegrasi dengan kemampuan MCP.

### Ikhtisar Arsitektur MCP

MCP mengikuti arsitektur **klien-server** di mana host MCP (aplikasi AI seperti Claude Code atau Claude Desktop) membangun koneksi ke satu atau lebih server MCP. Host MCP melakukan ini dengan membuat satu klien MCP untuk setiap server MCP.

#### Peserta Utama

- **Host MCP**: Aplikasi AI yang mengoordinasikan dan mengelola satu atau beberapa klien MCP
- **Klien MCP**: Komponen yang mempertahankan koneksi ke server MCP dan mendapatkan konteks dari server MCP untuk digunakan oleh host MCP
- **Server MCP**: Program yang menyediakan konteks kepada klien MCP

#### Arsitektur Dua Lapisan

MCP terdiri dari dua lapisan yang berbeda:

**Lapisan Data**: Mendefinisikan protokol berbasis JSON-RPC untuk komunikasi klien-server, termasuk:
- Manajemen siklus hidup (inisialisasi koneksi, negosiasi kemampuan)
- Primitif inti (alat, sumber daya, prompt)
- Fitur klien (sampling, elicitation, logging)
- Fitur utilitas (notifikasi, pelacakan kemajuan)

**Lapisan Transportasi**: Mendefinisikan mekanisme dan saluran komunikasi:
- **Transportasi STDIO**: Menggunakan aliran input/output standar untuk proses lokal (kinerja optimal, tanpa overhead jaringan)
- **Transportasi HTTP Streamable**: Menggunakan HTTP POST dengan Server-Sent Events opsional untuk server jarak jauh (mendukung autentikasi HTTP standar)

```
┌─────────────────────────────────────┐
│           MCP Host                  │
│     (AI Application)                │
└─────────────────┬───────────────────┘
                  │
┌─────────────────┴───────────────────┐
│         MCP Client 1                │
│  ┌─────────────────────────────────┐ │
│  │        Data Layer               │ │
│  │  ├── Lifecycle Management       │ │
│  │  ├── Primitives (Tools/Resources)│ │
│  │  └── Notifications              │ │
│  └─────────────────────────────────┘ │
│  ┌─────────────────────────────────┐ │
│  │      Transport Layer           │ │
│  │  ├── STDIO Transport           │ │
│  │  └── HTTP Transport            │ │
│  └─────────────────────────────────┘ │
└─────────────────┬───────────────────┘
                  │
┌─────────────────┴───────────────────┐
│         MCP Server 1                │
│    (Local/Remote Context Provider)  │
└─────────────────────────────────────┘
```

### Primitif Inti MCP

MCP mendefinisikan primitif yang menentukan jenis informasi kontekstual yang dapat dibagikan dengan aplikasi AI dan berbagai tindakan yang dapat dilakukan.

#### Primitif Server

MCP mendefinisikan tiga primitif inti yang dapat diekspos oleh server:

**Alat**: Fungsi yang dapat dijalankan yang dapat dipanggil oleh aplikasi AI untuk melakukan tindakan
- Contoh: operasi file, panggilan API, kueri basis data
- Metode: `tools/list`, `tools/call`
- Mendukung penemuan dan eksekusi dinamis

**Sumber Daya**: Sumber data yang menyediakan informasi kontekstual untuk aplikasi AI
- Contoh: isi file, catatan basis data, respons API
- Metode: `resources/list`, `resources/read`
- Memungkinkan akses ke data terstruktur

**Prompt**: Template yang dapat digunakan kembali yang membantu menyusun interaksi dengan model bahasa
- Contoh: prompt sistem, contoh few-shot
- Metode: `prompts/list`, `prompts/get`
- Menstandarkan pola interaksi AI

#### Primitif Klien

MCP juga mendefinisikan primitif yang dapat diekspos oleh klien untuk memungkinkan interaksi yang lebih kaya:

**Sampling**: Memungkinkan server meminta penyelesaian model bahasa dari aplikasi AI klien
- Metode: `sampling/complete`
- Memungkinkan pengembangan server yang independen dari model
- Memberikan akses ke model bahasa host

**Elicitation**: Memungkinkan server meminta informasi tambahan dari pengguna
- Metode: `elicitation/request`
- Memungkinkan interaksi dan konfirmasi pengguna
- Mendukung pengumpulan informasi dinamis

**Logging**: Memungkinkan server mengirim pesan log ke klien
- Digunakan untuk tujuan debugging dan pemantauan
- Memberikan visibilitas ke operasi server

### Siklus Protokol MCP

#### Inisialisasi dan Negosiasi Kemampuan

MCP adalah protokol stateful yang membutuhkan manajemen siklus hidup. Proses inisialisasi melayani beberapa tujuan penting:

1. **Negosiasi Versi Protokol**: Memastikan klien dan server menggunakan versi protokol yang kompatibel (misalnya, "2025-06-18")
2. **Penemuan Kemampuan**: Setiap pihak menyatakan fitur dan primitif yang didukung
3. **Pertukaran Identitas**: Memberikan informasi identifikasi dan versi

```python
# Example initialization request
{
  "jsonrpc": "2.0",
  "id": 1,
  "method": "initialize",
  "params": {
    "protocolVersion": "2025-06-18",
    "capabilities": {
      "elicitation": {},  # Client supports user interaction
      "sampling": {}      # Client can provide LLM completions
    },
    "clientInfo": {
      "name": "edge-ai-client",
      "version": "1.0.0"
    }
  }
}
```

#### Penemuan dan Eksekusi Alat

Setelah inisialisasi, klien dapat menemukan dan menjalankan alat:

```python
# Discover available tools
tools_response = await session.list_tools()

# Execute a tool
result = await session.call_tool(
    "weather_current",
    {
        "location": "San Francisco",
        "units": "imperial"
    }
)
```

#### Notifikasi Real-time

MCP mendukung notifikasi real-time untuk pembaruan dinamis:

```python
# Server sends notification when tools change
{
  "jsonrpc": "2.0",
  "method": "notifications/tools/list_changed"
}

# Client responds by refreshing tool list
await session.list_tools()  # Get updated tools
```

## Memulai: Panduan Langkah-demi-Langkah

### Langkah 1: Pengaturan Lingkungan

Instal dependensi yang diperlukan:
```bash
pip install fastmcp mcp-python-client openai requests pyautogui Pillow
```

### Langkah 2: Konfigurasi Dasar

Atur variabel lingkungan Anda:
```python
# System Configuration
SYSTEM_PROMPT = "You are an AI assistant with some tools."

# Ollama Configuration (Local)
OLLAMA_URL = "http://localhost:11434/api/chat"
OLLAMA_MODEL_ID = "phi4-mini:3.8b-fp16"

# vLLM Configuration (Server)
VLLM_URL = "http://localhost:8000/v1"
VLLM_MODEL_ID = "microsoft/Phi-4-mini-instruct"
```

### Langkah 3: Menjalankan Klien MCP Pertama Anda

**Pengaturan Ollama Dasar:**
```bash
python ghmodel_mcp_demo.py
```

**Menggunakan Backend vLLM:**
```bash
python ghmodel_mcp_demo.py --env vllm
```

**Koneksi Server-Sent Events:**
```bash
python ghmodel_mcp_demo.py --run sse
```

**Server MCP Kustom:**
```bash
python ghmodel_mcp_demo.py --server /path/to/server.py
```

### Langkah 4: Penggunaan Programatik

```python
import asyncio
from ghmodel_mcp_demo import OllamaClient, Phi4MiniMCPClient

async def automated_interaction():
    # Configure MCP server parameters
    server_params = StdioServerParameters(
        command="npx",
        args=["@playwright/mcp@latest"],
        env=None,
    )
    
    # Create MCP client and process tools
    async with Phi4MiniMCPClient(server_params) as mcp_client:
        tools = await process_mcp_tools(mcp_client)
        llm_client = OllamaClient()
        
        # Generate response with tool capabilities
        response, messages = await llm_client.generate_response(
            "Help me automate a web task",
            tools
        )
        return response

# Execute the automation
result = asyncio.run(automated_interaction())
print(result)
```

## Fitur Lanjutan

### Dukungan Multi-Backend

Implementasi mendukung backend Ollama dan vLLM, memungkinkan Anda memilih berdasarkan kebutuhan Anda:

- **Ollama**: Lebih baik untuk pengembangan dan pengujian lokal
- **vLLM**: Dioptimalkan untuk produksi dan skenario throughput tinggi

### Protokol Koneksi Fleksibel

Dua mode koneksi didukung:

**Mode STDIO**: Komunikasi proses langsung
- Latensi lebih rendah
- Cocok untuk alat lokal
- Pengaturan sederhana

**Mode SSE**: Streaming berbasis HTTP
- Mendukung jaringan
- Lebih baik untuk sistem terdistribusi
- Pembaruan real-time

### Kemampuan Integrasi Alat

Sistem dapat terintegrasi dengan berbagai alat:
- Otomasi web (Playwright)
- Operasi file
- Interaksi API
- Perintah sistem
- Fungsi kustom

## Penanganan Kesalahan dan Praktik Terbaik

### Manajemen Kesalahan yang Komprehensif

Implementasi mencakup penanganan kesalahan yang kuat untuk:

**Kesalahan Koneksi:**
- Kegagalan server MCP
- Timeout jaringan
- Masalah konektivitas

**Kesalahan Eksekusi Alat:**
- Alat yang hilang
- Validasi parameter
- Kegagalan eksekusi

**Kesalahan Pemrosesan Respons:**
- Masalah parsing JSON
- Ketidakkonsistenan format
- Anomali respons LLM

### Praktik Terbaik

1. **Manajemen Sumber Daya**: Gunakan pengelola konteks async
2. **Penanganan Kesalahan**: Terapkan blok try-catch yang komprehensif
3. **Logging**: Aktifkan level logging yang sesuai
4. **Keamanan**: Validasi input dan sanitasi output
5. **Kinerja**: Gunakan pooling koneksi dan caching

## Aplikasi Dunia Nyata

### Otomasi Web
```python
# Example: Automated web testing
async def web_automation_example():
    tools = await setup_playwright_tools()
    response = await llm_client.generate_response(
        "Navigate to example.com and take a screenshot",
        tools
    )
```

### Pemrosesan Data
```python
# Example: File analysis
async def data_processing_example():
    tools = await setup_file_tools()
    response = await llm_client.generate_response(
        "Analyze the CSV file and generate a summary report",
        tools
    )
```

### Integrasi API
```python
# Example: API interactions
async def api_integration_example():
    tools = await setup_api_tools()
    response = await llm_client.generate_response(
        "Fetch weather data and create a forecast summary",
        tools
    )
```

## Optimasi Kinerja

### Manajemen Memori
- Penanganan riwayat pesan yang efisien
- Pembersihan sumber daya yang tepat
- Pooling koneksi

### Optimasi Jaringan
- Operasi HTTP async
- Timeout yang dapat dikonfigurasi
- Pemulihan kesalahan yang baik

### Pemrosesan Konkuren
- I/O non-blocking
- Eksekusi alat paralel
- Pola async yang efisien

## Pertimbangan Keamanan

### Perlindungan Data
- Manajemen kunci API yang aman
- Validasi input
- Sanitasi output

### Keamanan Jaringan
- Dukungan HTTPS
- Default endpoint lokal
- Penanganan token yang aman

### Keamanan Eksekusi
- Penyaringan alat
- Lingkungan sandboxed
- Logging audit

## Ekosistem dan Pengembangan MCP

### Ruang Lingkup Proyek MCP

Ekosistem Model Context Protocol mencakup beberapa komponen utama:

- **[Spesifikasi MCP](https://modelcontextprotocol.io/specification/latest)**: Spesifikasi resmi yang menguraikan persyaratan implementasi untuk klien dan server
- **[SDK MCP](https://modelcontextprotocol.io/docs/sdk)**: SDK untuk berbagai bahasa pemrograman yang mengimplementasikan MCP
- **Alat Pengembangan MCP**: Alat untuk mengembangkan server dan klien MCP, termasuk [MCP Inspector](https://github.com/modelcontextprotocol/inspector)
- **[Implementasi Server Referensi MCP](https://github.com/modelcontextprotocol/servers)**: Implementasi referensi server MCP

### Memulai Pengembangan MCP

Untuk mulai membangun dengan MCP:

**Bangun Server**: [Buat server MCP](https://modelcontextprotocol.io/docs/develop/build-server) untuk mengekspos data dan alat Anda

**Bangun Klien**: [Kembangkan aplikasi](https://modelcontextprotocol.io/docs/develop/build-client) yang terhubung ke server MCP

**Pelajari Konsep**: [Pahami konsep inti](https://modelcontextprotocol.io/docs/learn/architecture) dan arsitektur MCP

## Kesimpulan

SLMs yang terintegrasi dengan MCP mewakili perubahan paradigma dalam pengembangan aplikasi AI. Dengan menggabungkan efisiensi model kecil dengan kekuatan alat eksternal, pengembang dapat menciptakan sistem cerdas yang efisien sumber daya dan sangat mampu.

Model Context Protocol menyediakan cara standar untuk menghubungkan aplikasi AI ke sistem eksternal, seperti USB-C menyediakan standar koneksi universal untuk perangkat elektronik. Standarisasi ini memungkinkan:

- **Integrasi Tanpa Hambatan**: Menghubungkan model AI ke berbagai sumber data dan alat
- **Pertumbuhan Ekosistem**: Bangun sekali, gunakan di berbagai aplikasi AI
- **Kemampuan yang Ditingkatkan**: Tingkatkan SLMs dengan fungsionalitas eksternal
- **Pembaruan Real-time**: Mendukung aplikasi AI yang dinamis dan responsif

Poin penting:
- MCP adalah standar terbuka yang menjembatani aplikasi AI dan sistem eksternal
- Protokol mendukung alat, sumber daya, dan prompt sebagai primitif inti
- Notifikasi real-time memungkinkan aplikasi yang dinamis dan responsif
- Manajemen siklus hidup dan penanganan kesalahan yang tepat sangat penting untuk penggunaan produksi
- Ekosistem menyediakan SDK dan alat pengembangan yang komprehensif

## Referensi dan Bacaan Lanjutan

### Dokumentasi Resmi MCP

- **[Situs Resmi Model Context Protocol](https://modelcontextprotocol.io/)** - Dokumentasi dan spesifikasi lengkap
- **[Panduan Memulai MCP](https://modelcontextprotocol.io/docs/getting-started/intro)** - Pengantar dan konsep inti
- **[Ikhtisar Arsitektur MCP](https://modelcontextprotocol.io/docs/learn/architecture)** - Arsitektur teknis yang mendetail
- **[Spesifikasi MCP](https://modelcontextprotocol.io/specification/latest)** - Spesifikasi protokol resmi
- **[Dokumentasi SDK MCP](https://modelcontextprotocol.io/docs/sdk)** - Panduan SDK spesifik bahasa

### Sumber Daya Pengembangan

- **[MCP untuk Pemula](https://aka.ms/mcp-for-beginners)** - Panduan pemula yang komprehensif tentang Model Context Protocol
- **[Organisasi GitHub MCP](https://github.com/modelcontextprotocol)** - Repositori dan contoh resmi
- **[Repositori Server MCP](https://github.com/modelcontextprotocol/servers)** - Implementasi server referensi
- **[MCP Inspector](https://github.com/modelcontextprotocol/inspector)** - Alat pengembangan dan debugging
- **[Panduan Membuat Server MCP](https://modelcontextprotocol.io/docs/develop/build-server)** - Tutorial pengembangan server
- **[Panduan Membuat Klien MCP](https://modelcontextprotocol.io/docs/develop/build-client)** - Tutorial pengembangan klien

### Small Language Models dan Edge AI

- **[Model Phi Microsoft](https://aka.ms/phicookbook)** - Keluarga model Phi 
- **[Dokumentasi Foundry Local](https://github.com/microsoft/Foundry-Local)** - Runtime AI edge dari Microsoft
- **[Dokumentasi Ollama](https://ollama.ai/docs)** - Platform penerapan LLM lokal
- **[Dokumentasi vLLM](https://docs.vllm.ai/)** - Layanan LLM berperforma tinggi

### Standar Teknis dan Protokol

- **[Spesifikasi JSON-RPC 2.0](https://www.jsonrpc.org/)** - Protokol RPC yang digunakan oleh MCP
- **[JSON Schema](https://json-schema.org/)** - Standar definisi skema untuk alat MCP
- **[Spesifikasi OpenAPI](https://swagger.io/specification/)** - Standar dokumentasi API
- **[Server-Sent Events (SSE)](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events)** - Standar web untuk pembaruan real-time

### Pengembangan Agen AI

- **[Microsoft Agent Framework](https://github.com/microsoft/agent-framework)** - Pengembangan agen siap produksi
- **[Dokumentasi LangChain](https://docs.langchain.com/)** - Kerangka kerja integrasi agen dan alat
- **[Semantic Kernel](https://learn.microsoft.com/en-us/semantic-kernel/)** - SDK orkestrasi AI dari Microsoft

### Laporan Industri dan Penelitian

- **[Pengumuman Protokol Model Context oleh Anthropic](https://www.anthropic.com/news/model-context-protocol)** - Pengenalan MCP asli
- **[Survei Model Bahasa Kecil](https://arxiv.org/abs/2410.20011)** - Survei akademik tentang penelitian SLM
- **[Analisis Pasar Edge AI](https://www.marketsandmarkets.com/Market-Reports/edge-ai-software-market-74385617.html)** - Tren industri dan prediksi
- **[Praktik Terbaik Pengembangan Agen AI](https://arxiv.org/abs/2309.02427)** - Penelitian tentang arsitektur agen

Bagian ini memberikan dasar untuk membangun aplikasi MCP yang didukung oleh SLM, membuka peluang untuk otomatisasi, pemrosesan data, dan integrasi sistem cerdas.

## ➡️ Langkah selanjutnya

- [Modul 7. Contoh Edge AI](../Module07/README.md)

---

**Penafian**:  
Dokumen ini telah diterjemahkan menggunakan layanan penerjemahan AI [Co-op Translator](https://github.com/Azure/co-op-translator). Meskipun kami berupaya untuk memberikan hasil yang akurat, harap diketahui bahwa terjemahan otomatis dapat mengandung kesalahan atau ketidakakuratan. Dokumen asli dalam bahasa aslinya harus dianggap sebagai sumber yang otoritatif. Untuk informasi yang penting, disarankan menggunakan jasa penerjemahan manusia profesional. Kami tidak bertanggung jawab atas kesalahpahaman atau penafsiran yang keliru yang timbul dari penggunaan terjemahan ini.