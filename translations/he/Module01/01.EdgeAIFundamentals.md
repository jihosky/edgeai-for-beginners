<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "be25052ac4c842765e7f6f7eb4d7dcc5",
  "translation_date": "2025-10-20T09:51:43+00:00",
  "source_file": "Module01/01.EdgeAIFundamentals.md",
  "language_code": "he"
}
-->
# פרק 1: יסודות EdgeAI

EdgeAI מייצג שינוי פרדיגמה בפריסת בינה מלאכותית, ומביא את יכולות הבינה המלאכותית ישירות למכשירי הקצה במקום להסתמך רק על עיבוד מבוסס ענן. חשוב להבין כיצד EdgeAI מאפשר עיבוד בינה מלאכותית מקומי במכשירים עם משאבים מוגבלים, תוך שמירה על ביצועים סבירים והתמודדות עם אתגרים כמו פרטיות, זמן תגובה ויכולות עבודה במצב לא מקוון.

## מבוא

בשיעור זה נחקור את EdgeAI ואת מושגי היסוד שלו. נסקור את פרדיגמת המחשוב המסורתית של בינה מלאכותית, את האתגרים של מחשוב קצה, את הטכנולוגיות המרכזיות שמאפשרות את EdgeAI ואת היישומים המעשיים בתעשיות שונות.

## מטרות למידה

בסיום השיעור, תוכלו:

- להבין את ההבדל בין גישות בינה מלאכותית מבוססת ענן לבין גישות EdgeAI.
- לזהות את הטכנולוגיות המרכזיות שמאפשרות עיבוד בינה מלאכותית במכשירי קצה.
- להכיר את היתרונות והמגבלות של יישומי EdgeAI.
- ליישם ידע על EdgeAI בתרחישים ושימושים בעולם האמיתי.

## הבנת פרדיגמת המחשוב המסורתית של בינה מלאכותית

באופן מסורתי, יישומי בינה מלאכותית גנרטיבית מסתמכים על תשתית מחשוב בעלת ביצועים גבוהים כדי להפעיל מודלים שפתיים גדולים (LLMs) בצורה יעילה. ארגונים בדרך כלל מפרסים את המודלים הללו על אשכולות GPU בסביבות ענן, ומנגישים את יכולותיהם דרך ממשקי API.

מודל מרכזי זה עובד היטב עבור יישומים רבים, אך יש לו מגבלות מובנות בכל הנוגע לתרחישי מחשוב קצה. הגישה המסורתית כוללת שליחת שאילתות משתמש לשרתים מרוחקים, עיבודן באמצעות חומרה חזקה והחזרת תוצאות דרך האינטרנט. בעוד ששיטה זו מספקת גישה למודלים מתקדמים, היא יוצרת תלות בקישוריות לאינטרנט, מציגה חששות לגבי זמן תגובה ומעלה סוגיות פרטיות כאשר יש צורך להעביר נתונים רגישים לשרתים חיצוניים.

ישנם מושגים מרכזיים שעלינו להבין כשעובדים עם פרדיגמות מחשוב מסורתיות של בינה מלאכותית, כלומר:

- **☁️ עיבוד מבוסס ענן**: מודלים של בינה מלאכותית פועלים על תשתית שרתים חזקה עם משאבי מחשוב גבוהים.
- **🔌 גישה מבוססת API**: יישומים ניגשים ליכולות בינה מלאכותית דרך קריאות API מרוחקות במקום עיבוד מקומי.
- **🎛️ ניהול מודלים מרכזי**: המודלים מתוחזקים ומעודכנים באופן מרכזי, מה שמבטיח עקביות אך דורש קישוריות רשת.
- **📈 יכולת הרחבת משאבים**: תשתית הענן יכולה להתרחב באופן דינמי כדי להתמודד עם דרישות מחשוב משתנות.

## האתגר של מחשוב קצה

מכשירי קצה כמו מחשבים ניידים, טלפונים ניידים ומכשירי אינטרנט של הדברים (IoT) כמו Raspberry Pi ו-NVIDIA Orin Nano מציגים מגבלות חישוביות ייחודיות. למכשירים אלו בדרך כלל יש כוח עיבוד מוגבל, זיכרון ומשאבי אנרגיה בהשוואה לתשתית מרכזי נתונים.

הפעלת מודלים שפתיים גדולים מסורתיים על מכשירים כאלה הייתה מאתגרת היסטורית בשל מגבלות החומרה הללו. עם זאת, הצורך בעיבוד בינה מלאכותית בקצה הפך לחשוב יותר ויותר בתרחישים שונים. חשבו על מצבים שבהם קישוריות לאינטרנט אינה אמינה או אינה זמינה, כמו אתרים תעשייתיים מרוחקים, כלי רכב בתנועה או אזורים עם כיסוי רשת לקוי. בנוסף, יישומים הדורשים סטנדרטים גבוהים של אבטחה, כמו מכשירים רפואיים, מערכות פיננסיות או יישומי ממשלה, עשויים להזדקק לעיבוד נתונים רגישים באופן מקומי כדי לשמור על פרטיות ודרישות תאימות.

### מגבלות מרכזיות של מחשוב קצה

סביבות מחשוב קצה מתמודדות עם מספר מגבלות יסודיות שפתרונות בינה מלאכותית מבוססי ענן מסורתיים אינם נתקלים בהן:

- **כוח עיבוד מוגבל**: למכשירי קצה יש בדרך כלל פחות ליבות מעבד ומהירויות שעון נמוכות יותר בהשוואה לחומרה ברמת שרתים.
- **מגבלות זיכרון**: כמות ה-RAM והקיבולת האחסון הזמינות במכשירי קצה מופחתות משמעותית.
- **מגבלות אנרגיה**: מכשירים המופעלים על ידי סוללה חייבים לאזן בין ביצועים לצריכת אנרגיה לפעולה ממושכת.
- **ניהול תרמי**: גורמי צורה קומפקטיים מגבילים את יכולות הקירור, מה שמשפיע על ביצועים מתמשכים תחת עומס.

## מהו EdgeAI?

### מושג: הגדרת EdgeAI

EdgeAI מתייחס לפריסה והפעלה של אלגוריתמים של בינה מלאכותית ישירות על מכשירי קצה—החומרה הפיזית שנמצאת ב"קצה" הרשת, קרוב למקום שבו הנתונים נוצרים ונאספים. מכשירים אלו כוללים סמארטפונים, חיישני IoT, מצלמות חכמות, כלי רכב אוטונומיים, מכשירים לבישים וציוד תעשייתי. בניגוד למערכות בינה מלאכותית מסורתיות שמסתמכות על שרתי ענן לעיבוד, EdgeAI מביא את האינטליגנציה ישירות למקור הנתונים.

בלב העניין, EdgeAI עוסק בהפצת עיבוד הבינה המלאכותית, הרחקת העיבוד ממרכזי נתונים מרכזיים והפצתו על פני רשת רחבה של מכשירים שמרכיבים את האקוסיסטם הדיגיטלי שלנו. זה מייצג שינוי ארכיטקטוני יסודי באופן שבו מערכות בינה מלאכותית מתוכננות ומופעלות.

העמודים הקונספטואליים המרכזיים של EdgeAI כוללים:

- **עיבוד קרוב**: חישוב מתבצע פיזית קרוב למקום שבו הנתונים נוצרים.
- **אינטליגנציה מבוזרת**: יכולות קבלת החלטות מופצות על פני מכשירים מרובים.
- **ריבונות נתונים**: מידע נשאר בשליטה מקומית, ולעיתים אינו עוזב את המכשיר.
- **פעולה אוטונומית**: מכשירים יכולים לפעול בצורה אינטליגנטית ללא צורך בקישוריות מתמדת.
- **בינה מלאכותית משובצת**: האינטליגנציה הופכת ליכולת אינטגרלית של מכשירים יומיומיים.

### הדמיית ארכיטקטורת EdgeAI

```
┌─────────────────────────────────────────────────────────────────────┐
│                         TRADITIONAL AI ARCHITECTURE                 │
└─────────────────────────────────────────────────────────────────────┘
                                  │
┌──────────────┐   Data Transfer  ┌───────────────┐   API Response   ┌───────────┐
│ Edge Devices ├─────────────────>│ Cloud Servers │────────────────> │ End Users │
└──────────────┘                  └───────────────┘                  └───────────┘
     Data                         Model Inference                     Results
   Collection                     High Latency
                                  High Bandwidth
                                  Privacy Concerns
                               
┌─────────────────────────────────────────────────────────────────────┐
│                            EDGE AI ARCHITECTURE                     │
└─────────────────────────────────────────────────────────────────────┘
                                  │
┌────────────────────────────────────────────────────┐   Direct Response  ┌───────────┐
│              Edge Devices with Embedded AI         │───────────────────>│ End Users │
│  ┌─────────┐  ┌───────────────┐  ┌──────────────┐  │                    └───────────┘
│  │ Sensors │─>│ SLM Inference │─>│ Local Action │  │
│  └─────────┘  └───────────────┘  └──────────────┘  │
└────────────────────────────────────────────────────┘
     Data         Low Latency       Immediate
   Collection     Processing        Response
                  No Data Transfer
                  Enhanced Privacy
```

EdgeAI מייצג שינוי פרדיגמה בפריסת בינה מלאכותית, ומביא את יכולות הבינה המלאכותית ישירות למכשירי הקצה במקום להסתמך רק על עיבוד מבוסס ענן. גישה זו מאפשרת למודלים של בינה מלאכותית לפעול באופן מקומי על מכשירים עם משאבי מחשוב מוגבלים, ומספקת יכולות הסקת מסקנות בזמן אמת ללא צורך בקישוריות מתמדת לאינטרנט.

EdgeAI כולל טכנולוגיות וטכניקות שונות שנועדו להפוך את מודלי הבינה המלאכותית ליעילים ומתאימים יותר לפריסה על מכשירים עם משאבים מוגבלים. המטרה היא לשמור על ביצועים סבירים תוך הפחתה משמעותית של דרישות המחשוב והזיכרון של מודלי הבינה המלאכותית.

בואו נבחן את הגישות הבסיסיות שמאפשרות יישומי EdgeAI על פני סוגי מכשירים ושימושים שונים.

### עקרונות יסוד של EdgeAI

EdgeAI מבוסס על מספר עקרונות יסוד שמבדילים אותו מבינה מלאכותית מבוססת ענן מסורתית:

- **עיבוד מקומי**: הסקת מסקנות של בינה מלאכותית מתבצעת ישירות על מכשיר הקצה ללא צורך בקישוריות חיצונית.
- **אופטימיזציה של משאבים**: המודלים מותאמים במיוחד למגבלות החומרה של מכשירי היעד.
- **ביצועים בזמן אמת**: העיבוד מתבצע עם זמן תגובה מינימלי עבור יישומים רגישים לזמן.
- **פרטיות מובנית**: נתונים רגישים נשארים על המכשיר, מה שמגביר את האבטחה והתאימות.

## טכנולוגיות מרכזיות שמאפשרות את EdgeAI

### כימות מודלים

אחת הטכניקות החשובות ביותר ב-EdgeAI היא כימות מודלים. תהליך זה כולל הפחתת דיוק הפרמטרים של המודל, בדרך כלל ממספרים בנקודה צפה של 32 ביטים למספרים שלמים של 8 ביטים או אפילו פורמטים מדויקים יותר נמוכים. למרות שהפחתת הדיוק עשויה להיראות מדאיגה, מחקרים הראו שרבים ממודלי הבינה המלאכותית יכולים לשמור על ביצועיהם גם עם דיוק מופחת משמעותית.

כימות פועלת על ידי מיפוי טווח הערכים בנקודה צפה לקבוצת ערכים דיסקרטיים קטנה יותר. לדוגמה, במקום להשתמש ב-32 ביטים כדי לייצג כל פרמטר, כימות עשויה להשתמש רק ב-8 ביטים, מה שמוביל להפחתה של פי 4 בדרישות הזיכרון ולעיתים קרובות גם לזמני הסקה מהירים יותר.

```python
# Example: PyTorch model quantization 
import torch

# Load a pre-trained model
model = torch.load('large_model.pth')

# Quantize the model to INT8
quantized_model = torch.quantization.quantize_dynamic(
    model,  # model to quantize
    {torch.nn.Linear, torch.nn.Conv2d},  # layers to quantize
    dtype=torch.qint8  # quantization data type
)

# Save the quantized model
torch.save(quantized_model, 'quantized_model.pth')

# Memory usage comparison
original_size = model.size()
quantized_size = quantized_model.size()
print(f"Memory reduction: {original_size / quantized_size:.2f}x")
```

טכניקות כימות שונות כוללות:

- **כימות לאחר אימון (PTQ)**: מיושם לאחר אימון המודל ללא צורך באימון מחדש.
- **אימון מודע לכימות (QAT)**: משלב את השפעות הכימות במהלך האימון לשיפור הדיוק.
- **כימות דינמי**: מכמת משקלים ל-int8 אך מחשב הפעלות באופן דינמי.
- **כימות סטטי**: מחשב מראש את כל פרמטרי הכימות עבור משקלים והפעלות.

לפריסות EdgeAI, בחירת אסטרטגיית הכימות המתאימה תלויה בארכיטקטורת המודל הספציפית, דרישות הביצועים ויכולות החומרה של מכשיר היעד.

### דחיסת מודלים ואופטימיזציה

מעבר לכימות, טכניקות דחיסה שונות מסייעות להפחית את גודל המודל ואת דרישות המחשוב. אלו כוללות:

**גיזום**: טכניקה זו מסירה חיבורים או נוירונים מיותרים מרשתות נוירונים. על ידי זיהוי והסרת פרמטרים שתורמים מעט לביצועי המודל, גיזום יכול להפחית משמעותית את גודל המודל תוך שמירה על דיוק.

```python
# Example: Neural network pruning in TensorFlow
import tensorflow as tf
import tensorflow_model_optimization as tfmot

# Define the model
model = tf.keras.Sequential([
    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

# Apply pruning during training
pruning_schedule = tfmot.sparsity.keras.PolynomialDecay(
    initial_sparsity=0.0,
    final_sparsity=0.5,  # 50% of connections will be pruned
    begin_step=0,
    end_step=10000
)

pruned_model = tfmot.sparsity.keras.prune_low_magnitude(
    model, pruning_schedule=pruning_schedule
)

# Compile the pruned model
pruned_model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# Train the model while pruning
pruned_model.fit(x_train, y_train, epochs=10)

# Convert to a smaller model for deployment
final_model = tfmot.sparsity.keras.strip_pruning(pruned_model)
```

**זיקוק ידע**: גישה זו כוללת אימון מודל "תלמיד" קטן יותר לחקות את התנהגות המודל "המורה" הגדול יותר. מודל התלמיד לומד להעריך את פלטי המורה, ולעיתים קרובות משיג ביצועים דומים עם פחות פרמטרים באופן משמעותי.

**אופטימיזציה של ארכיטקטורת מודלים**: חוקרים פיתחו ארכיטקטורות מיוחדות שתוכננו במיוחד לפריסה בקצה, כמו MobileNets, EfficientNets וארכיטקטורות קלות אחרות שמאזנות בין ביצועים ליעילות חישובית.

### מודלים שפתיים קטנים (SLMs)

מגמה מתפתחת ב-EdgeAI היא פיתוח מודלים שפתיים קטנים (SLMs). מודלים אלו מתוכננים מהיסוד להיות קומפקטיים ויעילים תוך שהם מספקים יכולות משמעותיות בתחום השפה הטבעית. SLMs משיגים זאת באמצעות בחירות ארכיטקטוניות מדויקות, טכניקות אימון יעילות ואימון ממוקד על תחומים או משימות ספציפיות.

בניגוד לגישות מסורתיות הכוללות דחיסת מודלים גדולים, SLMs מאומנים לעיתים קרובות עם מערכי נתונים קטנים יותר וארכיטקטורות אופטימליות שתוכננו במיוחד לפריסה בקצה. גישה זו יכולה להוביל למודלים שהם לא רק קטנים יותר אלא גם יעילים יותר עבור שימושים ספציפיים.

## האצת חומרה עבור EdgeAI

מכשירי קצה מודרניים כוללים יותר ויותר חומרה מיוחדת שנועדה להאיץ עומסי עבודה של בינה מלאכותית:

### יחידות עיבוד נוירוניות (NPUs)

NPUs הם מעבדים מיוחדים שנועדו במיוחד לחישובים של רשתות נוירונים. שבבים אלו יכולים לבצע משימות הסקת מסקנות של בינה מלאכותית בצורה יעילה יותר ממעבדים מסורתיים, לעיתים עם צריכת חשמל נמוכה יותר. סמארטפונים, מחשבים ניידים ומכשירי IoT מודרניים רבים כוללים כיום NPUs כדי לאפשר עיבוד בינה מלאכותית על המכשיר.

```csharp
// Example: Using Windows ML to target NPU acceleration in C#
using Microsoft.ML.OnnxRuntime;

// Create session options with NPU provider
var sessionOptions = new SessionOptions();
sessionOptions.AppendExecutionProvider_DmlExecutionProvider();  // DirectML for NPU

// Load the ONNX model
using var session = new InferenceSession("model.onnx", sessionOptions);

// Create input tensor
var inputTensor = new DenseTensor<float>(new[] { 1, 3, 224, 224 });  // Example input shape
var inputs = new List<NamedOnnxValue> { NamedOnnxValue.CreateFromTensor("input", inputTensor) };

// Run inference with NPU acceleration
using var results = session.Run(inputs);
var output = results.First().AsTensor<float>();

// Process output
Console.WriteLine($"Inference result: {output[0]}");
```

מכשירים עם NPUs כוללים:

- **Apple**: שבבי סדרת A ו-M עם Neural Engine
- **Qualcomm**: מעבדי Snapdragon עם Hexagon DSP/NPU
- **Samsung**: מעבדי Exynos עם NPU
- **Intel**: מעבדי Movidius VPUs ומאיצי Habana Labs
- **Microsoft**: מחשבי Windows Copilot+ עם NPUs

### 🎮 האצת GPU

למרות שמכשירי קצה עשויים שלא לכלול את ה-GPU החזקים שנמצאים במרכזי נתונים, רבים עדיין כוללים GPUs משולבים או נפרדים שיכולים להאיץ עומסי עבודה של בינה מלאכותית. GPUs ניידים מודרניים ומעבדי גרפיקה משולבים יכולים לספק שיפורים משמעותיים בביצועים עבור משימות הסקת מסקנות של בינה מלאכותית.

```python
# Example: Using TensorRT for GPU acceleration on edge devices
import tensorrt as trt
import numpy as np

# Create TensorRT logger and builder
TRT_LOGGER = trt.Logger(trt.Logger.WARNING)
builder = trt.Builder(TRT_LOGGER)
network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))
parser = trt.OnnxParser(network, TRT_LOGGER)

# Parse ONNX model
with open('model.onnx', 'rb') as model:
    parser.parse(model.read())

# Configure builder
config = builder.create_builder_config()
config.max_workspace_size = 1 << 28  # 256 MiB
config.set_flag(trt.BuilderFlag.FP16)  # Use FP16 precision for edge GPU

# Build and serialize engine
engine = builder.build_engine(network, config)
with open('model.trt', 'wb') as f:
    f.write(engine.serialize())
```

### אופטימיזציה של CPU

גם מכשירים עם מעבדי CPU בלבד יכולים להפיק תועלת מ-EdgeAI באמצעות יישומים אופטימליים. מעבדי CPU מודרניים כוללים הוראות מיוחדות לעומסי עבודה של בינה מלאכותית, ופיתוחו של מסגרות תוכנה נועד למקסם את ביצועי המעבד עבור הסקת מסקנות של בינה מלאכותית.

```bash
# Example: Using XNNPACK with TFLite for optimized CPU inference
# Compilation command with XNNPACK acceleration enabled

bazel build -c opt --copt=-O3 --copt=-march=native \
  tensorflow/lite/delegates/xnnpack:libxnnpack_delegate.so

# Convert TensorFlow model to TFLite with optimization
tflite_convert \
  --keras_model_file=model.h5 \
  --output_file=model.tflite \
  --inference_type=FLOAT \
  --experimental_new_converter \
  --experimental_new_quantizer
```

עבור מהנדסי תוכנה העובדים עם EdgeAI, הבנת כיצד לנצל את אפשרויות האצת החומרה הללו היא קריטית לאופטימיזציה של ביצועי ההסקה ויעילות האנרגיה במכשירי היעד.

## יתרונות EdgeAI

### פרטיות ואבטחה

אחד היתרונות המשמעותיים ביותר של EdgeAI הוא פרטיות ואבטחה משופרות. על ידי עיבוד נתונים באופן מקומי על המכשיר, מידע רגיש לעולם אינו עוזב את שליטת המשתמש. זה חשוב במיוחד עבור יישומים שמטפלים בנתונים אישיים, מידע רפואי או נתונים עסקיים סודיים.

### הפחתת זמן תגובה

EdgeAI מבטל את הצורך לשלוח נתונים לשרתים מרוחקים לעיבוד, מה שמפחית משמעותית את זמן התגובה. זה קריטי עבור יישומים בזמן אמת כמו כלי רכב אוטונומיים, אוטומציה תעשייתית או יישומים אינטראקטיביים שבהם נדרשות תגובות מיידיות.

### יכולת עבודה במצב לא מקוון

EdgeAI מאפשר פונקציונליות של בינה מלאכותית גם כאשר קישוריות לאינטרנט אינה זמינה. זה חשוב עבור יישומים במיקומים מרוחקים, במהלך נסיעות או במצבים שבהם אמינות הרשת מהווה דאגה.

### יעילות כלכלית

על ידי הפחתת התלות בשירותי בינה מלאכותית מבוססי ענן, EdgeAI יכול לעזור להפחית עלויות תפעול, במיוחד עבור יישומים עם נפחי שימוש גבוהים. ארגונים יכולים להימנע מעלויות API מתמשכות ולהפחית את דרישות רוחב הפס.

### יכולת הרחבה

EdgeAI מפזר את עומס המחשוב על פני מכשירי קצה במקום לרכז אותו במרכזי נתונים. זה יכול לעזור להפחית את עלויות התשתית ולשפר את יכולת ההרחבה הכוללת של המערכת.

## יישומים של EdgeAI

### מכשירים חכמים ו-IoT

EdgeAI מניע תכונות רבות של מכשירים חכמים, החל מעוזרים קוליים שיכולים לעבד פקודות באופן מקומי ועד מצלמות חכמות שיכולות לזהות אובייקטים ואנשים מבלי לשלוח וידאו לענן. מכשירי IoT משתמשים ב-EdgeAI לצורך תחזוקה חזויה, ניטור סביבתי וקבלת החלטות אוטומטית.

### יישומים ניידים

סמארטפונים וטאבלטים משתמשים ב-EdgeAI עבור תכונות שונות, כולל שיפור תמונות, תרגום בזמן אמת, מציאות רבודה והמלצות מותאמות אישית. יישומים אלו נהנים מהיתרונות של זמן תגובה נמוך ופרטיות של עיבוד מקומי.

### יישומים תעשייתיים

סביבות ייצור ותעשייה
- [02: יישומי EdgeAI](02.RealWorldCaseStudies.md)

---

**הצהרת אחריות**:  
מסמך זה תורגם באמצעות שירות תרגום AI [Co-op Translator](https://github.com/Azure/co-op-translator). למרות שאנו שואפים לדיוק, יש לקחת בחשבון שתרגומים אוטומטיים עשויים להכיל שגיאות או אי דיוקים. המסמך המקורי בשפתו המקורית צריך להיחשב כמקור סמכותי. עבור מידע קריטי, מומלץ להשתמש בתרגום מקצועי אנושי. איננו אחראים לאי הבנות או פירושים שגויים הנובעים משימוש בתרגום זה.