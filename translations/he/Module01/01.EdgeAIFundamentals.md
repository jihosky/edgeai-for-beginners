<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "76b134be93f45283a2df8f8a93717d06",
  "translation_date": "2025-10-17T09:52:38+00:00",
  "source_file": "Module01/01.EdgeAIFundamentals.md",
  "language_code": "he"
}
-->
# סעיף 1: יסודות EdgeAI

EdgeAI מייצג שינוי פרדיגמה בפריסת בינה מלאכותית, ומביא את יכולות הבינה המלאכותית ישירות למכשירי הקצה במקום להסתמך רק על עיבוד מבוסס ענן. חשוב להבין כיצד EdgeAI מאפשר עיבוד בינה מלאכותית מקומי על מכשירים עם משאבים מוגבלים, תוך שמירה על ביצועים סבירים והתמודדות עם אתגרים כמו פרטיות, זמן תגובה ויכולות עבודה במצב לא מקוון.

## מבוא

בשיעור זה נחקור את EdgeAI ואת מושגי היסוד שלו. נסקור את פרדיגמת המחשוב המסורתית של בינה מלאכותית, את האתגרים של מחשוב קצה, את הטכנולוגיות המרכזיות שמאפשרות את EdgeAI, ואת היישומים המעשיים בתעשיות שונות.

## מטרות למידה

בסיום השיעור, תוכלו:

- להבין את ההבדל בין גישות בינה מלאכותית מבוססת ענן לבין גישות EdgeAI.
- לזהות את הטכנולוגיות המרכזיות שמאפשרות עיבוד בינה מלאכותית על מכשירי קצה.
- להכיר את היתרונות והמגבלות של יישומי EdgeAI.
- ליישם ידע על EdgeAI בתרחישים ושימושים בעולם האמיתי.

## הבנת פרדיגמת המחשוב המסורתית של בינה מלאכותית

באופן מסורתי, יישומי בינה מלאכותית גנרטיבית מסתמכים על תשתית מחשוב בעלת ביצועים גבוהים כדי להפעיל מודלים שפתיים גדולים (LLMs) בצורה יעילה. ארגונים בדרך כלל מפרסים את המודלים הללו על אשכולות GPU בסביבות ענן, ומנגישים את יכולותיהם דרך ממשקי API.

מודל מרכזי זה עובד היטב עבור יישומים רבים, אך יש לו מגבלות מובנות כשמדובר בתרחישי מחשוב קצה. הגישה המסורתית כוללת שליחת שאילתות משתמש לשרתים מרוחקים, עיבודן באמצעות חומרה חזקה והחזרת תוצאות דרך האינטרנט. בעוד שגישה זו מספקת גישה למודלים מתקדמים, היא יוצרת תלות בקישוריות אינטרנט, מציגה חששות לגבי זמן תגובה, ומעלה סוגיות פרטיות כאשר יש צורך להעביר נתונים רגישים לשרתים חיצוניים.

ישנם מושגים מרכזיים שעלינו להבין כשעובדים עם פרדיגמות מחשוב מסורתיות של בינה מלאכותית, והם:

- **☁️ עיבוד מבוסס ענן**: מודלים של בינה מלאכותית פועלים על תשתית שרתים חזקה עם משאבי מחשוב גבוהים.
- **🔌 גישה מבוססת API**: יישומים ניגשים ליכולות בינה מלאכותית דרך קריאות API מרוחקות במקום עיבוד מקומי.
- **🎛️ ניהול מודלים מרכזי**: המודלים נשמרים ומעודכנים באופן מרכזי, מה שמבטיח עקביות אך דורש קישוריות רשת.
- **📈 יכולת הרחבת משאבים**: תשתית הענן יכולה להתרחב באופן דינמי כדי להתמודד עם דרישות מחשוב משתנות.

## האתגר של מחשוב קצה

מכשירי קצה כמו מחשבים ניידים, טלפונים ניידים ומכשירי אינטרנט של הדברים (IoT) כמו Raspberry Pi ו-NVIDIA Orin Nano מציגים מגבלות חישוביות ייחודיות. למכשירים אלו בדרך כלל יש כוח עיבוד, זיכרון ומשאבי אנרגיה מוגבלים בהשוואה לתשתית מרכזי נתונים.

הפעלת מודלים שפתיים גדולים (LLMs) מסורתיים על מכשירים כאלה הייתה היסטורית מאתגרת בשל מגבלות החומרה הללו. עם זאת, הצורך בעיבוד בינה מלאכותית בקצה הפך לחשוב יותר ויותר בתרחישים שונים. חשבו על מצבים שבהם קישוריות אינטרנט אינה אמינה או אינה זמינה, כמו אתרים תעשייתיים מרוחקים, כלי רכב בתנועה או אזורים עם כיסוי רשת לקוי. בנוסף, יישומים הדורשים סטנדרטים אבטחה גבוהים, כמו מכשירים רפואיים, מערכות פיננסיות או יישומים ממשלתיים, עשויים להזדקק לעיבוד נתונים רגישים באופן מקומי כדי לשמור על פרטיות ודרישות תאימות.

### מגבלות מרכזיות של מחשוב קצה

סביבות מחשוב קצה מתמודדות עם מספר מגבלות יסודיות שאותן פתרונות בינה מלאכותית מבוססי ענן מסורתיים אינם פוגשים:

- **כוח עיבוד מוגבל**: למכשירי קצה בדרך כלל יש פחות ליבות CPU ומהירויות שעון נמוכות בהשוואה לחומרה ברמת שרתים.
- **מגבלות זיכרון**: הזיכרון הזמין וקיבולת האחסון מופחתים משמעותית במכשירי קצה.
- **מגבלות אנרגיה**: מכשירים המופעלים על סוללה חייבים לאזן בין ביצועים לצריכת אנרגיה לצורך פעולה ממושכת.
- **ניהול תרמי**: גורמי צורה קומפקטיים מגבילים את יכולות הקירור, מה שמשפיע על ביצועים מתמשכים תחת עומס.

## מהו EdgeAI?

### מושג: הגדרת Edge AI

Edge AI מתייחס לפריסה והפעלה של אלגוריתמים בינה מלאכותית ישירות על מכשירי קצה—החומרה הפיזית שנמצאת ב"קו הקצה" של הרשת, קרוב למקום שבו הנתונים נוצרים ונאספים. מכשירים אלו כוללים סמארטפונים, חיישני IoT, מצלמות חכמות, כלי רכב אוטונומיים, מכשירים לבישים וציוד תעשייתי. בניגוד למערכות בינה מלאכותית מסורתיות שמסתמכות על שרתי ענן לעיבוד, Edge AI מביא את האינטליגנציה ישירות למקור הנתונים.

בלב העניין, Edge AI עוסק בהפצת עיבוד הבינה המלאכותית, הרחקתו ממרכזי נתונים מרכזיים והפצתו על פני הרשת הרחבה של מכשירים שמרכיבים את המערכת הדיגיטלית שלנו. זה מייצג שינוי ארכיטקטוני יסודי באופן שבו מערכות בינה מלאכותית מתוכננות ומופעלות.

העמודים הקונספטואליים המרכזיים של Edge AI כוללים:

- **עיבוד קרוב**: החישוב מתבצע פיזית קרוב למקום שבו הנתונים נוצרים.
- **אינטליגנציה מבוזרת**: יכולות קבלת החלטות מופצות על פני מכשירים מרובים.
- **ריבונות נתונים**: המידע נשאר בשליטה מקומית, ולעיתים קרובות אינו עוזב את המכשיר.
- **פעולה אוטונומית**: מכשירים יכולים לפעול בצורה אינטליגנטית ללא צורך בקישוריות מתמדת.
- **בינה משובצת**: האינטליגנציה הופכת ליכולת אינהרנטית של מכשירים יומיומיים.

### ויזואליזציה של ארכיטקטורת Edge AI

```
┌─────────────────────────────────────────────────────────────────────┐
│                         TRADITIONAL AI ARCHITECTURE                 │
└─────────────────────────────────────────────────────────────────────┘
                                  │
┌──────────────┐   Data Transfer  ┌───────────────┐   API Response   ┌───────────┐
│ Edge Devices ├─────────────────>│ Cloud Servers │────────────────> │ End Users │
└──────────────┘                  └───────────────┘                  └───────────┘
     Data                         Model Inference                     Results
   Collection                     High Latency
                                  High Bandwidth
                                  Privacy Concerns
                               
┌─────────────────────────────────────────────────────────────────────┐
│                            EDGE AI ARCHITECTURE                     │
└─────────────────────────────────────────────────────────────────────┘
                                  │
┌────────────────────────────────────────────────────┐   Direct Response  ┌───────────┐
│              Edge Devices with Embedded AI         │───────────────────>│ End Users │
│  ┌─────────┐  ┌───────────────┐  ┌──────────────┐  │                    └───────────┘
│  │ Sensors │─>│ SLM Inference │─>│ Local Action │  │
│  └─────────┘  └───────────────┘  └──────────────┘  │
└────────────────────────────────────────────────────┘
     Data         Low Latency       Immediate
   Collection     Processing        Response
                  No Data Transfer
                  Enhanced Privacy
```

EdgeAI מייצג שינוי פרדיגמה בפריסת בינה מלאכותית, ומביא את יכולות הבינה המלאכותית ישירות למכשירי קצה במקום להסתמך רק על עיבוד מבוסס ענן. גישה זו מאפשרת למודלים של בינה מלאכותית לפעול באופן מקומי על מכשירים עם משאבי מחשוב מוגבלים, ומספקת יכולות הסקת מסקנות בזמן אמת ללא צורך בקישוריות אינטרנט מתמדת.

EdgeAI כולל טכנולוגיות וטכניקות שונות שנועדו להפוך את מודלי הבינה המלאכותית ליעילים ומתאימים יותר לפריסה על מכשירים עם משאבים מוגבלים. המטרה היא לשמור על ביצועים סבירים תוך הפחתה משמעותית של דרישות החישוב והזיכרון של מודלי הבינה המלאכותית.

בואו נבחן את הגישות הבסיסיות שמאפשרות יישומי EdgeAI על פני סוגי מכשירים ושימושים שונים.

### עקרונות מרכזיים של EdgeAI

EdgeAI מבוסס על מספר עקרונות יסוד שמבדילים אותו מבינה מלאכותית מבוססת ענן מסורתית:

- **עיבוד מקומי**: הסקת מסקנות בינה מלאכותית מתבצעת ישירות על מכשיר הקצה ללא צורך בקישוריות חיצונית.
- **אופטימיזציית משאבים**: המודלים מותאמים במיוחד למגבלות החומרה של מכשירי היעד.
- **ביצועים בזמן אמת**: העיבוד מתבצע עם זמן תגובה מינימלי עבור יישומים רגישים לזמן.
- **פרטיות בעיצוב**: נתונים רגישים נשארים על המכשיר, מה שמשפר את האבטחה והתאימות.

## טכנולוגיות מרכזיות שמאפשרות EdgeAI

### כימות מודלים

אחת הטכניקות החשובות ביותר ב-EdgeAI היא כימות מודלים. תהליך זה כולל הפחתת דיוק הפרמטרים של המודל, בדרך כלל ממספרים בנקודה צפה של 32 ביטים למספרים שלמים של 8 ביטים או אפילו פורמטים דיוק נמוך יותר. בעוד שהפחתה זו בדיוק עשויה להיראות מדאיגה, מחקרים הראו שרבים ממודלי הבינה המלאכותית יכולים לשמור על ביצועיהם גם עם דיוק מופחת משמעותית.

כימות פועלת על ידי מיפוי טווח הערכים בנקודה צפה לקבוצה קטנה יותר של ערכים דיסקרטיים. לדוגמה, במקום להשתמש ב-32 ביטים כדי לייצג כל פרמטר, כימות עשויה להשתמש רק ב-8 ביטים, מה שמוביל להפחתה של פי 4 בדרישות הזיכרון ולעיתים קרובות לזמני הסקה מהירים יותר.

```python
# Example: PyTorch model quantization 
import torch

# Load a pre-trained model
model = torch.load('large_model.pth')

# Quantize the model to INT8
quantized_model = torch.quantization.quantize_dynamic(
    model,  # model to quantize
    {torch.nn.Linear, torch.nn.Conv2d},  # layers to quantize
    dtype=torch.qint8  # quantization data type
)

# Save the quantized model
torch.save(quantized_model, 'quantized_model.pth')

# Memory usage comparison
original_size = model.size()
quantized_size = quantized_model.size()
print(f"Memory reduction: {original_size / quantized_size:.2f}x")
```

טכניקות כימות שונות כוללות:

- **כימות לאחר אימון (PTQ)**: מיושם לאחר אימון המודל ללא צורך באימון מחדש.
- **אימון מודע לכימות (QAT)**: משלב את השפעות הכימות במהלך האימון לשיפור דיוק.
- **כימות דינמי**: מכמת משקלים ל-int8 אך מחשב הפעלות באופן דינמי.
- **כימות סטטי**: מחשב מראש את כל פרמטרי הכימות עבור משקלים והפעלות.

עבור פריסות EdgeAI, בחירת אסטרטגיית הכימות המתאימה תלויה בארכיטקטורת המודל הספציפית, דרישות הביצועים ויכולות החומרה של מכשיר היעד.

### דחיסת מודלים ואופטימיזציה

מעבר לכימות, טכניקות דחיסה שונות עוזרות להפחית את גודל המודל ודרישות החישוב. אלו כוללות:

**גיזום**: טכניקה זו מסירה חיבורים או נוירונים מיותרים מרשתות עצביות. על ידי זיהוי והסרת פרמטרים שתורמים מעט לביצועי המודל, גיזום יכול להפחית משמעותית את גודל המודל תוך שמירה על דיוק.

```python
# Example: Neural network pruning in TensorFlow
import tensorflow as tf
import tensorflow_model_optimization as tfmot

# Define the model
model = tf.keras.Sequential([
    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

# Apply pruning during training
pruning_schedule = tfmot.sparsity.keras.PolynomialDecay(
    initial_sparsity=0.0,
    final_sparsity=0.5,  # 50% of connections will be pruned
    begin_step=0,
    end_step=10000
)

pruned_model = tfmot.sparsity.keras.prune_low_magnitude(
    model, pruning_schedule=pruning_schedule
)

# Compile the pruned model
pruned_model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# Train the model while pruning
pruned_model.fit(x_train, y_train, epochs=10)

# Convert to a smaller model for deployment
final_model = tfmot.sparsity.keras.strip_pruning(pruned_model)
```

**זיקוק ידע**: גישה זו כוללת אימון מודל "תלמיד" קטן יותר לחקות את התנהגות מודל "מורה" גדול יותר. מודל התלמיד לומד להתקרב לתוצאות המורה, ולעיתים משיג ביצועים דומים עם פחות פרמטרים משמעותית.

**אופטימיזציית ארכיטקטורת מודלים**: חוקרים פיתחו ארכיטקטורות מיוחדות שתוכננו במיוחד לפריסה בקצה, כמו MobileNets, EfficientNets וארכיטקטורות קלות אחרות שמאזנות בין ביצועים ליעילות חישובית.

### מודלים שפתיים קטנים (SLMs)

מגמה מתפתחת ב-EdgeAI היא פיתוח מודלים שפתיים קטנים (SLMs). מודלים אלו מתוכננים מהיסוד להיות קומפקטיים ויעילים תוך מתן יכולות שפה טבעית משמעותיות. SLMs משיגים זאת באמצעות בחירות ארכיטקטוניות מדוקדקות, טכניקות אימון יעילות ואימון ממוקד על תחומים או משימות ספציפיות.

בניגוד לגישות מסורתיות שכוללות דחיסת מודלים גדולים, SLMs מאומנים לעיתים קרובות עם מערכי נתונים קטנים יותר וארכיטקטורות מותאמות שתוכננו במיוחד לפריסה בקצה. גישה זו יכולה להוביל למודלים שהם לא רק קטנים יותר אלא גם יעילים יותר עבור שימושים ספציפיים.

## האצת חומרה עבור EdgeAI

מכשירי קצה מודרניים כוללים יותר ויותר חומרה מיוחדת שנועדה להאיץ עומסי עבודה של בינה מלאכותית:

### יחידות עיבוד עצבי (NPUs)

NPUs הם מעבדים מיוחדים שתוכננו במיוחד עבור חישובי רשתות עצביות. שבבים אלו יכולים לבצע משימות הסקת מסקנות בינה מלאכותית בצורה יעילה יותר ממעבדי CPU מסורתיים, ולעיתים עם צריכת אנרגיה נמוכה יותר. סמארטפונים, מחשבים ניידים ומכשירי IoT מודרניים רבים כוללים כיום NPUs כדי לאפשר עיבוד בינה מלאכותית על המכשיר.

```csharp
// Example: Using Windows ML to target NPU acceleration in C#
using Microsoft.ML.OnnxRuntime;

// Create session options with NPU provider
var sessionOptions = new SessionOptions();
sessionOptions.AppendExecutionProvider_DmlExecutionProvider();  // DirectML for NPU

// Load the ONNX model
using var session = new InferenceSession("model.onnx", sessionOptions);

// Create input tensor
var inputTensor = new DenseTensor<float>(new[] { 1, 3, 224, 224 });  // Example input shape
var inputs = new List<NamedOnnxValue> { NamedOnnxValue.CreateFromTensor("input", inputTensor) };

// Run inference with NPU acceleration
using var results = session.Run(inputs);
var output = results.First().AsTensor<float>();

// Process output
Console.WriteLine($"Inference result: {output[0]}");
```

מכשירים עם NPUs כוללים:

- **Apple**: שבבי סדרת A ו-M עם Neural Engine
- **Qualcomm**: מעבדי Snapdragon עם Hexagon DSP/NPU
- **Samsung**: מעבדי Exynos עם NPU
- **Intel**: מעבדי Movidius VPUs ומאיצי Habana Labs
- **Microsoft**: מחשבי Windows Copilot+ עם NPUs

### 🎮 האצת GPU

בעוד שמכשירי קצה עשויים שלא לכלול את ה-GPU החזקים שנמצאים במרכזי נתונים, רבים עדיין כוללים GPUs משולבים או נפרדים שיכולים להאיץ עומסי עבודה של בינה מלאכותית. GPUs ניידים מודרניים ומעבדי גרפיקה משולבים יכולים לספק שיפורי ביצועים משמעותיים עבור משימות הסקת מסקנות בינה מלאכותית.

```python
# Example: Using TensorRT for GPU acceleration on edge devices
import tensorrt as trt
import numpy as np

# Create TensorRT logger and builder
TRT_LOGGER = trt.Logger(trt.Logger.WARNING)
builder = trt.Builder(TRT_LOGGER)
network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))
parser = trt.OnnxParser(network, TRT_LOGGER)

# Parse ONNX model
with open('model.onnx', 'rb') as model:
    parser.parse(model.read())

# Configure builder
config = builder.create_builder_config()
config.max_workspace_size = 1 << 28  # 256 MiB
config.set_flag(trt.BuilderFlag.FP16)  # Use FP16 precision for edge GPU

# Build and serialize engine
engine = builder.build_engine(network, config)
with open('model.trt', 'wb') as f:
    f.write(engine.serialize())
```

### אופטימיזציית CPU

גם מכשירים עם מעבדי CPU בלבד יכולים להפיק תועלת מ-EdgeAI באמצעות יישומים מותאמים. מעבדי CPU מודרניים כוללים הוראות מיוחדות עבור עומסי עבודה של בינה מלאכותית, ופלטפורמות תוכנה פותחו כדי למקסם את ביצועי ה-CPU עבור הסקת מסקנות בינה מלאכותית.

```bash
# Example: Using XNNPACK with TFLite for optimized CPU inference
# Compilation command with XNNPACK acceleration enabled

bazel build -c opt --copt=-O3 --copt=-march=native \
  tensorflow/lite/delegates/xnnpack:libxnnpack_delegate.so

# Convert TensorFlow model to TFLite with optimization
tflite_convert \
  --keras_model_file=model.h5 \
  --output_file=model.tflite \
  --inference_type=FLOAT \
  --experimental_new_converter \
  --experimental_new_quantizer
```

עבור מהנדסי תוכנה העובדים עם EdgeAI, הבנה כיצד לנצל את אפשרויות האצת החומרה הללו היא קריטית לאופטימיזציית ביצועי הסקת מסקנות ויעילות אנרגטית על מכשירי היעד.

## יתרונות EdgeAI

### פרטיות ואבטחה

אחד היתרונות המשמעותיים ביותר של EdgeAI הוא פרטיות ואבטחה משופרות. על ידי עיבוד נתונים באופן מקומי על המכשיר, מידע רגיש לעולם אינו עוזב את שליטת המשתמש. זה חשוב במיוחד עבור יישומים המטפלים בנתונים אישיים, מידע רפואי או נתוני עסק סודיים.

### הפחתת זמן תגובה

EdgeAI מבטל את הצורך לשלוח נתונים לשרתים מרוחקים לעיבוד, מה שמפחית משמעותית את זמן התגובה. זה קריטי עבור יישומים בזמן אמת כמו כלי רכב אוטונומיים, אוטומציה תעשייתית או יישומים אינטראקטיביים שבהם נדרשות תגובות מיידיות.

### יכולת עבודה במצב לא מקוון

EdgeAI מאפשר פונקציונליות בינה מלאכותית גם כאשר קישוריות אינטרנט אינה זמינה. זה חשוב עבור יישומים במיקומים מרוחקים, במהלך נסיעות או במצבים שבהם אמינות הרשת מהווה דאגה.

### יעילות כלכלית

על ידי הפחתת התלות בשירותי בינה מלאכותית מבוססי ענן, EdgeAI יכול לעזור להפחית עלויות תפעול, במיוחד עבור יישומים עם נפחי שימוש גבוהים. ארגונים יכולים להימנע מעלויות API מתמשכות ולהפחית את דרישות רוחב הפס.

### יכולת הרחבה

EdgeAI מפזר את עומס החישוב על פני מכשירי קצה במקום לרכז אותו במרכזי נתונים. זה יכול לעזור להפחית עלויות תשתית ולשפר את יכולת ההרחבה הכוללת של המערכת.

## יישומי EdgeAI

### מכשירים חכמים ו-IoT

EdgeAI מניע תכונות רבות של מכשירים חכמים, החל מעוזרים קוליים שיכולים לעבד פקודות באופן מקומי ועד מצלמות חכמות שיכולות לזהות אובייקטים ואנשים מבלי לשלוח וידאו לענן. מכשירי IoT משתמשים ב-EdgeAI לצורך תחזוקה חזויה, ניטור סביבתי וקבלת החלטות אוטומטית.

### יישומים ניידים

סמארטפונים וטאבלטים משתמשים ב-EdgeAI עבור תכונות שונות, כולל שיפור תמונות, תרגום בזמן אמת, מציאות רבודה והמלצות מותאמות אישית. יישומים אלו נהנים מהיתרונות של זמן תגובה נמוך ופרטיות של עיבוד מקומי.

### יישומים תעשייתיים

סביבות ייצור ותעשייה משתמשות ב-EdgeAI לצורך בקרת איכות, תחזוקה חזויה ואופטימיזציית ת
- [02: יישומי EdgeAI](02.RealWorldCaseStudies.md)

---

**כתב ויתור**:  
מסמך זה תורגם באמצעות שירות תרגום AI [Co-op Translator](https://github.com/Azure/co-op-translator). למרות שאנו שואפים לדיוק, יש לקחת בחשבון שתרגומים אוטומטיים עשויים להכיל שגיאות או אי דיוקים. המסמך המקורי בשפתו המקורית צריך להיחשב כמקור סמכותי. עבור מידע קריטי, מומלץ להשתמש בתרגום מקצועי אנושי. איננו אחראים לאי הבנות או לפרשנויות שגויות הנובעות משימוש בתרגום זה.