<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "efb0e70d6e87d0795f4d381c3bc99074",
  "translation_date": "2025-10-21T07:22:11+00:00",
  "source_file": "Module07/aitoolkit.md",
  "language_code": "he"
}
-->
# ערכת כלים AI ל-Visual Studio Code - מדריך לפיתוח AI בקצה

## מבוא

ברוכים הבאים למדריך המקיף לשימוש בערכת הכלים AI ל-Visual Studio Code בפיתוח AI בקצה. ככל שהבינה המלאכותית עוברת ממחשוב ענן מרכזי למכשירי קצה מבוזרים, מפתחים זקוקים לכלים חזקים ואינטגרטיביים שיכולים להתמודד עם האתגרים הייחודיים של פריסת קצה - החל ממגבלות משאבים ועד לדרישות לפעולה במצב לא מקוון.

ערכת הכלים AI ל-Visual Studio Code מגשרת על הפער הזה על ידי מתן סביבת פיתוח מלאה שתוכננה במיוחד לבניית, בדיקה ואופטימיזציה של יישומי AI שפועלים ביעילות על מכשירי קצה. בין אם אתם מפתחים עבור חיישני IoT, מכשירים ניידים, מערכות משובצות או שרתי קצה, ערכת הכלים הזו מפשטת את כל תהליך הפיתוח שלכם בתוך סביבת VS Code המוכרת.

מדריך זה ייקח אתכם דרך המושגים החיוניים, הכלים והפרקטיקות הטובות ביותר לשימוש בערכת הכלים AI בפרויקטים שלכם בקצה, החל מבחירת מודל ראשונית ועד לפריסה בייצור.

## סקירה כללית

ערכת הכלים AI ל-Visual Studio Code היא הרחבה חזקה שמפשטת את פיתוח הסוכנים ויצירת יישומי AI. הערכה מספקת יכולות מקיפות לחקר, הערכה ופריסה של מודלים AI ממגוון רחב של ספקים—כולל Anthropic, OpenAI, GitHub, Google—תוך תמיכה בביצוע מודלים מקומי באמצעות ONNX ו-Ollama.

מה שמייחד את ערכת הכלים AI הוא הגישה המקיפה שלה לכל מחזור החיים של פיתוח AI. בניגוד לכלי פיתוח AI מסורתיים שמתמקדים בהיבטים בודדים, ערכת הכלים AI מספקת סביבה אינטגרטיבית שמכסה גילוי מודלים, ניסויים, פיתוח סוכנים, הערכה ופריסה—הכל בתוך סביבת VS Code המוכרת.

הפלטפורמה תוכננה במיוחד לפרוטוטיפ מהיר ולפריסה בייצור, עם תכונות כמו יצירת הנחיות, התחלה מהירה, אינטגרציות חלקות עם MCP (Model Context Protocol) וכלי הערכה נרחבים. עבור פיתוח AI בקצה, המשמעות היא שתוכלו לפתח, לבדוק ולייעל יישומי AI לתרחישי פריסת קצה ביעילות תוך שמירה על כל תהליך הפיתוח בתוך VS Code.

## מטרות למידה

בסיום המדריך הזה, תוכלו:

### מיומנויות ליבה
- **להתקין ולהגדיר** את ערכת הכלים AI ל-Visual Studio Code עבור תהליכי עבודה של פיתוח AI בקצה
- **לנווט ולהשתמש** בממשק ערכת הכלים AI, כולל קטלוג מודלים, Playground ו-Agent Builder
- **לבחור ולהעריך** מודלים AI המתאימים לפריסת קצה בהתבסס על ביצועים ומגבלות משאבים
- **להמיר ולייעל** מודלים באמצעות פורמט ONNX וטכניקות כימות עבור מכשירי קצה

### מיומנויות פיתוח AI בקצה
- **לעצב וליישם** יישומי AI בקצה באמצעות סביבת הפיתוח האינטגרטיבית
- **לבצע בדיקות מודלים** בתנאים דמויי קצה באמצעות הסקה מקומית וניטור משאבים
- **ליצור ולהתאים אישית** סוכני AI המותאמים לתרחישי פריסת קצה
- **להעריך ביצועי מודלים** באמצעות מדדים רלוונטיים למחשוב קצה (זמן תגובה, שימוש בזיכרון, דיוק)

### אופטימיזציה ופריסה
- **ליישם טכניקות כימות וגיזום** כדי להקטין את גודל המודל תוך שמירה על ביצועים מקובלים
- **לייעל מודלים** עבור פלטפורמות חומרה ספציפיות בקצה כולל האצת CPU, GPU ו-NPU
- **ליישם פרקטיקות מומלצות** לפיתוח AI בקצה כולל ניהול משאבים ואסטרטגיות גיבוי
- **להכין מודלים ויישומים** לפריסה בייצור על מכשירי קצה

### מושגים מתקדמים ב-AI בקצה
- **להשתלב עם מסגרות AI בקצה** כולל ONNX Runtime, Windows ML ו-TensorFlow Lite
- **ליישם ארכיטקטורות רב-מודליות** ותסריטי למידה מבוזרת עבור סביבות קצה
- **לפתור בעיות נפוצות ב-AI בקצה** כולל מגבלות זיכרון, מהירות הסקה ותאימות חומרה
- **לעצב אסטרטגיות ניטור ורישום** עבור יישומי AI בקצה בייצור

### יישום מעשי
- **לבנות פתרונות AI בקצה מקצה לקצה** מבחירת מודל ועד לפריסה
- **להפגין מיומנות** בתהליכי פיתוח ואופטימיזציה ספציפיים לקצה
- **ליישם מושגים שנלמדו** על מקרי שימוש אמיתיים ב-AI בקצה כולל IoT, ניידים ויישומים משובצים
- **להעריך ולהשוות** אסטרטגיות פריסת AI בקצה שונות והפשרות שלהן

## תכונות מרכזיות לפיתוח AI בקצה

### 1. קטלוג מודלים וגילוי
- **תמיכה רב-ספקית**: עיון וגישה למודלים AI מ-Anthropic, OpenAI, GitHub, Google וספקים אחרים
- **אינטגרציה עם מודלים מקומיים**: גילוי פשוט של מודלים ONNX ו-Ollama לפריסת קצה
- **מודלים מ-GitHub**: אינטגרציה ישירה עם אירוח מודלים של GitHub לגישה חלקה
- **השוואת מודלים**: השוואת מודלים זה לצד זה למציאת איזון אופטימלי למגבלות מכשירי קצה

### 2. Playground אינטראקטיבי
- **סביבת בדיקה אינטראקטיבית**: ניסויים מהירים עם יכולות מודלים בסביבה מבוקרת
- **תמיכה רב-מודלית**: בדיקה עם תמונות, טקסט וקלטים אחרים אופייניים לתרחישי קצה
- **ניסויים בזמן אמת**: משוב מיידי על תגובות המודל וביצועיו
- **אופטימיזציית פרמטרים**: כוונון פרמטרי מודלים לדרישות פריסת קצה

### 3. Builder להנחיות (סוכנים)
- **יצירת שפה טבעית**: יצירת הנחיות התחלתיות באמצעות תיאורים בשפה טבעית
- **שיפור איטרטיבי**: שיפור הנחיות בהתבסס על תגובות המודל וביצועיו
- **פירוק משימות**: פירוק משימות מורכבות עם שרשור הנחיות ותוצאות מובנות
- **תמיכה במשתנים**: שימוש במשתנים בהנחיות להתנהגות סוכנים דינמית
- **יצירת קוד לייצור**: יצירת קוד מוכן לייצור לפיתוח אפליקציות מהיר

### 4. הרצה והערכה בכמות גדולה
- **בדיקת רב-מודלים**: ביצוע הנחיות מרובות על פני מודלים נבחרים בו זמנית
- **בדיקה יעילה בקנה מידה**: בדיקת קלטים וקונפיגורציות שונות ביעילות
- **מקרי בדיקה מותאמים אישית**: הרצת סוכנים עם מקרי בדיקה לאימות פונקציונליות
- **השוואת ביצועים**: השוואת תוצאות על פני מודלים וקונפיגורציות שונות

### 5. הערכת מודלים עם מערכי נתונים
- **מדדים סטנדרטיים**: בדיקת מודלים AI באמצעות מעריכים מובנים (ציון F1, רלוונטיות, דמיון, קוהרנטיות)
- **מעריכים מותאמים אישית**: יצירת מדדי הערכה משלכם למקרי שימוש ספציפיים
- **אינטגרציה עם מערכי נתונים**: בדיקת מודלים מול מערכי נתונים מקיפים
- **מדידת ביצועים**: כימות ביצועי מודלים להחלטות פריסת קצה

### 6. יכולות כוונון עדין
- **התאמת מודלים**: התאמת מודלים למקרי שימוש ותחומים ספציפיים
- **התאמה מיוחדת**: התאמת מודלים לדרישות ותחומים מיוחדים
- **אופטימיזציה לקצה**: כוונון מודלים במיוחד למגבלות פריסת קצה
- **אימון ספציפי לתחום**: יצירת מודלים מותאמים למקרי שימוש ספציפיים בקצה

### 7. אינטגרציה עם כלי MCP
- **חיבור לכלים חיצוניים**: חיבור סוכנים לכלים חיצוניים דרך שרתי Model Context Protocol
- **פעולות בעולם האמיתי**: אפשרות לסוכנים לשאול מסדי נתונים, לגשת ל-APIs או לבצע לוגיקה מותאמת אישית
- **שרתי MCP קיימים**: שימוש בכלים מפרוטוקולי פקודה (stdio) או HTTP (אירועי שרת)
- **פיתוח MCP מותאם אישית**: בנייה והכנה של שרתי MCP חדשים עם בדיקה ב-Agent Builder

### 8. פיתוח ובדיקת סוכנים
- **תמיכה בקריאה לפונקציות**: אפשרות לסוכנים לקרוא לפונקציות חיצוניות באופן דינמי
- **בדיקות אינטגרציה בזמן אמת**: בדיקת אינטגרציות עם הרצות בזמן אמת ושימוש בכלים
- **גרסאות סוכנים**: ניהול גרסאות לסוכנים עם יכולות השוואה לתוצאות הערכה
- **איתור באגים ומעקב**: יכולות מעקב ואיתור באגים מקומיות לפיתוח סוכנים

## תהליך פיתוח AI בקצה

### שלב 1: גילוי ובחירת מודלים
1. **חקירת קטלוג מודלים**: השתמשו בקטלוג המודלים למציאת מודלים המתאימים לפריסת קצה
2. **השוואת ביצועים**: הערכת מודלים בהתבסס על גודל, דיוק ומהירות הסקה
3. **בדיקה מקומית**: השתמשו במודלים Ollama או ONNX לבדיקה מקומית לפני פריסת קצה
4. **הערכת דרישות משאבים**: קביעת צרכי זיכרון ומחשוב למכשירי קצה יעד

### שלב 2: אופטימיזציית מודלים
1. **המרה ל-ONNX**: המרת מודלים נבחרים לפורמט ONNX להתאמה לקצה
2. **יישום כימות**: הקטנת גודל מודלים באמצעות כימות INT8 או INT4
3. **אופטימיזציית חומרה**: אופטימיזציה לחומרה יעד בקצה (ARM, x86, מאיצים מיוחדים)
4. **אימות ביצועים**: אימות שמודלים מותאמים שומרים על דיוק מקובל

### שלב 3: פיתוח יישומים
1. **עיצוב סוכנים**: השתמשו ב-Agent Builder ליצירת סוכני AI מותאמים לקצה
2. **הנדסת הנחיות**: פיתוח הנחיות שעובדות ביעילות עם מודלים קטנים יותר בקצה
3. **בדיקות אינטגרציה**: בדיקת סוכנים בתנאי קצה מדומים
4. **יצירת קוד**: יצירת קוד ייצור מותאם לפריסת קצה

### שלב 4: הערכה ובדיקה
1. **הערכה בכמות גדולה**: בדיקת קונפיגורציות מרובות למציאת הגדרות קצה אופטימליות
2. **פרופיל ביצועים**: ניתוח מהירות הסקה, שימוש בזיכרון ודיוק
3. **סימולציית קצה**: בדיקה בתנאים דומים לסביבת פריסת קצה יעד
4. **בדיקות עומס**: הערכת ביצועים תחת תנאי עומס שונים

### שלב 5: הכנה לפריסה
1. **אופטימיזציה סופית**: יישום אופטימיזציות סופיות בהתבסס על תוצאות הבדיקה
2. **אריזת פריסה**: אריזת מודלים וקוד לפריסת קצה
3. **תיעוד**: תיעוד דרישות פריסה וקונפיגורציה
4. **הכנת ניטור**: הכנת ניטור ורישום לפריסת קצה

## קהל יעד לפיתוח AI בקצה

### מפתחי AI בקצה
- מפתחי יישומים הבונים מכשירי קצה ופתרונות IoT מבוססי AI
- מפתחי מערכות משובצות המשלבים יכולות AI במכשירים עם מגבלות משאבים
- מפתחי ניידים היוצרים יישומי AI על המכשיר עבור סמארטפונים וטאבלטים

### מהנדסי AI בקצה
- מהנדסי AI המייעלים מודלים לפריסת קצה ומנהלים צינורות הסקה
- מהנדסי DevOps המפרסים ומנהלים מודלים AI בתשתית קצה מבוזרת
- מהנדסי ביצועים המייעלים עומסי עבודה AI למגבלות חומרה בקצה

### חוקרים ומחנכים
- חוקרי AI המפתחים מודלים ואלגוריתמים יעילים למחשוב קצה
- מחנכים המלמדים מושגי AI בקצה ומדגימים טכניקות אופטימיזציה
- סטודנטים הלומדים על האתגרים והפתרונות בפריסת AI בקצה

## מקרי שימוש ב-AI בקצה

### מכשירי IoT חכמים
- **זיהוי תמונה בזמן אמת**: פריסת מודלים ראיית מחשב על מצלמות וחיישני IoT
- **עיבוד קול**: יישום זיהוי דיבור ועיבוד שפה טבעית על רמקולים חכמים
- **תחזוקה חזויה**: הרצת מודלים לזיהוי אנומליות על מכשירי קצה תעשייתיים
- **ניטור סביבתי**: פריסת מודלים לניתוח נתוני חיישנים ליישומים סביבתיים

### יישומים ניידים ומשובצים
- **תרגום על המכשיר**: יישום מודלים לתרגום שפה שפועלים במצב לא מקוון
- **מציאות רבודה**: פריסת זיהוי אובייקטים ומעקב בזמן אמת ליישומי AR
- **ניטור בריאות**: הרצת מודלים לניתוח בריאות על מכשירים לבישים וציוד רפואי
- **מערכות אוטונומיות**: יישום מודלים לקבלת החלטות עבור רחפנים, רובוטים וכלי רכב

### תשתית מחשוב קצה
- **מרכזי נתונים בקצה**: פריסת מודלים AI במרכזי נתונים בקצה ליישומים בעלי זמן תגובה נמוך
- **אינטגרציה עם CDN**: שילוב יכולות עיבוד AI ברשתות הפצת תוכן
- **קצה 5G**: ניצול מחשוב קצה 5G ליישומים מבוססי AI
- **מחשוב ערפל**: יישום עיבוד AI בסביבות מחשוב ערפל

## התקנה והגדרה

### התקנת ההרחבה
התקינו את ההרחבה AI Toolkit ישירות מ-Marketplace של Visual Studio Code:

**מזהה ההרחבה**: `ms-windows-ai-studio.windows-ai-studio`

**שיטות התקנה**:
1. **Marketplace של VS Code**: חפשו "AI Toolkit" בתצוגת ההרחבות
2. **שורת פקודה**: `code --install-extension ms-windows-ai-studio.windows-ai-studio`
3. **התקנה ישירה**: הורידו מ-[VS Code Marketplace](https://marketplace.visualstudio.com/items?itemName=ms-windows-ai-studio.windows-ai-studio)

### דרישות מוקדמות לפיתוח AI בקצה
- **Visual Studio Code**: מומלץ הגרסה האחרונה
- **סביבת Python**: Python 3.8+ עם ספריות AI נדרשות
- **ONNX Runtime** (אופציונלי): להסקת מודלים ONNX
- **Ollama** (אופציונלי): לשירות מודלים מקומי
- **כלי האצת חומרה**: CUDA, OpenVINO או מאיצים ספציפיים לפלטפורמה

### הגדרה ראשונית
1. **הפעלת ההרחבה**: פתחו את VS Code ואמתו שערכת הכלים AI מופיעה בסרגל הפעילות
2. **הגדרת ספקי מודלים**: הגדירו גישה ל-GitHub, OpenAI, Anthropic או ספקי מודלים אחרים
3. **סביבה מקומית**: הגדירו סביבת Python והתקינו חבילות נדרשות
4. **האצת חומרה**: הגדירו האצת GPU/NPU אם זמינה
5. **אינטגרציית MCP**: הגדירו שרתי Model Context Protocol אם נדרש

### רשימת בדיקה להגדרה ראשונית
- [ ] ההרחבה AI Toolkit מותקנת ומופעלת
- [ ] קטלוג המודלים נגיש ומודלים ניתנים לגילוי
- [ ] Playground פעיל לבדיק
2. יצירת הנחיות התחלתיות באמצעות תיאורים בשפה טבעית  
3. חזרה ושיפור הנחיות על בסיס תגובות המודל  
4. שילוב כלי MCP לשיפור יכולות הסוכן  

#### שלב 3: בדיקה והערכה  
1. השתמשו ב-**Bulk Run** לבדיקת מספר הנחיות על פני מודלים נבחרים  
2. הריצו סוכנים עם מקרי בדיקה כדי לאמת את הפונקציונליות  
3. העריכו דיוק וביצועים באמצעות מדדים מובנים או מותאמים אישית  
4. השוו בין מודלים וקונפיגורציות שונות  

#### שלב 4: כוונון ואופטימיזציה  
1. התאימו מודלים למקרי שימוש ייחודיים  
2. בצעו כוונון ספציפי לתחום  
3. בצעו אופטימיזציה למגבלות פריסה בקצה  
4. גרסו והשוו בין קונפיגורציות סוכנים שונות  

#### שלב 5: הכנה לפריסה  
1. צרו קוד מוכן לייצור באמצעות Agent Builder  
2. הגדירו חיבורי שרת MCP לשימוש בייצור  
3. הכינו חבילות פריסה למכשירי קצה  
4. הגדירו מדדי ניטור והערכה  

## דוגמאות לערכת הכלים של AI  

נסו את הדוגמאות שלנו  
הדוגמאות של [ערכת הכלים של AI](https://github.com/Azure-Samples/AI_Toolkit_Samples) נועדו לעזור למפתחים וחוקרים לחקור וליישם פתרונות AI בצורה יעילה.  

הדוגמאות שלנו כוללות:  

קוד לדוגמה: דוגמאות מוכנות מראש להדגמת פונקציונליות AI, כמו אימון, פריסה או שילוב מודלים באפליקציות.  
תיעוד: מדריכים והדרכות שיעזרו למשתמשים להבין את תכונות ערכת הכלים של AI וכיצד להשתמש בהן.  
דרישות מקדימות  

- Visual Studio Code  
- ערכת הכלים של AI ל-Visual Studio Code  
- אסימון גישה אישי מדויק (PAT) של GitHub  
- Foundry Local  

## שיטות עבודה מומלצות לפיתוח AI בקצה  

### בחירת מודל  
- **מגבלות גודל**: בחרו מודלים שמתאימים למגבלות הזיכרון של מכשירי היעד  
- **מהירות הסקה**: תעדפו מודלים עם זמני הסקה מהירים ליישומים בזמן אמת  
- **פשרות דיוק**: איזנו בין דיוק המודל למגבלות משאבים  
- **תאימות פורמט**: העדיפו פורמטים כמו ONNX או פורמטים מותאמים לחומרה לפריסה בקצה  

### טכניקות אופטימיזציה  
- **כימות**: השתמשו בכימות INT8 או INT4 כדי להקטין את גודל המודל ולשפר את המהירות  
- **גיזום**: הסירו פרמטרים מיותרים במודל כדי להפחית את דרישות החישוב  
- **דיסטילציה של ידע**: צרו מודלים קטנים יותר ששומרים על ביצועי מודלים גדולים  
- **האצת חומרה**: השתמשו ב-NPU, GPU או מאיצים מיוחדים כאשר הם זמינים  

### זרימת עבודה בפיתוח  
- **בדיקות חוזרות**: בדקו בתנאים דמויי קצה לעיתים קרובות במהלך הפיתוח  
- **ניטור ביצועים**: עקבו באופן רציף אחר שימוש במשאבים ומהירות הסקה  
- **שליטה בגרסאות**: עקבו אחר גרסאות מודלים והגדרות אופטימיזציה  
- **תיעוד**: תעדו את כל החלטות האופטימיזציה והפשרות בביצועים  

### שיקולי פריסה  
- **ניטור משאבים**: עקבו אחר זיכרון, מעבד ושימוש באנרגיה בייצור  
- **אסטרטגיות גיבוי**: יישמו מנגנוני גיבוי לכשלים במודל  
- **מנגנוני עדכון**: תכננו עדכוני מודלים וניהול גרסאות  
- **אבטחה**: יישמו אמצעי אבטחה מתאימים ליישומי AI בקצה  

## שילוב עם מסגרות AI בקצה  

### ONNX Runtime  
- **פריסה חוצת פלטפורמות**: פרסו מודלים של ONNX על פני פלטפורמות קצה שונות  
- **אופטימיזציה לחומרה**: השתמשו באופטימיזציות ספציפיות לחומרה של ONNX Runtime  
- **תמיכה בניידים**: השתמשו ב-ONNX Runtime Mobile לאפליקציות סמארטפון וטאבלט  
- **שילוב IoT**: פרסו על מכשירי IoT באמצעות הפצות קלות של ONNX Runtime  

### Windows ML  
- **מכשירי Windows**: בצעו אופטימיזציה למכשירי קצה מבוססי Windows ומחשבים אישיים  
- **האצת NPU**: השתמשו ביחידות עיבוד עצבי במכשירי Windows  
- **DirectML**: השתמשו ב-DirectML להאצת GPU בפלטפורמות Windows  
- **שילוב UWP**: שלבו עם אפליקציות פלטפורמת Windows אוניברסלית  

### TensorFlow Lite  
- **אופטימיזציה לניידים**: פרסו מודלים של TensorFlow Lite על מכשירים ניידים ומוטמעים  
- **נציגי חומרה**: השתמשו בנציגי חומרה מיוחדים להאצה  
- **מיקרו-בקרים**: פרסו על מיקרו-בקרים באמצעות TensorFlow Lite Micro  
- **תמיכה חוצת פלטפורמות**: פרסו על פני Android, iOS ומערכות Linux מוטמעות  

### Azure IoT Edge  
- **היבריד ענן-קצה**: שלבו אימון בענן עם הסקה בקצה  
- **פריסת מודולים**: פרסו מודלים של AI כמודולים של IoT Edge  
- **ניהול מכשירים**: נהל מכשירי קצה ועדכוני מודלים מרחוק  
- **טלמטריה**: אספו נתוני ביצועים ומדדי מודלים מפריסות בקצה  

## תרחישי AI מתקדמים בקצה  

### פריסת מודלים מרובים  
- **אנסמבלים של מודלים**: פרסו מספר מודלים לשיפור דיוק או יתירות  
- **בדיקות A/B**: בדקו מודלים שונים בו-זמנית על מכשירי קצה  
- **בחירה דינמית**: בחרו מודלים על בסיס תנאי המכשיר הנוכחיים  
- **שיתוף משאבים**: בצעו אופטימיזציה לשימוש במשאבים על פני מודלים פרוסים מרובים  

### למידה מבוזרת  
- **אימון מבוזר**: אימנו מודלים על פני מכשירי קצה מרובים  
- **שימור פרטיות**: שמרו על נתוני אימון מקומיים תוך שיתוף שיפורי מודלים  
- **למידה שיתופית**: אפשרו למכשירים ללמוד מניסיונות משותפים  
- **תיאום קצה-ענן**: תיאמו למידה בין מכשירי קצה ותשתית ענן  

### עיבוד בזמן אמת  
- **עיבוד זרמים**: עבדו זרמי נתונים רציפים על מכשירי קצה  
- **הסקה בעלת השהיה נמוכה**: בצעו אופטימיזציה למינימום השהיה בהסקה  
- **עיבוד אצוות**: עבדו אצוות נתונים בצורה יעילה על מכשירי קצה  
- **עיבוד אדפטיבי**: התאימו עיבוד על בסיס יכולות המכשיר הנוכחיות  

## פתרון בעיות בפיתוח AI בקצה  

### בעיות נפוצות  
- **מגבלות זיכרון**: המודל גדול מדי לזיכרון המכשיר היעד  
- **מהירות הסקה**: ההסקה של המודל איטית מדי לדרישות בזמן אמת  
- **ירידת דיוק**: האופטימיזציה מפחיתה את דיוק המודל בצורה בלתי מקובלת  
- **תאימות חומרה**: המודל אינו תואם לחומרה היעד  

### אסטרטגיות דיבוג  
- **פרופיל ביצועים**: השתמשו בתכונות המעקב של ערכת הכלים של AI לזיהוי צווארי בקבוק  
- **ניטור משאבים**: עקבו אחר שימוש בזיכרון ומעבד במהלך הפיתוח  
- **בדיקות הדרגתיות**: בדקו אופטימיזציות באופן הדרגתי כדי לבודד בעיות  
- **סימולציית חומרה**: השתמשו בכלי פיתוח לסימולציה של חומרה יעד  

### פתרונות אופטימיזציה  
- **כימות נוסף**: יישמו טכניקות כימות אגרסיביות יותר  
- **ארכיטקטורת מודל**: שקלו ארכיטקטורות מודלים שונות המותאמות לקצה  
- **אופטימיזציה של עיבוד מקדים**: בצעו אופטימיזציה לעיבוד נתונים מקדים למגבלות קצה  
- **אופטימיזציה של הסקה**: השתמשו באופטימיזציות הסקה ספציפיות לחומרה  

## משאבים והשלבים הבאים  

### תיעוד רשמי  
- [תיעוד מפתחים של ערכת הכלים של AI](https://aka.ms/AIToolkit/doc)  
- [מדריך התקנה והגדרה](https://code.visualstudio.com/docs/intelligentapps/overview#_install-and-setup)  
- [תיעוד אפליקציות חכמות של VS Code](https://code.visualstudio.com/docs/intelligentapps)  
- [תיעוד פרוטוקול הקשר מודל (MCP)](https://modelcontextprotocol.io/)  

### קהילה ותמיכה  
- [מאגר GitHub של ערכת הכלים של AI](https://github.com/microsoft/vscode-ai-toolkit)  
- [בעיות ובקשות תכונה ב-GitHub](https://aka.ms/AIToolkit/feedback)  
- [קהילת Discord של Azure AI Foundry](https://aka.ms/azureaifoundry/discord)  
- [שוק הרחבות של VS Code](https://marketplace.visualstudio.com/items?itemName=ms-windows-ai-studio.windows-ai-studio)  

### משאבים טכניים  
- [תיעוד ONNX Runtime](https://onnxruntime.ai/)  
- [תיעוד Ollama](https://ollama.ai/)  
- [תיעוד Windows ML](https://docs.microsoft.com/en-us/windows/ai/)  
- [תיעוד Azure AI Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/)  

### מסלולי למידה  
- [קורס יסודות AI בקצה](../Module01/README.md)  
- [מדריך מודלים שפתיים קטנים](../Module02/README.md)  
- [אסטרטגיות פריסה בקצה](../Module03/README.md)  
- [פיתוח AI בקצה עבור Windows](./windowdeveloper.md)  

### משאבים נוספים  
- **סטטיסטיקות מאגר**: 1.8k+ כוכבים, 150+ מזלגות, 18+ תורמים  
- **רישיון**: רישיון MIT  
- **אבטחה**: מדיניות האבטחה של Microsoft חלה  
- **טלמטריה**: מכבדת את הגדרות הטלמטריה של VS Code  

## סיכום  

ערכת הכלים של AI ל-Visual Studio Code מייצגת פלטפורמה מקיפה לפיתוח AI מודרני, המספקת יכולות פיתוח סוכנים יעילות במיוחד ליישומי AI בקצה. עם קטלוג מודלים נרחב התומך בספקים כמו Anthropic, OpenAI, GitHub ו-Google, בשילוב עם ביצוע מקומי באמצעות ONNX ו-Ollama, הערכה מציעה את הגמישות הנדרשת לתרחישי פריסה מגוונים בקצה.  

הכוח של הערכה טמון בגישה המשולבת שלה—מגילוי מודלים וניסויים ב-Playground ועד פיתוח סוכנים מתוחכם עם Prompt Builder, יכולות הערכה מקיפות ושילוב חלק של כלי MCP. עבור מפתחי AI בקצה, זה אומר יצירת אב טיפוס מהירה ובדיקת סוכני AI לפני פריסה בקצה, עם יכולת לחזור במהירות ולבצע אופטימיזציה לסביבות עם מגבלות משאבים.  

יתרונות מרכזיים לפיתוח AI בקצה כוללים:  
- **ניסויים מהירים**: בדיקת מודלים וסוכנים במהירות לפני התחייבות לפריסה בקצה  
- **גמישות רב-ספקית**: גישה למודלים ממקורות שונים למציאת פתרונות אופטימליים לקצה  
- **פיתוח מקומי**: בדיקה עם ONNX ו-Ollama לפיתוח לא מקוון ושמירה על פרטיות  
- **מוכנות לייצור**: יצירת קוד מוכן לייצור ושילוב עם כלים חיצוניים באמצעות MCP  
- **הערכה מקיפה**: שימוש במדדים מובנים ומותאמים אישית לאימות ביצועי AI בקצה  

ככל ש-AI ממשיך להתקדם לעבר תרחישי פריסה בקצה, ערכת הכלים של AI ל-VS Code מספקת את סביבת הפיתוח וזרימת העבודה הנדרשת לבנייה, בדיקה ואופטימיזציה של אפליקציות חכמות לסביבות עם מגבלות משאבים. בין אם אתם מפתחים פתרונות IoT, אפליקציות AI לנייד או מערכות אינטליגנציה מוטמעת, סט התכונות המקיף וזרימת העבודה המשולבת של הערכה תומכים בכל מחזור החיים של פיתוח AI בקצה.  

עם פיתוח מתמשך וקהילה פעילה (1.8k+ כוכבים ב-GitHub), ערכת הכלים של AI נשארת בחזית כלי הפיתוח של AI, ומתפתחת באופן רציף כדי לענות על צרכי מפתחי AI מודרניים הבונים לתרחישי פריסה בקצה.  

[Next Foundry Local](./foundrylocal.md)  

---

**הצהרת אחריות**:  
מסמך זה תורגם באמצעות שירות תרגום AI [Co-op Translator](https://github.com/Azure/co-op-translator). למרות שאנו שואפים לדיוק, יש לקחת בחשבון שתרגומים אוטומטיים עשויים להכיל שגיאות או אי דיוקים. המסמך המקורי בשפתו המקורית צריך להיחשב כמקור סמכותי. עבור מידע קריטי, מומלץ להשתמש בתרגום מקצועי אנושי. אנו לא נושאים באחריות לאי הבנות או פירושים שגויים הנובעים משימוש בתרגום זה.