<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "44bc28c27b993c5fb988791b7a115705",
  "translation_date": "2025-10-30T11:38:30+00:00",
  "source_file": "Module06/01.IntroduceAgent.md",
  "language_code": "hi"
}
-->
# рдПрдЖрдИ рдПрдЬреЗрдВрдЯреНрд╕ рдФрд░ рдЫреЛрдЯреЗ рднрд╛рд╖рд╛ рдореЙрдбрд▓: рдПрдХ рд╡реНрдпрд╛рдкрдХ рдорд╛рд░реНрдЧрджрд░реНрд╢рд┐рдХрд╛

## рдкрд░рд┐рдЪрдп

рдЗрд╕ рдЯреНрдпреВрдЯреЛрд░рд┐рдпрд▓ рдореЗрдВ, рд╣рдо рдПрдЖрдИ рдПрдЬреЗрдВрдЯреНрд╕ рдФрд░ рдЫреЛрдЯреЗ рднрд╛рд╖рд╛ рдореЙрдбрд▓ (SLMs) рдХреЗ рдЙрдиреНрдирдд рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди рд░рдгрдиреАрддрд┐рдпреЛрдВ рдХреЛ рдПрдЬ рдХрдВрдкреНрдпреВрдЯрд┐рдВрдЧ рд╡рд╛рддрд╛рд╡рд░рдг рдХреЗ рд▓рд┐рдП рд╕рдордЭреЗрдВрдЧреЗред рд╣рдо рдПрдЬреЗрдВрдЯрд┐рдХ рдПрдЖрдИ рдХреЗ рдореВрд▓рднреВрдд рд╕рд┐рджреНрдзрд╛рдВрддреЛрдВ, SLM рдЕрдиреБрдХреВрд▓рди рддрдХрдиреАрдХреЛрдВ, рд╕рдВрд╕рд╛рдзрди-рд╕реАрдорд┐рдд рдЙрдкрдХрд░рдгреЛрдВ рдХреЗ рд▓рд┐рдП рд╡реНрдпрд╛рд╡рд╣рд╛рд░рд┐рдХ рддреИрдирд╛рддреА рд░рдгрдиреАрддрд┐рдпреЛрдВ, рдФрд░ рдЙрддреНрдкрд╛рджрди-рддреИрдпрд╛рд░ рдПрдЬреЗрдВрдЯ рд╕рд┐рд╕реНрдЯрдо рдмрдирд╛рдиреЗ рдХреЗ рд▓рд┐рдП Microsoft Agent Framework рдХреЛ рдХрд╡рд░ рдХрд░реЗрдВрдЧреЗред

2025 рдореЗрдВ рдХреГрддреНрд░рд┐рдо рдмреБрджреНрдзрд┐рдорддреНрддрд╛ рдХрд╛ рдкрд░рд┐рджреГрд╢реНрдп рдПрдХ рдорд╣рддреНрд╡рдкреВрд░реНрдг рдмрджрд▓рд╛рд╡ рдХрд╛ рдЕрдиреБрднрд╡ рдХрд░ рд░рд╣рд╛ рд╣реИред рдЬрдмрдХрд┐ 2023 рдЪреИрдЯрдмреЙрдЯреНрд╕ рдХрд╛ рд╡рд░реНрд╖ рдерд╛ рдФрд░ 2024 рдореЗрдВ рдХреЛ-рдкрд╛рдпрд▓рдЯреНрд╕ рдХрд╛ рдЙрдЫрд╛рд▓ рджреЗрдЦрд╛ рдЧрдпрд╛, 2025 рдПрдЖрдИ рдПрдЬреЗрдВрдЯреНрд╕ рдХрд╛ рд╣реИ тАФ рдмреБрджреНрдзрд┐рдорд╛рди рд╕рд┐рд╕реНрдЯрдо рдЬреЛ рд╕реЛрдЪрддреЗ рд╣реИрдВ, рддрд░реНрдХ рдХрд░рддреЗ рд╣реИрдВ, рдпреЛрдЬрдирд╛ рдмрдирд╛рддреЗ рд╣реИрдВ, рдЙрдкрдХрд░рдгреЛрдВ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рддреЗ рд╣реИрдВ, рдФрд░ рдиреНрдпреВрдирддрдо рдорд╛рдирд╡ рдЗрдирдкреБрдЯ рдХреЗ рд╕рд╛рде рдХрд╛рд░реНрдпреЛрдВ рдХреЛ рдирд┐рд╖реНрдкрд╛рджрд┐рдд рдХрд░рддреЗ рд╣реИрдВ, рдЬреЛ рдХреБрд╢рд▓ рдЫреЛрдЯреЗ рднрд╛рд╖рд╛ рдореЙрдбрд▓ рджреНрд╡рд╛рд░рд╛ рд╕рдВрдЪрд╛рд▓рд┐рдд рд╣реЛрддреЗ рд╣реИрдВред Microsoft Agent Framework рдСрдлрд▓рд╛рдЗрди рдПрдЬ-рдЖрдзрд╛рд░рд┐рдд рдХреНрд╖рдорддрд╛рдУрдВ рдХреЗ рд╕рд╛рде рдЗрди рдмреБрджреНрдзрд┐рдорд╛рди рд╕рд┐рд╕реНрдЯрдо рдХреЛ рдмрдирд╛рдиреЗ рдХреЗ рд▓рд┐рдП рдПрдХ рдкреНрд░рдореБрдЦ рд╕рдорд╛рдзрд╛рди рдХреЗ рд░реВрдк рдореЗрдВ рдЙрднрд░рддрд╛ рд╣реИред

## рд╕реАрдЦрдиреЗ рдХреЗ рдЙрджреНрджреЗрд╢реНрдп

рдЗрд╕ рдЯреНрдпреВрдЯреЛрд░рд┐рдпрд▓ рдХреЗ рдЕрдВрдд рддрдХ, рдЖрдк:

- ЁЯдЦ рдПрдЖрдИ рдПрдЬреЗрдВрдЯреНрд╕ рдФрд░ рдПрдЬреЗрдВрдЯрд┐рдХ рд╕рд┐рд╕реНрдЯрдо рдХреЗ рдореВрд▓рднреВрдд рд╕рд┐рджреНрдзрд╛рдВрддреЛрдВ рдХреЛ рд╕рдордЭ рдкрд╛рдПрдВрдЧреЗ
- ЁЯФм рдЫреЛрдЯреЗ рднрд╛рд╖рд╛ рдореЙрдбрд▓реНрд╕ рдХреЗ рд▓рд╛рднреЛрдВ рдХреЛ рдмрдбрд╝реЗ рднрд╛рд╖рд╛ рдореЙрдбрд▓реНрд╕ рдХреА рддреБрд▓рдирд╛ рдореЗрдВ рдПрдЬреЗрдВрдЯрд┐рдХ рдЕрдиреБрдкреНрд░рдпреЛрдЧреЛрдВ рдореЗрдВ рдкрд╣рдЪрд╛рди рдкрд╛рдПрдВрдЧреЗ
- ЁЯЪА рдПрдЬ рдХрдВрдкреНрдпреВрдЯрд┐рдВрдЧ рд╡рд╛рддрд╛рд╡рд░рдг рдХреЗ рд▓рд┐рдП рдЙрдиреНрдирдд SLM рддреИрдирд╛рддреА рд░рдгрдиреАрддрд┐рдпреЛрдВ рдХреЛ рд╕реАрдЦ рдкрд╛рдПрдВрдЧреЗ
- ЁЯУ▒ рд╡рд╛рд╕реНрддрд╡рд┐рдХ рджреБрдирд┐рдпрд╛ рдХреЗ рдЕрдиреБрдкреНрд░рдпреЛрдЧреЛрдВ рдХреЗ рд▓рд┐рдП SLM-рд╕рдВрдЪрд╛рд▓рд┐рдд рдПрдЬреЗрдВрдЯреНрд╕ рдХреЛ рд▓рд╛рдЧреВ рдХрд░ рдкрд╛рдПрдВрдЧреЗ
- ЁЯПЧя╕П Microsoft Agent Framework рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рдЙрддреНрдкрд╛рджрди-рддреИрдпрд╛рд░ рдПрдЬреЗрдВрдЯреНрд╕ рдмрдирд╛ рдкрд╛рдПрдВрдЧреЗ
- ЁЯМР рд╕реНрдерд╛рдиреАрдп LLM рдФрд░ SLM рдПрдХреАрдХрд░рдг рдХреЗ рд╕рд╛рде рдСрдлрд▓рд╛рдЗрди рдПрдЬ-рдЖрдзрд╛рд░рд┐рдд рдПрдЬреЗрдВрдЯреНрд╕ рдХреЛ рддреИрдирд╛рдд рдХрд░ рдкрд╛рдПрдВрдЧреЗ
- ЁЯФз Microsoft Agent Framework рдХреЛ Foundry Local рдХреЗ рд╕рд╛рде рдПрдЬ рддреИрдирд╛рддреА рдХреЗ рд▓рд┐рдП рдПрдХреАрдХреГрдд рдХрд░ рдкрд╛рдПрдВрдЧреЗ

## рдПрдЖрдИ рдПрдЬреЗрдВрдЯреНрд╕ рдХреЛ рд╕рдордЭрдирд╛: рдиреАрдВрд╡ рдФрд░ рд╡рд░реНрдЧреАрдХрд░рдг

### рдкрд░рд┐рднрд╛рд╖рд╛ рдФрд░ рдореБрдЦреНрдп рд╕рд┐рджреНрдзрд╛рдВрдд

рдХреГрддреНрд░рд┐рдо рдмреБрджреНрдзрд┐рдорддреНрддрд╛ (AI) рдПрдЬреЗрдВрдЯ рдПрдХ рдРрд╕рд╛ рд╕рд┐рд╕реНрдЯрдо рдпрд╛ рдкреНрд░реЛрдЧреНрд░рд╛рдо рд╣реИ рдЬреЛ рдЙрдкрдпреЛрдЧрдХрд░реНрддрд╛ рдпрд╛ рдХрд┐рд╕реА рдЕрдиреНрдп рд╕рд┐рд╕реНрдЯрдо рдХреА рдУрд░ рд╕реЗ рд╕реНрд╡рд╛рдпрддреНрдд рд░реВрдк рд╕реЗ рдХрд╛рд░реНрдпреЛрдВ рдХреЛ рдХрд░рдиреЗ рдореЗрдВ рд╕рдХреНрд╖рдо рд╣реЛрддрд╛ рд╣реИ, рдЕрдкрдиреЗ рдХрд╛рд░реНрдпрдкреНрд░рд╡рд╛рд╣ рдХреЛ рдбрд┐рдЬрд╝рд╛рдЗрди рдХрд░рдХреЗ рдФрд░ рдЙрдкрд▓рдмреНрдз рдЙрдкрдХрд░рдгреЛрдВ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗред рдкрд╛рд░рдВрдкрд░рд┐рдХ рдПрдЖрдИ рдХреЗ рд╡рд┐рдкрд░реАрдд, рдЬреЛ рдХреЗрд╡рд▓ рдЖрдкрдХреЗ рд╕рд╡рд╛рд▓реЛрдВ рдХрд╛ рдЬрд╡рд╛рдм рджреЗрддрд╛ рд╣реИ, рдПрдХ рдПрдЬреЗрдВрдЯ рд╕реНрд╡рддрдВрддреНрд░ рд░реВрдк рд╕реЗ рд▓рдХреНрд╖реНрдпреЛрдВ рдХреЛ рдкреНрд░рд╛рдкреНрдд рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдХрд╛рд░реНрдп рдХрд░ рд╕рдХрддрд╛ рд╣реИред

### рдПрдЬреЗрдВрдЯ рд╡рд░реНрдЧреАрдХрд░рдг рдврд╛рдВрдЪрд╛

рдПрдЬреЗрдВрдЯ рдХреА рд╕реАрдорд╛рдУрдВ рдХреЛ рд╕рдордЭрдирд╛ рд╡рд┐рднрд┐рдиреНрди рдХрдВрдкреНрдпреВрдЯрд┐рдВрдЧ рдкрд░рд┐рджреГрд╢реНрдпреЛрдВ рдХреЗ рд▓рд┐рдП рдЙрдкрдпреБрдХреНрдд рдПрдЬреЗрдВрдЯ рдкреНрд░рдХрд╛рд░реЛрдВ рдХрд╛ рдЪрдпрди рдХрд░рдиреЗ рдореЗрдВ рдорджрдж рдХрд░рддрд╛ рд╣реИ:

- **ЁЯФм рд╕рд░рд▓ рд░рд┐рдлреНрд▓реЗрдХреНрд╕ рдПрдЬреЗрдВрдЯреНрд╕**: рдирд┐рдпрдо-рдЖрдзрд╛рд░рд┐рдд рд╕рд┐рд╕реНрдЯрдо рдЬреЛ рддрддреНрдХрд╛рд▓ рдзрд╛рд░рдгрд╛рдУрдВ рдкрд░ рдкреНрд░рддрд┐рдХреНрд░рд┐рдпрд╛ рдХрд░рддреЗ рд╣реИрдВ (рдерд░реНрдореЛрд╕реНрдЯреЗрдЯреНрд╕, рдмреБрдирд┐рдпрд╛рджреА рд╕реНрд╡рдЪрд╛рд▓рди)
- **ЁЯУ▒ рдореЙрдбрд▓-рдЖрдзрд╛рд░рд┐рдд рдПрдЬреЗрдВрдЯреНрд╕**: рд╕рд┐рд╕реНрдЯрдо рдЬреЛ рдЖрдВрддрд░рд┐рдХ рд╕реНрдерд┐рддрд┐ рдФрд░ рдореЗрдореЛрд░реА рдмрдирд╛рдП рд░рдЦрддреЗ рд╣реИрдВ (рд░реЛрдмреЛрдЯ рд╡реИрдХреНрдпреВрдо, рдиреЗрд╡рд┐рдЧреЗрд╢рди рд╕рд┐рд╕реНрдЯрдо)
- **тЪЦя╕П рд▓рдХреНрд╖реНрдп-рдЖрдзрд╛рд░рд┐рдд рдПрдЬреЗрдВрдЯреНрд╕**: рд╕рд┐рд╕реНрдЯрдо рдЬреЛ рдЙрджреНрджреЗрд╢реНрдпреЛрдВ рдХреЛ рдкреНрд░рд╛рдкреНрдд рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдЕрдиреБрдХреНрд░рдореЛрдВ рдХреА рдпреЛрдЬрдирд╛ рдмрдирд╛рддреЗ рд╣реИрдВ рдФрд░ рдирд┐рд╖реНрдкрд╛рджрд┐рдд рдХрд░рддреЗ рд╣реИрдВ (рд░реВрдЯ рдкреНрд▓рд╛рдирд░реНрд╕, рдЯрд╛рд╕реНрдХ рд╢реЗрдбреНрдпреВрд▓рд░реНрд╕)
- **ЁЯза рд╕реАрдЦрдиреЗ рд╡рд╛рд▓реЗ рдПрдЬреЗрдВрдЯреНрд╕**: рдЕрдиреБрдХреВрд▓рдирд╢реАрд▓ рд╕рд┐рд╕реНрдЯрдо рдЬреЛ рд╕рдордп рдХреЗ рд╕рд╛рде рдкреНрд░рджрд░реНрд╢рди рдореЗрдВ рд╕реБрдзрд╛рд░ рдХрд░рддреЗ рд╣реИрдВ (рд╕рд┐рдлрд╛рд░рд┐рд╢ рдкреНрд░рдгрд╛рд▓реА, рд╡реНрдпрдХреНрддрд┐рдЧрдд рд╕рд╣рд╛рдпрдХ)

### рдПрдЖрдИ рдПрдЬреЗрдВрдЯреНрд╕ рдХреЗ рдореБрдЦреНрдп рд▓рд╛рдн

рдПрдЖрдИ рдПрдЬреЗрдВрдЯреНрд╕ рдХрдИ рдореМрд▓рд┐рдХ рд▓рд╛рдн рдкреНрд░рджрд╛рди рдХрд░рддреЗ рд╣реИрдВ рдЬреЛ рдЙрдиреНрд╣реЗрдВ рдПрдЬ рдХрдВрдкреНрдпреВрдЯрд┐рдВрдЧ рдЕрдиреБрдкреНрд░рдпреЛрдЧреЛрдВ рдХреЗ рд▓рд┐рдП рдЖрджрд░реНрд╢ рдмрдирд╛рддреЗ рд╣реИрдВ:

**рдСрдкрд░реЗрд╢рдирд▓ рд╕реНрд╡рд╛рдпрддреНрддрддрд╛**: рдПрдЬреЗрдВрдЯреНрд╕ рд╡рд╛рд╕реНрддрд╡рд┐рдХ рд╕рдордп рдЕрдиреБрдкреНрд░рдпреЛрдЧреЛрдВ рдХреЗ рд▓рд┐рдП рдиреНрдпреВрдирддрдо рдорд╛рдирд╡ рдирд┐рдЧрд░рд╛рдиреА рдХреЗ рд╕рд╛рде рд╕реНрд╡рддрдВрддреНрд░ рдХрд╛рд░реНрдп рдирд┐рд╖реНрдкрд╛рджрди рдкреНрд░рджрд╛рди рдХрд░рддреЗ рд╣реИрдВред рд╡реЗ рдЕрдиреБрдХреВрд▓рдирд╢реАрд▓ рд╡реНрдпрд╡рд╣рд╛рд░ рдмрдирд╛рдП рд░рдЦрддреЗ рд╣реБрдП рд╕рдВрд╕рд╛рдзрди-рд╕реАрдорд┐рдд рдЙрдкрдХрд░рдгреЛрдВ рдкрд░ рддреИрдирд╛рддреА рдХреЗ рд▓рд┐рдП рдЙрдкрдпреБрдХреНрдд рд╣реИрдВред

**рддреИрдирд╛рддреА рд▓рдЪреАрд▓рд╛рдкрди**: рдпреЗ рд╕рд┐рд╕реНрдЯрдо рдСрди-рдбрд┐рд╡рд╛рдЗрд╕ рдПрдЖрдИ рдХреНрд╖рдорддрд╛рдУрдВ рдХреЛ рдЗрдВрдЯрд░рдиреЗрдЯ рдХрдиреЗрдХреНрдЯрд┐рд╡рд┐рдЯреА рдЖрд╡рд╢реНрдпрдХрддрд╛рдУрдВ рдХреЗ рдмрд┐рдирд╛ рд╕рдХреНрд╖рдо рдХрд░рддреЗ рд╣реИрдВ, рд╕реНрдерд╛рдиреАрдп рдкреНрд░рд╕рдВрд╕реНрдХрд░рдг рдХреЗ рдорд╛рдзреНрдпрдо рд╕реЗ рдЧреЛрдкрдиреАрдпрддрд╛ рдФрд░ рд╕реБрд░рдХреНрд╖рд╛ рдХреЛ рдмрдврд╝рд╛рддреЗ рд╣реИрдВ, рдбреЛрдореЗрди-рд╡рд┐рд╢рд┐рд╖реНрдЯ рдЕрдиреБрдкреНрд░рдпреЛрдЧреЛрдВ рдХреЗ рд▓рд┐рдП рдЕрдиреБрдХреВрд▓рд┐рдд рдХрд┐рдП рдЬрд╛ рд╕рдХрддреЗ рд╣реИрдВ, рдФрд░ рд╡рд┐рднрд┐рдиреНрди рдПрдЬ рдХрдВрдкреНрдпреВрдЯрд┐рдВрдЧ рд╡рд╛рддрд╛рд╡рд░рдгреЛрдВ рдХреЗ рд▓рд┐рдП рдЙрдкрдпреБрдХреНрдд рд╣реИрдВред

**рд▓рд╛рдЧрдд рдкреНрд░рднрд╛рд╡рд╢реАрд▓рддрд╛**: рдПрдЬреЗрдВрдЯ рд╕рд┐рд╕реНрдЯрдо рдХреНрд▓рд╛рдЙрдб-рдЖрдзрд╛рд░рд┐рдд рд╕рдорд╛рдзрд╛рдиреЛрдВ рдХреА рддреБрд▓рдирд╛ рдореЗрдВ рд▓рд╛рдЧрдд рдкреНрд░рднрд╛рд╡реА рддреИрдирд╛рддреА рдкреНрд░рджрд╛рди рдХрд░рддреЗ рд╣реИрдВ, рдПрдЬ рдЕрдиреБрдкреНрд░рдпреЛрдЧреЛрдВ рдХреЗ рд▓рд┐рдП рдкрд░рд┐рдЪрд╛рд▓рди рд▓рд╛рдЧрдд рдФрд░ рдмреИрдВрдбрд╡рд┐рдбреНрде рдЖрд╡рд╢реНрдпрдХрддрд╛рдУрдВ рдХреЛ рдХрдо рдХрд░рддреЗ рд╣реИрдВред

## рдЙрдиреНрдирдд рдЫреЛрдЯреЗ рднрд╛рд╖рд╛ рдореЙрдбрд▓ рд░рдгрдиреАрддрд┐рдпрд╛рдБ

### SLM (рдЫреЛрдЯреЗ рднрд╛рд╖рд╛ рдореЙрдбрд▓) рдХреА рдореВрд▓ рдмрд╛рддреЗрдВ

рдПрдХ рдЫреЛрдЯрд╛ рднрд╛рд╖рд╛ рдореЙрдбрд▓ (SLM) рдПрдХ рднрд╛рд╖рд╛ рдореЙрдбрд▓ рд╣реИ рдЬреЛ рдПрдХ рд╕рд╛рдорд╛рдиреНрдп рдЙрдкрднреЛрдХреНрддрд╛ рдЗрд▓реЗрдХреНрдЯреНрд░реЙрдирд┐рдХ рдбрд┐рд╡рд╛рдЗрд╕ рдкрд░ рдлрд┐рдЯ рд╣реЛ рд╕рдХрддрд╛ рд╣реИ рдФрд░ рдПрдХ рдЙрдкрдпреЛрдЧрдХрд░реНрддрд╛ рдХреА рдПрдЬреЗрдВрдЯрд┐рдХ рдЕрдиреБрд░реЛрдзреЛрдВ рдХреА рд╕реЗрд╡рд╛ рдХрд░рддреЗ рд╕рдордп рд╡реНрдпрд╛рд╡рд╣рд╛рд░рд┐рдХ рд░реВрдк рд╕реЗ рдХрдо рд╡рд┐рд▓рдВрдмрддрд╛ рдХреЗ рд╕рд╛рде рдЕрдиреБрдорд╛рди рд▓рдЧрд╛ рд╕рдХрддрд╛ рд╣реИред рд╡реНрдпрд╛рд╡рд╣рд╛рд░рд┐рдХ рд░реВрдк рд╕реЗ, SLMs рдЖрдорддреМрд░ рдкрд░ 10 рдмрд┐рд▓рд┐рдпрди рд╕реЗ рдХрдо рдкреИрд░рд╛рдореАрдЯрд░ рд╡рд╛рд▓реЗ рдореЙрдбрд▓ рд╣реЛрддреЗ рд╣реИрдВред

**рдлреЙрд░реНрдореЗрдЯ рдбрд┐рд╕реНрдХрд╡рд░реА рдлреАрдЪрд░реНрд╕**: SLMs рд╡рд┐рднрд┐рдиреНрди рдХреНрд╡рд╛рдВрдЯрд╛рдЗрдЬреЗрд╢рди рд╕реНрддрд░реЛрдВ, рдХреНрд░реЙрд╕-рдкреНрд▓реЗрдЯрдлреЙрд░реНрдо рд╕рдВрдЧрддрддрд╛, рд╡рд╛рд╕реНрддрд╡рд┐рдХ рд╕рдордп рдкреНрд░рджрд░реНрд╢рди рдЕрдиреБрдХреВрд▓рди, рдФрд░ рдПрдЬ рддреИрдирд╛рддреА рдХреНрд╖рдорддрд╛рдУрдВ рдХреЗ рд▓рд┐рдП рдЙрдиреНрдирдд рд╕рдорд░реНрдерди рдкреНрд░рджрд╛рди рдХрд░рддреЗ рд╣реИрдВред рдЙрдкрдпреЛрдЧрдХрд░реНрддрд╛ рд╕реНрдерд╛рдиреАрдп рдкреНрд░рд╕рдВрд╕реНрдХрд░рдг рдФрд░ рдмреНрд░рд╛рдЙрдЬрд╝рд░-рдЖрдзрд╛рд░рд┐рдд рддреИрдирд╛рддреА рдХреЗ рд▓рд┐рдП WebGPU рд╕рдорд░реНрдерди рдХреЗ рдорд╛рдзреНрдпрдо рд╕реЗ рдЙрдиреНрдирдд рдЧреЛрдкрдиреАрдпрддрд╛ рддрдХ рдкрд╣реБрдБрдЪ рд╕рдХрддреЗ рд╣реИрдВред

**рдХреНрд╡рд╛рдВрдЯрд╛рдЗрдЬреЗрд╢рди рд╕реНрддрд░ рд╕рдВрдЧреНрд░рд╣**: рд▓реЛрдХрдкреНрд░рд┐рдп SLM рдлреЙрд░реНрдореЗрдЯреНрд╕ рдореЗрдВ рдореЛрдмрд╛рдЗрд▓ рдЕрдиреБрдкреНрд░рдпреЛрдЧреЛрдВ рдореЗрдВ рд╕рдВрддреБрд▓рд┐рдд рд╕рдВрдкреАрдбрд╝рди рдХреЗ рд▓рд┐рдП Q4_K_M, рдЧреБрдгрд╡рддреНрддрд╛-рдХреЗрдВрджреНрд░рд┐рдд рдПрдЬ рддреИрдирд╛рддреА рдХреЗ рд▓рд┐рдП Q5_K_S рд╢реНрд░реГрдВрдЦрд▓рд╛, рд╢рдХреНрддрд┐рд╢рд╛рд▓реА рдПрдЬ рдЙрдкрдХрд░рдгреЛрдВ рдкрд░ рд▓рдЧрднрдЧ-рдореВрд▓ рд╕рдЯреАрдХрддрд╛ рдХреЗ рд▓рд┐рдП Q8_0, рдФрд░ рдЕрд▓реНрдЯреНрд░рд╛-рд▓реЛ рд╕рдВрд╕рд╛рдзрди рдкрд░рд┐рджреГрд╢реНрдпреЛрдВ рдХреЗ рд▓рд┐рдП Q2_K рдЬреИрд╕реЗ рдкреНрд░рдпреЛрдЧрд╛рддреНрдордХ рдлреЙрд░реНрдореЗрдЯреНрд╕ рд╢рд╛рдорд┐рд▓ рд╣реИрдВред

### GGUF (рдЬрдирд░рд▓ GGML рдпреВрдирд┐рд╡рд░реНрд╕рд▓ рдлреЙрд░реНрдореЗрдЯ) SLM рддреИрдирд╛рддреА рдХреЗ рд▓рд┐рдП

GGUF CPU рдФрд░ рдПрдЬ рдЙрдкрдХрд░рдгреЛрдВ рдкрд░ рдХреНрд╡рд╛рдВрдЯрд╛рдЗрдЬреНрдб SLMs рдХреЛ рддреИрдирд╛рдд рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдкреНрд░рд╛рдердорд┐рдХ рдлреЙрд░реНрдореЗрдЯ рдХреЗ рд░реВрдк рдореЗрдВ рдХрд╛рд░реНрдп рдХрд░рддрд╛ рд╣реИ, рд╡рд┐рд╢реЗрд╖ рд░реВрдк рд╕реЗ рдПрдЬреЗрдВрдЯрд┐рдХ рдЕрдиреБрдкреНрд░рдпреЛрдЧреЛрдВ рдХреЗ рд▓рд┐рдП рдЕрдиреБрдХреВрд▓рд┐рдд:

**рдПрдЬреЗрдВрдЯ-рдСрдкреНрдЯрд┐рдорд╛рдЗрдЬрд╝реНрдб рдлреАрдЪрд░реНрд╕**: рдлреЙрд░реНрдореЗрдЯ SLM рд░реВрдкрд╛рдВрддрд░рдг рдФрд░ рддреИрдирд╛рддреА рдХреЗ рд▓рд┐рдП рд╡реНрдпрд╛рдкрдХ рд╕рдВрд╕рд╛рдзрди рдкреНрд░рджрд╛рди рдХрд░рддрд╛ рд╣реИ, рдЙрдкрдХрд░рдг рдХреЙрд▓рд┐рдВрдЧ, рд╕рдВрд░рдЪрд┐рдд рдЖрдЙрдЯрдкреБрдЯ рдЬрдирд░реЗрд╢рди, рдФрд░ рдорд▓реНрдЯреА-рдЯрд░реНрди рд╡рд╛рд░реНрддрд╛рд▓рд╛рдкреЛрдВ рдХреЗ рд▓рд┐рдП рдЙрдиреНрдирдд рд╕рдорд░реНрдерди рдХреЗ рд╕рд╛рдеред рдХреНрд░реЙрд╕-рдкреНрд▓реЗрдЯрдлреЙрд░реНрдо рд╕рдВрдЧрддрддрд╛ рд╡рд┐рднрд┐рдиреНрди рдПрдЬ рдЙрдкрдХрд░рдгреЛрдВ рдкрд░ рд╕реБрд╕рдВрдЧрдд рдПрдЬреЗрдВрдЯ рд╡реНрдпрд╡рд╣рд╛рд░ рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдХрд░рддреА рд╣реИред

**рдкреНрд░рджрд░реНрд╢рди рдЕрдиреБрдХреВрд▓рди**: GGUF рдПрдЬреЗрдВрдЯ рд╡рд░реНрдХрдлрд╝реНрд▓реЛ рдХреЗ рд▓рд┐рдП рдХреБрд╢рд▓ рдореЗрдореЛрд░реА рдЙрдкрдпреЛрдЧ рд╕рдХреНрд╖рдо рдХрд░рддрд╛ рд╣реИ, рдорд▓реНрдЯреА-рдПрдЬреЗрдВрдЯ рд╕рд┐рд╕реНрдЯрдо рдХреЗ рд▓рд┐рдП рдЧрддрд┐рд╢реАрд▓ рдореЙрдбрд▓ рд▓реЛрдбрд┐рдВрдЧ рдХрд╛ рд╕рдорд░реНрдерди рдХрд░рддрд╛ рд╣реИ, рдФрд░ рд╡рд╛рд╕реНрддрд╡рд┐рдХ рд╕рдордп рдПрдЬреЗрдВрдЯ рдЗрдВрдЯрд░реИрдХреНрд╢рди рдХреЗ рд▓рд┐рдП рдЕрдиреБрдХреВрд▓рд┐рдд рдЕрдиреБрдорд╛рди рдкреНрд░рджрд╛рди рдХрд░рддрд╛ рд╣реИред

### рдПрдЬ-рдСрдкреНрдЯрд┐рдорд╛рдЗрдЬрд╝реНрдб SLM рдлреНрд░реЗрдорд╡рд░реНрдХреНрд╕

#### Llama.cpp рдПрдЬреЗрдВрдЯреНрд╕ рдХреЗ рд▓рд┐рдП рдЕрдиреБрдХреВрд▓рди

Llama.cpp рдПрдЬреЗрдВрдЯрд┐рдХ SLM рддреИрдирд╛рддреА рдХреЗ рд▓рд┐рдП рд╡рд┐рд╢реЗрд╖ рд░реВрдк рд╕реЗ рдЕрдиреБрдХреВрд▓рд┐рдд рдХреНрд╡рд╛рдВрдЯрд╛рдЗрдЬреЗрд╢рди рддрдХрдиреАрдХреЛрдВ рдкреНрд░рджрд╛рди рдХрд░рддрд╛ рд╣реИ:

**рдПрдЬреЗрдВрдЯ-рд╡рд┐рд╢рд┐рд╖реНрдЯ рдХреНрд╡рд╛рдВрдЯрд╛рдЗрдЬреЗрд╢рди**: рдлреНрд░реЗрдорд╡рд░реНрдХ Q4_0 (рдореЛрдмрд╛рдЗрд▓ рдПрдЬреЗрдВрдЯ рддреИрдирд╛рддреА рдХреЗ рд▓рд┐рдП 75% рдЖрдХрд╛рд░ рдореЗрдВ рдХрдореА рдХреЗ рд╕рд╛рде рдЗрд╖реНрдЯрддрдо), Q5_1 (рдПрдЬ рдЕрдиреБрдорд╛рди рдПрдЬреЗрдВрдЯреНрд╕ рдХреЗ рд▓рд┐рдП рдЧреБрдгрд╡рддреНрддрд╛-рд╕рдВрдкреАрдбрд╝рди рд╕рдВрддреБрд▓рди), рдФрд░ Q8_0 (рдЙрддреНрдкрд╛рджрди рдПрдЬреЗрдВрдЯ рд╕рд┐рд╕реНрдЯрдо рдХреЗ рд▓рд┐рдП рд▓рдЧрднрдЧ-рдореВрд▓ рдЧреБрдгрд╡рддреНрддрд╛) рдХрд╛ рд╕рдорд░реНрдерди рдХрд░рддрд╛ рд╣реИред рдЙрдиреНрдирдд рдлреЙрд░реНрдореЗрдЯреНрд╕ рдЪрд░рдо рдПрдЬ рдкрд░рд┐рджреГрд╢реНрдпреЛрдВ рдХреЗ рд▓рд┐рдП рдЕрд▓реНрдЯреНрд░рд╛-рдХрдВрдкреНрд░реЗрд╕реНрдб рдПрдЬреЗрдВрдЯреНрд╕ рд╕рдХреНрд╖рдо рдХрд░рддреЗ рд╣реИрдВред

**рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди рд▓рд╛рдн**: SIMD рддреНрд╡рд░рдг рдХреЗ рд╕рд╛рде CPU-рдСрдкреНрдЯрд┐рдорд╛рдЗрдЬрд╝реНрдб рдЕрдиреБрдорд╛рди рдореЗрдореЛрд░реА-рдХреБрд╢рд▓ рдПрдЬреЗрдВрдЯ рдирд┐рд╖реНрдкрд╛рджрди рдкреНрд░рджрд╛рди рдХрд░рддрд╛ рд╣реИред x86, ARM, рдФрд░ Apple Silicon рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░ рдореЗрдВ рдХреНрд░реЙрд╕-рдкреНрд▓реЗрдЯрдлреЙрд░реНрдо рд╕рдВрдЧрддрддрд╛ рд╕рд╛рд░реНрд╡рднреМрдорд┐рдХ рдПрдЬреЗрдВрдЯ рддреИрдирд╛рддреА рдХреНрд╖рдорддрд╛рдУрдВ рдХреЛ рд╕рдХреНрд╖рдо рдХрд░рддреА рд╣реИред

#### Apple MLX рдлреНрд░реЗрдорд╡рд░реНрдХ SLM рдПрдЬреЗрдВрдЯреНрд╕ рдХреЗ рд▓рд┐рдП

Apple MLX Apple Silicon рдЙрдкрдХрд░рдгреЛрдВ рдкрд░ SLM-рд╕рдВрдЪрд╛рд▓рд┐рдд рдПрдЬреЗрдВрдЯреНрд╕ рдХреЗ рд▓рд┐рдП рд╡рд┐рд╢реЗрд╖ рд░реВрдк рд╕реЗ рдбрд┐рдЬрд╝рд╛рдЗрди рдХрд┐рдпрд╛ рдЧрдпрд╛ рджреЗрд╢реА рдЕрдиреБрдХреВрд▓рди рдкреНрд░рджрд╛рди рдХрд░рддрд╛ рд╣реИ:

**Apple Silicon рдПрдЬреЗрдВрдЯ рдЕрдиреБрдХреВрд▓рди**: рдлреНрд░реЗрдорд╡рд░реНрдХ рдПрдХреАрдХреГрдд рдореЗрдореЛрд░реА рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рддрд╛ рд╣реИ рдЬрд┐рд╕рдореЗрдВ рдореЗрдЯрд▓ рдкреНрд░рджрд░реНрд╢рди рд╢реЗрдбрд░реНрд╕ рдПрдХреАрдХрд░рдг, рдПрдЬреЗрдВрдЯ рдЕрдиреБрдорд╛рди рдХреЗ рд▓рд┐рдП рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рдорд┐рд╢реНрд░рд┐рдд рд╕рдЯреАрдХрддрд╛, рдФрд░ рдорд▓реНрдЯреА-рдПрдЬреЗрдВрдЯ рд╕рд┐рд╕реНрдЯрдо рдХреЗ рд▓рд┐рдП рдЕрдиреБрдХреВрд▓рд┐рдд рдореЗрдореЛрд░реА рдмреИрдВрдбрд╡рд┐рдбреНрде рд╢рд╛рдорд┐рд▓ рд╣реИред M-рд╕реАрд░реАрдЬ рдЪрд┐рдкреНрд╕ рдкрд░ SLM рдПрдЬреЗрдВрдЯреНрд╕ рдЕрд╕рд╛рдзрд╛рд░рдг рдкреНрд░рджрд░реНрд╢рди рджрд┐рдЦрд╛рддреЗ рд╣реИрдВред

**рд╡рд┐рдХрд╛рд╕ рд╕реБрд╡рд┐рдзрд╛рдПрдБ**: рдПрдЬреЗрдВрдЯ-рд╡рд┐рд╢рд┐рд╖реНрдЯ рдЕрдиреБрдХреВрд▓рди рдХреЗ рд╕рд╛рде Python рдФрд░ Swift API рд╕рдорд░реНрдерди, рдПрдЬреЗрдВрдЯ рд╕реАрдЦрдиреЗ рдХреЗ рд▓рд┐рдП рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рднрд┐рдиреНрдирддрд╛, рдФрд░ Apple рд╡рд┐рдХрд╛рд╕ рдЙрдкрдХрд░рдгреЛрдВ рдХреЗ рд╕рд╛рде рд╕рд╣рдЬ рдПрдХреАрдХрд░рдг рд╡реНрдпрд╛рдкрдХ рдПрдЬреЗрдВрдЯ рд╡рд┐рдХрд╛рд╕ рд╡рд╛рддрд╛рд╡рд░рдг рдкреНрд░рджрд╛рди рдХрд░рддреЗ рд╣реИрдВред

#### ONNX Runtime рдХреНрд░реЙрд╕-рдкреНрд▓реЗрдЯрдлреЙрд░реНрдо SLM рдПрдЬреЗрдВрдЯреНрд╕ рдХреЗ рд▓рд┐рдП

ONNX Runtime рдПрдХ рд╕рд╛рд░реНрд╡рднреМрдорд┐рдХ рдЕрдиреБрдорд╛рди рдЗрдВрдЬрди рдкреНрд░рджрд╛рди рдХрд░рддрд╛ рд╣реИ рдЬреЛ SLM рдПрдЬреЗрдВрдЯреНрд╕ рдХреЛ рд╡рд┐рднрд┐рдиреНрди рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рдкреНрд▓реЗрдЯрдлреЙрд░реНрдо рдФрд░ рдСрдкрд░реЗрдЯрд┐рдВрдЧ рд╕рд┐рд╕реНрдЯрдо рдореЗрдВ рд╕реБрд╕рдВрдЧрдд рд░реВрдк рд╕реЗ рдЪрд▓рд╛рдиреЗ рдореЗрдВ рд╕рдХреНрд╖рдо рдмрдирд╛рддрд╛ рд╣реИ:

**рд╕рд╛рд░реНрд╡рднреМрдорд┐рдХ рддреИрдирд╛рддреА**: ONNX Runtime Windows, Linux, macOS, iOS, рдФрд░ Android рдкреНрд▓реЗрдЯрдлреЙрд░реНрдо рдореЗрдВ рд╕реБрд╕рдВрдЧрдд SLM рдПрдЬреЗрдВрдЯ рд╡реНрдпрд╡рд╣рд╛рд░ рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдХрд░рддрд╛ рд╣реИред рдпрд╣ рдХреНрд░реЙрд╕-рдкреНрд▓реЗрдЯрдлреЙрд░реНрдо рд╕рдВрдЧрддрддрд╛ рдбреЗрд╡рд▓рдкрд░реНрд╕ рдХреЛ рдПрдХ рдмрд╛рд░ рд▓рд┐рдЦрдиреЗ рдФрд░ рд╣рд░ рдЬрдЧрд╣ рддреИрдирд╛рдд рдХрд░рдиреЗ рдореЗрдВ рд╕рдХреНрд╖рдо рдмрдирд╛рддреА рд╣реИ, рдЬрд┐рд╕рд╕реЗ рдмрд╣реБ-рдкреНрд▓реЗрдЯрдлреЙрд░реНрдо рдЕрдиреБрдкреНрд░рдпреЛрдЧреЛрдВ рдХреЗ рд▓рд┐рдП рд╡рд┐рдХрд╛рд╕ рдФрд░ рд░рдЦрд░рдЦрд╛рд╡ рдХрд╛ рдУрд╡рд░рд╣реЗрдб рдХрд╛рдлреА рдХрдо рд╣реЛ рдЬрд╛рддрд╛ рд╣реИред

**рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рддреНрд╡рд░рдг рд╡рд┐рдХрд▓реНрдк**: рдлреНрд░реЗрдорд╡рд░реНрдХ рд╡рд┐рднрд┐рдиреНрди рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рдХреЙрдиреНрдлрд╝рд┐рдЧрд░реЗрд╢рди рдХреЗ рд▓рд┐рдП рдЕрдиреБрдХреВрд▓рд┐рдд рдирд┐рд╖реНрдкрд╛рджрди рдкреНрд░рджрд╛рддрд╛ рдкреНрд░рджрд╛рди рдХрд░рддрд╛ рд╣реИ, рдЬрд┐рд╕рдореЗрдВ CPU (Intel, AMD, ARM), GPU (NVIDIA CUDA, AMD ROCm), рдФрд░ рд╡рд┐рд╢реЗрд╖ рдПрдХреНрд╕реЗрд▓реЗрд░реЗрдЯрд░ (Intel VPU, Qualcomm NPU) рд╢рд╛рдорд┐рд▓ рд╣реИрдВред SLM рдПрдЬреЗрдВрдЯреНрд╕ рдХреЛ рдХреЛрдб рдкрд░рд┐рд╡рд░реНрддрдиреЛрдВ рдХреЗ рдмрд┐рдирд╛ рдЙрдкрд▓рдмреНрдз рд╕рд░реНрд╡реЛрддреНрддрдо рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рдХрд╛ рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рд░реВрдк рд╕реЗ рд▓рд╛рдн рдЙрдард╛рдиреЗ рдореЗрдВ рд╕рдХреНрд╖рдо рдХрд┐рдпрд╛ рдЬрд╛ рд╕рдХрддрд╛ рд╣реИред

**рдЙрддреНрдкрд╛рджрди-рддреИрдпрд╛рд░ рд╕реБрд╡рд┐рдзрд╛рдПрдБ**: ONNX Runtime рдЙрддреНрдкрд╛рджрди рдПрдЬреЗрдВрдЯ рддреИрдирд╛рддреА рдХреЗ рд▓рд┐рдП рдЖрд╡рд╢реНрдпрдХ рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЬрд╝-рдЧреНрд░реЗрдб рд╕реБрд╡рд┐рдзрд╛рдПрдБ рдкреНрд░рджрд╛рди рдХрд░рддрд╛ рд╣реИ, рдЬрд┐рд╕рдореЗрдВ рддреЗрдЬрд╝ рдЕрдиреБрдорд╛рди рдХреЗ рд▓рд┐рдП рдЧреНрд░рд╛рдл рдЕрдиреБрдХреВрд▓рди, рд╕рдВрд╕рд╛рдзрди-рд╕реАрдорд┐рдд рд╡рд╛рддрд╛рд╡рд░рдг рдХреЗ рд▓рд┐рдП рдореЗрдореЛрд░реА рдкреНрд░рдмрдВрдзрди, рдФрд░ рдкреНрд░рджрд░реНрд╢рди рд╡рд┐рд╢реНрд▓реЗрд╖рдг рдХреЗ рд▓рд┐рдП рд╡реНрдпрд╛рдкрдХ рдкреНрд░реЛрдлрд╛рдЗрд▓рд┐рдВрдЧ рдЙрдкрдХрд░рдг рд╢рд╛рдорд┐рд▓ рд╣реИрдВред рдлреНрд░реЗрдорд╡рд░реНрдХ Python рдФрд░ C++ APIs рджреЛрдиреЛрдВ рдХрд╛ рд╕рдорд░реНрдерди рдХрд░рддрд╛ рд╣реИ, рдЬреЛ рд▓рдЪреАрд▓реЗ рдПрдХреАрдХрд░рдг рдХреА рдЕрдиреБрдорддрд┐ рджреЗрддрд╛ рд╣реИред
- Microsoft Agent Framework рдЗрдВрдЯреАрдЧреНрд░реЗрд╢рди рдХрд╛ рдкрд░реАрдХреНрд╖рдг рдХрд░реЗрдВ  
- рдСрдлрд▓рд╛рдЗрди рдСрдкрд░реЗрд╢рди рдХреНрд╖рдорддрд╛рдУрдВ рдХреА рдЬрд╛рдВрдЪ рдХрд░реЗрдВ  
- рдлреЗрд▓рдУрд╡рд░ рдкрд░рд┐рджреГрд╢реНрдпреЛрдВ рдФрд░ рддреНрд░реБрдЯрд┐ рд╣реИрдВрдбрд▓рд┐рдВрдЧ рдХрд╛ рдкрд░реАрдХреНрд╖рдг рдХрд░реЗрдВ  
- рдПрдЬреЗрдВрдЯ рд╡рд░реНрдХрдлрд╝реНрд▓реЛ рдХрд╛ рдПрдВрдб-рдЯреВ-рдПрдВрдб рд╕рддреНрдпрд╛рдкрди рдХрд░реЗрдВ  

**Foundry Local рдХреЗ рд╕рд╛рде рддреБрд▓рдирд╛**:

| рдлреАрдЪрд░ | Foundry Local | Ollama |
|------|---------------|--------|
| **рд▓рдХреНрд╖рд┐рдд рдЙрдкрдпреЛрдЧ рдХрд╛ рдорд╛рдорд▓рд╛** | рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЬрд╝ рдЙрддреНрдкрд╛рджрди | рд╡рд┐рдХрд╛рд╕ рдФрд░ рд╕рдореБрджрд╛рдп |
| **рдореЙрдбрд▓ рдЗрдХреЛрд╕рд┐рд╕реНрдЯрдо** | Microsoft рджреНрд╡рд╛рд░рд╛ рдХреНрдпреВрд░реЗрдЯреЗрдб | рд╡реНрдпрд╛рдкрдХ рд╕рдореБрджрд╛рдп |
| **рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рдСрдкреНрдЯрд┐рдорд╛рдЗрдЬрд╝реЗрд╢рди** | рд╕реНрд╡рдЪрд╛рд▓рд┐рдд (CUDA/NPU/CPU) | рдореИрдиреБрдЕрд▓ рдХреЙрдиреНрдлрд╝рд┐рдЧрд░реЗрд╢рди |
| **рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЬрд╝ рдлреАрдЪрд░реНрд╕** | рдЕрдВрддрд░реНрдирд┐рд╣рд┐рдд рдореЙрдирд┐рдЯрд░рд┐рдВрдЧ, рд╕реБрд░рдХреНрд╖рд╛ | рд╕рд╛рдореБрджрд╛рдпрд┐рдХ рдЙрдкрдХрд░рдг |
| **рдбрд┐рдкреНрд▓реЙрдпрдореЗрдВрдЯ рдЬрдЯрд┐рд▓рддрд╛** | рд╕рд░рд▓ (winget рдЗрдВрд╕реНрдЯреЙрд▓) | рд╕рд░рд▓ (curl рдЗрдВрд╕реНрдЯреЙрд▓) |
| **API рд╕рдВрдЧрддрддрд╛** | OpenAI + рдПрдХреНрд╕рдЯреЗрдВрд╢рди | OpenAI рдорд╛рдирдХ |
| **рд╕рдкреЛрд░реНрдЯ** | Microsoft рдЖрдзрд┐рдХрд╛рд░рд┐рдХ | рд╕рд╛рдореБрджрд╛рдпрд┐рдХ-рдЪрд╛рд▓рд┐рдд |
| **рд╕рд░реНрд╡рд╢реНрд░реЗрд╖реНрда рдЙрдкрдпреЛрдЧ рдХреЗ рд▓рд┐рдП** | рдЙрддреНрдкрд╛рджрди рдПрдЬреЗрдВрдЯ | рдкреНрд░реЛрдЯреЛрдЯрд╛рдЗрдкрд┐рдВрдЧ, рдЕрдиреБрд╕рдВрдзрд╛рди |

**Ollama рдХрдм рдЪреБрдиреЗрдВ**:
- **рд╡рд┐рдХрд╛рд╕ рдФрд░ рдкреНрд░реЛрдЯреЛрдЯрд╛рдЗрдкрд┐рдВрдЧ**: рд╡рд┐рднрд┐рдиреНрди рдореЙрдбрд▓реЛрдВ рдХреЗ рд╕рд╛рде рддреЗрдЬрд╝реА рд╕реЗ рдкреНрд░рдпреЛрдЧ рдХрд░рдирд╛  
- **рд╕рд╛рдореБрджрд╛рдпрд┐рдХ рдореЙрдбрд▓**: рдирд╡реАрдирддрдо рд╕рд╛рдореБрджрд╛рдпрд┐рдХ рдпреЛрдЧрджрд╛рди рд╡рд╛рд▓реЗ рдореЙрдбрд▓реЛрдВ рддрдХ рдкрд╣реБрдВрдЪ  
- **рд╢реИрдХреНрд╖рд┐рдХ рдЙрдкрдпреЛрдЧ**: AI рдПрдЬреЗрдВрдЯ рд╡рд┐рдХрд╛рд╕ рд╕реАрдЦрдиреЗ рдФрд░ рд╕рд┐рдЦрд╛рдиреЗ рдХреЗ рд▓рд┐рдП  
- **рдЕрдиреБрд╕рдВрдзрд╛рди рдкрд░рд┐рдпреЛрдЬрдирд╛рдПрдВ**: рд╡рд┐рд╡рд┐рдз рдореЙрдбрд▓ рдПрдХреНрд╕реЗрд╕ рдХреА рдЖрд╡рд╢реНрдпрдХрддрд╛ рд╡рд╛рд▓реЗ рдЕрдХрд╛рджрдорд┐рдХ рдЕрдиреБрд╕рдВрдзрд╛рди  
- **рдХрд╕реНрдЯрдо рдореЙрдбрд▓**: рдХрд╕реНрдЯрдо рдлрд╛рдЗрди-рдЯреНрдпреВрди рдХрд┐рдП рдЧрдП рдореЙрдбрд▓реЛрдВ рдХрд╛ рдирд┐рд░реНрдорд╛рдг рдФрд░ рдкрд░реАрдХреНрд╖рдг  

### VLLM: рдЙрдЪреНрдЪ-рдкреНрд░рджрд░реНрд╢рди SLM рдПрдЬреЗрдВрдЯ рдЗрдВрдлрд░реЗрдВрд╕

VLLM (рдмрд╣реБрдд рдмрдбрд╝реЗ рднрд╛рд╖рд╛ рдореЙрдбрд▓ рдЗрдВрдлрд░реЗрдВрд╕) рдПрдХ рдЙрдЪреНрдЪ-рдереНрд░реВрдкреБрдЯ, рдореЗрдореЛрд░реА-рдХреБрд╢рд▓ рдЗрдВрдлрд░реЗрдВрд╕ рдЗрдВрдЬрди рдкреНрд░рджрд╛рди рдХрд░рддрд╛ рд╣реИ, рдЬреЛ рдмрдбрд╝реЗ рдкреИрдорд╛рдиреЗ рдкрд░ рдЙрддреНрдкрд╛рджрди SLM рдбрд┐рдкреНрд▓реЙрдпрдореЗрдВрдЯ рдХреЗ рд▓рд┐рдП рд╡рд┐рд╢реЗрд╖ рд░реВрдк рд╕реЗ рдЕрдиреБрдХреВрд▓рд┐рдд рд╣реИред рдЬрд╣рд╛рдВ Foundry Local рдЙрдкрдпреЛрдЧ рдореЗрдВ рдЖрд╕рд╛рдиреА рдкрд░ рдХреЗрдВрджреНрд░рд┐рдд рд╣реИ рдФрд░ Ollama рд╕рд╛рдореБрджрд╛рдпрд┐рдХ рдореЙрдбрд▓реЛрдВ рдкрд░ рдЬреЛрд░ рджреЗрддрд╛ рд╣реИ, VLLM рдЙрдЪреНрдЪ-рдкреНрд░рджрд░реНрд╢рди рдкрд░рд┐рджреГрд╢реНрдпреЛрдВ рдореЗрдВ рдЙрддреНрдХреГрд╖реНрдЯ рд╣реИ, рдЬрд┐рд╕рдореЗрдВ рдЕрдзрд┐рдХрддрдо рдереНрд░реВрдкреБрдЯ рдФрд░ рдХреБрд╢рд▓ рд╕рдВрд╕рд╛рдзрди рдЙрдкрдпреЛрдЧ рдХреА рдЖрд╡рд╢реНрдпрдХрддрд╛ рд╣реЛрддреА рд╣реИред

**рдореБрдЦреНрдп рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░ рдФрд░ рдлреАрдЪрд░реНрд╕**:
- **PagedAttention**: рдХреБрд╢рд▓ рдзреНрдпрд╛рди рдЧрдгрдирд╛ рдХреЗ рд▓рд┐рдП рдХреНрд░рд╛рдВрддрд┐рдХрд╛рд░реА рдореЗрдореЛрд░реА рдкреНрд░рдмрдВрдзрди  
- **рдбрд╛рдпрдирд╛рдорд┐рдХ рдмреИрдЪрд┐рдВрдЧ**: рдЗрдВрдЯреЗрд▓рд┐рдЬреЗрдВрдЯ рдЕрдиреБрд░реЛрдз рдмреИрдЪрд┐рдВрдЧ рдХреЗ рд▓рд┐рдП рдЗрд╖реНрдЯрддрдо рдереНрд░реВрдкреБрдЯ  
- **GPU рдСрдкреНрдЯрд┐рдорд╛рдЗрдЬрд╝реЗрд╢рди**: рдЙрдиреНрдирдд CUDA рдХрд░реНрдирд▓ рдФрд░ рдЯреЗрдВрд╕рд░ рдкреИрд░реЗрд▓рд▓рд┐рдЬрд╝реНрдо рд╕рдкреЛрд░реНрдЯ  
- **OpenAI рд╕рдВрдЧрддрддрд╛**: рд╕рд╣рдЬ рдЗрдВрдЯреАрдЧреНрд░реЗрд╢рди рдХреЗ рд▓рд┐рдП рдкреВрд░реНрдг API рд╕рдВрдЧрддрддрд╛  
- **рд╕реНрдкреЗрдХреБрд▓реЗрдЯрд┐рд╡ рдбрд┐рдХреЛрдбрд┐рдВрдЧ**: рдЙрдиреНрдирдд рдЗрдВрдлрд░реЗрдВрд╕ рддреНрд╡рд░рдг рддрдХрдиреАрдХ  
- **рдХреНрд╡рд╛рдВрдЯрд╛рдЗрдЬрд╝реЗрд╢рди рд╕рдкреЛрд░реНрдЯ**: рдореЗрдореЛрд░реА рджрдХреНрд╖рддрд╛ рдХреЗ рд▓рд┐рдП INT4, INT8, рдФрд░ FP16 рдХреНрд╡рд╛рдВрдЯрд╛рдЗрдЬрд╝реЗрд╢рди  

#### рдЗрдВрд╕реНрдЯреЙрд▓реЗрд╢рди рдФрд░ рд╕реЗрдЯрдЕрдк

**рдЗрдВрд╕реНрдЯреЙрд▓реЗрд╢рди рд╡рд┐рдХрд▓реНрдк**:  
```bash
# Standard installation
pip install vllm

# With additional dependencies for agent frameworks
pip install vllm[agent] openai

# Docker deployment for production
docker pull vllm/vllm-openai:latest

# From source for latest features
git clone https://github.com/vllm-project/vllm.git
cd vllm
pip install -e .
```
  
**рдПрдЬреЗрдВрдЯ рд╡рд┐рдХрд╛рд╕ рдХреЗ рд▓рд┐рдП рддреНрд╡рд░рд┐рдд рд╢реБрд░реБрдЖрдд**:  
```bash
# Start VLLM server with SLM model
python -m vllm.entrypoints.openai.api_server \
    --model microsoft/Phi-3.5-mini-instruct \
    --trust-remote-code \
    --max-model-len 4096 \
    --gpu-memory-utilization 0.8

# Alternative: Start with Qwen2.5 for lightweight agents
python -m vllm.entrypoints.openai.api_server \
    --model Qwen/Qwen2.5-0.5B-Instruct \
    --trust-remote-code \
    --max-model-len 2048 \
    --tensor-parallel-size 1

# Test API endpoint
curl http://localhost:8000/v1/models

# Test chat completion
curl http://localhost:8000/v1/chat/completions \
    -H "Content-Type: application/json" \
    -d '{
        "model": "microsoft/Phi-3.5-mini-instruct",
        "messages": [{"role": "user", "content": "Hello!"}]
    }'
```
  

#### рдПрдЬреЗрдВрдЯ рдлреНрд░реЗрдорд╡рд░реНрдХ рдЗрдВрдЯреАрдЧреНрд░реЗрд╢рди

**Microsoft Agent Framework рдХреЗ рд╕рд╛рде VLLM**:  
```python
from microsoft_agent_framework import Agent, Config
import openai
import subprocess
import time
import requests
from typing import Optional, Dict, Any

class VLLMManager:
    def __init__(self, model_name: str, 
                 host: str = "localhost", 
                 port: int = 8000,
                 gpu_memory_utilization: float = 0.8,
                 max_model_len: int = 4096):
        self.model_name = model_name
        self.host = host
        self.port = port
        self.base_url = f"http://{host}:{port}"
        self.gpu_memory_utilization = gpu_memory_utilization
        self.max_model_len = max_model_len
        self.process = None
        self.client = None
        
    def start_server(self) -> bool:
        """Start VLLM server with optimized settings for agents."""
        try:
            cmd = [
                "python", "-m", "vllm.entrypoints.openai.api_server",
                "--model", self.model_name,
                "--host", self.host,
                "--port", str(self.port),
                "--gpu-memory-utilization", str(self.gpu_memory_utilization),
                "--max-model-len", str(self.max_model_len),
                "--trust-remote-code",
                "--disable-log-requests",  # Reduce logging for agents
                "--served-model-name", self.get_served_model_name()
            ]
            
            self.process = subprocess.Popen(cmd, 
                stdout=subprocess.PIPE, 
                stderr=subprocess.PIPE)
            
            # Wait for server to start
            max_retries = 30
            for _ in range(max_retries):
                if self.health_check():
                    self.client = openai.OpenAI(base_url=f"{self.base_url}/v1")
                    return True
                time.sleep(2)
                
            return False
            
        except Exception as e:
            print(f"Failed to start VLLM server: {e}")
            return False
    
    def get_served_model_name(self) -> str:
        """Get a clean model name for serving."""
        return self.model_name.replace("/", "--")
    
    def health_check(self) -> bool:
        """Check if VLLM server is healthy."""
        try:
            response = requests.get(f"{self.base_url}/health", timeout=5)
            return response.status_code == 200
        except:
            return False
    
    def get_openai_client(self) -> openai.OpenAI:
        """Get OpenAI-compatible client for VLLM."""
        if not self.client:
            self.client = openai.OpenAI(base_url=f"{self.base_url}/v1")
        return self.client
    
    def get_model_info(self) -> Dict[str, Any]:
        """Get model information and statistics."""
        try:
            response = requests.get(f"{self.base_url}/v1/models")
            if response.status_code == 200:
                return response.json()
        except:
            pass
        return {}
    
    def shutdown(self):
        """Shutdown VLLM server."""
        if self.process:
            self.process.terminate()
            self.process.wait()

# Initialize VLLM for high-performance agents
vllm_manager = VLLMManager("microsoft/Phi-3.5-mini-instruct")
if vllm_manager.start_server():
    print("VLLM server started successfully")
    
    # Configure agent with VLLM backend
    agent_config = Config(
        name="vllm-performance-agent",
        model_provider="vllm",
        model_id=vllm_manager.get_served_model_name(),
        endpoint=f"{vllm_manager.base_url}/v1",
        api_key="none"  # VLLM doesn't require API key
    )
    
    agent = Agent(config=agent_config)
else:
    print("Failed to start VLLM server")
```
  
**рдЙрдЪреНрдЪ-рдереНрд░реВрдкреБрдЯ рдорд▓реНрдЯреА-рдПрдЬреЗрдВрдЯ рд╕реЗрдЯрдЕрдк**:  
```python
import asyncio
from concurrent.futures import ThreadPoolExecutor
from microsoft_agent_framework import Agent, Config
import openai

class VLLMHighThroughputManager:
    def __init__(self):
        self.model_configs = {
            "lightweight": {
                "model": "Qwen/Qwen2.5-0.5B-Instruct",
                "port": 8000,
                "max_model_len": 2048,
                "gpu_memory_utilization": 0.3
            },
            "balanced": {
                "model": "microsoft/Phi-3.5-mini-instruct",
                "port": 8001,
                "max_model_len": 4096,
                "gpu_memory_utilization": 0.5
            },
            "capable": {
                "model": "meta-llama/Llama-3.2-3B-Instruct",
                "port": 8002,
                "max_model_len": 8192,
                "gpu_memory_utilization": 0.7
            }
        }
        self.managers = {}
        self.agents = {}
        self.client_pool = {}
        
    async def initialize_all_models(self):
        """Initialize all VLLM models in parallel."""
        initialization_tasks = []
        
        for category, config in self.model_configs.items():
            task = self._initialize_model(category, config)
            initialization_tasks.append(task)
        
        results = await asyncio.gather(*initialization_tasks, return_exceptions=True)
        
        successful_inits = 0
        for i, result in enumerate(results):
            category = list(self.model_configs.keys())[i]
            if isinstance(result, Exception):
                print(f"Failed to initialize {category}: {result}")
            else:
                successful_inits += 1
                print(f"Successfully initialized {category} model")
        
        return successful_inits
    
    async def _initialize_model(self, category: str, config: Dict[str, Any]):
        """Initialize a single VLLM model instance."""
        manager = VLLMManager(
            model_name=config["model"],
            port=config["port"],
            max_model_len=config["max_model_len"],
            gpu_memory_utilization=config["gpu_memory_utilization"]
        )
        
        # Start server in thread to avoid blocking
        loop = asyncio.get_event_loop()
        with ThreadPoolExecutor() as executor:
            success = await loop.run_in_executor(executor, manager.start_server)
        
        if success:
            self.managers[category] = manager
            
            # Create agent
            agent_config = Config(
                name=f"vllm-{category}-agent",
                model_provider="vllm",
                model_id=manager.get_served_model_name(),
                endpoint=f"{manager.base_url}/v1",
                api_key="none"
            )
            
            self.agents[category] = Agent(config=agent_config)
            
            # Create client pool for high throughput
            self.client_pool[category] = [
                openai.OpenAI(base_url=f"{manager.base_url}/v1")
                for _ in range(5)  # 5 clients per model for parallelism
            ]
            
            return True
        else:
            raise Exception(f"Failed to start VLLM server for {category}")
    
    def get_optimal_agent(self, request_complexity: str, current_load: Dict[str, int]) -> str:
        """Select optimal agent based on request complexity and current load."""
        complexity_mapping = {
            "simple": "lightweight",
            "moderate": "balanced", 
            "complex": "capable"
        }
        
        preferred_category = complexity_mapping.get(request_complexity, "balanced")
        
        # Check if preferred agent is available and not overloaded
        if (preferred_category in self.agents and 
            current_load.get(preferred_category, 0) < 10):  # Max 10 concurrent per agent
            return preferred_category
        
        # Fallback to least loaded available agent
        available_agents = [(cat, load) for cat, load in current_load.items() 
                          if cat in self.agents and load < 10]
        
        if available_agents:
            return min(available_agents, key=lambda x: x[1])[0]
        
        return "balanced"  # Default fallback
    
    async def process_batch_requests(self, requests: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Process multiple requests in parallel for maximum throughput."""
        current_load = {cat: 0 for cat in self.agents.keys()}
        tasks = []
        
        for request in requests:
            # Determine optimal agent
            complexity = request.get("complexity", "moderate")
            agent_category = self.get_optimal_agent(complexity, current_load)
            current_load[agent_category] += 1
            
            # Create processing task
            task = self._process_single_request(request, agent_category)
            tasks.append(task)
        
        # Process all requests in parallel
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Format results
        formatted_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                formatted_results.append({
                    "request_id": requests[i].get("id", i),
                    "status": "error",
                    "error": str(result)
                })
            else:
                formatted_results.append(result)
        
        return formatted_results
    
    async def _process_single_request(self, request: Dict[str, Any], agent_category: str) -> Dict[str, Any]:
        """Process a single request with the specified agent."""
        start_time = time.time()
        
        try:
            agent = self.agents[agent_category]
            response = await agent.chat_async(request["message"])
            
            processing_time = time.time() - start_time
            
            return {
                "request_id": request.get("id"),
                "status": "success",
                "response": response,
                "agent_used": agent_category,
                "processing_time": processing_time
            }
            
        except Exception as e:
            return {
                "request_id": request.get("id"),
                "status": "error",
                "error": str(e),
                "agent_used": agent_category,
                "processing_time": time.time() - start_time
            }

# High-throughput usage example
throughput_manager = VLLMHighThroughputManager()

# Initialize all models
initialized_count = await throughput_manager.initialize_all_models()
print(f"Initialized {initialized_count} models")

# Process batch requests
batch_requests = [
    {"id": 1, "message": "Simple question", "complexity": "simple"},
    {"id": 2, "message": "Complex analysis needed", "complexity": "complex"},
    {"id": 3, "message": "Moderate difficulty task", "complexity": "moderate"}
]

results = await throughput_manager.process_batch_requests(batch_requests)
for result in results:
    print(f"Request {result['request_id']}: {result['status']} in {result.get('processing_time', 0):.2f}s")
```
  

#### рдЙрддреНрдкрд╛рджрди рдбрд┐рдкреНрд▓реЙрдпрдореЗрдВрдЯ рдкреИрдЯрд░реНрди

**рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЬрд╝ VLLM рдЙрддреНрдкрд╛рджрди рд╕реЗрд╡рд╛**:  
```python
import asyncio
import logging
import time
from typing import Dict, List, Optional
from dataclasses import dataclass
from microsoft_agent_framework import Agent, Config
import uvicorn
from fastapi import FastAPI, HTTPException, BackgroundTasks
from pydantic import BaseModel

@dataclass
class VLLMServerConfig:
    model_name: str
    port: int
    gpu_memory_utilization: float
    max_model_len: int
    tensor_parallel_size: int = 1
    quantization: Optional[str] = None

class AgentRequest(BaseModel):
    message: str
    agent_type: str = "general"
    priority: str = "normal"
    timeout: int = 30

class VLLMProductionService:
    def __init__(self, server_configs: Dict[str, VLLMServerConfig]):
        self.server_configs = server_configs
        self.managers = {}
        self.agents = {}
        self.metrics = {
            "requests_processed": 0,
            "requests_failed": 0,
            "total_processing_time": 0,
            "agent_usage": {name: 0 for name in server_configs.keys()},
            "throughput_per_minute": 0
        }
        self.request_queue = asyncio.Queue(maxsize=1000)
        self.processing_workers = []
        self.app = FastAPI(title="VLLM Agent Service")
        self._setup_routes()
        
    async def initialize_production_environment(self):
        """Initialize all VLLM servers for production."""
        logging.info("Initializing VLLM production environment...")
        
        initialization_tasks = []
        for name, config in self.server_configs.items():
            task = self._initialize_server(name, config)
            initialization_tasks.append(task)
        
        results = await asyncio.gather(*initialization_tasks, return_exceptions=True)
        
        successful_servers = 0
        for i, result in enumerate(results):
            server_name = list(self.server_configs.keys())[i]
            if isinstance(result, Exception):
                logging.error(f"Failed to initialize {server_name}: {result}")
            else:
                successful_servers += 1
                logging.info(f"Successfully initialized {server_name}")
        
        if successful_servers == 0:
            raise Exception("No VLLM servers could be initialized")
        
        # Start processing workers
        self.processing_workers = [
            asyncio.create_task(self._processing_worker(i))
            for i in range(min(4, successful_servers))  # 4 workers max
        ]
        
        logging.info(f"Production environment ready with {successful_servers} servers")
        return successful_servers
    
    async def _initialize_server(self, name: str, config: VLLMServerConfig):
        """Initialize a single VLLM server."""
        manager = VLLMManager(
            model_name=config.model_name,
            port=config.port,
            gpu_memory_utilization=config.gpu_memory_utilization,
            max_model_len=config.max_model_len
        )
        
        # Add quantization if specified
        if config.quantization:
            # This would be added to the manager's start command
            pass
        
        success = manager.start_server()
        if success:
            self.managers[name] = manager
            
            # Create production agent
            agent_config = Config(
                name=f"vllm-production-{name}",
                model_provider="vllm",
                model_id=manager.get_served_model_name(),
                endpoint=f"{manager.base_url}/v1",
                api_key="none",
                timeout=30.0
            )
            
            agent = Agent(config=agent_config)
            
            # Add production tools
            self._add_production_tools(agent, name)
            
            self.agents[name] = agent
            return True
        else:
            raise Exception(f"Failed to start VLLM server for {name}")
    
    def _add_production_tools(self, agent: Agent, server_type: str):
        """Add production tools based on server type."""
        if server_type == "customer_service":
            @agent.tool
            def escalate_to_human(issue: str, customer_id: str) -> str:
                """Escalate complex issues to human agents."""
                return f"Escalated issue for customer {customer_id}: {issue}"
            
            @agent.tool
            def lookup_order_status(order_id: str) -> dict:
                """Look up order status from production database."""
                # Production database lookup
                return {"order_id": order_id, "status": "shipped", "eta": "2 days"}
        
        elif server_type == "technical_support":
            @agent.tool
            def run_system_diagnostics(system_id: str) -> dict:
                """Run comprehensive system diagnostics."""
                return {"system_id": system_id, "status": "healthy", "issues": []}
            
            @agent.tool
            def create_incident_report(description: str, severity: str) -> str:
                """Create incident report in production system."""
                incident_id = f"INC-{hash(description) % 100000:05d}"
                return f"Created incident {incident_id} with severity {severity}"
    
    def _setup_routes(self):
        """Set up FastAPI routes for production service."""
        @self.app.post("/chat")
        async def chat_endpoint(request: AgentRequest, background_tasks: BackgroundTasks):
            try:
                # Add request to queue
                await self.request_queue.put({
                    "request": request,
                    "timestamp": time.time(),
                    "future": asyncio.Future()
                })
                
                # Wait for processing (with timeout)
                result = await asyncio.wait_for(
                    self._wait_for_result(request),
                    timeout=request.timeout
                )
                
                return result
                
            except asyncio.TimeoutError:
                raise HTTPException(status_code=408, detail="Request timeout")
            except Exception as e:
                raise HTTPException(status_code=500, detail=str(e))
        
        @self.app.get("/health")
        async def health_endpoint():
            return await self.get_health_status()
        
        @self.app.get("/metrics")
        async def metrics_endpoint():
            return self.get_production_metrics()
    
    async def _processing_worker(self, worker_id: int):
        """Background worker for processing agent requests."""
        logging.info(f"Starting processing worker {worker_id}")
        
        while True:
            try:
                # Get request from queue
                queue_item = await self.request_queue.get()
                request_data = queue_item["request"]
                request_future = queue_item["future"]
                
                # Select appropriate agent
                agent_name = self._select_agent(request_data.agent_type)
                
                if agent_name not in self.agents:
                    request_future.set_exception(Exception(f"Agent {agent_name} not available"))
                    continue
                
                # Process request
                start_time = time.time()
                try:
                    agent = self.agents[agent_name]
                    response = await agent.chat_async(request_data.message)
                    
                    processing_time = time.time() - start_time
                    
                    # Update metrics
                    self.metrics["requests_processed"] += 1
                    self.metrics["total_processing_time"] += processing_time
                    self.metrics["agent_usage"][agent_name] += 1
                    
                    result = {
                        "response": response,
                        "agent_used": agent_name,
                        "processing_time": processing_time,
                        "worker_id": worker_id
                    }
                    
                    request_future.set_result(result)
                    
                except Exception as e:
                    self.metrics["requests_failed"] += 1
                    request_future.set_exception(e)
                
                finally:
                    self.request_queue.task_done()
                    
            except Exception as e:
                logging.error(f"Worker {worker_id} error: {e}")
                await asyncio.sleep(1)
    
    def _select_agent(self, agent_type: str) -> str:
        """Select appropriate agent based on request type."""
        agent_mapping = {
            "customer_service": "customer_service",
            "technical": "technical_support",
            "general": "general_purpose"
        }
        
        return agent_mapping.get(agent_type, "general_purpose")
    
    async def _wait_for_result(self, request: AgentRequest):
        """Wait for request processing to complete."""
        # This is simplified - in production you'd track futures properly
        await asyncio.sleep(0.1)  # Placeholder
        return {"response": "Processed", "status": "success"}
    
    async def get_health_status(self) -> dict:
        """Get comprehensive health status of all services."""
        health_status = {
            "overall_status": "healthy",
            "servers": {},
            "queue_size": self.request_queue.qsize(),
            "active_workers": len([w for w in self.processing_workers if not w.done()]),
            "timestamp": time.time()
        }
        
        unhealthy_servers = 0
        for name, manager in self.managers.items():
            try:
                is_healthy = manager.health_check()
                health_status["servers"][name] = {
                    "status": "healthy" if is_healthy else "unhealthy",
                    "endpoint": manager.base_url,
                    "model": manager.model_name
                }
                if not is_healthy:
                    unhealthy_servers += 1
            except Exception as e:
                health_status["servers"][name] = {
                    "status": "error",
                    "error": str(e)
                }
                unhealthy_servers += 1
        
        if unhealthy_servers > 0:
            health_status["overall_status"] = "degraded" if unhealthy_servers < len(self.managers) else "unhealthy"
        
        return health_status
    
    def get_production_metrics(self) -> dict:
        """Get production performance metrics."""
        total_requests = self.metrics["requests_processed"] + self.metrics["requests_failed"]
        avg_processing_time = (
            self.metrics["total_processing_time"] / self.metrics["requests_processed"]
            if self.metrics["requests_processed"] > 0 else 0
        )
        
        success_rate = (
            self.metrics["requests_processed"] / total_requests * 100
            if total_requests > 0 else 0
        )
        
        return {
            "total_requests": total_requests,
            "successful_requests": self.metrics["requests_processed"],
            "failed_requests": self.metrics["requests_failed"],
            "success_rate_percent": success_rate,
            "average_processing_time_seconds": avg_processing_time,
            "agent_usage_distribution": self.metrics["agent_usage"],
            "queue_size": self.request_queue.qsize()
        }
    
    async def start_production_server(self, host: str = "0.0.0.0", port: int = 8080):
        """Start the production FastAPI server."""
        config = uvicorn.Config(
            self.app,
            host=host,
            port=port,
            log_level="info",
            workers=1  # Single worker for simplicity
        )
        server = uvicorn.Server(config)
        await server.serve()

# Production deployment example
production_configs = {
    "customer_service": VLLMServerConfig(
        model_name="microsoft/Phi-3.5-mini-instruct",
        port=8000,
        gpu_memory_utilization=0.4,
        max_model_len=4096
    ),
    "technical_support": VLLMServerConfig(
        model_name="meta-llama/Llama-3.2-3B-Instruct",
        port=8001,
        gpu_memory_utilization=0.6,
        max_model_len=8192
    ),
    "general_purpose": VLLMServerConfig(
        model_name="Qwen/Qwen2.5-1.5B-Instruct",
        port=8002,
        gpu_memory_utilization=0.3,
        max_model_len=2048
    )
}

production_service = VLLMProductionService(production_configs)

# Initialize and start production service
# await production_service.initialize_production_environment()
# await production_service.start_production_server()
```
  

#### рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЬрд╝ рдлреАрдЪрд░реНрд╕ рдФрд░ рдореЙрдирд┐рдЯрд░рд┐рдВрдЧ

**рдЙрдиреНрдирдд VLLM рдкреНрд░рджрд░реНрд╢рди рдореЙрдирд┐рдЯрд░рд┐рдВрдЧ**:  
```python
import psutil
import nvidia_ml_py3 as nvml
from dataclasses import dataclass
from typing import List, Dict, Optional
import json
import asyncio

@dataclass
class PerformanceMetrics:
    timestamp: float
    requests_per_second: float
    average_latency_ms: float
    gpu_utilization_percent: float
    gpu_memory_used_gb: float
    cpu_utilization_percent: float
    memory_used_gb: float
    queue_length: int
    active_requests: int

class VLLMAdvancedMonitoring:
    def __init__(self, vllm_managers: Dict[str, VLLMManager]):
        self.managers = vllm_managers
        self.metrics_history = []
        self.alert_thresholds = {
            "gpu_utilization_max": 95,
            "gpu_memory_max_gb": 10,
            "latency_max_ms": 3000,
            "queue_length_max": 50,
            "error_rate_max_percent": 10
        }
        
        # Initialize NVIDIA ML for GPU monitoring
        try:
            nvml.nvmlInit()
            self.gpu_monitoring_available = True
            self.gpu_count = nvml.nvmlDeviceGetCount()
        except:
            self.gpu_monitoring_available = False
            self.gpu_count = 0
    
    async def collect_comprehensive_metrics(self) -> Dict[str, PerformanceMetrics]:
        """Collect detailed performance metrics for all VLLM instances."""
        all_metrics = {}
        
        for name, manager in self.managers.items():
            try:
                metrics = await self._collect_single_instance_metrics(name, manager)
                all_metrics[name] = metrics
            except Exception as e:
                logging.error(f"Failed to collect metrics for {name}: {e}")
                # Create error metrics
                all_metrics[name] = PerformanceMetrics(
                    timestamp=time.time(),
                    requests_per_second=0,
                    average_latency_ms=0,
                    gpu_utilization_percent=0,
                    gpu_memory_used_gb=0,
                    cpu_utilization_percent=0,
                    memory_used_gb=0,
                    queue_length=0,
                    active_requests=0
                )
        
        return all_metrics
    
    async def _collect_single_instance_metrics(self, name: str, manager: VLLMManager) -> PerformanceMetrics:
        """Collect metrics for a single VLLM instance."""
        timestamp = time.time()
        
        # Get VLLM-specific metrics via API
        vllm_stats = await self._get_vllm_stats(manager)
        
        # Get system metrics
        cpu_percent = psutil.cpu_percent(interval=0.1)
        memory_info = psutil.virtual_memory()
        memory_used_gb = memory_info.used / (1024**3)
        
        # Get GPU metrics if available
        gpu_utilization = 0
        gpu_memory_used = 0
        
        if self.gpu_monitoring_available and self.gpu_count > 0:
            try:
                # Assuming first GPU for simplicity
                handle = nvml.nvmlDeviceGetHandleByIndex(0)
                gpu_util = nvml.nvmlDeviceGetUtilizationRates(handle)
                gpu_utilization = gpu_util.gpu
                
                gpu_mem = nvml.nvmlDeviceGetMemoryInfo(handle)
                gpu_memory_used = gpu_mem.used / (1024**3)
                
            except Exception as e:
                logging.warning(f"GPU monitoring failed: {e}")
        
        return PerformanceMetrics(
            timestamp=timestamp,
            requests_per_second=vllm_stats.get("requests_per_second", 0),
            average_latency_ms=vllm_stats.get("average_latency_ms", 0),
            gpu_utilization_percent=gpu_utilization,
            gpu_memory_used_gb=gpu_memory_used,
            cpu_utilization_percent=cpu_percent,
            memory_used_gb=memory_used_gb,
            queue_length=vllm_stats.get("queue_length", 0),
            active_requests=vllm_stats.get("active_requests", 0)
        )
    
    async def _get_vllm_stats(self, manager: VLLMManager) -> dict:
        """Get VLLM-specific statistics via API calls."""
        try:
            # Test inference to measure latency
            start_time = time.time()
            client = manager.get_openai_client()
            
            response = await asyncio.wait_for(
                asyncio.to_thread(
                    client.chat.completions.create,
                    model=manager.get_served_model_name(),
                    messages=[{"role": "user", "content": "ping"}],
                    max_tokens=1
                ),
                timeout=5.0
            )
            
            latency_ms = (time.time() - start_time) * 1000
            
            return {
                "average_latency_ms": latency_ms,
                "requests_per_second": 1000 / latency_ms if latency_ms > 0 else 0,
                "queue_length": 0,  # Would need to be exposed by VLLM
                "active_requests": 1  # Approximation
            }
            
        except Exception as e:
            logging.warning(f"Failed to get VLLM stats: {e}")
            return {
                "average_latency_ms": 0,
                "requests_per_second": 0,
                "queue_length": 0,
                "active_requests": 0
            }
    
    def generate_performance_report(self, time_window_minutes: int = 60) -> dict:
        """Generate comprehensive performance report."""
        cutoff_time = time.time() - (time_window_minutes * 60)
        recent_metrics = [
            metrics for metrics in self.metrics_history
            if any(m.timestamp > cutoff_time for m in metrics.values())
        ]
        
        if not recent_metrics:
            return {"error": "No recent metrics available"}
        
        report = {
            "time_window_minutes": time_window_minutes,
            "total_samples": len(recent_metrics),
            "instances": {}
        }
        
        # Analyze each instance
        for instance_name in self.managers.keys():
            instance_metrics = [
                metrics[instance_name] for metrics in recent_metrics
                if instance_name in metrics
            ]
            
            if instance_metrics:
                report["instances"][instance_name] = {
                    "avg_latency_ms": sum(m.average_latency_ms for m in instance_metrics) / len(instance_metrics),
                    "max_latency_ms": max(m.average_latency_ms for m in instance_metrics),
                    "avg_gpu_utilization": sum(m.gpu_utilization_percent for m in instance_metrics) / len(instance_metrics),
                    "avg_requests_per_second": sum(m.requests_per_second for m in instance_metrics) / len(instance_metrics),
                    "max_queue_length": max(m.queue_length for m in instance_metrics),
                    "availability_percent": (len(instance_metrics) / len(recent_metrics)) * 100
                }
        
        return report
    
    async def auto_scaling_recommendations(self) -> List[dict]:
        """Generate auto-scaling recommendations based on performance metrics."""
        recommendations = []
        
        if not self.metrics_history:
            return recommendations
        
        latest_metrics = self.metrics_history[-1]
        
        for instance_name, metrics in latest_metrics.items():
            # High latency recommendation
            if metrics.average_latency_ms > self.alert_thresholds["latency_max_ms"]:
                recommendations.append({
                    "instance": instance_name,
                    "type": "scale_up",
                    "reason": f"High latency: {metrics.average_latency_ms:.0f}ms",
                    "suggestion": "Consider adding tensor parallelism or increasing GPU memory"
                })
            
            # High GPU utilization recommendation
            if metrics.gpu_utilization_percent > self.alert_thresholds["gpu_utilization_max"]:
                recommendations.append({
                    "instance": instance_name,
                    "type": "scale_out",
                    "reason": f"High GPU utilization: {metrics.gpu_utilization_percent:.1f}%",
                    "suggestion": "Consider adding additional GPU instances"
                })
            
            # Low utilization recommendation
            if (metrics.gpu_utilization_percent < 20 and 
                metrics.requests_per_second < 1):
                recommendations.append({
                    "instance": instance_name,
                    "type": "scale_down",
                    "reason": f"Low utilization: {metrics.gpu_utilization_percent:.1f}% GPU, {metrics.requests_per_second:.1f} RPS",
                    "suggestion": "Consider consolidating workloads or reducing resources"
                })
        
        return recommendations

# Advanced monitoring setup
monitoring = VLLMAdvancedMonitoring({
    "customer_service": vllm_manager,
    # Add other managers as needed
})

async def advanced_monitoring_loop():
    """Advanced monitoring with auto-scaling recommendations."""
    while True:
        try:
            # Collect metrics
            metrics = await monitoring.collect_comprehensive_metrics()
            monitoring.metrics_history.append(metrics)
            
            # Keep only last 1000 entries
            if len(monitoring.metrics_history) > 1000:
                monitoring.metrics_history = monitoring.metrics_history[-1000:]
            
            # Generate recommendations every 5 minutes
            if len(monitoring.metrics_history) % 10 == 0:  # Every 10th collection (5 minutes if collecting every 30s)
                recommendations = await monitoring.auto_scaling_recommendations()
                
                if recommendations:
                    logging.info(f"Auto-scaling recommendations: {recommendations}")
            
            # Generate performance report every hour
            if len(monitoring.metrics_history) % 120 == 0:  # Every 120th collection (1 hour)
                report = monitoring.generate_performance_report(60)
                logging.info(f"Performance report: {json.dumps(report, indent=2)}")
            
        except Exception as e:
            logging.error(f"Advanced monitoring error: {e}")
        
        await asyncio.sleep(30)  # Collect metrics every 30 seconds

# Start advanced monitoring
# asyncio.create_task(advanced_monitoring_loop())
```
  

#### рдЙрдиреНрдирдд рдХреЙрдиреНрдлрд╝рд┐рдЧрд░реЗрд╢рди рдФрд░ рдСрдкреНрдЯрд┐рдорд╛рдЗрдЬрд╝реЗрд╢рди

**рдЙрддреНрдкрд╛рджрди VLLM рдХреЙрдиреНрдлрд╝рд┐рдЧрд░реЗрд╢рди рдЯреЗрдореНрдкрд▓реЗрдЯреНрд╕**:  
```python
from enum import Enum
from typing import Dict, Any

class DeploymentScenario(Enum):
    DEVELOPMENT = "development"
    STAGING = "staging"
    PRODUCTION_LOW = "production_low"
    PRODUCTION_HIGH = "production_high"
    ENTERPRISE = "enterprise"

class VLLMConfigTemplates:
    """Production-ready VLLM configuration templates."""
    
    @staticmethod
    def get_config_template(scenario: DeploymentScenario) -> Dict[str, Any]:
        """Get optimized configuration for deployment scenario."""
        
        templates = {
            DeploymentScenario.DEVELOPMENT: {
                "gpu_memory_utilization": 0.6,
                "max_model_len": 2048,
                "tensor_parallel_size": 1,
                "pipeline_parallel_size": 1,
                "quantization": None,
                "enable_prefix_caching": False,
                "max_num_seqs": 32,
                "max_num_batched_tokens": 2048
            },
            
            DeploymentScenario.STAGING: {
                "gpu_memory_utilization": 0.8,
                "max_model_len": 4096,
                "tensor_parallel_size": 1,
                "pipeline_parallel_size": 1,
                "quantization": "awq",
                "enable_prefix_caching": True,
                "max_num_seqs": 64,
                "max_num_batched_tokens": 4096
            },
            
            DeploymentScenario.PRODUCTION_LOW: {
                "gpu_memory_utilization": 0.85,
                "max_model_len": 4096,
                "tensor_parallel_size": 1,
                "pipeline_parallel_size": 1,
                "quantization": "awq",
                "enable_prefix_caching": True,
                "max_num_seqs": 128,
                "max_num_batched_tokens": 8192,
                "enable_chunked_prefill": True
            },
            
            DeploymentScenario.PRODUCTION_HIGH: {
                "gpu_memory_utilization": 0.9,
                "max_model_len": 8192,
                "tensor_parallel_size": 2,
                "pipeline_parallel_size": 1,
                "quantization": "awq",
                "enable_prefix_caching": True,
                "max_num_seqs": 256,
                "max_num_batched_tokens": 16384,
                "enable_chunked_prefill": True,
                "speculative_model": "small_draft_model"
            },
            
            DeploymentScenario.ENTERPRISE: {
                "gpu_memory_utilization": 0.95,
                "max_model_len": 16384,
                "tensor_parallel_size": 4,
                "pipeline_parallel_size": 2,
                "quantization": "awq",
                "enable_prefix_caching": True,
                "max_num_seqs": 512,
                "max_num_batched_tokens": 32768,
                "enable_chunked_prefill": True,
                "speculative_model": "optimized_draft_model",
                "guided_decoding_backend": "outlines"
            }
        }
        
        return templates[scenario]
    
    @staticmethod
    def generate_vllm_command(model_name: str, 
                             scenario: DeploymentScenario,
                             port: int = 8000,
                             host: str = "0.0.0.0") -> List[str]:
        """Generate optimized VLLM command for deployment scenario."""
        
        config = VLLMConfigTemplates.get_config_template(scenario)
        
        cmd = [
            "python", "-m", "vllm.entrypoints.openai.api_server",
            "--model", model_name,
            "--host", host,
            "--port", str(port),
            "--gpu-memory-utilization", str(config["gpu_memory_utilization"]),
            "--max-model-len", str(config["max_model_len"]),
            "--tensor-parallel-size", str(config["tensor_parallel_size"]),
            "--max-num-seqs", str(config["max_num_seqs"]),
            "--max-num-batched-tokens", str(config["max_num_batched_tokens"]),
            "--trust-remote-code",
            "--disable-log-requests"
        ]
        
        # Add optional parameters
        if config.get("quantization"):
            cmd.extend(["--quantization", config["quantization"]])
        
        if config.get("enable_prefix_caching"):
            cmd.append("--enable-prefix-caching")
        
        if config.get("enable_chunked_prefill"):
            cmd.append("--enable-chunked-prefill")
        
        if config.get("pipeline_parallel_size", 1) > 1:
            cmd.extend(["--pipeline-parallel-size", str(config["pipeline_parallel_size"])])
        
        if config.get("speculative_model"):
            cmd.extend(["--speculative-model", config["speculative_model"]])
        
        return cmd

# Usage examples
dev_cmd = VLLMConfigTemplates.generate_vllm_command(
    "microsoft/Phi-3.5-mini-instruct",
    DeploymentScenario.DEVELOPMENT,
    port=8000
)

prod_cmd = VLLMConfigTemplates.generate_vllm_command(
    "microsoft/Phi-3.5-mini-instruct",
    DeploymentScenario.PRODUCTION_HIGH,
    port=8001
)

print(f"Development command: {' '.join(dev_cmd)}")
print(f"Production command: {' '.join(prod_cmd)}")
```
  
**VLLM рдХреЗ рд▓рд┐рдП рдЙрддреНрдкрд╛рджрди рдбрд┐рдкреНрд▓реЙрдпрдореЗрдВрдЯ рдЪреЗрдХрд▓рд┐рд╕реНрдЯ**:

тЬЕ **рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рдСрдкреНрдЯрд┐рдорд╛рдЗрдЬрд╝реЗрд╢рди**:  
- рдорд▓реНрдЯреА-GPU рд╕реЗрдЯрдЕрдк рдХреЗ рд▓рд┐рдП рдЯреЗрдВрд╕рд░ рдкреИрд░реЗрд▓рд▓рд┐рдЬрд╝реНрдо рдХреЙрдиреНрдлрд╝рд┐рдЧрд░ рдХрд░реЗрдВ  
- рдореЗрдореЛрд░реА рджрдХреНрд╖рддрд╛ рдХреЗ рд▓рд┐рдП рдХреНрд╡рд╛рдВрдЯрд╛рдЗрдЬрд╝реЗрд╢рди (AWQ/GPTQ) рд╕рдХреНрд╖рдо рдХрд░реЗрдВ  
- GPU рдореЗрдореЛрд░реА рдЙрдкрдпреЛрдЧ рдХреЛ рдЗрд╖реНрдЯрддрдо рд╕реНрддрд░ (85-95%) рдкрд░ рд╕реЗрдЯ рдХрд░реЗрдВ  
- рдереНрд░реВрдкреБрдЯ рдХреЗ рд▓рд┐рдП рдЙрдкрдпреБрдХреНрдд рдмреИрдЪ рд╕рд╛рдЗрдЬрд╝ рдХреЙрдиреНрдлрд╝рд┐рдЧрд░ рдХрд░реЗрдВ  

тЬЕ **рдкреНрд░рджрд░реНрд╢рди рдЯреНрдпреВрдирд┐рдВрдЧ**:  
- рдмрд╛рд░-рдмрд╛рд░ рдкреВрдЫреЗ рдЬрд╛рдиреЗ рд╡рд╛рд▓реЗ рдкреНрд░рд╢реНрдиреЛрдВ рдХреЗ рд▓рд┐рдП рдкреНрд░реАрдлрд┐рдХреНрд╕ рдХреИрд╢рд┐рдВрдЧ рд╕рдХреНрд╖рдо рдХрд░реЗрдВ  
- рд▓рдВрдмреЗ рдЕрдиреБрдХреНрд░рдореЛрдВ рдХреЗ рд▓рд┐рдП рдЪрдВрдХреЗрдб рдкреНрд░реАрдлрд┐рд▓ рдХреЙрдиреНрдлрд╝рд┐рдЧрд░ рдХрд░реЗрдВ  
- рддреЗрдЬрд╝ рдЗрдВрдлрд░реЗрдВрд╕ рдХреЗ рд▓рд┐рдП рд╕реНрдкреЗрдХреБрд▓реЗрдЯрд┐рд╡ рдбрд┐рдХреЛрдбрд┐рдВрдЧ рд╕реЗрдЯ рдХрд░реЗрдВ  
- рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рдХреЗ рдЖрдзрд╛рд░ рдкрд░ max_num_seqs рдХреЛ рдСрдкреНрдЯрд┐рдорд╛рдЗрдЬрд╝ рдХрд░реЗрдВ  

тЬЕ **рдЙрддреНрдкрд╛рджрди рдлреАрдЪрд░реНрд╕**:  
- рд╕реНрд╡рд╛рд╕реНрдереНрдп рдореЙрдирд┐рдЯрд░рд┐рдВрдЧ рдФрд░ рдореЗрдЯреНрд░рд┐рдХреНрд╕ рд╕рдВрдЧреНрд░рд╣ рд╕реЗрдЯ рдХрд░реЗрдВ  
- рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рдкреБрдирдГ рдЖрд░рдВрдн рдФрд░ рдлреЗрд▓рдУрд╡рд░ рдХреЙрдиреНрдлрд╝рд┐рдЧрд░ рдХрд░реЗрдВ  
- рдЕрдиреБрд░реЛрдз рдХрддрд╛рд░рдмрджреНрдз рдФрд░ рд▓реЛрдб рдмреИрд▓реЗрдВрд╕рд┐рдВрдЧ рд▓рд╛рдЧреВ рдХрд░реЗрдВ  
- рд╡реНрдпрд╛рдкрдХ рд▓реЙрдЧрд┐рдВрдЧ рдФрд░ рдЕрд▓рд░реНрдЯрд┐рдВрдЧ рд╕реЗрдЯ рдХрд░реЗрдВ  

тЬЕ **рд╕реБрд░рдХреНрд╖рд╛ рдФрд░ рд╡рд┐рд╢реНрд╡рд╕рдиреАрдпрддрд╛**:  
- рдлрд╝рд╛рдпрд░рд╡реЙрд▓ рдирд┐рдпрдо рдФрд░ рдПрдХреНрд╕реЗрд╕ рдХрдВрдЯреНрд░реЛрд▓ рдХреЙрдиреНрдлрд╝рд┐рдЧрд░ рдХрд░реЗрдВ  
- API рджрд░ рд╕реАрдорд┐рдд рдФрд░ рдкреНрд░рдорд╛рдгреАрдХрд░рдг рд╕реЗрдЯ рдХрд░реЗрдВ  
- рдЧреНрд░реЗрд╕рдлреБрд▓ рд╢рдЯрдбрд╛рдЙрди рдФрд░ рдХреНрд▓реАрдирдЕрдк рд▓рд╛рдЧреВ рдХрд░реЗрдВ  
- рдмреИрдХрдЕрдк рдФрд░ рдЖрдкрджрд╛ рд╡рд╕реВрд▓реА рдХреЙрдиреНрдлрд╝рд┐рдЧрд░ рдХрд░реЗрдВ  

тЬЕ **рдЗрдВрдЯреАрдЧреНрд░реЗрд╢рди рдкрд░реАрдХреНрд╖рдг**:  
- Microsoft Agent Framework рдЗрдВрдЯреАрдЧреНрд░реЗрд╢рди рдХрд╛ рдкрд░реАрдХреНрд╖рдг рдХрд░реЗрдВ  
- рдЙрдЪреНрдЪ-рдереНрд░реВрдкреБрдЯ рдкрд░рд┐рджреГрд╢реНрдпреЛрдВ рдХреЛ рд╕рддреНрдпрд╛рдкрд┐рдд рдХрд░реЗрдВ  
- рдлреЗрд▓рдУрд╡рд░ рдФрд░ рд░рд┐рдХрд╡рд░реА рдкреНрд░рдХреНрд░рд┐рдпрд╛рдУрдВ рдХрд╛ рдкрд░реАрдХреНрд╖рдг рдХрд░реЗрдВ  
- рд▓реЛрдб рдХреЗ рддрд╣рдд рдкреНрд░рджрд░реНрд╢рди рдХрд╛ рдмреЗрдВрдЪрдорд╛рд░реНрдХ рдХрд░реЗрдВ  

**рдЕрдиреНрдп рд╕рдорд╛рдзрд╛рдиреЛрдВ рдХреЗ рд╕рд╛рде рддреБрд▓рдирд╛**:

| рдлреАрдЪрд░ | VLLM | Foundry Local | Ollama |
|------|------|---------------|--------|
| **рд▓рдХреНрд╖рд┐рдд рдЙрдкрдпреЛрдЧ рдХрд╛ рдорд╛рдорд▓рд╛** | рдЙрдЪреНрдЪ-рдереНрд░реВрдкреБрдЯ рдЙрддреНрдкрд╛рджрди | рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЬрд╝ рдЙрдкрдпреЛрдЧ рдореЗрдВ рдЖрд╕рд╛рдиреА | рд╡рд┐рдХрд╛рд╕ рдФрд░ рд╕рдореБрджрд╛рдп |
| **рдкреНрд░рджрд░реНрд╢рди** | рдЕрдзрд┐рдХрддрдо рдереНрд░реВрдкреБрдЯ | рд╕рдВрддреБрд▓рд┐рдд | рдЕрдЪреНрдЫрд╛ |
| **рдореЗрдореЛрд░реА рджрдХреНрд╖рддрд╛** | PagedAttention рдСрдкреНрдЯрд┐рдорд╛рдЗрдЬрд╝реЗрд╢рди | рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рдСрдкреНрдЯрд┐рдорд╛рдЗрдЬрд╝реЗрд╢рди | рдорд╛рдирдХ |
| **рд╕реЗрдЯрдЕрдк рдЬрдЯрд┐рд▓рддрд╛** | рдЙрдЪреНрдЪ (рдХрдИ рдкреИрд░рд╛рдореАрдЯрд░) | рдХрдо (рд╕реНрд╡рдЪрд╛рд▓рд┐рдд) | рдХрдо (рд╕рд░рд▓) |
| **рд╕реНрдХреЗрд▓реЗрдмрд┐рд▓рд┐рдЯреА** | рдЙрддреНрдХреГрд╖реНрдЯ (рдЯреЗрдВрд╕рд░/рдкрд╛рдЗрдкрд▓рд╛рдЗрди рдкреИрд░реЗрд▓рд▓) | рдЕрдЪреНрдЫрд╛ | рд╕реАрдорд┐рдд |
| **рдХреНрд╡рд╛рдВрдЯрд╛рдЗрдЬрд╝реЗрд╢рди** | рдЙрдиреНрдирдд (AWQ, GPTQ, FP8) | рд╕реНрд╡рдЪрд╛рд▓рд┐рдд | рдорд╛рдирдХ GGUF |
| **рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЬрд╝ рдлреАрдЪрд░реНрд╕** | рдХрд╕реНрдЯрдо рдЗрдВрдкреНрд▓реАрдореЗрдВрдЯреЗрд╢рди рдЖрд╡рд╢реНрдпрдХ | рдЕрдВрддрд░реНрдирд┐рд╣рд┐рдд | рд╕рд╛рдореБрджрд╛рдпрд┐рдХ рдЙрдкрдХрд░рдг |
| **рд╕рд░реНрд╡рд╢реНрд░реЗрд╖реНрда рдЙрдкрдпреЛрдЧ рдХреЗ рд▓рд┐рдП** | рдЙрдЪреНрдЪ-рд╕реНрддрд░реАрдп рдЙрддреНрдкрд╛рджрди рдПрдЬреЗрдВрдЯ | рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЬрд╝ рдЙрддреНрдкрд╛рджрди | рд╡рд┐рдХрд╛рд╕ |

**VLLM рдХрдм рдЪреБрдиреЗрдВ**:
- **рдЙрдЪреНрдЪ-рдереНрд░реВрдкреБрдЯ рдЖрд╡рд╢реНрдпрдХрддрд╛рдПрдВ**: рдкреНрд░рддрд┐ рд╕реЗрдХрдВрдб рд╕реИрдХрдбрд╝реЛрдВ рдЕрдиреБрд░реЛрдзреЛрдВ рдХреЛ рд╕рдВрд╕рд╛рдзрд┐рдд рдХрд░рдирд╛  
- **рдмрдбрд╝реЗ рдкреИрдорд╛рдиреЗ рдкрд░ рдбрд┐рдкреНрд▓реЙрдпрдореЗрдВрдЯ**: рдорд▓реНрдЯреА-GPU, рдорд▓реНрдЯреА-рдиреЛрдб рдбрд┐рдкреНрд▓реЙрдпрдореЗрдВрдЯ  
- **рдкреНрд░рджрд░реНрд╢рди рдорд╣рддреНрд╡рдкреВрд░реНрдг**: рдмрдбрд╝реЗ рдкреИрдорд╛рдиреЗ рдкрд░ рдЙрдк-рд╕реЗрдХрдВрдб рдкреНрд░рддрд┐рдХреНрд░рд┐рдпрд╛ рд╕рдордп  
- **рдЙрдиреНрдирдд рдСрдкреНрдЯрд┐рдорд╛рдЗрдЬрд╝реЗрд╢рди**: рдХрд╕реНрдЯрдо рдХреНрд╡рд╛рдВрдЯрд╛рдЗрдЬрд╝реЗрд╢рди рдФрд░ рдмреИрдЪрд┐рдВрдЧ рдХреА рдЖрд╡рд╢реНрдпрдХрддрд╛  
- **рд╕рдВрд╕рд╛рдзрди рджрдХреНрд╖рддрд╛**: рдорд╣рдВрдЧреЗ GPU рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рдХрд╛ рдЕрдзрд┐рдХрддрдо рдЙрдкрдпреЛрдЧ  

## рд╡рд╛рд╕реНрддрд╡рд┐рдХ рджреБрдирд┐рдпрд╛ рдХреЗ SLM рдПрдЬреЗрдВрдЯ рдЕрдиреБрдкреНрд░рдпреЛрдЧ

### рдЧреНрд░рд╛рд╣рдХ рд╕реЗрд╡рд╛ SLM рдПрдЬреЗрдВрдЯ
- **SLM рдХреНрд╖рдорддрд╛рдПрдВ**: рдЦрд╛рддрд╛ рдЦреЛрдЬ, рдкрд╛рд╕рд╡рд░реНрдб рд░реАрд╕реЗрдЯ, рдСрд░реНрдбрд░ рд╕реНрдерд┐рддрд┐ рдЬрд╛рдВрдЪ  
- **рд▓рд╛рдЧрдд рд▓рд╛рдн**: LLM рдПрдЬреЗрдВрдЯреЛрдВ рдХреА рддреБрд▓рдирд╛ рдореЗрдВ рдЗрдВрдлрд░реЗрдВрд╕ рд▓рд╛рдЧрдд рдореЗрдВ 10 рдЧреБрдирд╛ рдХрдореА  
- **рдкреНрд░рджрд░реНрд╢рди**: рдирд┐рдпрдорд┐рдд рдкреНрд░рд╢реНрдиреЛрдВ рдХреЗ рд▓рд┐рдП рддреЗрдЬрд╝ рдкреНрд░рддрд┐рдХреНрд░рд┐рдпрд╛ рд╕рдордп рдФрд░ рд╕реБрд╕рдВрдЧрдд рдЧреБрдгрд╡рддреНрддрд╛  

### рд╡реНрдпрд╛рдкрд╛рд░ рдкреНрд░рдХреНрд░рд┐рдпрд╛ SLM рдПрдЬреЗрдВрдЯ
- **рдЗрдирд╡реЙрдЗрд╕ рдкреНрд░реЛрд╕реЗрд╕рд┐рдВрдЧ рдПрдЬреЗрдВрдЯ**: рдбреЗрдЯрд╛ рдирд┐рдХрд╛рд▓реЗрдВ, рдЬрд╛рдирдХрд╛рд░реА рд╕рддреНрдпрд╛рдкрд┐рдд рдХрд░реЗрдВ, рдЕрдиреБрдореЛрджрди рдХреЗ рд▓рд┐рдП рд░реВрдЯ рдХрд░реЗрдВ  
- **рдИрдореЗрд▓ рдкреНрд░рдмрдВрдзрди рдПрдЬреЗрдВрдЯ**: рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рд░реВрдк рд╕реЗ рд╡рд░реНрдЧреАрдХреГрдд рдХрд░реЗрдВ, рдкреНрд░рд╛рдердорд┐рдХрддрд╛ рджреЗрдВ, рдЙрддреНрддрд░ рдХрд╛ рдорд╕реМрджрд╛ рддреИрдпрд╛рд░ рдХрд░реЗрдВ  
- **рд╢реЗрдбреНрдпреВрд▓рд┐рдВрдЧ рдПрдЬреЗрдВрдЯ**: рдореАрдЯрд┐рдВрдЧреНрд╕ рдХрд╛ рд╕рдордиреНрд╡рдп рдХрд░реЗрдВ, рдХреИрд▓реЗрдВрдбрд░ рдкреНрд░рдмрдВрдзрд┐рдд рдХрд░реЗрдВ, рд░рд┐рдорд╛рдЗрдВрдбрд░ рднреЗрдЬреЗрдВ  

### рд╡реНрдпрдХреНрддрд┐рдЧрдд SLM рдбрд┐рдЬрд┐рдЯрд▓ рд╕рд╣рд╛рдпрдХ
- **рдХрд╛рд░реНрдп рдкреНрд░рдмрдВрдзрди рдПрдЬреЗрдВрдЯ**: рдЯреВ-рдбреВ рд╕реВрдЪреА рдХреЛ рдХреБрд╢рд▓рддрд╛рдкреВрд░реНрд╡рдХ рдмрдирд╛рдПрдВ, рдЕрдкрдбреЗрдЯ рдХрд░реЗрдВ, рд╡реНрдпрд╡рд╕реНрдерд┐рдд рдХрд░реЗрдВ  
- **рд╕реВрдЪрдирд╛ рд╕рдВрдЧреНрд░рд╣ рдПрдЬреЗрдВрдЯ**: рд╡рд┐рд╖рдпреЛрдВ рдкрд░ рд╢реЛрдз рдХрд░реЗрдВ, рд╕реНрдерд╛рдиреАрдп рд░реВрдк рд╕реЗ рдирд┐рд╖реНрдХрд░реНрд╖реЛрдВ рдХрд╛ рд╕рд╛рд░рд╛рдВрд╢ рдмрдирд╛рдПрдВ  
- **рд╕рдВрдЪрд╛рд░ рдПрдЬреЗрдВрдЯ**: рдИрдореЗрд▓, рд╕рдВрджреЗрд╢, рд╕реЛрд╢рд▓ рдореАрдбрд┐рдпрд╛ рдкреЛрд╕реНрдЯ рдирд┐рдЬреА рддреМрд░ рдкрд░ рддреИрдпрд╛рд░ рдХрд░реЗрдВ  

### рдЯреНрд░реЗрдбрд┐рдВрдЧ рдФрд░ рд╡рд┐рддреНрддреАрдп SLM рдПрдЬреЗрдВрдЯ
- **рдорд╛рд░реНрдХреЗрдЯ рдореЙрдирд┐рдЯрд░рд┐рдВрдЧ рдПрдЬреЗрдВрдЯ**: рд╡рд╛рд╕реНрддрд╡рд┐рдХ рд╕рдордп рдореЗрдВ рдХреАрдорддреЛрдВ рдХреЛ рдЯреНрд░реИрдХ рдХрд░реЗрдВ, рд░реБрдЭрд╛рдиреЛрдВ рдХреА рдкрд╣рдЪрд╛рди рдХрд░реЗрдВ  
- **рд░рд┐рдкреЛрд░реНрдЯ рдЬрдирд░реЗрд╢рди рдПрдЬреЗрдВрдЯ**: рджреИрдирд┐рдХ/рд╕рд╛рдкреНрддрд╛рд╣рд┐рдХ рд╕рд╛рд░рд╛рдВрд╢ рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рд░реВрдк рд╕реЗ рдмрдирд╛рдПрдВ  
- **рдЬреЛрдЦрд┐рдо рдореВрд▓реНрдпрд╛рдВрдХрди рдПрдЬреЗрдВрдЯ**: рд╕реНрдерд╛рдиреАрдп рдбреЗрдЯрд╛ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рдкреЛрд░реНрдЯрдлреЛрд▓рд┐рдпреЛ рд╕реНрдерд┐рддрд┐ рдХрд╛ рдореВрд▓реНрдпрд╛рдВрдХрди рдХрд░реЗрдВ  

### рд╕реНрд╡рд╛рд╕реНрдереНрдп рд╕реЗрд╡рд╛ рд╕рдорд░реНрдерди SLM рдПрдЬреЗрдВрдЯ
- **рдорд░реАрдЬ рд╢реЗрдбреНрдпреВрд▓рд┐рдВрдЧ рдПрдЬреЗрдВрдЯ**: рдЕрдкреЙрдЗрдВрдЯрдореЗрдВрдЯ рдХрд╛ рд╕рдордиреНрд╡рдп рдХрд░реЗрдВ, рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рд░рд┐рдорд╛рдЗрдВрдбрд░ рднреЗрдЬреЗрдВ  
- **рдбреЙрдХреНрдпреВрдореЗрдВрдЯреЗрд╢рди рдПрдЬреЗрдВрдЯ**: рд╕реНрдерд╛рдиреАрдп рд░реВрдк рд╕реЗ рдореЗрдбрд┐рдХрд▓ рд╕рд╛рд░рд╛рдВрд╢, рд░рд┐рдкреЛрд░реНрдЯ рддреИрдпрд╛рд░ рдХрд░реЗрдВ  
- **рдкреНрд░рд┐рд╕реНрдХреНрд░рд┐рдкреНрд╢рди рдкреНрд░рдмрдВрдзрди рдПрдЬреЗрдВрдЯ**: рд░рд┐рдлрд┐рд▓реНрд╕ рдХреЛ рдЯреНрд░реИрдХ рдХрд░реЗрдВ, рдирд┐рдЬреА рддреМрд░ рдкрд░ рдЗрдВрдЯрд░реИрдХреНрд╢рди рдХреА рдЬрд╛рдВрдЪ рдХрд░реЗрдВ  

## Microsoft Agent Framework: рдЙрддреНрдкрд╛рджрди-рддреИрдпрд╛рд░ рдПрдЬреЗрдВрдЯ рд╡рд┐рдХрд╛рд╕

### рдЕрд╡рд▓реЛрдХрди рдФрд░ рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░

Microsoft Agent Framework рдПрдХ рд╡реНрдпрд╛рдкрдХ, рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЬрд╝-рдЧреНрд░реЗрдб рдкреНрд▓реЗрдЯрдлрд╝реЙрд░реНрдо рдкреНрд░рджрд╛рди рдХрд░рддрд╛ рд╣реИ, рдЬреЛ AI рдПрдЬреЗрдВрдЯреЛрдВ рдХреЛ рдмрдирд╛рдиреЗ, рддреИрдирд╛рдд рдХрд░рдиреЗ рдФрд░ рдкреНрд░рдмрдВрдзрд┐рдд рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдбрд┐рдЬрд╝рд╛рдЗрди рдХрд┐рдпрд╛ рдЧрдпрд╛ рд╣реИ, рдЬреЛ рдХреНрд▓рд╛рдЙрдб рдФрд░ рдСрдлрд▓рд╛рдЗрди рдПрдЬ рд╡рд╛рддрд╛рд╡рд░рдг рджреЛрдиреЛрдВ рдореЗрдВ рдХрд╛рдо рдХрд░ рд╕рдХрддреЗ рд╣реИрдВред рдпрд╣ рдлреНрд░реЗрдорд╡рд░реНрдХ рд╡рд┐рд╢реЗрд╖ рд░реВрдк рд╕реЗ рдЫреЛрдЯреЗ рднрд╛рд╖рд╛ рдореЙрдбрд▓реЛрдВ рдФрд░ рдПрдЬ рдХрдВрдкреНрдпреВрдЯрд┐рдВрдЧ рдкрд░рд┐рджреГрд╢реНрдпреЛрдВ рдХреЗ рд╕рд╛рде рд╕рд╣рдЬрддрд╛ рд╕реЗ рдХрд╛рдо рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдбрд┐рдЬрд╝рд╛рдЗрди рдХрд┐рдпрд╛ рдЧрдпрд╛ рд╣реИ, рдЬреЛ рдЧреЛрдкрдиреАрдпрддрд╛-рд╕рдВрд╡реЗрджрдирд╢реАрд▓ рдФрд░ рд╕рдВрд╕рд╛рдзрди-рд╕реАрдорд┐рдд рдбрд┐рдкреНрд▓реЙрдпрдореЗрдВрдЯ рдХреЗ рд▓рд┐рдП рдЖрджрд░реНрд╢ рд╣реИред

**рдореБрдЦреНрдп рдлреНрд░реЗрдорд╡рд░реНрдХ рдШрдЯрдХ**:
- **рдПрдЬреЗрдВрдЯ рд░рдирдЯрд╛рдЗрдо**: рдПрдЬ рдбрд┐рд╡рд╛рдЗрд╕ рдХреЗ рд▓рд┐рдП рдЕрдиреБрдХреВрд▓рд┐рдд рд╣рд▓реНрдХрд╛ рдирд┐рд╖реНрдкрд╛рджрди рд╡рд╛рддрд╛рд╡рд░рдг  
- **рдЯреВрд▓ рдЗрдВрдЯреАрдЧреНрд░реЗрд╢рди рд╕рд┐рд╕реНрдЯрдо**: рдмрд╛рд╣рд░реА рд╕реЗрд╡рд╛рдУрдВ рдФрд░ API рдХреЛ рдЬреЛрдбрд╝рдиреЗ рдХреЗ рд▓рд┐рдП рдПрдХреНрд╕рдЯреЗрдВрд╕рд┐рдмрд▓ рдкреНрд▓рдЧрдЗрди рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░  
- **рд╕реНрдЯреЗрдЯ рдореИрдиреЗрдЬрдореЗрдВрдЯ**: рд╕рддреНрд░реЛрдВ рдХреЗ рдмреАрдЪ рд╕реНрдерд╛рдпреА рдПрдЬреЗрдВрдЯ рдореЗрдореЛрд░реА рдФрд░ рд╕рдВрджрд░реНрдн рдкреНрд░рдмрдВрдзрди  
- **рд╕реБрд░рдХреНрд╖рд╛ рдкрд░рдд**: рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЬрд╝ рдбрд┐рдкреНрд▓реЙрдпрдореЗрдВрдЯ рдХреЗ рд▓рд┐рдП рдЕрдВрддрд░реНрдирд┐рд╣рд┐рдд рд╕реБрд░рдХреНрд╖рд╛ рдирд┐рдпрдВрддреНрд░рдг  
- **рдСрд░реНрдХреЗрд╕реНрдЯреНрд░реЗрд╢рди рдЗрдВрдЬрди**: рдорд▓реНрдЯреА-рдПрдЬреЗрдВрдЯ рд╕рдордиреНрд╡рдп рдФрд░ рд╡рд░реНрдХрдлрд╝реНрд▓реЛ рдкреНрд░рдмрдВрдзрди  

### рдПрдЬ рдбрд┐рдкреНрд▓реЙрдпрдореЗрдВрдЯ рдХреЗ рд▓рд┐рдП рдкреНрд░рдореБрдЦ рдлреАрдЪрд░реНрд╕

**рдСрдлрд▓рд╛рдЗрди-рдкреНрд░рдердо рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░**: Microsoft Agent Framework рдХреЛ рдСрдлрд▓рд╛рдЗрди-рдкреНрд░рдердо рд╕рд┐рджреНрдзрд╛рдВрддреЛрдВ рдХреЗ рд╕рд╛рде рдбрд┐рдЬрд╝рд╛рдЗрди рдХрд┐рдпрд╛ рдЧрдпрд╛ рд╣реИ, рдЬрд┐рд╕рд╕реЗ рдПрдЬреЗрдВрдЯ рдмрд┐рдирд╛ рдЗрдВрдЯрд░рдиреЗрдЯ рдХрдиреЗрдХреНрдЯрд┐рд╡рд┐рдЯреА рдХреЗ рдкреНрд░рднрд╛рд╡реА рдврдВрдЧ рд╕реЗ рдХрд╛рдо рдХрд░ рд╕рдХрддреЗ рд╣реИрдВред рдЗрд╕рдореЗрдВ рд╕реНрдерд╛рдиреАрдп рдореЙрдбрд▓ рдЗрдВрдлрд░реЗрдВрд╕, рдХреИрд╢реНрдб рдиреЙрд▓реЗрдЬ рдмреЗрд╕, рдСрдлрд▓рд╛рдЗрди рдЯреВрд▓ рдирд┐рд╖реНрдкрд╛рджрди, рдФрд░ рдХреНрд▓рд╛рдЙрдб рд╕реЗрд╡рд╛рдУрдВ рдХреА рдЕрдиреБрдкрд▓рдмреНрдзрддрд╛ рдХреЗ рджреМрд░рд╛рди рдЧреНрд░реЗрд╕рдлреБрд▓ рдбрд┐рдЧреНрд░реЗрдбреЗрд╢рди рд╢рд╛рдорд┐рд▓ рд╣реИред

**рд╕рдВрд╕рд╛рдзрди рдСрдкреНрдЯрд┐рдорд╛рдЗрдЬрд╝реЗрд╢рди**: рдлреНрд░реЗрдорд╡рд░реНрдХ SLMs рдХреЗ рд▓рд┐рдП рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рдореЗрдореЛрд░реА рдСрдкреНрдЯрд┐рдорд╛рдЗрдЬрд╝реЗрд╢рди, рдПрдЬ рдбрд┐рд╡рд╛рдЗрд╕ рдХреЗ рд▓рд┐рдП CPU/GPU рд▓реЛрдб рдмреИрд▓реЗрдВрд╕рд┐рдВрдЧ, рдЙрдкрд▓рдмреНрдз рд╕рдВрд╕рд╛рдзрдиреЛрдВ рдХреЗ рдЖрдзрд╛рд░ рдкрд░ рдЕрдиреБрдХреВрд▓реА рдореЙрдбрд▓ рдЪрдпрди, рдФрд░ рдореЛрдмрд╛рдЗрд▓ рдбрд┐рдкреНрд▓реЙрдпрдореЗрдВрдЯ рдХреЗ рд▓рд┐рдП рдкрд╛рд╡рд░-рдХреБрд╢рд▓ рдЗрдВрдлрд░реЗрдВрд╕ рдкреИрдЯрд░реНрди рдкреНрд░рджрд╛рди рдХрд░рддрд╛ рд╣реИред

**рд╕реБрд░рдХреНрд╖рд╛ рдФрд░ рдЧреЛрдкрдиреАрдпрддрд╛**: рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЬрд╝-рдЧреНрд░реЗрдб рд╕реБрд░рдХреНрд╖рд╛ рдлреАрдЪрд░реНрд╕ рдореЗрдВ рдЧреЛрдкрдиреАрдпрддрд╛ рдмрдирд╛рдП рд░рдЦрдиреЗ рдХреЗ рд▓рд┐рдП рд╕реНрдерд╛рдиреАрдп рдбреЗрдЯрд╛ рдкреНрд░реЛрд╕реЗрд╕рд┐рдВрдЧ, рдПрдиреНрдХреНрд░рд┐рдкреНрдЯреЗрдб рдПрдЬреЗрдВрдЯ рд╕рдВрдЪрд╛рд░ рдЪреИрдирд▓, рдПрдЬреЗрдВрдЯ рдХреНрд╖рдорддрд╛рдУрдВ рдХреЗ рд▓рд┐рдП рднреВрдорд┐рдХрд╛-рдЖрдзрд╛рд░рд┐рдд рдПрдХреНрд╕реЗрд╕ рдХрдВрдЯреНрд░реЛрд▓, рдФрд░ рдЕрдиреБрдкрд╛рд▓рди рдЖрд╡рд╢реНрдпрдХрддрд╛рдУрдВ рдХреЗ рд▓рд┐рдП рдСрдбрд┐рдЯ рд▓реЙрдЧрд┐рдВрдЧ рд╢рд╛рдорд┐рд▓ рд╣реИрдВред

### Foundry Local рдХреЗ рд╕рд╛рде рдЗрдВрдЯреАрдЧреНрд░реЗрд╢рди

Microsoft Agent Framework Foundry Local рдХреЗ рд╕рд╛рде рд╕рд╣рдЬрддрд╛ рд╕реЗ рдЗрдВрдЯреАрдЧреНрд░реЗрдЯ рд╣реЛрддрд╛ рд╣реИ, рдЬрд┐рд╕рд╕реЗ рдПрдХ рд╕рдВрдкреВрд░реНрдг рдПрдЬ AI рд╕рдорд╛рдзрд╛рди рдкреНрд░рджрд╛рди рд╣реЛрддрд╛ рд╣реИ:

**рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рдореЙрдбрд▓ рдбрд┐рд╕реНрдХрд╡рд░реА**: рдлреНрд░реЗрдорд╡рд░реНрдХ рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рд░реВрдк рд╕реЗ Foundry Local рдЗрдВрд╕реНрдЯреЗрдВрд╕ рдХрд╛ рдкрддрд╛ рд▓рдЧрд╛рддрд╛ рд╣реИ, рдЙрдкрд▓рдмреНрдз SLM рдореЙрдбрд▓реЛрдВ рд╕реЗ рдЬреБрдбрд╝рддрд╛ рд╣реИ, рдФрд░ рдПрдЬреЗрдВрдЯ рдЖрд╡рд╢реНрдпрдХрддрд╛рдУрдВ рдФрд░ рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рдХреНрд╖рдорддрд╛рдУрдВ рдХреЗ рдЖрдзрд╛рд░ рдкрд░ рдЗрд╖реНрдЯрддрдо рдореЙрдбрд▓ рдХрд╛ рдЪрдпрди рдХрд░рддрд╛ рд╣реИред

**рдбрд╛рдпрдирд╛рдорд┐рдХ рдореЙрдбрд▓ рд▓реЛрдбрд┐рдВрдЧ**: рдПрдЬреЗрдВрдЯ рд╡рд┐рд╢рд┐рд╖реНрдЯ рдХрд╛рд░реНрдпреЛрдВ рдХреЗ рд▓рд┐рдП рд╡рд┐рднрд┐рдиреНрди SLMs рдХреЛ рдбрд╛рдпрдирд╛рдорд┐рдХ рд░реВрдк рд╕реЗ рд▓реЛрдб рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ, рдЬрд┐рд╕рд╕реЗ рдорд▓реНрдЯреА-рдореЙрдбрд▓ рдПрдЬреЗрдВрдЯ рд╕рд┐рд╕реНрдЯрдо рд╕рдХреНрд╖рдо рд╣реЛрддрд╛ рд╣реИ, рдЬрд╣рд╛рдВ рд╡рд┐рднрд┐рдиреНрди рдореЙрдбрд▓ рд╡рд┐рднрд┐рдиреНрди рдкреНрд░рдХрд╛рд░ рдХреЗ рдЕрдиреБрд░реЛрдзреЛрдВ рдХреЛ рд╕рдВрднрд╛рд▓рддреЗ рд╣реИрдВ, рдФрд░ рдЙрдкрд▓рдмреНрдзрддрд╛ рдФрд░ рдкреНрд░рджрд░реНрд╢рди рдХреЗ рдЖрдзрд╛рд░ рдкрд░ рдореЙрдбрд▓реЛрдВ рдХреЗ рдмреАрдЪ рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рдлреЗрд▓рдУрд╡рд░ рд╣реЛрддрд╛ рд╣реИред

**рдкреНрд░рджрд░реНрд╢рди рдСрдкреНрдЯрд┐рдорд╛рдЗрдЬрд╝реЗрд╢рди**: рдПрдХреАрдХреГрдд рдХреИрд╢рд┐рдВрдЧ рддрдВрддреНрд░ рдореЙрдбрд▓ рд▓реЛрдбрд┐рдВрдЧ рд╕рдордп рдХреЛ рдХрдо рдХрд░рддрд╛ рд╣реИ, рдХрдиреЗрдХреНрд╢рди рдкреВрд▓рд┐рдВрдЧ Foundry Local рдХреЗ API рдХреЙрд▓ рдХреЛ рдСрдкреНрдЯрд┐рдорд╛рдЗрдЬрд╝ рдХрд░рддрд╛ рд╣реИ, рдФрд░ рдЗрдВрдЯреЗрд▓рд┐рдЬреЗрдВрдЯ рдмреИрдЪрд┐рдВрдЧ рдХрдИ рдПрдЬреЗрдВрдЯ рдЕрдиреБрд░реЛрдзреЛрдВ рдХреЗ рд▓рд┐рдП рдереНрд░реВрдкреБрдЯ рдореЗрдВ рд╕реБрдзрд╛рд░ рдХрд░рддрд╛ рд╣реИред

### Microsoft Agent Framework рдХреЗ рд╕рд╛рде рдПрдЬреЗрдВрдЯ рдмрдирд╛рдирд╛

#### рдПрдЬреЗрдВрдЯ рдкрд░рд┐рднрд╛рд╖рд╛ рдФрд░ рдХреЙрдиреНрдлрд╝рд┐рдЧрд░реЗрд╢рди

```python
from microsoft_agent_framework import Agent, Tool, Config
from foundry_local import FoundryLocalManager

# Configure agent with Foundry Local integration
config = Config(
    name="customer-service-agent",
    model_provider="foundry-local",
    model_alias="phi-4-mini",
    max_tokens=512,
    temperature=0.1,
    offline_mode=True
)

# Initialize Foundry Local connection
foundry = FoundryLocalManager("phi-4-mini")

# Create agent instance
agent = Agent(
    config=config,
    model_endpoint=foundry.endpoint,
    api_key=foundry.api_key
)
```
  
#### рдПрдЬ рдкрд░рд┐рджреГрд╢реНрдпреЛрдВ рдХреЗ рд▓рд┐рдП рдЯреВрд▓ рдЗрдВрдЯреАрдЧреНрд░реЗрд╢рди

```python
# Define tools for offline operation
@agent.tool
def lookup_customer_info(customer_id: str) -> dict:
    """Look up customer information from local database."""
    # Local database query - works offline
    return local_db.get_customer(customer_id)

@agent.tool
def create_support_ticket(issue: str, priority: str) -> str:
    """Create a support ticket in local system."""
    # Local ticket creation with sync when online
    ticket_id = local_system.create_ticket(issue, priority)
    return f"Ticket {ticket_id} created successfully"

@agent.tool
def schedule_callback(customer_id: str, preferred_time: str) -> str:
    """Schedule a callback for the customer."""
    # Local scheduling with calendar integration
    return local_calendar.schedule(customer_id, preferred_time)
```
  
#### рдорд▓реНрдЯреА-рдПрдЬреЗрдВрдЯ рдСрд░реНрдХреЗрд╕реНрдЯреНрд░реЗрд╢рди

```python
from microsoft_agent_framework import AgentOrchestrator

# Create specialized agents for different domains
scheduling_agent = Agent(
    config=Config(
        name="scheduling-agent",
        model_alias="qwen2.5-0.5b",  # Lightweight for simple tasks
        specialized_for="scheduling"
    )
)

technical_support_agent = Agent(
    config=Config(
        name="technical-agent",
        model_alias="phi-4-mini",  # More capable for complex issues
        specialized_for="technical_support"
    )
)

# Orchestrate multiple agents
orchestrator = AgentOrchestrator([
    scheduling_agent,
    technical_support_agent
])

# Route requests based on intent
result = orchestrator.process_request(
    "I need to schedule a callback for a technical issue",
    routing_strategy="intent-based"
)
```
  

### рдЙрдиреНрдирдд рдПрдЬ рдбрд┐рдкреНрд▓реЙрдпрдореЗрдВрдЯ рдкреИрдЯрд░реНрди

#### рдкрджрд╛рдиреБрдХреНрд░рдорд┐рдд рдПрдЬреЗрдВрдЯ рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░

**рд╕реНрдерд╛рдиреАрдп рдПрдЬреЗрдВрдЯ рдХреНрд▓рд╕реНрдЯрд░**: рдПрдЬ рдбрд┐рд╡рд╛рдЗрд╕ рдкрд░ рдХрдИ рд╡рд┐рд╢реЗрд╖реАрдХреГрдд SLM рдПрдЬреЗрдВрдЯ рддреИрдирд╛рдд рдХрд░реЗрдВ, рдкреНрд░рддреНрдпреЗрдХ рд╡рд┐рд╢рд┐рд╖реНрдЯ рдХрд╛рд░реНрдпреЛрдВ рдХреЗ рд▓рд┐рдП рдЕрдиреБрдХреВрд▓рд┐рддред рд╕рд░рд▓ рд░реВрдЯрд┐рдВрдЧ рдФрд░ рд╢реЗрдбреНрдпреВрд▓рд┐рдВрдЧ рдХреЗ рд▓рд┐рдП Qwen2.5-0.5B рдЬреИрд╕реЗ рд╣рд▓реНрдХреЗ рдореЙрдбрд▓ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВ, рдЧреНрд░рд╛рд╣рдХ рд╕реЗрд╡рд╛ рдФрд░ рдбреЙрдХреНрдпреВрдореЗрдВрдЯреЗрд╢рди рдХреЗ рд▓рд┐рдП Phi-4-Mini рдЬреИрд╕реЗ рдордзреНрдпрдо рдореЙрдбрд▓, рдФрд░ рдЬрдЯрд┐рд▓ рддрд░реНрдХ рдХреЗ рд▓рд┐рдП рдмрдбрд╝реЗ рдореЙрдбрд▓ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВ рдЬрдм рд╕рдВрд╕рд╛рдзрди рдЕрдиреБрдорддрд┐ рджреЗрдВред

**рдПрдЬ-рдЯреВ-рдХреНрд▓рд╛рдЙрдб рд╕рдордиреНрд╡рдп**: рдмреБрджреНрдзрд┐рдорд╛рди рдПрд╕реНрдХреЗрд▓реЗрд╢рди рдкреИрдЯрд░реНрди рд▓рд╛рдЧреВ рдХрд░реЗрдВ рдЬрд╣рд╛рдВ рд╕реНрдерд╛рдиреАрдп рдПрдЬреЗрдВрдЯ рдирд┐рдпрдорд┐рдд рдХрд╛рд░реНрдпреЛрдВ рдХреЛ рд╕рдВрднрд╛рд▓рддреЗ рд╣реИрдВ, рдХреНрд▓рд╛рдЙрдб рдПрдЬреЗрдВрдЯ рдХрдиреЗрдХреНрдЯрд┐рд╡рд┐рдЯреА рдХреА рдЕрдиреБрдорддрд┐ рдорд┐рд▓рдиреЗ рдкрд░ рдЬрдЯрд┐рд▓ рддрд░реНрдХ рдкреНрд░рджрд╛рди рдХрд░рддреЗ рд╣реИрдВ, рдФрд░ рдПрдЬ рдФрд░ рдХреНрд▓рд╛рдЙрдб рдкреНрд░реЛрд╕реЗрд╕рд┐рдВрдЧ рдХреЗ рдмреАрдЪ рд╕рд╣рдЬ рд╣реИрдВрдбрдСрдл рдирд┐рд░рдВрддрд░рддрд╛ рдмрдирд╛рдП рд░рдЦрддрд╛ рд╣реИред

#### рдбрд┐рдкреНрд▓реЙрдпрдореЗрдВрдЯ рдХреЙрдиреНрдлрд╝рд┐рдЧрд░реЗрд╢рди

**рд╕рд┐рдВрдЧрд▓ рдбрд┐рд╡рд╛рдЗрд╕ рдбрд┐рдкреНрд▓реЙрдпрдореЗрдВрдЯ**:  
```yaml
deployment:
  type: single-device
  hardware: edge-device
  models:
    - alias: "phi-4-mini"
      primary: true
      tasks: ["conversation", "reasoning"]
    - alias: "qwen2.5-0.5b"
      secondary: true
      tasks: ["routing", "classification"]
  agents:
    - name: "primary-agent"
      model: "phi-4-mini"
      tools: ["database", "calendar", "email"]
```
  
**рд╡рд┐рддрд░рд┐рдд рдПрдЬ рдбрд┐рдкреНрд▓реЙрдпрдореЗрдВрдЯ**:  
```yaml
deployment:
  type: distributed-edge
  nodes:
    - id: "edge-1"
      agents: ["customer-service", "scheduling"]
      models: ["phi-4-mini"]
    - id: "edge-2"
      agents: ["technical-support", "documentation"]
      models: ["qwen2.5-coder-0.5b"]
  coordination:
    load_balancing: true
    failover: automatic
```
  

### рдПрдЬ рдПрдЬреЗрдВрдЯреЛрдВ рдХреЗ рд▓рд┐рдП рдкреНрд░рджрд░реНрд╢рди рдСрдкреНрдЯрд┐рдорд╛рдЗрдЬрд╝реЗрд╢рди

#### рдореЙрдбрд▓ рдЪрдпрди рд░рдгрдиреАрддрд┐рдпрд╛рдВ

**рдХрд╛рд░реНрдп-рдЖрдзрд╛рд░рд┐рдд рдореЙрдбрд▓ рдЕрд╕рд╛рдЗрдирдореЗрдВрдЯ**: Microsoft Agent Framework рдХрд╛рд░реНрдп рдХреА рдЬрдЯрд┐рд▓рддрд╛ рдФрд░ рдЖрд╡рд╢реНрдпрдХрддрд╛рдУрдВ рдХреЗ рдЖрдзрд╛рд░ рдкрд░ рдмреБрджреНрдзрд┐рдорд╛рди рдореЙрдбрд▓ рдЪрдпрди рд╕рдХреНрд╖рдо рдХрд░рддрд╛ рд╣реИ:

- **рд╕рд░рд▓ рдХрд╛рд░реНрдп** (Q&A, рд░реВрдЯрд┐рдВрдЧ): Qwen2.5-0.5B (500MB, <100ms рдкреНрд░рддрд┐рдХреНрд░рд┐рдпрд╛)  
- **рдордзреНрдпрдо рдХрд╛рд░реНрдп** (рдЧреНрд░рд╛рд╣рдХ рд╕реЗрд╡рд╛, рд╢реЗрдбреНрдпреВрд▓рд┐рдВрдЧ): Phi-4-Mini (2.4GB, 200-500ms рдкреНрд░рддрд┐рдХреНрд░рд┐рдпрд╛)  
- **рдЬрдЯрд┐рд▓ рдХрд╛рд░реНрдп** (рддрдХрдиреАрдХреА рд╡рд┐рд╢реНрд▓реЗрд╖рдг, рдпреЛрдЬрдирд╛): Phi-4 (7GB, 1-3s рдкреНрд░рддрд┐рдХреНрд░рд┐рдпрд╛ рдЬрдм рд╕рдВрд╕рд╛рдзрди рдЕрдиреБрдорддрд┐ рджреЗрдВ)  

**рдбрд╛рдпрдирд╛рдорд┐рдХ рдореЙрдбрд▓ рд╕реНрд╡рд┐рдЪрд┐рдВрдЧ**: рдПрдЬреЗрдВрдЯ рд╡рд░реНрддрдорд╛рди рд╕рд┐рд╕реНрдЯрдо рд▓реЛрдб, рдХрд╛рд░реНрдп рдХреА рдЬрдЯрд┐рд▓рддрд╛ рдореВрд▓реНрдпрд╛рдВрдХрди, рдЙрдкрдпреЛрдЧрдХрд░реНрддрд╛ рдкреНрд░рд╛рдердорд┐рдХрддрд╛ рд╕реНрддрд░, рдФрд░ рдЙрдкрд▓рдмреНрдз рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рд╕рдВрд╕рд╛рдзрдиреЛрдВ рдХреЗ рдЖрдзрд╛рд░ рдкрд░ рдореЙрдбрд▓реЛрдВ рдХреЗ рдмреАрдЪ рд╕реНрд╡рд┐рдЪ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВред

#### рдореЗрдореЛрд░реА рдФрд░ рд╕рдВрд╕рд╛рдзрди рдкреНрд░рдмрдВрдзрди

```python
# Configure resource constraints for edge deployment
resource_config = ResourceConfig(
    max_memory_usage="4GB",
    max_concurrent_agents=3,
    model_cache_size="2GB",
    auto_unload_idle_models=True,
    power_management=True
)

agent = Agent(
    config=config,
    resource_limits=resource_config
)
```
  

### рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЬрд╝ рдЗрдВрдЯреАрдЧреНрд░реЗрд╢рди рдкреИрдЯрд░реНрди

#### рд╕реБрд░рдХреНрд╖рд╛ рдФрд░ рдЕрдиреБрдкрд╛рд▓рди

**рд╕реНрдерд╛рдиреАрдп рдбреЗрдЯрд╛ рдкреНрд░реЛрд╕реЗрд╕рд┐рдВрдЧ**: рд╕рднреА рдПрдЬреЗрдВрдЯ рдкреНрд░реЛрд╕реЗрд╕рд┐рдВрдЧ рд╕реНрдерд╛рдиреАрдп рд░реВрдк рд╕реЗ рд╣реЛрддреА рд╣реИ, рдЬрд┐рд╕рд╕реЗ рд╕рдВрд╡реЗрджрдирд╢реАрд▓ рдбреЗрдЯрд╛ рдХрднреА рднреА рдПрдЬ рдбрд┐рд╡рд╛рдЗрд╕ рд╕реЗ рдмрд╛рд╣рд░ рдирд╣реАрдВ рдЬрд╛рддрд╛ред рдЗрд╕рдореЗрдВ рдЧреНрд░рд╛рд╣рдХ рдЬрд╛рдирдХрд╛рд░реА рдХреА рд╕реБрд░рдХреНрд╖рд╛, рд╕реНрд╡рд╛рд╕реНрдереНрдп рд╕реЗрд╡рд╛ рдПрдЬреЗрдВрдЯреЛрдВ рдХреЗ рд▓рд┐рдП HIPAA рдЕрдиреБрдкрд╛рд▓рди, рдмреИрдВрдХрд┐рдВрдЧ рдПрдЬреЗрдВрдЯреЛрдВ рдХреЗ рд▓рд┐рдП рд╡рд┐рддреНрддреАрдп рдбреЗрдЯрд╛ рд╕реБрд░рдХреНрд╖рд╛, рдФрд░ рдпреВрд░реЛрдкреАрдп рдбрд┐рдкреНрд▓реЙрдпрдореЗрдВрдЯ рдХреЗ рд▓рд┐рдП GDPR рдЕрдиреБрдкрд╛рд▓рди рд╢рд╛рдорд┐рд▓ рд╣реИред

**рдПрдХреНрд╕реЗрд╕ рдХрдВрдЯреНрд░реЛрд▓**: рднреВрдорд┐рдХрд╛-рдЖрдзрд╛рд░рд┐рдд рдЕрдиреБрдорддрд┐рдпрд╛рдВ рдирд┐рдпрдВрддреНрд░рд┐рдд рдХрд░рддреА рд╣реИрдВ рдХрд┐ рдПрдЬреЗрдВрдЯ рдХреМрди рд╕реЗ рдЙрдкрдХрд░рдг рдПрдХреНрд╕реЗрд╕ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ, рдПрдЬреЗрдВрдЯ рдЗрдВрдЯрд░реИрдХреНрд╢рди рдХреЗ рд▓рд┐рдП рдЙрдкрдпреЛрдЧрдХрд░реНрддрд╛ рдкреНрд░рдорд╛рдгреАрдХрд░рдг, рдФрд░ рд╕рднреА рдПрдЬреЗрдВрдЯ рдХреНрд░рд┐рдпрд╛рдУрдВ рдФрд░ рдирд┐рд░реНрдгрдпреЛрдВ рдХреЗ рд▓рд┐рдП рдСрдбрд┐рдЯ рдЯреНрд░реЗрд▓реНрд╕ред

#### рдореЙрдирд┐рдЯрд░рд┐рдВрдЧ рдФрд░ рдСрдмреНрдЬрд╝рд░реНрд╡реЗрдмрд┐рд▓рд┐рдЯреА

```python
from microsoft_agent_framework import AgentMonitor

# Set up monitoring for edge agents
monitor = AgentMonitor(
    metrics=["response_time", "success_rate", "resource_usage"],
    alerts=[
        {"metric": "response_time", "threshold": "2s", "action": "scale_down_model"},
        {"metric": "memory_usage", "threshold": "80%", "action": "unload_idle_agents"}
    ],
    local_storage=True  # Store metrics locally for offline operation
)

agent.add_monitor(monitor)
```
  

### рд╡рд╛рд╕реНрддрд╡рд┐рдХ рджреБрдирд┐рдпрд╛ рдХреЗ рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди рдЙрджрд╛рд╣рд░рдг

#### рд░рд┐рдЯреЗрд▓ рдПрдЬ рдПрдЬреЗрдВрдЯ рд╕рд┐рд╕реНрдЯрдо

```python
# Retail kiosk agent for in-store customer assistance
retail_agent = Agent(
    config=Config(
        name="retail-assistant",
        model_alias="phi-4-mini",
        context="You are a helpful retail assistant in an electronics store."
    )
)

@retail_agent.tool
def check_inventory(product_sku: str) -> dict:
    """Check local inventory for a product."""
    return local_inventory.lookup(product_sku)

@retail_agent.tool
def find_alternatives(product_category: str) -> list:
    """Find alternative products in the same category."""
    return local_catalog.find_similar(product_category)

@retail_agent.tool
def create_price_quote(items: list) -> dict:
    """Generate a price quote for multiple items."""
    return pricing_engine.calculate_quote(items)
```
  
#### рд╕реНрд╡рд╛рд╕реНрдереНрдп рд╕реЗрд╡рд╛ рд╕рдорд░реНрдерди рдПрдЬреЗрдВрдЯ

```python
# HIPAA-compliant patient support agent
healthcare_agent = Agent(
    config=Config(
        name="patient-support",
        model_alias="phi-4-mini",
        privacy_mode=True,  # Enhanced privacy for healthcare
        compliance=["HIPAA"]
    )
)

@healthcare_agent.tool
def check_appointment_availability(provider_id: str, date_range: str) -> list:
    """Check appointment slots with healthcare provider."""
    return local_scheduling.get_availability(provider_id, date_range)

@healthcare_agent.tool
def access_patient_portal(patient_id: str, auth_token: str) -> dict:
    """Secure access to patient information."""
    if security.validate_token(auth_token):
        return patient_portal.get_summary(patient_id)
    return {"error": "Authentication failed"}
```
  

### Microsoft Agent Framework рдХреЗ рд▓рд┐рдП рд╕рд░реНрд╡реЛрддреНрддрдо рдкреНрд░рдерд╛рдПрдВ

#### рд╡рд┐рдХрд╛рд╕ рджрд┐рд╢рд╛рдирд┐рд░реНрджреЗрд╢

1. **рд╕рд░рд▓ рд╢реБрд░реБрдЖрдд рдХрд░реЗрдВ**: рдЬрдЯрд┐рд▓ рдорд▓реНрдЯреА-рдПрдЬреЗрдВрдЯ рд╕рд┐рд╕реНрдЯрдо рдмрдирд╛рдиреЗ рд╕реЗ рдкрд╣рд▓реЗ рд╕рд┐рдВрдЧрд▓-рдПрдЬреЗрдВрдЯ рдкрд░рд┐рджреГрд╢реНрдпреЛрдВ рд╕реЗ рд╢реБрд░реВ рдХрд░реЗрдВ  
2. **рдореЙрдбрд▓ рд░рд╛рдЗрдЯ-рд╕рд╛рдЗ
**рдПрдЬреЗрдВрдЯ рддреИрдирд╛рддреА рдХреЗ рд▓рд┐рдП рдлреНрд░реЗрдорд╡рд░реНрдХ рдЪрдпрди**: рд▓рдХреНрд╖реНрдп рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рдФрд░ рдПрдЬреЗрдВрдЯ рдЖрд╡рд╢реНрдпрдХрддрд╛рдУрдВ рдХреЗ рдЖрдзрд╛рд░ рдкрд░ рдЕрдиреБрдХреВрд▓рди рдлреНрд░реЗрдорд╡рд░реНрдХ рдЪреБрдиреЗрдВред CPU-рдЕрдиреБрдХреВрд▓рд┐рдд рдПрдЬреЗрдВрдЯ рддреИрдирд╛рддреА рдХреЗ рд▓рд┐рдП Llama.cpp рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВ, Apple Silicon рдПрдЬреЗрдВрдЯ рдЕрдиреБрдкреНрд░рдпреЛрдЧреЛрдВ рдХреЗ рд▓рд┐рдП Apple MLX рдФрд░ рдХреНрд░реЙрд╕-рдкреНрд▓реЗрдЯрдлрд╝реЙрд░реНрдо рдПрдЬреЗрдВрдЯ рд╕рдВрдЧрддрддрд╛ рдХреЗ рд▓рд┐рдП ONNX рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВред

## рд╡реНрдпрд╛рд╡рд╣рд╛рд░рд┐рдХ SLM рдПрдЬреЗрдВрдЯ рд░реВрдкрд╛рдВрддрд░рдг рдФрд░ рдЙрдкрдпреЛрдЧ рдХреЗ рдорд╛рдорд▓реЗ

### рд╡рд╛рд╕реНрддрд╡рд┐рдХ рджреБрдирд┐рдпрд╛ рдХреЗ рдПрдЬреЗрдВрдЯ рддреИрдирд╛рддреА рдкрд░рд┐рджреГрд╢реНрдп

**рдореЛрдмрд╛рдЗрд▓ рдПрдЬреЗрдВрдЯ рдЕрдиреБрдкреНрд░рдпреЛрдЧ**: рд╕реНрдорд╛рд░реНрдЯрдлреЛрди рдПрдЬреЗрдВрдЯ рдЕрдиреБрдкреНрд░рдпреЛрдЧреЛрдВ рдХреЗ рд▓рд┐рдП Q4_K рдкреНрд░рд╛рд░реВрдк рдиреНрдпреВрдирддрдо рдореЗрдореЛрд░реА рдЙрдкрдпреЛрдЧ рдХреЗ рд╕рд╛рде рдЙрддреНрдХреГрд╖реНрдЯ рд╣реИ, рдЬрдмрдХрд┐ Q8_0 рдЯреИрдмрд▓реЗрдЯ-рдЖрдзрд╛рд░рд┐рдд рдПрдЬреЗрдВрдЯ рд╕рд┐рд╕реНрдЯрдо рдХреЗ рд▓рд┐рдП рд╕рдВрддреБрд▓рд┐рдд рдкреНрд░рджрд░реНрд╢рди рдкреНрд░рджрд╛рди рдХрд░рддрд╛ рд╣реИред Q5_K рдкреНрд░рд╛рд░реВрдк рдореЛрдмрд╛рдЗрд▓ рдЙрддреНрдкрд╛рджрдХрддрд╛ рдПрдЬреЗрдВрдЯреЛрдВ рдХреЗ рд▓рд┐рдП рдЙрдЪреНрдЪ рдЧреБрдгрд╡рддреНрддрд╛ рдкреНрд░рджрд╛рди рдХрд░рддрд╛ рд╣реИред

**рдбреЗрд╕реНрдХрдЯреЙрдк рдФрд░ рдПрдЬ рдПрдЬреЗрдВрдЯ рдХрдВрдкреНрдпреВрдЯрд┐рдВрдЧ**: Q5_K рдбреЗрд╕реНрдХрдЯреЙрдк рдПрдЬреЗрдВрдЯ рдЕрдиреБрдкреНрд░рдпреЛрдЧреЛрдВ рдХреЗ рд▓рд┐рдП рдЗрд╖реНрдЯрддрдо рдкреНрд░рджрд░реНрд╢рди рдкреНрд░рджрд╛рди рдХрд░рддрд╛ рд╣реИ, Q8_0 рд╡рд░реНрдХрд╕реНрдЯреЗрд╢рди рдПрдЬреЗрдВрдЯ рд╡рд╛рддрд╛рд╡рд░рдг рдХреЗ рд▓рд┐рдП рдЙрдЪреНрдЪ рдЧреБрдгрд╡рддреНрддрд╛ рд╡рд╛рд▓реА рдЗрдирдлреЗрд░реЗрдВрд╕ рдкреНрд░рджрд╛рди рдХрд░рддрд╛ рд╣реИ, рдФрд░ Q4_K рдПрдЬ рдПрдЬреЗрдВрдЯ рдЙрдкрдХрд░рдгреЛрдВ рдкрд░ рдХреБрд╢рд▓ рдкреНрд░рд╕рдВрд╕реНрдХрд░рдг рд╕рдХреНрд╖рдо рдХрд░рддрд╛ рд╣реИред

**рдЕрдиреБрд╕рдВрдзрд╛рди рдФрд░ рдкреНрд░рдпреЛрдЧрд╛рддреНрдордХ рдПрдЬреЗрдВрдЯ**: рдЙрдиреНрдирдд рдХреНрд╡рд╛рдВрдЯрд╛рдЗрдЬреЗрд╢рди рдкреНрд░рд╛рд░реВрдк рдЕрддреНрдпрдзрд┐рдХ рд╕рдВрд╕рд╛рдзрди рд╕реАрдорд╛рдУрдВ рдХреА рдЖрд╡рд╢реНрдпрдХрддрд╛ рд╡рд╛рд▓реЗ рд╢реИрдХреНрд╖рдгрд┐рдХ рдЕрдиреБрд╕рдВрдзрд╛рди рдФрд░ рдкреНрд░реВрдл-рдСрдл-рдХреЙрдиреНрд╕реЗрдкреНрдЯ рдПрдЬреЗрдВрдЯ рдЕрдиреБрдкреНрд░рдпреЛрдЧреЛрдВ рдХреЗ рд▓рд┐рдП рдЕрд▓реНрдЯреНрд░рд╛-рд▓реЛ рдкреНрд░рд┐рд╕рд┐рдЬрди рдПрдЬреЗрдВрдЯ рдЗрдирдлреЗрд░реЗрдВрд╕ рдХрд╛ рдЕрдиреНрд╡реЗрд╖рдг рдХрд░рдиреЗ рдореЗрдВ рд╕рдХреНрд╖рдо рдмрдирд╛рддреЗ рд╣реИрдВред

### SLM рдПрдЬреЗрдВрдЯ рдкреНрд░рджрд░реНрд╢рди рдмреЗрдВрдЪрдорд╛рд░реНрдХ

**рдПрдЬреЗрдВрдЯ рдЗрдирдлреЗрд░реЗрдВрд╕ рдЧрддрд┐**: Q4_K рдореЛрдмрд╛рдЗрд▓ CPUs рдкрд░ рд╕рдмрд╕реЗ рддреЗрдЬрд╝ рдПрдЬреЗрдВрдЯ рдкреНрд░рддрд┐рдХреНрд░рд┐рдпрд╛ рд╕рдордп рдкреНрд░рд╛рдкреНрдд рдХрд░рддрд╛ рд╣реИ, Q5_K рд╕рд╛рдорд╛рдиреНрдп рдПрдЬреЗрдВрдЯ рдЕрдиреБрдкреНрд░рдпреЛрдЧреЛрдВ рдХреЗ рд▓рд┐рдП рд╕рдВрддреБрд▓рд┐рдд рдЧрддрд┐-рдЧреБрдгрд╡рддреНрддрд╛ рдЕрдиреБрдкрд╛рдд рдкреНрд░рджрд╛рди рдХрд░рддрд╛ рд╣реИ, Q8_0 рдЬрдЯрд┐рд▓ рдПрдЬреЗрдВрдЯ рдХрд╛рд░реНрдпреЛрдВ рдХреЗ рд▓рд┐рдП рдЙрдЪреНрдЪ рдЧреБрдгрд╡рддреНрддрд╛ рдкреНрд░рджрд╛рди рдХрд░рддрд╛ рд╣реИ, рдФрд░ рдкреНрд░рдпреЛрдЧрд╛рддреНрдордХ рдкреНрд░рд╛рд░реВрдк рд╡рд┐рд╢реЗрд╖ рдПрдЬреЗрдВрдЯ рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рдХреЗ рд▓рд┐рдП рдЕрдзрд┐рдХрддрдо рдереНрд░реВрдкреБрдЯ рдкреНрд░рджрд╛рди рдХрд░рддреЗ рд╣реИрдВред

**рдПрдЬреЗрдВрдЯ рдореЗрдореЛрд░реА рдЖрд╡рд╢реНрдпрдХрддрд╛рдПрдБ**: рдПрдЬреЗрдВрдЯреЛрдВ рдХреЗ рд▓рд┐рдП рдХреНрд╡рд╛рдВрдЯрд╛рдЗрдЬреЗрд╢рди рд╕реНрддрд░ Q2_K (рдЫреЛрдЯреЗ рдПрдЬреЗрдВрдЯ рдореЙрдбрд▓ рдХреЗ рд▓рд┐рдП 500MB рд╕реЗ рдХрдо) рд╕реЗ Q8_0 (рдореВрд▓ рдЖрдХрд╛рд░ рдХрд╛ рд▓рдЧрднрдЧ 50%) рддрдХ рд╣реЛрддреЗ рд╣реИрдВ, рдФрд░ рд╕рдВрд╕рд╛рдзрди-рд╕реАрдорд┐рдд рдПрдЬреЗрдВрдЯ рд╡рд╛рддрд╛рд╡рд░рдг рдХреЗ рд▓рд┐рдП рдЕрдзрд┐рдХрддрдо рд╕рдВрдкреАрдбрд╝рди рдкреНрд░рд╛рдкреНрдд рдХрд░рдиреЗ рд╡рд╛рд▓реЗ рдкреНрд░рдпреЛрдЧрд╛рддреНрдордХ рдХреЙрдиреНрдлрд╝рд┐рдЧрд░реЗрд╢рдиред

## SLM рдПрдЬреЗрдВрдЯреЛрдВ рдХреЗ рд▓рд┐рдП рдЪреБрдиреМрддрд┐рдпрд╛рдБ рдФрд░ рд╡рд┐рдЪрд╛рд░

### рдПрдЬреЗрдВрдЯ рд╕рд┐рд╕реНрдЯрдо рдореЗрдВ рдкреНрд░рджрд░реНрд╢рди рд╕рдордЭреМрддреЗ

SLM рдПрдЬреЗрдВрдЯ рддреИрдирд╛рддреА рдореЗрдВ рдореЙрдбрд▓ рдЖрдХрд╛рд░, рдПрдЬреЗрдВрдЯ рдкреНрд░рддрд┐рдХреНрд░рд┐рдпрд╛ рдЧрддрд┐, рдФрд░ рдЖрдЙрдЯрдкреБрдЯ рдЧреБрдгрд╡рддреНрддрд╛ рдХреЗ рдмреАрдЪ рд╕рдордЭреМрддреЗ рдХрд╛ рд╕рд╛рд╡рдзрд╛рдиреАрдкреВрд░реНрд╡рдХ рд╡рд┐рдЪрд╛рд░ рдХрд░рдирд╛ рд╢рд╛рдорд┐рд▓ рд╣реИред рдЬрдмрдХрд┐ Q4_K рдореЛрдмрд╛рдЗрд▓ рдПрдЬреЗрдВрдЯреЛрдВ рдХреЗ рд▓рд┐рдП рдЕрд╕рд╛рдзрд╛рд░рдг рдЧрддрд┐ рдФрд░ рджрдХреНрд╖рддрд╛ рдкреНрд░рджрд╛рди рдХрд░рддрд╛ рд╣реИ, Q8_0 рдЬрдЯрд┐рд▓ рдПрдЬреЗрдВрдЯ рдХрд╛рд░реНрдпреЛрдВ рдХреЗ рд▓рд┐рдП рдЙрдЪреНрдЪ рдЧреБрдгрд╡рддреНрддрд╛ рдкреНрд░рджрд╛рди рдХрд░рддрд╛ рд╣реИред Q5_K рдЕрдзрд┐рдХрд╛рдВрд╢ рд╕рд╛рдорд╛рдиреНрдп рдПрдЬреЗрдВрдЯ рдЕрдиреБрдкреНрд░рдпреЛрдЧреЛрдВ рдХреЗ рд▓рд┐рдП рдПрдХ рдордзреНрдп рдорд╛рд░реНрдЧ рдкреНрд░рджрд╛рди рдХрд░рддрд╛ рд╣реИред

### SLM рдПрдЬреЗрдВрдЯреЛрдВ рдХреЗ рд▓рд┐рдП рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рд╕рдВрдЧрддрддрд╛

рд╡рд┐рднрд┐рдиреНрди рдПрдЬ рдЙрдкрдХрд░рдгреЛрдВ рдореЗрдВ SLM рдПрдЬреЗрдВрдЯ рддреИрдирд╛рддреА рдХреЗ рд▓рд┐рдП рдЕрд▓рдЧ-рдЕрд▓рдЧ рдХреНрд╖рдорддрд╛рдПрдБ рд╣реЛрддреА рд╣реИрдВред Q4_K рд╕рд░рд▓ рдПрдЬреЗрдВрдЯреЛрдВ рдХреЗ рд▓рд┐рдП рдмреБрдирд┐рдпрд╛рджреА рдкреНрд░реЛрд╕реЗрд╕рд░ рдкрд░ рдХреБрд╢рд▓рддрд╛ рд╕реЗ рдЪрд▓рддрд╛ рд╣реИ, Q5_K рд╕рдВрддреБрд▓рд┐рдд рдПрдЬреЗрдВрдЯ рдкреНрд░рджрд░реНрд╢рди рдХреЗ рд▓рд┐рдП рдордзреНрдпрдо рдХрдВрдкреНрдпреВрдЯреЗрд╢рдирд▓ рд╕рдВрд╕рд╛рдзрдиреЛрдВ рдХреА рдЖрд╡рд╢реНрдпрдХрддрд╛ рд╣реЛрддреА рд╣реИ, рдФрд░ Q8_0 рдЙрдиреНрдирдд рдПрдЬреЗрдВрдЯ рдХреНрд╖рдорддрд╛рдУрдВ рдХреЗ рд▓рд┐рдП рдЙрдЪреНрдЪ-рд╕реНрддрд░реАрдп рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рд╕реЗ рд▓рд╛рдн рдЙрдард╛рддрд╛ рд╣реИред

### SLM рдПрдЬреЗрдВрдЯ рд╕рд┐рд╕реНрдЯрдо рдореЗрдВ рд╕реБрд░рдХреНрд╖рд╛ рдФрд░ рдЧреЛрдкрдиреАрдпрддрд╛

SLM рдПрдЬреЗрдВрдЯ рд╕реНрдерд╛рдиреАрдп рдкреНрд░рд╕рдВрд╕реНрдХрд░рдг рдХреЛ рд╕рдХреНрд╖рдо рдХрд░рддреЗ рд╣реИрдВ рдЬрд┐рд╕рд╕реЗ рдЧреЛрдкрдиреАрдпрддрд╛ рдореЗрдВ рд╕реБрдзрд╛рд░ рд╣реЛрддрд╛ рд╣реИ, рд▓реЗрдХрд┐рди рдПрдЬ рд╡рд╛рддрд╛рд╡рд░рдг рдореЗрдВ рдПрдЬреЗрдВрдЯ рдореЙрдбрд▓ рдФрд░ рдбреЗрдЯрд╛ рдХреА рд╕реБрд░рдХреНрд╖рд╛ рдХреЗ рд▓рд┐рдП рдЙрдЪрд┐рдд рд╕реБрд░рдХреНрд╖рд╛ рдЙрдкрд╛рдп рд▓рд╛рдЧреВ рдХрд░рдиреЗ рдХреА рдЖрд╡рд╢реНрдпрдХрддрд╛ рд╣реЛрддреА рд╣реИред рдпрд╣ рд╡рд┐рд╢реЗрд╖ рд░реВрдк рд╕реЗ рдорд╣рддреНрд╡рдкреВрд░реНрдг рд╣реИ рдЬрдм рдЙрдЪреНрдЪ-рдкреНрд░рд┐рд╕рд┐рдЬрди рдПрдЬреЗрдВрдЯ рдкреНрд░рд╛рд░реВрдкреЛрдВ рдХреЛ рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЬрд╝ рд╡рд╛рддрд╛рд╡рд░рдг рдореЗрдВ рдпрд╛ рд╕рдВрдХреБрдЪрд┐рдд рдПрдЬреЗрдВрдЯ рдкреНрд░рд╛рд░реВрдкреЛрдВ рдХреЛ рд╕рдВрд╡реЗрджрдирд╢реАрд▓ рдбреЗрдЯрд╛ рдХреЛ рд╕рдВрднрд╛рд▓рдиреЗ рд╡рд╛рд▓реЗ рдЕрдиреБрдкреНрд░рдпреЛрдЧреЛрдВ рдореЗрдВ рддреИрдирд╛рдд рдХрд┐рдпрд╛ рдЬрд╛рддрд╛ рд╣реИред

## SLM рдПрдЬреЗрдВрдЯ рд╡рд┐рдХрд╛рд╕ рдореЗрдВ рднрд╡рд┐рд╖реНрдп рдХреА рдкреНрд░рд╡реГрддреНрддрд┐рдпрд╛рдБ

SLM рдПрдЬреЗрдВрдЯ рдкрд░рд┐рджреГрд╢реНрдп рд╕рдВрдкреАрдбрд╝рди рддрдХрдиреАрдХреЛрдВ, рдЕрдиреБрдХреВрд▓рди рд╡рд┐рдзрд┐рдпреЛрдВ, рдФрд░ рдПрдЬ рддреИрдирд╛рддреА рд░рдгрдиреАрддрд┐рдпреЛрдВ рдореЗрдВ рдкреНрд░рдЧрддрд┐ рдХреЗ рд╕рд╛рде рд╡рд┐рдХрд╕рд┐рдд рд╣реЛрддрд╛ рд░рд╣рддрд╛ рд╣реИред рднрд╡рд┐рд╖реНрдп рдХреЗ рд╡рд┐рдХрд╛рд╕ рдореЗрдВ рдПрдЬреЗрдВрдЯ рдореЙрдбрд▓ рдХреЗ рд▓рд┐рдП рдЕрдзрд┐рдХ рдХреБрд╢рд▓ рдХреНрд╡рд╛рдВрдЯрд╛рдЗрдЬреЗрд╢рди рдПрд▓реНрдЧреЛрд░рд┐рджрдо, рдПрдЬреЗрдВрдЯ рд╡рд░реНрдХрдлрд╝реНрд▓реЛ рдХреЗ рд▓рд┐рдП рдмреЗрд╣рддрд░ рд╕рдВрдкреАрдбрд╝рди рд╡рд┐рдзрд┐рдпрд╛рдБ, рдФрд░ рдПрдЬреЗрдВрдЯ рдкреНрд░рд╕рдВрд╕реНрдХрд░рдг рдХреЗ рд▓рд┐рдП рдПрдЬ рд╣рд╛рд░реНрдбрд╡реЗрдпрд░ рдПрдХреНрд╕реЗрд▓реЗрд░реЗрдЯрд░ рдХреЗ рд╕рд╛рде рдмреЗрд╣рддрд░ рдПрдХреАрдХрд░рдг рд╢рд╛рдорд┐рд▓ рд╣реИрдВред

**SLM рдПрдЬреЗрдВрдЯреЛрдВ рдХреЗ рд▓рд┐рдП рдмрд╛рдЬрд╝рд╛рд░ рдХреА рднрд╡рд┐рд╖реНрдпрд╡рд╛рдгрд┐рдпрд╛рдБ**: рд╣рд╛рд▓рд┐рдпрд╛ рд╢реЛрдз рдХреЗ рдЕрдиреБрд╕рд╛рд░, рдПрдЬреЗрдВрдЯ-рд╕рдВрдЪрд╛рд▓рд┐рдд рд╕реНрд╡рдЪрд╛рд▓рди 2027 рддрдХ рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЬрд╝ рд╡рд░реНрдХрдлрд╝реНрд▓реЛ рдореЗрдВ 40тАУ60% рджреЛрд╣рд░рд╛рд╡ рд╡рд╛рд▓реЗ рд╕рдВрдЬреНрдЮрд╛рдирд╛рддреНрдордХ рдХрд╛рд░реНрдпреЛрдВ рдХреЛ рд╕рдорд╛рдкреНрдд рдХрд░ рд╕рдХрддрд╛ рд╣реИ, рдЬрд┐рд╕рдореЗрдВ SLMs рдЗрд╕ рдкрд░рд┐рд╡рд░реНрддрди рдХрд╛ рдиреЗрддреГрддреНрд╡ рдХрд░реЗрдВрдЧреЗ рдХреНрдпреЛрдВрдХрд┐ рд╡реЗ рд▓рд╛рдЧрдд рдкреНрд░рднрд╛рд╡реА рдФрд░ рддреИрдирд╛рддреА рдореЗрдВ рд▓рдЪреАрд▓реЗ рд╣реИрдВред

**SLM рдПрдЬреЗрдВрдЯреЛрдВ рдореЗрдВ рддрдХрдиреАрдХреА рдкреНрд░рд╡реГрддреНрддрд┐рдпрд╛рдБ**:
- **рд╡рд┐рд╢реЗрд╖реАрдХреГрдд SLM рдПрдЬреЗрдВрдЯ**: рд╡рд┐рд╢реЗрд╖ рдПрдЬреЗрдВрдЯ рдХрд╛рд░реНрдпреЛрдВ рдФрд░ рдЙрджреНрдпреЛрдЧреЛрдВ рдХреЗ рд▓рд┐рдП рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд рдбреЛрдореЗрди-рд╡рд┐рд╢рд┐рд╖реНрдЯ рдореЙрдбрд▓
- **рдПрдЬ рдПрдЬреЗрдВрдЯ рдХрдВрдкреНрдпреВрдЯрд┐рдВрдЧ**: рдмреЗрд╣рддрд░ рдЧреЛрдкрдиреАрдпрддрд╛ рдФрд░ рдХрдо рд╡рд┐рд▓рдВрдмрддрд╛ рдХреЗ рд╕рд╛рде рдСрди-рдбрд┐рд╡рд╛рдЗрд╕ рдПрдЬреЗрдВрдЯ рдХреНрд╖рдорддрд╛рдПрдБ
- **рдПрдЬреЗрдВрдЯ рдСрд░реНрдХреЗрд╕реНрдЯреНрд░реЗрд╢рди**: рдХрдИ SLM рдПрдЬреЗрдВрдЯреЛрдВ рдХреЗ рдмреАрдЪ рдмреЗрд╣рддрд░ рд╕рдордиреНрд╡рдп, рдЧрддрд┐рд╢реАрд▓ рд░реВрдЯрд┐рдВрдЧ рдФрд░ рд▓реЛрдб рдмреИрд▓реЗрдВрд╕рд┐рдВрдЧ
- **рд▓реЛрдХрддрдВрддреНрд░реАрдХрд░рдг**: SLM рд▓рдЪреАрд▓рд╛рдкрди рд╕рдВрдЧрдардиреЛрдВ рдореЗрдВ рдПрдЬреЗрдВрдЯ рд╡рд┐рдХрд╛рд╕ рдореЗрдВ рд╡реНрдпрд╛рдкрдХ рднрд╛рдЧреАрджрд╛рд░реА рдХреЛ рд╕рдХреНрд╖рдо рдмрдирд╛рддрд╛ рд╣реИ

## SLM рдПрдЬреЗрдВрдЯреЛрдВ рдХреЗ рд╕рд╛рде рд╢реБрд░реБрдЖрдд рдХрд░рдирд╛

### рдЪрд░рдг 1: Microsoft Agent Framework рд╡рд╛рддрд╛рд╡рд░рдг рд╕реЗрдЯ рдХрд░реЗрдВ

**рдбрд┐рдкреЗрдВрдбреЗрдВрд╕реА рдЗрдВрд╕реНрдЯреЙрд▓ рдХрд░реЗрдВ**:
```bash
# Install Microsoft Agent Framework
pip install microsoft-agent-framework

# Install Foundry Local SDK for edge deployment
pip install foundry-local-sdk

# Install additional dependencies for edge agents
pip install openai asyncio
```

**Foundry Local рдкреНрд░рд╛рд░рдВрдн рдХрд░реЗрдВ**:
```bash
# Start Foundry Local service
foundry service start

# Load default model for agent development
foundry model run phi-4-mini
```

### рдЪрд░рдг 2: рдПрдЬреЗрдВрдЯ рдЕрдиреБрдкреНрд░рдпреЛрдЧреЛрдВ рдХреЗ рд▓рд┐рдП рдЕрдкрдирд╛ SLM рдЪреБрдиреЗрдВ
Microsoft Agent Framework рдХреЗ рд▓рд┐рдП рд▓реЛрдХрдкреНрд░рд┐рдп рд╡рд┐рдХрд▓реНрдк:
- **Microsoft Phi-4 Mini (3.8B)**: рд╕рд╛рдорд╛рдиреНрдп рдПрдЬреЗрдВрдЯ рдХрд╛рд░реНрдпреЛрдВ рдХреЗ рд▓рд┐рдП рдЙрддреНрдХреГрд╖реНрдЯ, рд╕рдВрддреБрд▓рд┐рдд рдкреНрд░рджрд░реНрд╢рди рдХреЗ рд╕рд╛рде
- **Qwen2.5-0.5B (0.5B)**: рд╕рд░рд▓ рд░реВрдЯрд┐рдВрдЧ рдФрд░ рд╡рд░реНрдЧреАрдХрд░рдг рдПрдЬреЗрдВрдЯреЛрдВ рдХреЗ рд▓рд┐рдП рдЕрддреНрдпрдзрд┐рдХ рдХреБрд╢рд▓
- **Qwen2.5-Coder-0.5B (0.5B)**: рдХреЛрдб-рд╕рдВрдмрдВрдзрд┐рдд рдПрдЬреЗрдВрдЯ рдХрд╛рд░реНрдпреЛрдВ рдХреЗ рд▓рд┐рдП рд╡рд┐рд╢реЗрд╖реАрдХреГрдд
- **Phi-4 (7B)**: рдЬрдЯрд┐рд▓ рдПрдЬ рдкрд░рд┐рджреГрд╢реНрдпреЛрдВ рдХреЗ рд▓рд┐рдП рдЙрдиреНрдирдд рддрд░реНрдХ рдЬрдм рд╕рдВрд╕рд╛рдзрди рдЕрдиреБрдорддрд┐ рджреЗрддреЗ рд╣реИрдВ

### рдЪрд░рдг 3: Microsoft Agent Framework рдХреЗ рд╕рд╛рде рдЕрдкрдирд╛ рдкрд╣рд▓рд╛ рдПрдЬреЗрдВрдЯ рдмрдирд╛рдПрдВ

**рдмреЗрд╕рд┐рдХ рдПрдЬреЗрдВрдЯ рд╕реЗрдЯрдЕрдк**:
```python
from microsoft_agent_framework import Agent, Config
from foundry_local import FoundryLocalManager

# Initialize Foundry Local connection
foundry = FoundryLocalManager("phi-4-mini")

# Create agent configuration
config = Config(
    name="my-first-agent",
    model_provider="foundry-local",
    model_alias="phi-4-mini",
    offline_mode=True
)

# Create and configure agent
agent = Agent(
    config=config,
    model_endpoint=foundry.endpoint,
    api_key=foundry.api_key
)

# Define a simple tool
@agent.tool
def get_current_time() -> str:
    """Get the current time."""
    from datetime import datetime
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

# Test the agent
response = agent.chat("What time is it?")
print(response)
```

### рдЪрд░рдг 4: рдПрдЬреЗрдВрдЯ рдХрд╛ рджрд╛рдпрд░рд╛ рдФрд░ рдЖрд╡рд╢реНрдпрдХрддрд╛рдПрдБ рдкрд░рд┐рднрд╛рд╖рд┐рдд рдХрд░реЗрдВ
Microsoft Agent Framework рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рдХреЗрдВрджреНрд░рд┐рдд, рдЕрдЪреНрдЫреА рддрд░рд╣ рд╕реЗ рдкрд░рд┐рднрд╛рд╖рд┐рдд рдПрдЬреЗрдВрдЯ рдЕрдиреБрдкреНрд░рдпреЛрдЧреЛрдВ рд╕реЗ рд╢реБрд░реБрдЖрдд рдХрд░реЗрдВ:
- **рдПрдХрд▓ рдбреЛрдореЗрди рдПрдЬреЗрдВрдЯ**: рдЧреНрд░рд╛рд╣рдХ рд╕реЗрд╡рд╛ рдпрд╛ рд╢реЗрдбреНрдпреВрд▓рд┐рдВрдЧ рдпрд╛ рдЕрдиреБрд╕рдВрдзрд╛рди
- **рд╕реНрдкрд╖реНрдЯ рдПрдЬреЗрдВрдЯ рдЙрджреНрджреЗрд╢реНрдп**: рдПрдЬреЗрдВрдЯ рдкреНрд░рджрд░реНрд╢рди рдХреЗ рд▓рд┐рдП рд╡рд┐рд╢рд┐рд╖реНрдЯ, рдорд╛рдкрдиреЗ рдпреЛрдЧреНрдп рд▓рдХреНрд╖реНрдп
- **рд╕реАрдорд┐рдд рдЯреВрд▓ рдПрдХреАрдХрд░рдг**: рдкреНрд░рд╛рд░рдВрднрд┐рдХ рдПрдЬреЗрдВрдЯ рддреИрдирд╛рддреА рдХреЗ рд▓рд┐рдП рдЕрдзрд┐рдХрддрдо 3-5 рдЯреВрд▓
- **рдкрд░рд┐рднрд╛рд╖рд┐рдд рдПрдЬреЗрдВрдЯ рд╕реАрдорд╛рдПрдБ**: рдЬрдЯрд┐рд▓ рдкрд░рд┐рджреГрд╢реНрдпреЛрдВ рдХреЗ рд▓рд┐рдП рд╕реНрдкрд╖реНрдЯ рдПрд╕реНрдХреЗрд▓реЗрд╢рди рдкрде
- **рдПрдЬ-рдкреНрд░рдердо рдбрд┐рдЬрд╝рд╛рдЗрди**: рдСрдлрд╝рд▓рд╛рдЗрди рдХрд╛рд░реНрдпрдХреНрд╖рдорддрд╛ рдФрд░ рд╕реНрдерд╛рдиреАрдп рдкреНрд░рд╕рдВрд╕реНрдХрд░рдг рдХреЛ рдкреНрд░рд╛рдердорд┐рдХрддрд╛ рджреЗрдВ

### рдЪрд░рдг 5: Microsoft Agent Framework рдХреЗ рд╕рд╛рде рдПрдЬ рддреИрдирд╛рддреА рд▓рд╛рдЧреВ рдХрд░реЗрдВ

**рд╕рдВрд╕рд╛рдзрди рдХреЙрдиреНрдлрд╝рд┐рдЧрд░реЗрд╢рди**:
```python
from microsoft_agent_framework import ResourceConfig

# Configure for edge deployment
resource_config = ResourceConfig(
    max_memory_usage="2GB",
    max_concurrent_agents=2,
    model_cache_size="1GB",
    auto_unload_idle_models=True,
    power_management=True
)

agent = Agent(
    config=config,
    resource_limits=resource_config
)
```

**рдПрдЬ рдПрдЬреЗрдВрдЯреЛрдВ рдХреЗ рд▓рд┐рдП рд╕реБрд░рдХреНрд╖рд╛ рдЙрдкрд╛рдп рддреИрдирд╛рдд рдХрд░реЗрдВ**:
- **рд╕реНрдерд╛рдиреАрдп рдЗрдирдкреБрдЯ рдорд╛рдиреНрдпрддрд╛**: рдХреНрд▓рд╛рдЙрдб рдирд┐рд░реНрднрд░рддрд╛ рдХреЗ рдмрд┐рдирд╛ рдЕрдиреБрд░реЛрдзреЛрдВ рдХреА рдЬрд╛рдБрдЪ рдХрд░реЗрдВ
- **рдСрдлрд╝рд▓рд╛рдЗрди рдЖрдЙрдЯрдкреБрдЯ рдлрд╝рд┐рд▓реНрдЯрд░рд┐рдВрдЧ**: рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдХрд░реЗрдВ рдХрд┐ рдкреНрд░рддрд┐рдХреНрд░рд┐рдпрд╛рдПрдБ рд╕реНрдерд╛рдиреАрдп рд░реВрдк рд╕реЗ рдЧреБрдгрд╡рддреНрддрд╛ рдорд╛рдирдХреЛрдВ рдХреЛ рдкреВрд░рд╛ рдХрд░рддреА рд╣реИрдВ
- **рдПрдЬ рд╕реБрд░рдХреНрд╖рд╛ рдирд┐рдпрдВрддреНрд░рдг**: рдЗрдВрдЯрд░рдиреЗрдЯ рдХрдиреЗрдХреНрдЯрд┐рд╡рд┐рдЯреА рдХреА рдЖрд╡рд╢реНрдпрдХрддрд╛ рдХреЗ рдмрд┐рдирд╛ рд╕реБрд░рдХреНрд╖рд╛ рд▓рд╛рдЧреВ рдХрд░реЗрдВ
- **рд╕реНрдерд╛рдиреАрдп рдирд┐рдЧрд░рд╛рдиреА**: рдкреНрд░рджрд░реНрд╢рди рдХреЛ рдЯреНрд░реИрдХ рдХрд░реЗрдВ рдФрд░ рдПрдЬ рдЯреЗрд▓реАрдореЗрдЯреНрд░реА рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рд╕рдорд╕реНрдпрд╛рдУрдВ рдХреЛ рдлрд╝реНрд▓реИрдЧ рдХрд░реЗрдВ

### рдЪрд░рдг 6: рдПрдЬ рдПрдЬреЗрдВрдЯ рдкреНрд░рджрд░реНрд╢рди рдХреЛ рдорд╛рдкреЗрдВ рдФрд░ рдЕрдиреБрдХреВрд▓рд┐рдд рдХрд░реЗрдВ
- **рдПрдЬреЗрдВрдЯ рдХрд╛рд░реНрдп рдкреВрд░реНрдгрддрд╛ рджрд░**: рдСрдлрд╝рд▓рд╛рдЗрди рдкрд░рд┐рджреГрд╢реНрдпреЛрдВ рдореЗрдВ рд╕рдлрд▓рддрд╛ рджрд░ рдХреА рдирд┐рдЧрд░рд╛рдиреА рдХрд░реЗрдВ
- **рдПрдЬреЗрдВрдЯ рдкреНрд░рддрд┐рдХреНрд░рд┐рдпрд╛ рд╕рдордп**: рдПрдЬ рддреИрдирд╛рддреА рдХреЗ рд▓рд┐рдП рдЙрдк-рд╕реЗрдХрдВрдб рдкреНрд░рддрд┐рдХреНрд░рд┐рдпрд╛ рд╕рдордп рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдХрд░реЗрдВ
- **рд╕рдВрд╕рд╛рдзрди рдЙрдкрдпреЛрдЧ**: рдПрдЬ рдЙрдкрдХрд░рдгреЛрдВ рдкрд░ рдореЗрдореЛрд░реА, CPU, рдФрд░ рдмреИрдЯрд░реА рдЙрдкрдпреЛрдЧ рдХреЛ рдЯреНрд░реИрдХ рдХрд░реЗрдВ
- **рд▓рд╛рдЧрдд рджрдХреНрд╖рддрд╛**: рдХреНрд▓рд╛рдЙрдб-рдЖрдзрд╛рд░рд┐рдд рд╡рд┐рдХрд▓реНрдкреЛрдВ рдХреА рддреБрд▓рдирд╛ рдореЗрдВ рдПрдЬ рддреИрдирд╛рддреА рд▓рд╛рдЧрдд рдХреА рддреБрд▓рдирд╛ рдХрд░реЗрдВ
- **рдСрдлрд╝рд▓рд╛рдЗрди рд╡рд┐рд╢реНрд╡рд╕рдиреАрдпрддрд╛**: рдиреЗрдЯрд╡рд░реНрдХ рдЖрдЙрдЯреЗрдЬ рдХреЗ рджреМрд░рд╛рди рдПрдЬреЗрдВрдЯ рдкреНрд░рджрд░реНрд╢рди рдХреЛ рдорд╛рдкреЗрдВ

## SLM рдПрдЬреЗрдВрдЯ рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди рдХреЗ рд▓рд┐рдП рдореБрдЦреНрдп рдмрд╛рддреЗрдВ

1. **рдПрдЬреЗрдВрдЯреЛрдВ рдХреЗ рд▓рд┐рдП SLM рдкрд░реНрдпрд╛рдкреНрдд рд╣реИрдВ**: рдЕрдзрд┐рдХрд╛рдВрд╢ рдПрдЬреЗрдВрдЯ рдХрд╛рд░реНрдпреЛрдВ рдХреЗ рд▓рд┐рдП, рдЫреЛрдЯреЗ рдореЙрдбрд▓ рдмрдбрд╝реЗ рдореЙрдбрд▓ рдХреЗ рд╕рдорд╛рди рдкреНрд░рджрд░реНрд╢рди рдХрд░рддреЗ рд╣реИрдВ рдФрд░ рдорд╣рддреНрд╡рдкреВрд░реНрдг рд▓рд╛рдн рдкреНрд░рджрд╛рди рдХрд░рддреЗ рд╣реИрдВ
2. **рдПрдЬреЗрдВрдЯреЛрдВ рдореЗрдВ рд▓рд╛рдЧрдд рджрдХреНрд╖рддрд╛**: SLM рдПрдЬреЗрдВрдЯ рдЪрд▓рд╛рдиреЗ рдХреЗ рд▓рд┐рдП 10-30x рд╕рд╕реНрддрд╛, рдЙрдиреНрд╣реЗрдВ рд╡реНрдпрд╛рдкрдХ рддреИрдирд╛рддреА рдХреЗ рд▓рд┐рдП рдЖрд░реНрдерд┐рдХ рд░реВрдк рд╕реЗ рд╡реНрдпрд╡рд╣рд╛рд░реНрдп рдмрдирд╛рддрд╛ рд╣реИ
3. **рдПрдЬреЗрдВрдЯреЛрдВ рдХреЗ рд▓рд┐рдП рд╡рд┐рд╢реЗрд╖рдЬреНрдЮрддрд╛ рдХрд╛рдо рдХрд░рддреА рд╣реИ**: рд╡рд┐рд╢рд┐рд╖реНрдЯ рдПрдЬреЗрдВрдЯ рдЕрдиреБрдкреНрд░рдпреЛрдЧреЛрдВ рдореЗрдВ рдлрд╛рдЗрди-рдЯреНрдпреВрди рдХрд┐рдП рдЧрдП SLM рдЕрдХреНрд╕рд░ рд╕рд╛рдорд╛рдиреНрдп-рдЙрджреНрджреЗрд╢реНрдп LLMs рд╕реЗ рдмреЗрд╣рддрд░ рдкреНрд░рджрд░реНрд╢рди рдХрд░рддреЗ рд╣реИрдВ
4. **рд╣рд╛рдЗрдмреНрд░рд┐рдб рдПрдЬреЗрдВрдЯ рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░**: рдирд┐рдпрдорд┐рдд рдПрдЬреЗрдВрдЯ рдХрд╛рд░реНрдпреЛрдВ рдХреЗ рд▓рд┐рдП SLM рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВ, рдЬрдЯрд┐рд▓ рддрд░реНрдХ рдХреЗ рд▓рд┐рдП рдЖрд╡рд╢реНрдпрдХ рд╣реЛрдиреЗ рдкрд░ LLM рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВ
5. **Microsoft Agent Framework рдЙрддреНрдкрд╛рджрди рддреИрдирд╛рддреА рд╕рдХреНрд╖рдо рдХрд░рддрд╛ рд╣реИ**: рдПрдЬ рдПрдЬреЗрдВрдЯреЛрдВ рдХреЛ рдмрдирд╛рдиреЗ, рддреИрдирд╛рдд рдХрд░рдиреЗ, рдФрд░ рдкреНрд░рдмрдВрдзрд┐рдд рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЬрд╝-рдЧреНрд░реЗрдб рдЯреВрд▓ рдкреНрд░рджрд╛рди рдХрд░рддрд╛ рд╣реИ
6. **рдПрдЬ-рдкреНрд░рдердо рдбрд┐рдЬрд╝рд╛рдЗрди рд╕рд┐рджреНрдзрд╛рдВрдд**: рдСрдлрд╝рд▓рд╛рдЗрди-рд╕рдХреНрд╖рдо рдПрдЬреЗрдВрдЯ рд╕реНрдерд╛рдиреАрдп рдкреНрд░рд╕рдВрд╕реНрдХрд░рдг рдХреЗ рд╕рд╛рде рдЧреЛрдкрдиреАрдпрддрд╛ рдФрд░ рд╡рд┐рд╢реНрд╡рд╕рдиреАрдпрддрд╛ рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдХрд░рддреЗ рд╣реИрдВ
7. **Foundry Local рдПрдХреАрдХрд░рдг**: Microsoft Agent Framework рдФрд░ рд╕реНрдерд╛рдиреАрдп рдореЙрдбрд▓ рдЗрдирдлреЗрд░реЗрдВрд╕ рдХреЗ рдмреАрдЪ рд╕рд╣рдЬ рдХрдиреЗрдХреНрд╢рди
8. **рднрд╡рд┐рд╖реНрдп SLM рдПрдЬреЗрдВрдЯ рд╣реИрдВ**: рдЙрддреНрдкрд╛рджрди рдлреНрд░реЗрдорд╡рд░реНрдХ рдХреЗ рд╕рд╛рде рдЫреЛрдЯреЗ рднрд╛рд╖рд╛ рдореЙрдбрд▓ рдПрдЬреЗрдВрдЯрд┐рдХ AI рдХрд╛ рднрд╡рд┐рд╖реНрдп рд╣реИрдВ, рдЬреЛ рд▓реЛрдХрддрд╛рдВрддреНрд░рд┐рдд рдФрд░ рдХреБрд╢рд▓ рдПрдЬреЗрдВрдЯ рддреИрдирд╛рддреА рдХреЛ рд╕рдХреНрд╖рдо рдмрдирд╛рддреЗ рд╣реИрдВ

## рд╕рдВрджрд░реНрдн рдФрд░ рдЖрдЧреЗ рдкрдврд╝рд╛рдИ

### рдореБрдЦреНрдп рд╢реЛрдз рдкрддреНрд░ рдФрд░ рдкреНрд░рдХрд╛рд╢рди

#### AI рдПрдЬреЗрдВрдЯ рдФрд░ рдПрдЬреЗрдВрдЯрд┐рдХ рд╕рд┐рд╕реНрдЯрдо
- **"Language Agents as Optimizable Graphs"** (2024) - рдПрдЬреЗрдВрдЯ рдЖрд░реНрдХрд┐рдЯреЗрдХреНрдЪрд░ рдФрд░ рдЕрдиреБрдХреВрд▓рди рдкрд░ рдореМрд▓рд┐рдХ рд╢реЛрдз
  - рд▓реЗрдЦрдХ: Wenyue Hua, Lishan Yang, рдЖрджрд┐
  - рд▓рд┐рдВрдХ: https://arxiv.org/abs/2402.16823
  - рдореБрдЦреНрдп рдЕрдВрддрд░реНрджреГрд╖реНрдЯрд┐: рдЧреНрд░рд╛рдл-рдЖрдзрд╛рд░рд┐рдд рдПрдЬреЗрдВрдЯ рдбрд┐рдЬрд╝рд╛рдЗрди рдФрд░ рдЕрдиреБрдХреВрд▓рди рд░рдгрдиреАрддрд┐рдпрд╛рдБ

- **"The Rise and Potential of Large Language Model Based Agents"** (2023)
  - рд▓реЗрдЦрдХ: Zhiheng Xi, Wenxiang Chen, рдЖрджрд┐
  - рд▓рд┐рдВрдХ: https://arxiv.org/abs/2309.07864
  - рдореБрдЦреНрдп рдЕрдВрддрд░реНрджреГрд╖реНрдЯрд┐: LLM-рдЖрдзрд╛рд░рд┐рдд рдПрдЬреЗрдВрдЯ рдХреНрд╖рдорддрд╛рдУрдВ рдФрд░ рдЕрдиреБрдкреНрд░рдпреЛрдЧреЛрдВ рдХрд╛ рд╡реНрдпрд╛рдкрдХ рд╕рд░реНрд╡реЗрдХреНрд╖рдг

- **"Cognitive Architectures for Language Agents"** (2024)
  - рд▓реЗрдЦрдХ: Theodore Sumers, Shunyu Yao, рдЖрджрд┐
  - рд▓рд┐рдВрдХ: https://arxiv.org/abs/2309.02427
  - рдореБрдЦреНрдп рдЕрдВрддрд░реНрджреГрд╖реНрдЯрд┐: рдмреБрджреНрдзрд┐рдорд╛рди рдПрдЬреЗрдВрдЯреЛрдВ рдХреЛ рдбрд┐рдЬрд╝рд╛рдЗрди рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рд╕рдВрдЬреНрдЮрд╛рдирд╛рддреНрдордХ рдлреНрд░реЗрдорд╡рд░реНрдХ

#### рдЫреЛрдЯреЗ рднрд╛рд╖рд╛ рдореЙрдбрд▓ рдФрд░ рдЕрдиреБрдХреВрд▓рди
- **"Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone"** (2024)
  - рд▓реЗрдЦрдХ: Microsoft Research Team
  - рд▓рд┐рдВрдХ: https://arxiv.org/abs/2404.14219
  - рдореБрдЦреНрдп рдЕрдВрддрд░реНрджреГрд╖реНрдЯрд┐: SLM рдбрд┐рдЬрд╝рд╛рдЗрди рд╕рд┐рджреНрдзрд╛рдВрдд рдФрд░ рдореЛрдмрд╛рдЗрд▓ рддреИрдирд╛рддреА рд░рдгрдиреАрддрд┐рдпрд╛рдБ

- **"Qwen2.5 Technical Report"** (2024)
  - рд▓реЗрдЦрдХ: Alibaba Cloud Team
  - рд▓рд┐рдВрдХ: https://arxiv.org/abs/2407.10671
  - рдореБрдЦреНрдп рдЕрдВрддрд░реНрджреГрд╖реНрдЯрд┐: рдЙрдиреНрдирдд SLM рдкреНрд░рд╢рд┐рдХреНрд╖рдг рддрдХрдиреАрдХ рдФрд░ рдкреНрд░рджрд░реНрд╢рди рдЕрдиреБрдХреВрд▓рди

- **"TinyLlama: An Open-Source Small Language Model"** (2024)
  - рд▓реЗрдЦрдХ: Peiyuan Zhang, Guangtao Zeng, рдЖрджрд┐
  - рд▓рд┐рдВрдХ: https://arxiv.org/abs/2401.02385
  - рдореБрдЦреНрдп рдЕрдВрддрд░реНрджреГрд╖реНрдЯрд┐: рдЕрд▓реНрдЯреНрд░рд╛-рдХреЙрдореНрдкреИрдХреНрдЯ рдореЙрдбрд▓ рдбрд┐рдЬрд╝рд╛рдЗрди рдФрд░ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рджрдХреНрд╖рддрд╛

### рдЖрдзрд┐рдХрд╛рд░рд┐рдХ рджрд╕реНрддрд╛рд╡реЗрдЬрд╝ рдФрд░ рдлреНрд░реЗрдорд╡рд░реНрдХ

#### Microsoft Agent Framework
- **рдЖрдзрд┐рдХрд╛рд░рд┐рдХ рджрд╕реНрддрд╛рд╡реЗрдЬрд╝**: https://docs.microsoft.com/en-us/azure/ai-services/agents/
- **GitHub рд░рд┐рдкреЙрдЬрд┐рдЯрд░реА**: https://github.com/microsoft/agent-framework

#### Foundry Local
- **рдкреНрд░рд╛рдердорд┐рдХ рд░рд┐рдкреЙрдЬрд┐рдЯрд░реА**: https://github.com/microsoft/foundry-local
- **рджрд╕реНрддрд╛рд╡реЗрдЬрд╝**: https://github.com/microsoft/foundry-local/blob/main/docs/README.md


#### VLLM
- **рдореБрдЦреНрдп рд░рд┐рдкреЙрдЬрд┐рдЯрд░реА**: https://github.com/vllm-project/vllm
- **рджрд╕реНрддрд╛рд╡реЗрдЬрд╝**: https://docs.vllm.ai/


#### Ollama
- **рдЖрдзрд┐рдХрд╛рд░рд┐рдХ рд╡реЗрдмрд╕рд╛рдЗрдЯ**: https://ollama.ai/
- **GitHub рд░рд┐рдкреЙрдЬрд┐рдЯрд░реА**: https://github.com/ollama/ollama

### рдореЙрдбрд▓ рдЕрдиреБрдХреВрд▓рди рдлреНрд░реЗрдорд╡рд░реНрдХ

#### Llama.cpp
- **рд░рд┐рдкреЙрдЬрд┐рдЯрд░реА**: https://github.com/ggml-org/llama.cpp


#### Microsoft Olive
- **рджрд╕реНрддрд╛рд╡реЗрдЬрд╝**: https://microsoft.github.io/Olive/
- **GitHub рд░рд┐рдкреЙрдЬрд┐рдЯрд░реА**: https://github.com/microsoft/Olive

#### OpenVINO
- **рдЖрдзрд┐рдХрд╛рд░рд┐рдХ рд╕рд╛рдЗрдЯ**: https://docs.openvino.ai/

#### Apple MLX
- **рд░рд┐рдкреЙрдЬрд┐рдЯрд░реА**: https://github.com/ml-explore/mlx

### рдЙрджреНрдпреЛрдЧ рд░рд┐рдкреЛрд░реНрдЯ рдФрд░ рдмрд╛рдЬрд╝рд╛рд░ рд╡рд┐рд╢реНрд▓реЗрд╖рдг

#### AI рдПрдЬреЗрдВрдЯ рдмрд╛рдЬрд╝рд╛рд░ рдЕрдиреБрд╕рдВрдзрд╛рди
- **"The State of AI Agents 2025"** - McKinsey Global Institute
  - рд▓рд┐рдВрдХ: https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/ai-agents-2025
  - рдореБрдЦреНрдп рдЕрдВрддрд░реНрджреГрд╖реНрдЯрд┐: рдмрд╛рдЬрд╝рд╛рд░ рдкреНрд░рд╡реГрддреНрддрд┐рдпрд╛рдБ рдФрд░ рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЬрд╝ рдЕрдкрдирд╛рдиреЗ рдХреЗ рдкреИрдЯрд░реНрди

#### рддрдХрдиреАрдХреА рдмреЗрдВрдЪрдорд╛рд░реНрдХ

- **"Edge AI Inference Benchmarks"** - MLPerf
  - рд▓рд┐рдВрдХ: https://mlcommons.org/en/inference-edge/
  - рдореБрдЦреНрдп рдЕрдВрддрд░реНрджреГрд╖реНрдЯрд┐: рдПрдЬ рддреИрдирд╛рддреА рдХреЗ рд▓рд┐рдП рдорд╛рдирдХреАрдХреГрдд рдкреНрд░рджрд░реНрд╢рди рдореЗрдЯреНрд░рд┐рдХреНрд╕

### рдорд╛рдирдХ рдФрд░ рд╡рд┐рдирд┐рд░реНрджреЗрд╢

#### рдореЙрдбрд▓ рдкреНрд░рд╛рд░реВрдк рдФрд░ рдорд╛рдирдХ
- **ONNX (Open Neural Network Exchange)**: https://onnx.ai/
  - рдЗрдВрдЯрд░рдСрдкрд░реЗрдмрд┐рд▓рд┐рдЯреА рдХреЗ рд▓рд┐рдП рдХреНрд░реЙрд╕-рдкреНрд▓реЗрдЯрдлрд╝реЙрд░реНрдо рдореЙрдбрд▓ рдкреНрд░рд╛рд░реВрдк
- **GGUF рд╡рд┐рдирд┐рд░реНрджреЗрд╢**: https://github.com/ggerganov/ggml/blob/master/docs/gguf.md
  - CPU рдЗрдирдлреЗрд░реЗрдВрд╕ рдХреЗ рд▓рд┐рдП рдХреНрд╡рд╛рдВрдЯрд╛рдЗрдЬреНрдб рдореЙрдбрд▓ рдкреНрд░рд╛рд░реВрдк
- **OpenAI API рд╡рд┐рдирд┐рд░реНрджреЗрд╢**: https://platform.openai.com/docs/api-reference
  - рднрд╛рд╖рд╛ рдореЙрдбрд▓ рдПрдХреАрдХрд░рдг рдХреЗ рд▓рд┐рдП рдорд╛рдирдХ API рдкреНрд░рд╛рд░реВрдк

#### рд╕реБрд░рдХреНрд╖рд╛ рдФрд░ рдЕрдиреБрдкрд╛рд▓рди
- **NIST AI рдЬреЛрдЦрд┐рдо рдкреНрд░рдмрдВрдзрди рдлреНрд░реЗрдорд╡рд░реНрдХ**: https://www.nist.gov/itl/ai-risk-management-framework
- **ISO/IEC 23053:2022 - AI рд╕рд┐рд╕реНрдЯрдо**: AI рд╕рд┐рд╕реНрдЯрдо рдФрд░ рд╕реБрд░рдХреНрд╖рд╛ рдХреЗ рд▓рд┐рдП рдлреНрд░реЗрдорд╡рд░реНрдХ
- **IEEE AI рдорд╛рдирдХ**: https://standards.ieee.org/industry-connections/ai/

SLM-рд╕рдВрдЪрд╛рд▓рд┐рдд рдПрдЬреЗрдВрдЯреЛрдВ рдХреА рдУрд░ рдмрджрд▓рд╛рд╡ AI рддреИрдирд╛рддреА рдХреЗ рдкреНрд░рддрд┐ рд╣рдорд╛рд░реЗ рджреГрд╖реНрдЯрд┐рдХреЛрдг рдореЗрдВ рдПрдХ рдореМрд▓рд┐рдХ рдкрд░рд┐рд╡рд░реНрддрди рдХрд╛ рдкреНрд░рддрд┐рдирд┐рдзрд┐рддреНрд╡ рдХрд░рддрд╛ рд╣реИред Microsoft Agent Framework, рд╕реНрдерд╛рдиреАрдп рдкреНрд▓реЗрдЯрдлрд╝реЙрд░реНрдо рдФрд░ рдХреБрд╢рд▓ рдЫреЛрдЯреЗ рднрд╛рд╖рд╛ рдореЙрдбрд▓ рдХреЗ рд╕рд╛рде рдорд┐рд▓рдХрд░, рдЙрддреНрдкрд╛рджрди-рддреИрдпрд╛рд░ рдПрдЬреЗрдВрдЯреЛрдВ рдХреЛ рдмрдирд╛рдиреЗ рдХреЗ рд▓рд┐рдП рдПрдХ рд╕рдВрдкреВрд░реНрдг рд╕рдорд╛рдзрд╛рди рдкреНрд░рджрд╛рди рдХрд░рддрд╛ рд╣реИ рдЬреЛ рдПрдЬ рд╡рд╛рддрд╛рд╡рд░рдг рдореЗрдВ рдкреНрд░рднрд╛рд╡реА рдврдВрдЧ рд╕реЗ рдХрд╛рдо рдХрд░рддреЗ рд╣реИрдВред рджрдХреНрд╖рддрд╛, рд╡рд┐рд╢реЗрд╖рдЬреНрдЮрддрд╛, рдФрд░ рд╡реНрдпрд╛рд╡рд╣рд╛рд░рд┐рдХ рдЙрдкрдпреЛрдЧрд┐рддрд╛ рдкрд░ рдзреНрдпрд╛рди рдХреЗрдВрджреНрд░рд┐рдд рдХрд░рдХреЗ, рдпрд╣ рддрдХрдиреАрдХреА рд╕реНрдЯреИрдХ AI рдПрдЬреЗрдВрдЯреЛрдВ рдХреЛ рд╣рд░ рдЙрджреНрдпреЛрдЧ рдФрд░ рдПрдЬ рдХрдВрдкреНрдпреВрдЯрд┐рдВрдЧ рд╡рд╛рддрд╛рд╡рд░рдг рдореЗрдВ рд╡рд╛рд╕реНрддрд╡рд┐рдХ рджреБрдирд┐рдпрд╛ рдХреЗ рдЕрдиреБрдкреНрд░рдпреЛрдЧреЛрдВ рдХреЗ рд▓рд┐рдП рдЕрдзрд┐рдХ рд╕реБрд▓рдн, рдХрд┐рдлрд╛рдпрддреА, рдФрд░ рдкреНрд░рднрд╛рд╡реА рдмрдирд╛рддрд╛ рд╣реИред

рдЬреИрд╕реЗ-рдЬреИрд╕реЗ рд╣рдо 2025 рддрдХ рдЖрдЧреЗ рдмрдврд╝рддреЗ рд╣реИрдВ, рдЫреЛрдЯреЗ рдореЙрдбрд▓, рдкрд░рд┐рд╖реНрдХреГрдд рдПрдЬреЗрдВрдЯ рдлреНрд░реЗрдорд╡рд░реНрдХ рдЬреИрд╕реЗ Microsoft Agent Framework, рдФрд░ рдордЬрдмреВрдд рдПрдЬ рддреИрдирд╛рддреА рдкреНрд▓реЗрдЯрдлрд╝реЙрд░реНрдо рдХреЗ рд╕рдВрдпреЛрдЬрди рд╕реЗ рд╕реНрд╡рд╛рдпрддреНрдд рд╕рд┐рд╕реНрдЯрдо рдХреЗ рд▓рд┐рдП рдирдИ рд╕рдВрднрд╛рд╡рдирд╛рдПрдБ рдЦреБрд▓реЗрдВрдЧреА рдЬреЛ рдПрдЬ рдЙрдкрдХрд░рдгреЛрдВ рдкрд░ рдХреБрд╢рд▓рддрд╛ рд╕реЗ рдХрд╛рдо рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ, рдЧреЛрдкрдиреАрдпрддрд╛ рдмрдирд╛рдП рд░рдЦрддреЗ рд╣реИрдВ, рд▓рд╛рдЧрдд рдХрдо рдХрд░рддреЗ рд╣реИрдВ, рдФрд░ рдЕрд╕рд╛рдзрд╛рд░рдг рдЙрдкрдпреЛрдЧрдХрд░реНрддрд╛ рдЕрдиреБрднрд╡ рдкреНрд░рджрд╛рди рдХрд░рддреЗ рд╣реИрдВред

**рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди рдХреЗ рд▓рд┐рдП рдЕрдЧрд▓реЗ рдХрджрдо**:
1. **рдлрдВрдХреНрд╢рди рдХреЙрд▓рд┐рдВрдЧ рдХрд╛ рдЕрдиреНрд╡реЗрд╖рдг рдХрд░реЗрдВ**: рдЬрд╛рдиреЗрдВ рдХрд┐ SLMs рдЯреВрд▓ рдПрдХреАрдХрд░рдг рдФрд░ рд╕рдВрд░рдЪрд┐рдд рдЖрдЙрдЯрдкреБрдЯ рдХреЛ рдХреИрд╕реЗ рд╕рдВрднрд╛рд▓рддреЗ рд╣реИрдВ
2. **рдореЙрдбрд▓ рд╕рдВрджрд░реНрдн рдкреНрд░реЛрдЯреЛрдХреЙрд▓ (MCP) рдореЗрдВ рдорд╣рд╛рд░рдд рд╣рд╛рд╕рд┐рд▓ рдХрд░реЗрдВ**: рдЙрдиреНрдирдд рдПрдЬреЗрдВрдЯ рд╕рдВрдЪрд╛рд░ рдкреИрдЯрд░реНрди рдХреЛ рд╕рдордЭреЗрдВ
3. **рдЙрддреНрдкрд╛рджрди рдПрдЬреЗрдВрдЯ рдмрдирд╛рдПрдВ**: рдПрдВрдЯрд░рдкреНрд░рд╛рдЗрдЬрд╝-рдЧреНрд░реЗрдб рддреИрдирд╛рддреА рдХреЗ рд▓рд┐рдП Microsoft Agent Framework рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВ
4. **рдПрдЬ рдХреЗ рд▓рд┐рдП рдЕрдиреБрдХреВрд▓рд┐рдд рдХрд░реЗрдВ**: рд╕рдВрд╕рд╛рдзрди-рд╕реАрдорд┐рдд рд╡рд╛рддрд╛рд╡рд░рдг рдХреЗ рд▓рд┐рдП рдЙрдиреНрдирдд рдЕрдиреБрдХреВрд▓рди рддрдХрдиреАрдХреЛрдВ рдХреЛ рд▓рд╛рдЧреВ рдХрд░реЗрдВ

## тЮбя╕П рдЖрдЧреЗ рдХреНрдпрд╛ рд╣реИ

- [02: рдЫреЛрдЯреЗ рднрд╛рд╖рд╛ рдореЙрдбрд▓ (SLMs) рдореЗрдВ рдлрдВрдХреНрд╢рди рдХреЙрд▓рд┐рдВрдЧ](./02.FunctionCalling.md)

---

**рдЕрд╕реНрд╡реАрдХрд░рдг**:  
рдпрд╣ рджрд╕реНрддрд╛рд╡реЗрдЬрд╝ AI рдЕрдиреБрд╡рд╛рдж рд╕реЗрд╡рд╛ [Co-op Translator](https://github.com/Azure/co-op-translator) рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рдЕрдиреБрд╡рд╛рджрд┐рдд рдХрд┐рдпрд╛ рдЧрдпрд╛ рд╣реИред рдЬрдмрдХрд┐ рд╣рдо рд╕рдЯреАрдХрддрд╛ рдХреЗ рд▓рд┐рдП рдкреНрд░рдпрд╛рд╕ рдХрд░рддреЗ рд╣реИрдВ, рдХреГрдкрдпрд╛ рдзреНрдпрд╛рди рджреЗрдВ рдХрд┐ рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рдЕрдиреБрд╡рд╛рдж рдореЗрдВ рддреНрд░реБрдЯрд┐рдпрд╛рдВ рдпрд╛ рдЕрд╢реБрджреНрдзрд┐рдпрд╛рдВ рд╣реЛ рд╕рдХрддреА рд╣реИрдВред рдореВрд▓ рднрд╛рд╖рд╛ рдореЗрдВ рджрд╕реНрддрд╛рд╡реЗрдЬрд╝ рдХреЛ рдЖрдзрд┐рдХрд╛рд░рд┐рдХ рд╕реНрд░реЛрдд рдорд╛рдирд╛ рдЬрд╛рдирд╛ рдЪрд╛рд╣рд┐рдПред рдорд╣рддреНрд╡рдкреВрд░реНрдг рдЬрд╛рдирдХрд╛рд░реА рдХреЗ рд▓рд┐рдП, рдкреЗрд╢реЗрд╡рд░ рдорд╛рдирд╡ рдЕрдиреБрд╡рд╛рдж рдХреА рд╕рд┐рдлрд╛рд░рд┐рд╢ рдХреА рдЬрд╛рддреА рд╣реИред рдЗрд╕ рдЕрдиреБрд╡рд╛рдж рдХреЗ рдЙрдкрдпреЛрдЧ рд╕реЗ рдЙрддреНрдкрдиреНрди рдХрд┐рд╕реА рднреА рдЧрд▓рддрдлрд╣рдореА рдпрд╛ рдЧрд▓рдд рд╡реНрдпрд╛рдЦреНрдпрд╛ рдХреЗ рд▓рд┐рдП рд╣рдо рдЙрддреНрддрд░рджрд╛рдпреА рдирд╣реАрдВ рд╣реИрдВред