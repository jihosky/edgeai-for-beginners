<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8a7765b85f123e8a62aa3847141ca072",
  "translation_date": "2025-10-30T11:39:45+00:00",
  "source_file": "Module06/03.IntroduceMCP.md",
  "language_code": "hi"
}
-->
# अनुभाग 03 - मॉडल संदर्भ प्रोटोकॉल (MCP) एकीकरण

## MCP (मॉडल संदर्भ प्रोटोकॉल) का परिचय

मॉडल संदर्भ प्रोटोकॉल (MCP) एक ओपन-सोर्स मानक है जो AI एप्लिकेशन को बाहरी सिस्टम से जोड़ने के लिए उपयोग किया जाता है। MCP का उपयोग करके, AI एप्लिकेशन जैसे Claude या ChatGPT डेटा स्रोतों (जैसे, स्थानीय फाइलें, डेटाबेस), टूल्स (जैसे, सर्च इंजन, कैलकुलेटर), और वर्कफ़्लो (जैसे, विशेष प्रॉम्प्ट) से जुड़ सकते हैं—जिससे वे महत्वपूर्ण जानकारी तक पहुंच सकते हैं और कार्य कर सकते हैं।

MCP को AI एप्लिकेशन के लिए **USB-C पोर्ट** की तरह समझें। जैसे USB-C इलेक्ट्रॉनिक डिवाइस को जोड़ने का एक मानकीकृत तरीका प्रदान करता है, वैसे ही MCP AI एप्लिकेशन को बाहरी सिस्टम से जोड़ने का एक मानकीकृत तरीका प्रदान करता है।

### MCP क्या सक्षम कर सकता है?

MCP AI एप्लिकेशन के लिए शक्तिशाली क्षमताओं को अनलॉक करता है:

- **व्यक्तिगत AI सहायक**: एजेंट आपके Google कैलेंडर और Notion तक पहुंच सकते हैं, जिससे वे अधिक व्यक्तिगत AI सहायक बन जाते हैं।
- **उन्नत कोड जनरेशन**: Claude Code Figma डिज़ाइन का उपयोग करके एक पूरा वेब ऐप बना सकता है।
- **एंटरप्राइज डेटा इंटीग्रेशन**: एंटरप्राइज चैटबॉट्स एक संगठन के कई डेटाबेस से जुड़ सकते हैं, जिससे उपयोगकर्ता चैट के माध्यम से डेटा का विश्लेषण कर सकते हैं।
- **क्रिएटिव वर्कफ़्लो**: AI मॉडल Blender पर 3D डिज़ाइन बना सकते हैं और उन्हें 3D प्रिंटर का उपयोग करके प्रिंट कर सकते हैं।
- **रियल-टाइम जानकारी तक पहुंच**: बाहरी डेटा स्रोतों से जुड़कर नवीनतम जानकारी प्राप्त करें।
- **जटिल बहु-चरणीय संचालन**: कई टूल्स और सिस्टम को मिलाकर परिष्कृत वर्कफ़्लो को अंजाम दें।

### MCP क्यों महत्वपूर्ण है?

MCP पूरे इकोसिस्टम में लाभ प्रदान करता है:

**डेवलपर्स के लिए**: MCP AI एप्लिकेशन या एजेंट को बनाते या एकीकृत करते समय विकास समय और जटिलता को कम करता है।

**AI एप्लिकेशन के लिए**: MCP डेटा स्रोतों, टूल्स और ऐप्स के इकोसिस्टम तक पहुंच प्रदान करता है, जो क्षमताओं को बढ़ाता है और अंतिम उपयोगकर्ता अनुभव को बेहतर बनाता है।

**अंतिम उपयोगकर्ताओं के लिए**: MCP अधिक सक्षम AI एप्लिकेशन या एजेंट प्रदान करता है जो आपकी डेटा तक पहुंच सकते हैं और आवश्यक होने पर आपके लिए कार्य कर सकते हैं।

## छोटे भाषा मॉडल (SLMs) MCP में

छोटे भाषा मॉडल AI तैनाती के लिए एक कुशल दृष्टिकोण का प्रतिनिधित्व करते हैं, जो कई लाभ प्रदान करते हैं:

### SLMs के लाभ
- **संसाधन दक्षता**: कम कंप्यूटेशनल आवश्यकताएं
- **तेज प्रतिक्रिया समय**: रियल-टाइम एप्लिकेशन के लिए कम विलंबता  
- **लागत प्रभावशीलता**: न्यूनतम इंफ्रास्ट्रक्चर आवश्यकताएं
- **गोपनीयता**: डेटा ट्रांसमिशन के बिना स्थानीय रूप से चल सकते हैं
- **अनुकूलन**: विशिष्ट डोमेन के लिए आसानी से अनुकूलित किया जा सकता है

### MCP के साथ SLMs क्यों अच्छा काम करते हैं

MCP के साथ जोड़े गए SLMs एक शक्तिशाली संयोजन बनाते हैं, जहां मॉडल की तर्क क्षमता बाहरी टूल्स द्वारा बढ़ाई जाती है, जिससे उनके छोटे पैरामीटर काउंट के बावजूद कार्यक्षमता में सुधार होता है।

## Python MCP SDK का अवलोकन

Python MCP SDK MCP-सक्षम एप्लिकेशन बनाने के लिए आधार प्रदान करता है। SDK में शामिल हैं:

- **क्लाइंट लाइब्रेरी**: MCP सर्वर से जुड़ने के लिए
- **सर्वर फ्रेमवर्क**: कस्टम MCP सर्वर बनाने के लिए
- **प्रोटोकॉल हैंडलर**: संचार प्रबंधन के लिए
- **टूल इंटीग्रेशन**: बाहरी कार्यों को निष्पादित करने के लिए

## व्यावहारिक कार्यान्वयन: Phi-4 MCP क्लाइंट

Microsoft के Phi-4 मिनी मॉडल का उपयोग करके MCP क्षमताओं के साथ एक वास्तविक-विश्व कार्यान्वयन का अन्वेषण करें।

### MCP आर्किटेक्चर का अवलोकन

MCP एक **क्लाइंट-सर्वर आर्किटेक्चर** का अनुसरण करता है, जहां एक MCP होस्ट (जैसे Claude Code या Claude Desktop) एक या अधिक MCP सर्वर से कनेक्शन स्थापित करता है। MCP होस्ट प्रत्येक MCP सर्वर के लिए एक MCP क्लाइंट बनाकर ऐसा करता है।

#### प्रमुख प्रतिभागी

- **MCP होस्ट**: AI एप्लिकेशन जो एक या एक से अधिक MCP क्लाइंट्स का समन्वय और प्रबंधन करता है।
- **MCP क्लाइंट**: एक घटक जो MCP सर्वर से कनेक्शन बनाए रखता है और MCP होस्ट के उपयोग के लिए MCP सर्वर से संदर्भ प्राप्त करता है।
- **MCP सर्वर**: एक प्रोग्राम जो MCP क्लाइंट्स को संदर्भ प्रदान करता है।

#### दो-स्तरीय आर्किटेक्चर

MCP दो अलग-अलग स्तरों से बना है:

**डेटा स्तर**: क्लाइंट-सर्वर संचार के लिए JSON-RPC आधारित प्रोटोकॉल को परिभाषित करता है, जिसमें शामिल हैं:
- जीवनचक्र प्रबंधन (कनेक्शन प्रारंभ, क्षमता वार्ता)
- कोर प्रिमिटिव्स (टूल्स, संसाधन, प्रॉम्प्ट्स)
- क्लाइंट फीचर्स (सैंपलिंग, जानकारी प्राप्त करना, लॉगिंग)
- उपयोगिता फीचर्स (सूचनाएं, प्रगति ट्रैकिंग)

**ट्रांसपोर्ट स्तर**: संचार तंत्र और चैनल को परिभाषित करता है:
- **STDIO ट्रांसपोर्ट**: स्थानीय प्रक्रियाओं के लिए मानक इनपुट/आउटपुट स्ट्रीम का उपयोग करता है (इष्टतम प्रदर्शन, कोई नेटवर्क ओवरहेड नहीं)
- **स्ट्रीमेबल HTTP ट्रांसपोर्ट**: HTTP POST का उपयोग करता है, जिसमें वैकल्पिक सर्वर-सेंट इवेंट्स होते हैं (मानक HTTP प्रमाणीकरण का समर्थन करता है)

```
┌─────────────────────────────────────┐
│           MCP Host                  │
│     (AI Application)                │
└─────────────────┬───────────────────┘
                  │
┌─────────────────┴───────────────────┐
│         MCP Client 1                │
│  ┌─────────────────────────────────┐ │
│  │        Data Layer               │ │
│  │  ├── Lifecycle Management       │ │
│  │  ├── Primitives (Tools/Resources)│ │
│  │  └── Notifications              │ │
│  └─────────────────────────────────┘ │
│  ┌─────────────────────────────────┐ │
│  │      Transport Layer           │ │
│  │  ├── STDIO Transport           │ │
│  │  └── HTTP Transport            │ │
│  └─────────────────────────────────┘ │
└─────────────────┬───────────────────┘
                  │
┌─────────────────┴───────────────────┐
│         MCP Server 1                │
│    (Local/Remote Context Provider)  │
└─────────────────────────────────────┘
```

### MCP कोर प्रिमिटिव्स

MCP प्रिमिटिव्स को परिभाषित करता है जो AI एप्लिकेशन के साथ साझा की जा सकने वाली संदर्भ जानकारी के प्रकार और किए जा सकने वाले कार्यों की सीमा को निर्दिष्ट करते हैं।

#### सर्वर प्रिमिटिव्स

MCP तीन कोर प्रिमिटिव्स को परिभाषित करता है जिन्हें सर्वर उजागर कर सकते हैं:

**टूल्स**: निष्पादन योग्य कार्य जो AI एप्लिकेशन क्रियाओं को अंजाम देने के लिए बुला सकते हैं।
- उदाहरण: फाइल ऑपरेशन, API कॉल्स, डेटाबेस क्वेरीज़
- विधियां: `tools/list`, `tools/call`
- गतिशील खोज और निष्पादन का समर्थन करते हैं

**संसाधन**: डेटा स्रोत जो AI एप्लिकेशन को संदर्भ जानकारी प्रदान करते हैं।
- उदाहरण: फाइल सामग्री, डेटाबेस रिकॉर्ड्स, API प्रतिक्रियाएं
- विधियां: `resources/list`, `resources/read`
- संरचित डेटा तक पहुंच सक्षम करें

**प्रॉम्प्ट्स**: पुन: उपयोग योग्य टेम्पलेट्स जो भाषा मॉडल के साथ इंटरैक्शन को संरचित करने में मदद करते हैं।
- उदाहरण: सिस्टम प्रॉम्प्ट्स, कुछ-शॉट उदाहरण
- विधियां: `prompts/list`, `prompts/get`
- AI इंटरैक्शन पैटर्न को मानकीकृत करें

#### क्लाइंट प्रिमिटिव्स

MCP प्रिमिटिव्स को भी परिभाषित करता है जिन्हें क्लाइंट्स उजागर कर सकते हैं ताकि अधिक समृद्ध इंटरैक्शन सक्षम हो सके:

**सैंपलिंग**: सर्वर को क्लाइंट के AI एप्लिकेशन से भाषा मॉडल पूर्णता का अनुरोध करने की अनुमति देता है।
- विधि: `sampling/complete`
- मॉडल-स्वतंत्र सर्वर विकास को सक्षम करता है
- होस्ट के भाषा मॉडल तक पहुंच प्रदान करता है

**जानकारी प्राप्त करना**: सर्वर को उपयोगकर्ताओं से अतिरिक्त जानकारी का अनुरोध करने की अनुमति देता है।
- विधि: `elicitation/request`
- उपयोगकर्ता इंटरैक्शन और पुष्टि सक्षम करता है
- गतिशील जानकारी एकत्र करने का समर्थन करता है

**लॉगिंग**: सर्वर को क्लाइंट्स को लॉग संदेश भेजने की अनुमति देता है।
- डिबगिंग और निगरानी उद्देश्यों के लिए उपयोग किया जाता है
- सर्वर संचालन में दृश्यता प्रदान करता है

### MCP प्रोटोकॉल जीवनचक्र

#### प्रारंभिककरण और क्षमता वार्ता

MCP एक स्टेटफुल प्रोटोकॉल है जिसे जीवनचक्र प्रबंधन की आवश्यकता होती है। प्रारंभिक प्रक्रिया कई महत्वपूर्ण उद्देश्यों को पूरा करती है:

1. **प्रोटोकॉल संस्करण वार्ता**: सुनिश्चित करता है कि क्लाइंट और सर्वर संगत प्रोटोकॉल संस्करण का उपयोग करते हैं (जैसे, "2025-06-18")
2. **क्षमता खोज**: प्रत्येक पक्ष समर्थित फीचर्स और प्रिमिटिव्स की घोषणा करता है
3. **पहचान विनिमय**: पहचान और संस्करण जानकारी प्रदान करता है

```python
# Example initialization request
{
  "jsonrpc": "2.0",
  "id": 1,
  "method": "initialize",
  "params": {
    "protocolVersion": "2025-06-18",
    "capabilities": {
      "elicitation": {},  # Client supports user interaction
      "sampling": {}      # Client can provide LLM completions
    },
    "clientInfo": {
      "name": "edge-ai-client",
      "version": "1.0.0"
    }
  }
}
```

#### टूल खोज और निष्पादन

प्रारंभिककरण के बाद, क्लाइंट्स टूल्स की खोज और निष्पादन कर सकते हैं:

```python
# Discover available tools
tools_response = await session.list_tools()

# Execute a tool
result = await session.call_tool(
    "weather_current",
    {
        "location": "San Francisco",
        "units": "imperial"
    }
)
```

#### रियल-टाइम सूचनाएं

MCP गतिशील अपडेट के लिए रियल-टाइम सूचनाओं का समर्थन करता है:

```python
# Server sends notification when tools change
{
  "jsonrpc": "2.0",
  "method": "notifications/tools/list_changed"
}

# Client responds by refreshing tool list
await session.list_tools()  # Get updated tools
```

## शुरुआत करें: चरण-दर-चरण गाइड

### चरण 1: पर्यावरण सेटअप

आवश्यक निर्भरताएं स्थापित करें:
```bash
pip install fastmcp mcp-python-client openai requests pyautogui Pillow
```

### चरण 2: बुनियादी कॉन्फ़िगरेशन

अपने पर्यावरण वेरिएबल्स सेट करें:
```python
# System Configuration
SYSTEM_PROMPT = "You are an AI assistant with some tools."

# Ollama Configuration (Local)
OLLAMA_URL = "http://localhost:11434/api/chat"
OLLAMA_MODEL_ID = "phi4-mini:3.8b-fp16"

# vLLM Configuration (Server)
VLLM_URL = "http://localhost:8000/v1"
VLLM_MODEL_ID = "microsoft/Phi-4-mini-instruct"
```

### चरण 3: अपना पहला MCP क्लाइंट चलाना

**बेसिक Ollama सेटअप:**
```bash
python ghmodel_mcp_demo.py
```

**vLLM बैकएंड का उपयोग करना:**
```bash
python ghmodel_mcp_demo.py --env vllm
```

**सर्वर-सेंट इवेंट्स कनेक्शन:**
```bash
python ghmodel_mcp_demo.py --run sse
```

**कस्टम MCP सर्वर:**
```bash
python ghmodel_mcp_demo.py --server /path/to/server.py
```

### चरण 4: प्रोग्रामेटिक उपयोग

```python
import asyncio
from ghmodel_mcp_demo import OllamaClient, Phi4MiniMCPClient

async def automated_interaction():
    # Configure MCP server parameters
    server_params = StdioServerParameters(
        command="npx",
        args=["@playwright/mcp@latest"],
        env=None,
    )
    
    # Create MCP client and process tools
    async with Phi4MiniMCPClient(server_params) as mcp_client:
        tools = await process_mcp_tools(mcp_client)
        llm_client = OllamaClient()
        
        # Generate response with tool capabilities
        response, messages = await llm_client.generate_response(
            "Help me automate a web task",
            tools
        )
        return response

# Execute the automation
result = asyncio.run(automated_interaction())
print(result)
```

## उन्नत सुविधाएं

### मल्टी-बैकएंड समर्थन

यह कार्यान्वयन Ollama और vLLM दोनों बैकएंड्स का समर्थन करता है, जिससे आप अपनी आवश्यकताओं के आधार पर चुन सकते हैं:

- **Ollama**: स्थानीय विकास और परीक्षण के लिए बेहतर
- **vLLM**: उत्पादन और उच्च-थ्रूपुट परिदृश्यों के लिए अनुकूलित

### लचीले कनेक्शन प्रोटोकॉल

दो कनेक्शन मोड समर्थित हैं:

**STDIO मोड**: डायरेक्ट प्रक्रिया संचार
- कम विलंबता
- स्थानीय टूल्स के लिए उपयुक्त
- सरल सेटअप

**SSE मोड**: HTTP-आधारित स्ट्रीमिंग
- नेटवर्क-सक्षम
- वितरित सिस्टम के लिए बेहतर
- रियल-टाइम अपडेट

### टूल इंटीग्रेशन क्षमताएं

सिस्टम विभिन्न टूल्स के साथ एकीकृत हो सकता है:
- वेब ऑटोमेशन (Playwright)
- फाइल ऑपरेशन
- API इंटरैक्शन
- सिस्टम कमांड्स
- कस्टम फंक्शन्स

## त्रुटि प्रबंधन और सर्वोत्तम प्रथाएं

### व्यापक त्रुटि प्रबंधन

यह कार्यान्वयन मजबूत त्रुटि प्रबंधन शामिल करता है:

**कनेक्शन त्रुटियां:**
- MCP सर्वर विफलताएं
- नेटवर्क टाइमआउट्स
- कनेक्टिविटी समस्याएं

**टूल निष्पादन त्रुटियां:**
- गायब टूल्स
- पैरामीटर सत्यापन
- निष्पादन विफलताएं

**प्रतिक्रिया प्रसंस्करण त्रुटियां:**
- JSON पार्सिंग समस्याएं
- स्वरूप असंगतियां
- LLM प्रतिक्रिया विसंगतियां

### सर्वोत्तम प्रथाएं

1. **संसाधन प्रबंधन**: असिंक्रोनस संदर्भ प्रबंधकों का उपयोग करें
2. **त्रुटि प्रबंधन**: व्यापक try-catch ब्लॉक्स लागू करें
3. **लॉगिंग**: उपयुक्त लॉगिंग स्तर सक्षम करें
4. **सुरक्षा**: इनपुट्स को मान्य करें और आउटपुट्स को सैनिटाइज़ करें
5. **प्रदर्शन**: कनेक्शन पूलिंग और कैशिंग का उपयोग करें

## वास्तविक-विश्व अनुप्रयोग

### वेब ऑटोमेशन
```python
# Example: Automated web testing
async def web_automation_example():
    tools = await setup_playwright_tools()
    response = await llm_client.generate_response(
        "Navigate to example.com and take a screenshot",
        tools
    )
```

### डेटा प्रोसेसिंग
```python
# Example: File analysis
async def data_processing_example():
    tools = await setup_file_tools()
    response = await llm_client.generate_response(
        "Analyze the CSV file and generate a summary report",
        tools
    )
```

### API इंटीग्रेशन
```python
# Example: API interactions
async def api_integration_example():
    tools = await setup_api_tools()
    response = await llm_client.generate_response(
        "Fetch weather data and create a forecast summary",
        tools
    )
```

## प्रदर्शन अनुकूलन

### मेमोरी प्रबंधन
- कुशल संदेश इतिहास प्रबंधन
- उचित संसाधन सफाई
- कनेक्शन पूलिंग

### नेटवर्क अनुकूलन
- असिंक्रोनस HTTP संचालन
- कॉन्फ़िगर करने योग्य टाइमआउट्स
- ग्रेसफुल त्रुटि रिकवरी

### समवर्ती प्रसंस्करण
- नॉन-ब्लॉकिंग I/O
- समानांतर टूल निष्पादन
- कुशल असिंक्रोनस पैटर्न

## सुरक्षा विचार

### डेटा सुरक्षा
- सुरक्षित API कुंजी प्रबंधन
- इनपुट सत्यापन
- आउटपुट सैनिटाइजेशन

### नेटवर्क सुरक्षा
- HTTPS समर्थन
- स्थानीय एंडपॉइंट डिफॉल्ट्स
- सुरक्षित टोकन हैंडलिंग

### निष्पादन सुरक्षा
- टूल फ़िल्टरिंग
- सैंडबॉक्स्ड वातावरण
- ऑडिट लॉगिंग

## MCP इकोसिस्टम और विकास

### MCP प्रोजेक्ट स्कोप

मॉडल संदर्भ प्रोटोकॉल इकोसिस्टम में कई प्रमुख घटक शामिल हैं:

- **[MCP स्पेसिफिकेशन](https://modelcontextprotocol.io/specification/latest)**: क्लाइंट्स और सर्वर्स के लिए कार्यान्वयन आवश्यकताओं को रेखांकित करने वाला आधिकारिक स्पेसिफिकेशन
- **[MCP SDKs](https://modelcontextprotocol.io/docs/sdk)**: MCP को लागू करने वाली विभिन्न प्रोग्रामिंग भाषाओं के SDKs
- **MCP विकास उपकरण**: MCP सर्वर्स और क्लाइंट्स विकसित करने के लिए उपकरण, जिसमें [MCP इंस्पेक्टर](https://github.com/modelcontextprotocol/inspector) शामिल है
- **[MCP संदर्भ सर्वर कार्यान्वयन](https://github.com/modelcontextprotocol/servers)**: MCP सर्वर्स के संदर्भ कार्यान्वयन

### MCP विकास के साथ शुरुआत

MCP के साथ निर्माण शुरू करने के लिए:

**सर्वर्स बनाएं**: [MCP सर्वर्स बनाएं](https://modelcontextprotocol.io/docs/develop/build-server) जो आपके डेटा और टूल्स को उजागर करें

**क्लाइंट्स बनाएं**: [ऐप्लिकेशन विकसित करें](https://modelcontextprotocol.io/docs/develop/build-client) जो MCP सर्वर्स से जुड़ें

**अवधारणाएं सीखें**: [कोर अवधारणाओं को समझें](https://modelcontextprotocol.io/docs/learn/architecture) और MCP की आर्किटेक्चर

## निष्कर्ष

MCP के साथ एकीकृत SLMs AI एप्लिकेशन विकास में एक नई दिशा का प्रतिनिधित्व करते हैं। छोटे मॉडल की दक्षता को बाहरी टूल्स की शक्ति के साथ जोड़कर, डेवलपर्स ऐसे बुद्धिमान सिस्टम बना सकते हैं जो संसाधन-कुशल और अत्यधिक सक्षम हों।

मॉडल संदर्भ प्रोटोकॉल AI एप्लिकेशन को बाहरी सिस्टम से जोड़ने का एक मानकीकृत तरीका प्रदान करता है, जैसे USB-C इलेक्ट्रॉनिक डिवाइस के लिए एक सार्वभौमिक कनेक्शन मानक प्रदान करता है। यह मानकीकरण सक्षम करता है:

- **सहज एकीकरण**: AI मॉडल को विविध डेटा स्रोतों और टूल्स से जोड़ें
- **इकोसिस्टम विकास**: एक बार बनाएं, कई AI एप्लिकेशन में उपयोग करें
- **वर्धित क्षमताएं**: SLMs को बाहरी कार्यक्षमता के साथ बढ़ाएं
- **रियल-टाइम अपडेट्स**: गतिशील, उत्तरदायी AI एप्लिकेशन का समर्थन करें

मुख्य बातें:
- MCP एक ओपन मानक है जो AI एप्लिकेशन और बाहरी सिस्टम के बीच पुल का काम करता है
- प्रोटोकॉल टूल्स, संसाधन, और प्रॉम्प्ट्स को कोर प्रिमिटिव्स के रूप में समर्थन करता है
- रियल-टाइम सूचनाएं गतिशील, उत्तरदायी एप्लिकेशन सक्षम करती हैं
- उत्पादन उपयोग के लिए उचित जीवनचक्र प्रबंधन और त्रुटि प्रबंधन आवश्यक है
- इकोसिस्टम व्यापक SDKs और विकास उपकरण प्रदान करता है

## संदर्भ और आगे पढ़ाई

### आधिकारिक MCP दस्तावेज़

- **[मॉडल संदर्भ प्रोटोकॉल आधिकारिक साइट](https://modelcontextprotocol.io/)** - पूर्ण दस्तावेज़ और स्पेसिफिकेशन
- **[MCP शुरुआत गाइड](https://modelcontextprotocol.io/docs/getting-started/intro)** - परिचय और कोर अवधारणाएं
- **[MCP आर्किटेक्चर अवलोकन](https://modelcontextprotocol.io/docs/learn/architecture)** - विस्तृत तकनीकी आर्किटेक्चर
- **[MCP स्पेसिफिकेशन](https://modelcontextprotocol.io/specification/latest)** - आधिकारिक प्रोटोकॉल स्पेसिफिकेशन
- **
- **[Ollama दस्तावेज़](https://ollama.ai/docs)** - स्थानीय LLM तैनाती प्लेटफ़ॉर्म  
- **[vLLM दस्तावेज़](https://docs.vllm.ai/)** - उच्च-प्रदर्शन LLM सेवा  

### तकनीकी मानक और प्रोटोकॉल  

- **[JSON-RPC 2.0 विनिर्देश](https://www.jsonrpc.org/)** - MCP द्वारा उपयोग किया जाने वाला अंतर्निहित RPC प्रोटोकॉल  
- **[JSON Schema](https://json-schema.org/)** - MCP उपकरणों के लिए स्कीमा परिभाषा मानक  
- **[OpenAPI विनिर्देश](https://swagger.io/specification/)** - API दस्तावेज़ीकरण मानक  
- **[Server-Sent Events (SSE)](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events)** - वास्तविक समय अपडेट के लिए वेब मानक  

### एआई एजेंट विकास  

- **[Microsoft Agent Framework](https://github.com/microsoft/agent-framework)** - उत्पादन-तैयार एजेंट विकास  
- **[LangChain दस्तावेज़](https://docs.langchain.com/)** - एजेंट और उपकरण एकीकरण फ्रेमवर्क  
- **[Semantic Kernel](https://learn.microsoft.com/en-us/semantic-kernel/)** - Microsoft का AI ऑर्केस्ट्रेशन SDK  

### उद्योग रिपोर्ट और शोध  

- **[Anthropic का मॉडल संदर्भ प्रोटोकॉल घोषणा](https://www.anthropic.com/news/model-context-protocol)** - मूल MCP परिचय  
- **[छोटे भाषा मॉडल सर्वेक्षण](https://arxiv.org/abs/2410.20011)** - SLM शोध का शैक्षणिक सर्वेक्षण  
- **[एज AI बाजार विश्लेषण](https://www.marketsandmarkets.com/Market-Reports/edge-ai-software-market-74385617.html)** - उद्योग रुझान और पूर्वानुमान  
- **[AI एजेंट विकास सर्वोत्तम प्रथाएँ](https://arxiv.org/abs/2309.02427)** - एजेंट आर्किटेक्चर पर शोध  

यह अनुभाग आपके स्वयं के SLM-संचालित MCP अनुप्रयोगों को बनाने के लिए आधार प्रदान करता है, जो स्वचालन, डेटा प्रसंस्करण, और बुद्धिमान प्रणाली एकीकरण के लिए संभावनाएँ खोलता है।  

## ➡️ आगे क्या  

- [मॉड्यूल 7. एज AI नमूने](../Module07/README.md)  

---

**अस्वीकरण**:  
यह दस्तावेज़ AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) का उपयोग करके अनुवादित किया गया है। जबकि हम सटीकता के लिए प्रयास करते हैं, कृपया ध्यान दें कि स्वचालित अनुवाद में त्रुटियां या अशुद्धियां हो सकती हैं। मूल भाषा में दस्तावेज़ को आधिकारिक स्रोत माना जाना चाहिए। महत्वपूर्ण जानकारी के लिए, पेशेवर मानव अनुवाद की सिफारिश की जाती है। इस अनुवाद के उपयोग से उत्पन्न किसी भी गलतफहमी या गलत व्याख्या के लिए हम उत्तरदायी नहीं हैं।