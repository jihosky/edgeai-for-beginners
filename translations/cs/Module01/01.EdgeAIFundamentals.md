<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "be25052ac4c842765e7f6f7eb4d7dcc5",
  "translation_date": "2025-10-20T09:57:09+00:00",
  "source_file": "Module01/01.EdgeAIFundamentals.md",
  "language_code": "cs"
}
-->
# Sekce 1: Základy EdgeAI

EdgeAI představuje zásadní změnu v nasazení umělé inteligence, přinášející schopnosti AI přímo na koncová zařízení místo spoléhání se výhradně na zpracování v cloudu. Je důležité pochopit, jak EdgeAI umožňuje lokální zpracování AI na zařízeních s omezenými zdroji, přičemž si zachovává přiměřený výkon a řeší výzvy jako soukromí, latence a offline schopnosti.

## Úvod

V této lekci se budeme zabývat EdgeAI a jejími základními koncepty. Probereme tradiční paradigma výpočetní techniky AI, výzvy spojené s edge computingem, klíčové technologie umožňující EdgeAI a praktické aplikace v různých odvětvích.

## Cíle učení

Na konci této lekce budete schopni:

- Porozumět rozdílu mezi tradičním přístupem AI založeným na cloudu a přístupem EdgeAI.
- Identifikovat klíčové technologie umožňující zpracování AI na koncových zařízeních.
- Rozpoznat výhody a omezení implementací EdgeAI.
- Aplikovat znalosti o EdgeAI na reálné scénáře a případy použití.

## Porozumění tradičnímu paradigmatu výpočetní techniky AI

Tradičně se generativní AI aplikace spoléhají na vysoce výkonnou výpočetní infrastrukturu, aby efektivně provozovaly velké jazykové modely (LLMs). Organizace obvykle nasazují tyto modely na GPU clusterech v cloudových prostředích a přistupují k jejich schopnostem prostřednictvím API rozhraní.

Tento centralizovaný model funguje dobře pro mnoho aplikací, ale má inherentní omezení v případě scénářů edge computingu. Tradiční přístup zahrnuje odesílání uživatelských dotazů na vzdálené servery, jejich zpracování pomocí výkonného hardwaru a vracení výsledků přes internet. Zatímco tato metoda poskytuje přístup k nejmodernějším modelům, vytváří závislosti na internetovém připojení, přináší obavy z latence a vyvolává otázky ohledně soukromí při přenosu citlivých dat na externí servery.

Existují některé základní koncepty, které je třeba pochopit při práci s tradičními paradigmaty výpočetní techniky AI, konkrétně:

- **☁️ Zpracování v cloudu**: AI modely běží na výkonné serverové infrastruktuře s vysokými výpočetními zdroji.
- **🔌 Přístup přes API**: Aplikace přistupují k schopnostem AI prostřednictvím vzdálených API volání místo lokálního zpracování.
- **🎛️ Centralizovaná správa modelů**: Modely jsou udržovány a aktualizovány centrálně, což zajišťuje konzistenci, ale vyžaduje síťové připojení.
- **📈 Škálovatelnost zdrojů**: Cloudová infrastruktura se může dynamicky škálovat, aby zvládla různé výpočetní požadavky.

## Výzvy edge computingu

Koncová zařízení, jako jsou notebooky, mobilní telefony a zařízení internetu věcí (IoT), například Raspberry Pi a NVIDIA Orin Nano, mají specifická omezení v oblasti výpočetního výkonu. Tato zařízení obvykle disponují omezeným výpočetním výkonem, pamětí a energetickými zdroji ve srovnání s datovými centry.

Provozování tradičních LLMs na těchto zařízeních bylo historicky náročné kvůli těmto hardwarovým omezením. Nicméně potřeba zpracování AI na koncových zařízeních se stává stále důležitější v různých situacích. Zvažte situace, kdy je internetové připojení nespolehlivé nebo nedostupné, například na vzdálených průmyslových lokalitách, v dopravních prostředcích nebo v oblastech se špatným pokrytím sítě. Navíc aplikace vyžadující vysoké bezpečnostní standardy, jako jsou lékařská zařízení, finanční systémy nebo vládní aplikace, mohou potřebovat zpracovávat citlivá data lokálně, aby zachovaly soukromí a splnily požadavky na soulad.

### Klíčová omezení edge computingu

Prostředí edge computingu čelí několika základním omezením, která tradiční cloudová řešení AI neřeší:

- **Omezený výpočetní výkon**: Koncová zařízení obvykle mají méně CPU jader a nižší taktovací frekvence ve srovnání s hardwarem datových center.
- **Paměťová omezení**: Dostupná RAM a kapacita úložiště jsou na koncových zařízeních výrazně sníženy.
- **Energetická omezení**: Zařízení napájená bateriemi musí vyvážit výkon s energetickou spotřebou pro dlouhodobý provoz.
- **Tepelné řízení**: Kompaktní formáty omezují schopnosti chlazení, což ovlivňuje udržitelný výkon při zátěži.

## Co je EdgeAI?

### Koncept: Definice Edge AI

Edge AI označuje nasazení a provádění algoritmů umělé inteligence přímo na koncových zařízeních – fyzickém hardwaru, který se nachází na "okraji" sítě, blízko místa, kde jsou data generována a sbírána. Tato zařízení zahrnují chytré telefony, IoT senzory, chytré kamery, autonomní vozidla, nositelná zařízení a průmyslové vybavení. Na rozdíl od tradičních AI systémů, které se spoléhají na cloudové servery pro zpracování, Edge AI přináší inteligenci přímo ke zdroji dat.

V jádru jde u Edge AI o decentralizaci zpracování AI, jeho přesun z centralizovaných datových center a distribuci napříč rozsáhlou sítí zařízení, která tvoří náš digitální ekosystém. To představuje zásadní architektonický posun v tom, jak jsou AI systémy navrhovány a nasazovány.

Klíčové konceptuální pilíře Edge AI zahrnují:

- **Zpracování v blízkosti**: Výpočty probíhají fyzicky blízko místa, kde data vznikají.
- **Decentralizovaná inteligence**: Schopnosti rozhodování jsou distribuovány napříč více zařízeními.
- **Suverenita dat**: Informace zůstávají pod lokální kontrolou, často nikdy neopouštějí zařízení.
- **Autonomní provoz**: Zařízení mohou fungovat inteligentně bez nutnosti neustálého připojení.
- **Vestavěná AI**: Inteligence se stává nedílnou součástí běžných zařízení.

### Vizualizace architektury Edge AI

```
┌─────────────────────────────────────────────────────────────────────┐
│                         TRADITIONAL AI ARCHITECTURE                 │
└─────────────────────────────────────────────────────────────────────┘
                                  │
┌──────────────┐   Data Transfer  ┌───────────────┐   API Response   ┌───────────┐
│ Edge Devices ├─────────────────>│ Cloud Servers │────────────────> │ End Users │
└──────────────┘                  └───────────────┘                  └───────────┘
     Data                         Model Inference                     Results
   Collection                     High Latency
                                  High Bandwidth
                                  Privacy Concerns
                               
┌─────────────────────────────────────────────────────────────────────┐
│                            EDGE AI ARCHITECTURE                     │
└─────────────────────────────────────────────────────────────────────┘
                                  │
┌────────────────────────────────────────────────────┐   Direct Response  ┌───────────┐
│              Edge Devices with Embedded AI         │───────────────────>│ End Users │
│  ┌─────────┐  ┌───────────────┐  ┌──────────────┐  │                    └───────────┘
│  │ Sensors │─>│ SLM Inference │─>│ Local Action │  │
│  └─────────┘  └───────────────┘  └──────────────┘  │
└────────────────────────────────────────────────────┘
     Data         Low Latency       Immediate
   Collection     Processing        Response
                  No Data Transfer
                  Enhanced Privacy
```

EdgeAI představuje zásadní změnu v nasazení umělé inteligence, přinášející schopnosti AI přímo na koncová zařízení místo spoléhání se výhradně na zpracování v cloudu. Tento přístup umožňuje provozování AI modelů lokálně na zařízeních s omezenými výpočetními zdroji, poskytující schopnosti inferencí v reálném čase bez nutnosti neustálého připojení k internetu.

EdgeAI zahrnuje různé technologie a techniky navržené tak, aby byly AI modely efektivnější a vhodné pro nasazení na zařízeních s omezenými zdroji. Cílem je zachovat přiměřený výkon při výrazném snížení výpočetních a paměťových požadavků AI modelů.

Podívejme se na základní přístupy, které umožňují implementace EdgeAI na různých typech zařízení a v různých případech použití.

### Základní principy EdgeAI

EdgeAI je postaveno na několika základních principech, které jej odlišují od tradiční AI založené na cloudu:

- **Lokální zpracování**: Inferenční procesy AI probíhají přímo na koncovém zařízení bez nutnosti externího připojení.
- **Optimalizace zdrojů**: Modely jsou optimalizovány speciálně pro hardwarová omezení cílových zařízení.
- **Výkon v reálném čase**: Zpracování probíhá s minimální latencí pro aplikace citlivé na čas.
- **Soukromí jako základ**: Citlivá data zůstávají na zařízení, což zvyšuje bezpečnost a soulad s předpisy.

## Klíčové technologie umožňující EdgeAI

### Kvantizace modelu

Jednou z nejdůležitějších technik v EdgeAI je kvantizace modelu. Tento proces zahrnuje snížení přesnosti parametrů modelu, obvykle z 32bitových čísel s plovoucí desetinnou čárkou na 8bitová celá čísla nebo dokonce na formáty s nižší přesností. Ačkoli se toto snížení přesnosti může zdát znepokojující, výzkum ukázal, že mnoho AI modelů si dokáže udržet svůj výkon i při výrazně snížené přesnosti.

Kvantizace funguje tak, že mapuje rozsah hodnot s plovoucí desetinnou čárkou na menší sadu diskrétních hodnot. Například místo použití 32 bitů k reprezentaci každého parametru může kvantizace použít pouze 8 bitů, což vede ke čtyřnásobnému snížení požadavků na paměť a často k rychlejším časům inferencí.

```python
# Example: PyTorch model quantization 
import torch

# Load a pre-trained model
model = torch.load('large_model.pth')

# Quantize the model to INT8
quantized_model = torch.quantization.quantize_dynamic(
    model,  # model to quantize
    {torch.nn.Linear, torch.nn.Conv2d},  # layers to quantize
    dtype=torch.qint8  # quantization data type
)

# Save the quantized model
torch.save(quantized_model, 'quantized_model.pth')

# Memory usage comparison
original_size = model.size()
quantized_size = quantized_model.size()
print(f"Memory reduction: {original_size / quantized_size:.2f}x")
```

Různé techniky kvantizace zahrnují:

- **Post-training kvantizace (PTQ)**: Aplikována po tréninku modelu bez nutnosti opětovného tréninku.
- **Kvantizace s vědomím tréninku (QAT)**: Zahrnuje účinky kvantizace během tréninku pro lepší přesnost.
- **Dynamická kvantizace**: Kvantizuje váhy na int8, ale aktivace počítá dynamicky.
- **Statická kvantizace**: Předem vypočítává všechny parametry kvantizace pro váhy i aktivace.

Pro nasazení EdgeAI je výběr vhodné strategie kvantizace závislý na konkrétní architektuře modelu, požadavcích na výkon a hardwarových schopnostech cílového zařízení.

### Komprese a optimalizace modelu

Kromě kvantizace pomáhají různé kompresní techniky snížit velikost modelu a výpočetní požadavky. Patří sem:

**Pruning**: Tato technika odstraňuje nepotřebné spojení nebo neurony z neuronových sítí. Identifikací a eliminací parametrů, které málo přispívají k výkonu modelu, může pruning výrazně snížit velikost modelu při zachování přesnosti.

```python
# Example: Neural network pruning in TensorFlow
import tensorflow as tf
import tensorflow_model_optimization as tfmot

# Define the model
model = tf.keras.Sequential([
    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

# Apply pruning during training
pruning_schedule = tfmot.sparsity.keras.PolynomialDecay(
    initial_sparsity=0.0,
    final_sparsity=0.5,  # 50% of connections will be pruned
    begin_step=0,
    end_step=10000
)

pruned_model = tfmot.sparsity.keras.prune_low_magnitude(
    model, pruning_schedule=pruning_schedule
)

# Compile the pruned model
pruned_model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# Train the model while pruning
pruned_model.fit(x_train, y_train, epochs=10)

# Convert to a smaller model for deployment
final_model = tfmot.sparsity.keras.strip_pruning(pruned_model)
```

**Destilace znalostí**: Tento přístup zahrnuje trénink menšího "studentského" modelu, aby napodoboval chování většího "učitelského" modelu. Studentský model se učí přibližovat výstupy učitele, často dosahuje podobného výkonu s výrazně menším počtem parametrů.

**Optimalizace architektury modelu**: Výzkumníci vyvinuli specializované architektury navržené speciálně pro nasazení na koncových zařízeních, jako jsou MobileNets, EfficientNets a další lehké architektury, které vyvažují výkon s výpočetní efektivitou.

### Malé jazykové modely (SLMs)

Vznikající trend v EdgeAI je vývoj malých jazykových modelů (SLMs). Tyto modely jsou navrženy od základu tak, aby byly kompaktní a efektivní, přičemž stále poskytují smysluplné schopnosti zpracování přirozeného jazyka. SLMs toho dosahují prostřednictvím pečlivého výběru architektury, efektivních tréninkových technik a zaměření na specifické domény nebo úkoly.

Na rozdíl od tradičních přístupů, které zahrnují kompresi velkých modelů, jsou SLMs často trénovány na menších datových sadách a optimalizovaných architekturách speciálně navržených pro nasazení na koncových zařízeních. Tento přístup může vést k modelům, které jsou nejen menší, ale také efektivnější pro specifické případy použití.

## Hardwarová akcelerace pro EdgeAI

Moderní koncová zařízení stále častěji zahrnují specializovaný hardware navržený k akceleraci AI úloh:

### Neuronové procesní jednotky (NPUs)

NPUs jsou specializované procesory navržené speciálně pro výpočty neuronových sítí. Tyto čipy mohou provádět inferenční úlohy AI mnohem efektivněji než tradiční CPU, často s nižší spotřebou energie. Mnoho moderních chytrých telefonů, notebooků a IoT zařízení nyní zahrnuje NPUs, které umožňují zpracování AI přímo na zařízení.

```csharp
// Example: Using Windows ML to target NPU acceleration in C#
using Microsoft.ML.OnnxRuntime;

// Create session options with NPU provider
var sessionOptions = new SessionOptions();
sessionOptions.AppendExecutionProvider_DmlExecutionProvider();  // DirectML for NPU

// Load the ONNX model
using var session = new InferenceSession("model.onnx", sessionOptions);

// Create input tensor
var inputTensor = new DenseTensor<float>(new[] { 1, 3, 224, 224 });  // Example input shape
var inputs = new List<NamedOnnxValue> { NamedOnnxValue.CreateFromTensor("input", inputTensor) };

// Run inference with NPU acceleration
using var results = session.Run(inputs);
var output = results.First().AsTensor<float>();

// Process output
Console.WriteLine($"Inference result: {output[0]}");
```

Zařízení s NPUs zahrnují:

- **Apple**: Čipy řady A a M s Neural Engine
- **Qualcomm**: Procesory Snapdragon s Hexagon DSP/NPU
- **Samsung**: Procesory Exynos s NPU
- **Intel**: Movidius VPUs a akcelerátory Habana Labs
- **Microsoft**: Windows Copilot+ PC s NPUs

### 🎮 Akcelerace pomocí GPU

Ačkoli koncová zařízení nemusí mít výkonné GPU, které se nacházejí v datových centrech, mnoho z nich stále zahrnuje integrované nebo diskrétní GPU, které mohou akcelerovat AI úlohy. Moderní mobilní GPU a integrované grafické procesory mohou poskytnout významné zlepšení výkonu pro inferenční úlohy AI.

```python
# Example: Using TensorRT for GPU acceleration on edge devices
import tensorrt as trt
import numpy as np

# Create TensorRT logger and builder
TRT_LOGGER = trt.Logger(trt.Logger.WARNING)
builder = trt.Builder(TRT_LOGGER)
network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))
parser = trt.OnnxParser(network, TRT_LOGGER)

# Parse ONNX model
with open('model.onnx', 'rb') as model:
    parser.parse(model.read())

# Configure builder
config = builder.create_builder_config()
config.max_workspace_size = 1 << 28  # 256 MiB
config.set_flag(trt.BuilderFlag.FP16)  # Use FP16 precision for edge GPU

# Build and serialize engine
engine = builder.build_engine(network, config)
with open('model.trt', 'wb') as f:
    f.write(engine.serialize())
```

### Optimalizace CPU

Dokonce i zařízení pouze s CPU mohou těžit z EdgeAI díky optimalizovaným implementacím. Moderní CPU zahrnují specializované instrukce pro AI úlohy a byly vyvinuty softwarové rámce, které maximalizují výkon CPU pro inferenční úlohy AI.

```bash
# Example: Using XNNPACK with TFLite for optimized CPU inference
# Compilation command with XNNPACK acceleration enabled

bazel build -c opt --copt=-O3 --copt=-march=native \
  tensorflow/lite/delegates/xnnpack:libxnnpack_delegate.so

# Convert TensorFlow model to TFLite with optimization
tflite_convert \
  --keras_model_file=model.h5 \
  --output_file=model.tflite \
  --inference_type=FLOAT \
  --experimental_new_converter \
  --experimental_new_quantizer
```

Pro softwarové inženýry pracující s EdgeAI je klíčové pochopit, jak využít tyto možnosti hardwarové akcelerace pro optimalizaci výkonu inferencí a energetické účinnosti na cílových zařízeních.

## Výhody EdgeAI

### Soukromí a bezpečnost

Jednou z nejvýznamnějších výhod EdgeAI je zvýšené soukromí a bezpečnost. Zpracováním dat lokálně na zařízení citlivé informace nikdy neopustí kontrolu uživatele. To je obzvláště důležité pro aplikace, které pracují s osobními údaji, lékařskými informacemi nebo důvěrnými obchodními daty.

### Snížená latence

EdgeAI eliminuje potřebu odesílat data na vzdálené servery ke zpracování, což výrazně snižuje latenci. To je klíčové pro aplikace v reálném čase, jako jsou autonomní vozidla, průmyslová automatizace nebo interaktivní aplikace, kde jsou vyžadovány okamžité reakce.

### Offline schopnosti

EdgeAI umožňuje funkčnost AI i v případě, že není dostupné internetové připojení. To je cenné pro aplikace na vzdálených místech, během cestování nebo v situacích, kdy je spolehlivost sítě problematická.

### Nákladová efektivita

Snížením závislosti na cloudových AI službách může EdgeAI pomoci snížit provozní náklady, zejména u aplikací s vysokým objemem využití. Organizace se mohou vyhnout průběžným nákladům na API a snížit požadavky na šířku pásma.

### Škálovatelnost

EdgeAI rozkládá výpočetní zátěž na koncová zařízení místo její centralizace v datových centrech. To může pomoci snížit náklady na infrastrukturu a zlepšit celkovou škálovatelnost systému.

## Aplikace EdgeAI

### Chytrá zařízení a IoT

EdgeAI pohání mnoho funkcí chytrých zařízení, od hlasových asistentů, kteří mohou zpracovávat příkazy lokálně, po chytré kamery, které dokážou identifikovat objekty a osoby bez odesílání videa do cloudu. IoT zařízení využívají EdgeAI pro prediktivní údržbu, monitorování prostředí a automatizované rozhodování.

### Mobilní aplikace

Chytré telefony a tablety využívají EdgeAI pro různé funkce, včetně vylepšení fotografií, překladů v reálném čase, rozší
- [02: EdgeAI Aplikace](02.RealWorldCaseStudies.md)

---

**Prohlášení**:  
Tento dokument byl přeložen pomocí služby AI pro překlady [Co-op Translator](https://github.com/Azure/co-op-translator). Ačkoli se snažíme o přesnost, mějte prosím na paměti, že automatizované překlady mohou obsahovat chyby nebo nepřesnosti. Původní dokument v jeho původním jazyce by měl být považován za autoritativní zdroj. Pro důležité informace se doporučuje profesionální lidský překlad. Neodpovídáme za žádná nedorozumění nebo nesprávné interpretace vyplývající z použití tohoto překladu.