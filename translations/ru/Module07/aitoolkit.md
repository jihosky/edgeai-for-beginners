<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "efb0e70d6e87d0795f4d381c3bc99074",
  "translation_date": "2025-10-21T06:49:09+00:00",
  "source_file": "Module07/aitoolkit.md",
  "language_code": "ru"
}
-->
# AI Toolkit для Visual Studio Code - Руководство по разработке Edge AI

## Введение

Добро пожаловать в подробное руководство по использованию AI Toolkit для Visual Studio Code в разработке Edge AI. По мере того, как искусственный интеллект переходит от централизованных облачных вычислений к распределенным устройствам на периферии, разработчикам требуются мощные интегрированные инструменты, способные справляться с уникальными вызовами развертывания на периферии — от ограничений ресурсов до требований к работе в автономном режиме.

AI Toolkit для Visual Studio Code устраняет этот разрыв, предоставляя полноценную среду разработки, специально предназначенную для создания, тестирования и оптимизации AI-приложений, которые эффективно работают на периферийных устройствах. Независимо от того, разрабатываете ли вы для IoT-датчиков, мобильных устройств, встроенных систем или серверов на периферии, этот набор инструментов упрощает весь процесс разработки в привычной среде VS Code.

Это руководство познакомит вас с основными концепциями, инструментами и лучшими практиками использования AI Toolkit в ваших проектах Edge AI — от выбора модели до развертывания в производственной среде.

## Обзор

AI Toolkit для Visual Studio Code — это мощное расширение, которое упрощает разработку агентов и создание AI-приложений. Набор инструментов предоставляет широкие возможности для изучения, оценки и развертывания AI-моделей от множества провайдеров, включая Anthropic, OpenAI, GitHub, Google, а также поддерживает локальное выполнение моделей с использованием ONNX и Ollama.

Что отличает AI Toolkit, так это его комплексный подход ко всему жизненному циклу разработки AI. В отличие от традиционных инструментов, которые сосредоточены на отдельных аспектах, AI Toolkit предлагает интегрированную среду, охватывающую поиск моделей, эксперименты, разработку агентов, оценку и развертывание — все это в привычной среде VS Code.

Платформа специально разработана для быстрого прототипирования и развертывания в производственной среде, с такими функциями, как генерация подсказок, быстрые стартеры, бесшовная интеграция инструментов MCP (Model Context Protocol) и расширенные возможности оценки. Для разработки Edge AI это означает, что вы можете эффективно разрабатывать, тестировать и оптимизировать AI-приложения для сценариев развертывания на периферии, сохраняя полный рабочий процесс разработки в VS Code.

## Цели обучения

К концу этого руководства вы сможете:

### Основные навыки
- **Установить и настроить** AI Toolkit для Visual Studio Code для рабочих процессов разработки Edge AI
- **Ориентироваться и использовать** интерфейс AI Toolkit, включая Model Catalog, Playground и Agent Builder
- **Выбирать и оценивать** AI-модели, подходящие для развертывания на периферии, с учетом производительности и ограничений ресурсов
- **Конвертировать и оптимизировать** модели с использованием формата ONNX и методов квантования для периферийных устройств

### Навыки разработки Edge AI
- **Проектировать и реализовывать** приложения Edge AI с использованием интегрированной среды разработки
- **Проводить тестирование моделей** в условиях, приближенных к периферийным, с использованием локального вывода и мониторинга ресурсов
- **Создавать и настраивать** AI-агентов, оптимизированных для сценариев развертывания на периферии
- **Оценивать производительность моделей** с использованием метрик, релевантных для периферийных вычислений (задержка, использование памяти, точность)

### Оптимизация и развертывание
- **Применять методы квантования и обрезки** для уменьшения размера модели при сохранении приемлемой производительности
- **Оптимизировать модели** для конкретных периферийных аппаратных платформ, включая ускорение на CPU, GPU и NPU
- **Применять лучшие практики** разработки Edge AI, включая управление ресурсами и стратегии резервирования
- **Готовить модели и приложения** к развертыванию на периферийных устройствах

### Продвинутые концепции Edge AI
- **Интегрировать с периферийными AI-фреймворками**, включая ONNX Runtime, Windows ML и TensorFlow Lite
- **Реализовывать многомодельные архитектуры** и сценарии федеративного обучения для периферийных сред
- **Устранять распространенные проблемы Edge AI**, включая ограничения памяти, скорость вывода и совместимость оборудования
- **Разрабатывать стратегии мониторинга и логирования** для AI-приложений на периферии в производственной среде

### Практическое применение
- **Создавать комплексные решения Edge AI** от выбора модели до развертывания
- **Демонстрировать навыки** в специфичных для периферии рабочих процессах разработки и методах оптимизации
- **Применять изученные концепции** к реальным сценариям использования Edge AI, включая IoT, мобильные и встроенные приложения
- **Оценивать и сравнивать** различные стратегии развертывания Edge AI и их компромиссы

## Основные функции для разработки Edge AI

### 1. Каталог моделей и их поиск
- **Поддержка нескольких провайдеров**: Просмотр и доступ к AI-моделям от Anthropic, OpenAI, GitHub, Google и других
- **Интеграция локальных моделей**: Упрощенный поиск моделей ONNX и Ollama для развертывания на периферии
- **Модели GitHub**: Прямая интеграция с хостингом моделей GitHub для упрощенного доступа
- **Сравнение моделей**: Сравнение моделей бок о бок для поиска оптимального баланса для ограничений периферийных устройств

### 2. Интерактивная площадка
- **Интерактивная среда тестирования**: Быстрое экспериментирование с возможностями моделей в контролируемой среде
- **Поддержка мультимодальности**: Тестирование с изображениями, текстом и другими типичными для периферии входными данными
- **Эксперименты в реальном времени**: Мгновенная обратная связь о ответах и производительности моделей
- **Оптимизация параметров**: Тонкая настройка параметров моделей для требований развертывания на периферии

### 3. Конструктор подсказок (агентов)
- **Генерация на естественном языке**: Создание стартовых подсказок с использованием описаний на естественном языке
- **Итеративное улучшение**: Улучшение подсказок на основе ответов моделей и их производительности
- **Декомпозиция задач**: Разделение сложных задач с помощью цепочек подсказок и структурированных выходных данных
- **Поддержка переменных**: Использование переменных в подсказках для динамического поведения агентов
- **Генерация производственного кода**: Создание готового кода для быстрого разработки приложений

### 4. Массовое выполнение и оценка
- **Тестирование нескольких моделей**: Выполнение множества подсказок на выбранных моделях одновременно
- **Эффективное тестирование в масштабе**: Тестирование различных входных данных и конфигураций эффективно
- **Пользовательские тестовые случаи**: Запуск агентов с тестовыми случаями для проверки функциональности
- **Сравнение производительности**: Сравнение результатов на разных моделях и конфигурациях

### 5. Оценка моделей с использованием наборов данных
- **Стандартные метрики**: Тестирование AI-моделей с использованием встроенных оценщиков (F1, релевантность, сходство, когерентность)
- **Пользовательские оценщики**: Создание собственных метрик оценки для конкретных случаев использования
- **Интеграция наборов данных**: Тестирование моделей на обширных наборах данных
- **Измерение производительности**: Количественная оценка производительности моделей для решений о развертывании на периферии

### 6. Возможности тонкой настройки
- **Настройка моделей**: Адаптация моделей для конкретных случаев использования и областей
- **Специализированная адаптация**: Адаптация моделей к специализированным областям и требованиям
- **Оптимизация для периферии**: Тонкая настройка моделей специально для ограничений развертывания на периферии
- **Обучение для конкретных областей**: Создание моделей, адаптированных к специфическим сценариям использования на периферии

### 7. Интеграция инструментов MCP
- **Подключение внешних инструментов**: Подключение агентов к внешним инструментам через серверы Model Context Protocol
- **Действия в реальном мире**: Позволяет агентам запрашивать базы данных, получать доступ к API или выполнять пользовательскую логику
- **Существующие серверы MCP**: Использование инструментов через команды (stdio) или HTTP (server-sent event) протоколы
- **Разработка пользовательских MCP**: Создание и тестирование новых серверов MCP в Agent Builder

### 8. Разработка и тестирование агентов
- **Поддержка вызова функций**: Позволяет агентам динамически вызывать внешние функции
- **Тестирование интеграции в реальном времени**: Тестирование интеграций с реальными запусками и использованием инструментов
- **Версионирование агентов**: Контроль версий агентов с возможностью сравнения результатов оценки
- **Отладка и трассировка**: Локальная трассировка и возможности отладки для разработки агентов

## Рабочий процесс разработки Edge AI

### Фаза 1: Поиск и выбор модели
1. **Изучение каталога моделей**: Используйте каталог моделей для поиска подходящих для развертывания на периферии
2. **Сравнение производительности**: Оцените модели по размеру, точности и скорости вывода
3. **Локальное тестирование**: Используйте модели Ollama или ONNX для локального тестирования перед развертыванием
4. **Оценка требований к ресурсам**: Определите потребности в памяти и вычислительных ресурсах для целевых периферийных устройств

### Фаза 2: Оптимизация модели
1. **Конвертация в ONNX**: Конвертируйте выбранные модели в формат ONNX для совместимости с периферией
2. **Применение квантования**: Уменьшите размер модели с помощью квантования INT8 или INT4
3. **Оптимизация оборудования**: Оптимизируйте для целевого периферийного оборудования (ARM, x86, специализированные ускорители)
4. **Проверка производительности**: Убедитесь, что оптимизированные модели сохраняют приемлемую точность

### Фаза 3: Разработка приложений
1. **Проектирование агентов**: Используйте Agent Builder для создания AI-агентов, оптимизированных для периферии
2. **Инженерия подсказок**: Разрабатывайте подсказки, которые эффективно работают с меньшими моделями для периферии
3. **Тестирование интеграции**: Тестируйте агентов в условиях, имитирующих периферийные
4. **Генерация кода**: Создавайте производственный код, оптимизированный для развертывания на периферии

### Фаза 4: Оценка и тестирование
1. **Массовая оценка**: Тестируйте множество конфигураций для поиска оптимальных настроек периферии
2. **Профилирование производительности**: Анализируйте скорость вывода, использование памяти и точность
3. **Симуляция периферии**: Тестируйте в условиях, аналогичных целевому развертыванию на периферии
4. **Стресс-тестирование**: Оценивайте производительность при различных условиях нагрузки

### Фаза 5: Подготовка к развертыванию
1. **Финальная оптимизация**: Применяйте финальные оптимизации на основе результатов тестирования
2. **Упаковка для развертывания**: Упаковывайте модели и код для развертывания на периферии
3. **Документация**: Документируйте требования к развертыванию и конфигурации
4. **Настройка мониторинга**: Подготовьте мониторинг и логирование для развертывания на периферии

## Целевая аудитория для разработки Edge AI

### Разработчики Edge AI
- Разработчики приложений, создающие устройства с AI и IoT-решения
- Разработчики встроенных систем, интегрирующие AI в устройства с ограниченными ресурсами
- Мобильные разработчики, создающие AI-приложения для смартфонов и планшетов

### Инженеры Edge AI
- Инженеры AI, оптимизирующие модели для развертывания на периферии и управляющие конвейерами вывода
- Инженеры DevOps, развертывающие и управляющие AI-моделями в распределенной периферийной инфраструктуре
- Инженеры производительности, оптимизирующие AI-нагрузки для ограничений периферийного оборудования

### Исследователи и преподаватели
- Исследователи AI, разрабатывающие эффективные модели и алгоритмы для периферийных вычислений
- Преподаватели, обучающие концепциям Edge AI и демонстрирующие методы оптимизации
- Студенты, изучающие вызовы и решения в развертывании Edge AI

## Сценарии использования Edge AI

### Умные IoT-устройства
- **Распознавание изображений в реальном времени**: Развертывание моделей компьютерного зрения на IoT-камерах и датчиках
- **Обработка голоса**: Реализация распознавания речи и обработки естественного языка на умных колонках
- **Прогнозирующее обслуживание**: Запуск моделей обнаружения аномалий на промышленных периферийных устройствах
- **Мониторинг окружающей среды**: Развертывание моделей анализа данных датчиков для экологических приложений

### Мобильные и встроенные приложения
- **Перевод на устройстве**: Реализация моделей перевода языков, работающих в автономном режиме
- **Дополненная реальность**: Развертывание распознавания объектов и отслеживания в реальном времени для приложений AR
- **Мониторинг здоровья**: Запуск моделей анализа здоровья на носимых устройствах и медицинском оборудовании
- **Автономные системы**: Реализация моделей принятия решений для дронов, роботов и транспортных средств

### Инфраструктура периферийных вычислений
- **Периферийные дата-центры**: Развертывание AI-моделей в периферийных дата-центрах для приложений с низкой задержкой
- **Интеграция CDN**: Интеграция возможностей AI-обработки в сети доставки контента
- **Периферия 5G**: Использование периферийных вычислений 5G для приложений с поддержкой AI
- **Туманные вычисления**: Реализация AI-обработки в средах туманных вычислений

## Установка и настройка

### Установка расширения
Установите расширение AI Toolkit напрямую из Visual Studio Code Marketplace:

**ID расширения**: `ms-windows-ai-studio.windows-ai-studio`

**Методы установки**:
1. **VS Code Marketplace**: Найдите "AI Toolkit" в представлении Extensions
2. **Командная строка**: `code --install-extension ms-windows-ai-studio.windows-ai-studio`
3. **Прямая установка**: Загрузите с [VS Code Marketplace](https://marketplace.visualstudio.com/items?itemName=ms-windows-ai-studio.windows-ai-studio)

### Предварительные требования для разработки Edge AI
- **Visual Studio Code**: Рекомендуется последняя версия
- **Среда Python**: Python 3.8+ с необходимыми библиотеками AI
- **ONNX Runtime** (опционально): Для вывода моделей ONNX
- **Ollama** (опционально): Для локального обслуживания моделей
- **Инструменты аппаратного ускорения**: CUDA, OpenVINO или ускорители, специфичные для платформы

### Первоначальная настройка
1. **Активация расширения**: Откройте VS Code и убедитесь, что AI Toolkit отображается в панели активности
2. **Настройка провайдера моделей**: Настройте доступ к GitHub, OpenAI, Anthropic или другим провайдерам моделей
3. **Локальная среда**: Настройте среду Python и установите необходимые пакеты
4. **Аппаратное ускорение**: Настройте ускорение GPU/NPU, если доступно
5. **Интеграция MCP**: Настройте серверы Model Context Protocol, если это необходимо

### Контрольный список для первого запуска
- [ ] Установлено и активировано расширение AI Toolkit
- [ ] Доступен каталог моделей и модели обнаружены
- [ ] Площадка работает для тестирования моделей
- [ ] Доступен Agent Builder для разработки подсказок
- [ ] Настроена локальная среда разработки
- [ ] Аппаратное ускорение (если доступно) настроено правильно

## Начало работы с AI Toolkit

### Руководство по быстрому старту

Мы рекомендуем начать с моделей, размещенных на GitHub, для наиболее упрощенного опыта:

1. **Установка**: Следуйте [руководству по установке](https://code.visualstudio.com/docs/intelligentapps/overview#_install-and-setup), чтобы настроить AI Toolkit на вашем устройстве
2. **Поиск моделей**: В дереве расширений выберите **CATALOG > Models**, чтобы изучить доступные модели
3. **Модели GitHub**: Начните с моделей, размещенных на GitHub, для оптимальной интеграции
4. **Тестирование в Playground**: На любой карточке модели выберите **Try in Playground**, чтобы начать экспериментировать с возможностями модели

### Пошаговая разработка Edge AI
2. Создайте начальные подсказки, используя описания на естественном языке  
3. Итеративно уточняйте подсказки на основе ответов модели  
4. Интегрируйте инструменты MCP для расширения возможностей агентов  

#### Шаг 3: Тестирование и оценка  
1. Используйте **Bulk Run** для тестирования множества подсказок на выбранных моделях  
2. Запускайте агентов с тестовыми случаями для проверки функциональности  
3. Оценивайте точность и производительность с помощью встроенных или пользовательских метрик  
4. Сравнивайте различные модели и конфигурации  

#### Шаг 4: Тонкая настройка и оптимизация  
1. Настраивайте модели для специфических случаев использования  
2. Применяйте тонкую настройку для конкретных доменов  
3. Оптимизируйте для ограничений развертывания на периферийных устройствах  
4. Версионируйте и сравнивайте различные конфигурации агентов  

#### Шаг 5: Подготовка к развертыванию  
1. Генерируйте готовый к производству код с помощью Agent Builder  
2. Настройте подключения к серверу MCP для использования в производстве  
3. Подготовьте пакеты развертывания для периферийных устройств  
4. Настройте метрики мониторинга и оценки  

## Примеры для AI Toolkit  

Попробуйте наши примеры  
[Примеры AI Toolkit](https://github.com/Azure-Samples/AI_Toolkit_Samples) разработаны, чтобы помочь разработчикам и исследователям эффективно изучать и внедрять AI-решения.  

Наши примеры включают:  

Пример кода: Готовые примеры, демонстрирующие функциональность AI, такие как обучение, развертывание или интеграция моделей в приложения.  
Документация: Руководства и учебные материалы, помогающие пользователям понять возможности AI Toolkit и как их использовать.  
Требования  

- Visual Studio Code  
- AI Toolkit для Visual Studio Code  
- Личный токен доступа GitHub (PAT)  
- Foundry Local  

## Лучшие практики разработки Edge AI  

### Выбор модели  
- **Ограничения размера**: Выбирайте модели, которые соответствуют ограничениям памяти целевых устройств  
- **Скорость вывода**: Отдавайте предпочтение моделям с быстрой скоростью вывода для приложений в реальном времени  
- **Компромиссы точности**: Балансируйте точность модели с ограничениями ресурсов  
- **Совместимость форматов**: Предпочитайте форматы ONNX или оптимизированные для оборудования для развертывания на периферии  

### Техники оптимизации  
- **Квантизация**: Используйте квантизацию INT8 или INT4 для уменьшения размера модели и повышения скорости  
- **Обрезка**: Удаляйте ненужные параметры модели для снижения вычислительных требований  
- **Дистилляция знаний**: Создавайте меньшие модели, сохраняющие производительность больших  
- **Аппаратное ускорение**: Используйте NPU, GPU или специализированные ускорители, если они доступны  

### Рабочий процесс разработки  
- **Итеративное тестирование**: Часто тестируйте в условиях, похожих на периферийные, во время разработки  
- **Мониторинг производительности**: Постоянно отслеживайте использование ресурсов и скорость вывода  
- **Контроль версий**: Отслеживайте версии моделей и настройки оптимизации  
- **Документация**: Документируйте все решения по оптимизации и компромиссы производительности  

### Учет при развертывании  
- **Мониторинг ресурсов**: Отслеживайте использование памяти, процессора и энергии в производстве  
- **Резервные стратегии**: Реализуйте механизмы резервирования на случай отказов модели  
- **Механизмы обновления**: Планируйте обновления моделей и управление версиями  
- **Безопасность**: Реализуйте соответствующие меры безопасности для приложений Edge AI  

## Интеграция с фреймворками Edge AI  

### ONNX Runtime  
- **Кроссплатформенное развертывание**: Развертывайте модели ONNX на различных периферийных платформах  
- **Оптимизация оборудования**: Используйте оптимизации ONNX Runtime для конкретного оборудования  
- **Поддержка мобильных устройств**: Используйте ONNX Runtime Mobile для приложений на смартфонах и планшетах  
- **Интеграция с IoT**: Развертывайте на IoT-устройствах с использованием легких дистрибутивов ONNX Runtime  

### Windows ML  
- **Устройства Windows**: Оптимизируйте для периферийных устройств и ПК на базе Windows  
- **Ускорение NPU**: Используйте нейронные процессоры на устройствах Windows  
- **DirectML**: Используйте DirectML для ускорения на GPU на платформах Windows  
- **Интеграция UWP**: Интегрируйте с приложениями Universal Windows Platform  

### TensorFlow Lite  
- **Оптимизация для мобильных устройств**: Развертывайте модели TensorFlow Lite на мобильных и встроенных устройствах  
- **Аппаратные делегаты**: Используйте специализированные аппаратные делегаты для ускорения  
- **Микроконтроллеры**: Развертывайте на микроконтроллерах с использованием TensorFlow Lite Micro  
- **Кроссплатформенная поддержка**: Развертывайте на Android, iOS и встроенных системах Linux  

### Azure IoT Edge  
- **Гибрид облако-периферия**: Совмещайте обучение в облаке с выводом на периферии  
- **Развертывание модулей**: Развертывайте AI-модели как модули IoT Edge  
- **Управление устройствами**: Управляйте периферийными устройствами и обновлениями моделей удаленно  
- **Телеметрия**: Сбор данных о производительности и метрик моделей с периферийных развертываний  

## Сложные сценарии Edge AI  

### Развертывание нескольких моделей  
- **Ансамбли моделей**: Развертывайте несколько моделей для повышения точности или надежности  
- **A/B тестирование**: Тестируйте разные модели одновременно на периферийных устройствах  
- **Динамический выбор**: Выбирайте модели на основе текущих условий устройства  
- **Общий доступ к ресурсам**: Оптимизируйте использование ресурсов между несколькими развернутыми моделями  

### Федеративное обучение  
- **Распределенное обучение**: Обучайте модели на нескольких периферийных устройствах  
- **Сохранение конфиденциальности**: Оставляйте данные обучения локально, делясь улучшениями моделей  
- **Коллаборативное обучение**: Позволяйте устройствам учиться на коллективном опыте  
- **Координация периферия-облако**: Координируйте обучение между периферийными устройствами и облачной инфраструктурой  

### Обработка в реальном времени  
- **Обработка потоков**: Обрабатывайте непрерывные потоки данных на периферийных устройствах  
- **Вывод с низкой задержкой**: Оптимизируйте для минимальной задержки вывода  
- **Пакетная обработка**: Эффективно обрабатывайте пакеты данных на периферийных устройствах  
- **Адаптивная обработка**: Регулируйте обработку в зависимости от текущих возможностей устройства  

## Устранение неполадок в разработке Edge AI  

### Распространенные проблемы  
- **Ограничения памяти**: Модель слишком большая для памяти целевого устройства  
- **Скорость вывода**: Вывод модели слишком медленный для требований реального времени  
- **Снижение точности**: Оптимизация снижает точность модели до неприемлемого уровня  
- **Совместимость оборудования**: Модель несовместима с целевым оборудованием  

### Стратегии отладки  
- **Профилирование производительности**: Используйте функции трассировки AI Toolkit для выявления узких мест  
- **Мониторинг ресурсов**: Отслеживайте использование памяти и процессора во время разработки  
- **Инкрементное тестирование**: Тестируйте оптимизации поэтапно, чтобы изолировать проблемы  
- **Симуляция оборудования**: Используйте инструменты разработки для симуляции целевого оборудования  

### Решения для оптимизации  
- **Дополнительная квантизация**: Применяйте более агрессивные техники квантизации  
- **Архитектура модели**: Рассмотрите другие архитектуры моделей, оптимизированные для периферии  
- **Оптимизация предварительной обработки**: Оптимизируйте предварительную обработку данных для ограничений периферии  
- **Оптимизация вывода**: Используйте оптимизации вывода, специфичные для оборудования  

## Ресурсы и дальнейшие шаги  

### Официальная документация  
- [Документация для разработчиков AI Toolkit](https://aka.ms/AIToolkit/doc)  
- [Руководство по установке и настройке](https://code.visualstudio.com/docs/intelligentapps/overview#_install-and-setup)  
- [Документация VS Code Intelligent Apps](https://code.visualstudio.com/docs/intelligentapps)  
- [Документация Model Context Protocol (MCP)](https://modelcontextprotocol.io/)  

### Сообщество и поддержка  
- [Репозиторий AI Toolkit на GitHub](https://github.com/microsoft/vscode-ai-toolkit)  
- [Обсуждения и запросы функций на GitHub](https://aka.ms/AIToolkit/feedback)  
- [Сообщество Azure AI Foundry в Discord](https://aka.ms/azureaifoundry/discord)  
- [Marketplace расширений VS Code](https://marketplace.visualstudio.com/items?itemName=ms-windows-ai-studio.windows-ai-studio)  

### Технические ресурсы  
- [Документация ONNX Runtime](https://onnxruntime.ai/)  
- [Документация Ollama](https://ollama.ai/)  
- [Документация Windows ML](https://docs.microsoft.com/en-us/windows/ai/)  
- [Документация Azure AI Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/)  

### Учебные материалы  
- [Курс основ Edge AI](../Module01/README.md)  
- [Руководство по малым языковым моделям](../Module02/README.md)  
- [Стратегии развертывания на периферии](../Module03/README.md)  
- [Разработка Edge AI для Windows](./windowdeveloper.md)  

### Дополнительные ресурсы  
- **Статистика репозитория**: 1.8k+ звезд, 150+ форков, 18+ участников  
- **Лицензия**: Лицензия MIT  
- **Безопасность**: Применяются политики безопасности Microsoft  
- **Телеметрия**: Учитывает настройки телеметрии VS Code  

## Заключение  

AI Toolkit для Visual Studio Code представляет собой комплексную платформу для современной разработки AI, предоставляя возможности для разработки агентов, которые особенно ценны для приложений Edge AI. С обширным каталогом моделей, поддерживающим таких провайдеров, как Anthropic, OpenAI, GitHub и Google, а также локальным выполнением через ONNX и Ollama, этот инструмент предлагает гибкость, необходимую для разнообразных сценариев развертывания на периферии.  

Сила AI Toolkit заключается в интегрированном подходе — от поиска моделей и экспериментов в Playground до сложной разработки агентов с Prompt Builder, комплексных возможностей оценки и бесшовной интеграции инструментов MCP. Для разработчиков Edge AI это означает быстрое создание прототипов и тестирование AI-агентов перед развертыванием на периферии с возможностью быстрого итеративного процесса и оптимизации для сред с ограниченными ресурсами.  

Ключевые преимущества для разработки Edge AI включают:  
- **Быстрое тестирование**: Тестируйте модели и агентов быстро перед развертыванием на периферии  
- **Гибкость провайдеров**: Доступ к моделям от различных источников для поиска оптимальных решений  
- **Локальная разработка**: Тестируйте с ONNX и Ollama для автономной и конфиденциальной разработки  
- **Готовность к производству**: Генерируйте готовый к производству код и интегрируйте с внешними инструментами через MCP  
- **Комплексная оценка**: Используйте встроенные и пользовательские метрики для проверки производительности Edge AI  

По мере того как AI продолжает двигаться в сторону сценариев развертывания на периферии, AI Toolkit для VS Code предоставляет среду разработки и рабочий процесс, необходимые для создания, тестирования и оптимизации интеллектуальных приложений для сред с ограниченными ресурсами. Независимо от того, разрабатываете ли вы IoT-решения, мобильные AI-приложения или встроенные интеллектуальные системы, комплексный набор функций и интегрированный рабочий процесс поддерживают весь жизненный цикл разработки Edge AI.  

С постоянным развитием и активным сообществом (1.8k+ звезд на GitHub) AI Toolkit остается на передовой среди инструментов разработки AI, постоянно адаптируясь к потребностям современных разработчиков AI, создающих решения для сценариев развертывания на периферии.  

[Next Foundry Local](./foundrylocal.md)

---

**Отказ от ответственности**:  
Этот документ был переведен с использованием сервиса автоматического перевода [Co-op Translator](https://github.com/Azure/co-op-translator). Хотя мы стремимся к точности, пожалуйста, учитывайте, что автоматические переводы могут содержать ошибки или неточности. Оригинальный документ на его родном языке следует считать авторитетным источником. Для получения критически важной информации рекомендуется профессиональный перевод человеком. Мы не несем ответственности за любые недоразумения или неправильные интерпретации, возникающие в результате использования данного перевода.