<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "44bc28c27b993c5fb988791b7a115705",
  "translation_date": "2025-10-30T10:45:57+00:00",
  "source_file": "Module06/01.IntroduceAgent.md",
  "language_code": "ru"
}
-->
# AI-–∞–≥–µ–Ω—Ç—ã –∏ –º–∞–ª—ã–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏: –ü–æ–ª–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ

## –í–≤–µ–¥–µ–Ω–∏–µ

–í —ç—Ç–æ–º —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–µ –º—ã —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º AI-–∞–≥–µ–Ω—Ç–æ–≤ –∏ –º–∞–ª—ã–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ (SLM), –∞ —Ç–∞–∫–∂–µ –∏—Ö –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–ª—è —Å—Ä–µ–¥ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –Ω–∞ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–∏. –ú—ã –æ–±—Å—É–¥–∏–º –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ –∞–≥–µ–Ω—Ç–Ω–æ–≥–æ –ò–ò, –º–µ—Ç–æ–¥—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ SLM, –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –¥–ª—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–º–∏ —Ä–µ—Å—É—Ä—Å–∞–º–∏ –∏ Microsoft Agent Framework –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≥–æ—Ç–æ–≤—ã—Ö –∫ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤—É –∞–≥–µ–Ω—Ç–Ω—ã—Ö —Å–∏—Å—Ç–µ–º.

–õ–∞–Ω–¥—à–∞—Ñ—Ç –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞ –ø–µ—Ä–µ–∂–∏–≤–∞–µ—Ç –ø–∞—Ä–∞–¥–∏–≥–º–∞–ª—å–Ω—ã–π —Å–¥–≤–∏–≥ –≤ 2025 –≥–æ–¥—É. –ï—Å–ª–∏ 2023 –≥–æ–¥ –±—ã–ª –≥–æ–¥–æ–º —á–∞—Ç-–±–æ—Ç–æ–≤, –∞ 2024 ‚Äî –±—É–º–æ–º –∫–æ–ø–∏–ª–æ—Ç–æ–≤, —Ç–æ 2025 –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç AI-–∞–≥–µ–Ω—Ç–∞–º ‚Äî –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–º —Å–∏—Å—Ç–µ–º–∞–º, –∫–æ—Ç–æ—Ä—ã–µ –¥—É–º–∞—é—Ç, —Ä–∞—Å—Å—É–∂–¥–∞—é—Ç, –ø–ª–∞–Ω–∏—Ä—É—é—Ç, –∏—Å–ø–æ–ª—å–∑—É—é—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –∏ –≤—ã–ø–æ–ª–Ω—è—é—Ç –∑–∞–¥–∞—á–∏ —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º —É—á–∞—Å—Ç–∏–µ–º —á–µ–ª–æ–≤–µ–∫–∞, –≤—Å–µ —á–∞—â–µ –æ–ø–∏—Ä–∞—è—Å—å –Ω–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ –º–∞–ª—ã–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏. Microsoft Agent Framework —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è –≤–µ–¥—É—â–∏–º —Ä–µ—à–µ–Ω–∏–µ–º –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —ç—Ç–∏—Ö –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã—Ö —Å–∏—Å—Ç–µ–º —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏ —Ä–∞–±–æ—Ç—ã –≤ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–º —Ä–µ–∂–∏–º–µ –Ω–∞ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–∏.

## –¶–µ–ª–∏ –æ–±—É—á–µ–Ω–∏—è

–ö –∫–æ–Ω—Ü—É —ç—Ç–æ–≥–æ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞ –≤—ã —Å–º–æ–∂–µ—Ç–µ:

- ü§ñ –ü–æ–Ω—è—Ç—å –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ AI-–∞–≥–µ–Ω—Ç–æ–≤ –∏ –∞–≥–µ–Ω—Ç–Ω—ã—Ö —Å–∏—Å—Ç–µ–º
- üî¨ –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –º–∞–ª—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –±–æ–ª—å—à–∏–º–∏ —è–∑—ã–∫–æ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ –≤ –∞–≥–µ–Ω—Ç–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è—Ö
- üöÄ –ò–∑—É—á–∏—Ç—å –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è SLM –¥–ª—è —Å—Ä–µ–¥ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –Ω–∞ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–∏
- üì± –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∞–≥–µ–Ω—Ç—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ SLM –¥–ª—è —Ä–µ–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π
- üèóÔ∏è –°–æ–∑–¥–∞—Ç—å –≥–æ—Ç–æ–≤—ã—Ö –∫ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤—É –∞–≥–µ–Ω—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Microsoft Agent Framework
- üåê –†–∞–∑–≤–µ—Ä–Ω—É—Ç—å –∞–≤—Ç–æ–Ω–æ–º–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–∏ —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π –ª–æ–∫–∞–ª—å–Ω—ã—Ö LLM –∏ SLM
- üîß –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å Microsoft Agent Framework —Å Foundry Local –¥–ª—è —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –Ω–∞ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–∏

## –ü–æ–Ω–∏–º–∞–Ω–∏–µ AI-–∞–≥–µ–Ω—Ç–æ–≤: –æ—Å–Ω–æ–≤—ã –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è

### –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏ –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏

–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç (AI) –∞–≥–µ–Ω—Ç ‚Äî —ç—Ç–æ —Å–∏—Å—Ç–µ–º–∞ –∏–ª–∏ –ø—Ä–æ–≥—Ä–∞–º–º–∞, —Å–ø–æ—Å–æ–±–Ω–∞—è –∞–≤—Ç–æ–Ω–æ–º–Ω–æ –≤—ã–ø–æ–ª–Ω—è—Ç—å –∑–∞–¥–∞—á–∏ –æ—Ç –∏–º–µ–Ω–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–ª–∏ –¥—Ä—É–≥–æ–π —Å–∏—Å—Ç–µ–º—ã, –ø—Ä–æ–µ–∫—Ç–∏—Ä—É—è —Å–≤–æ–π —Ä–∞–±–æ—á–∏–π –ø—Ä–æ—Ü–µ—Å—Å –∏ –∏—Å–ø–æ–ª—å–∑—É—è –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã. –í –æ—Ç–ª–∏—á–∏–µ –æ—Ç —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω–æ–≥–æ –ò–ò, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–æ—Å—Ç–æ –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –≤–∞—à–∏ –≤–æ–ø—Ä–æ—Å—ã, –∞–≥–µ–Ω—Ç –º–æ–∂–µ—Ç –¥–µ–π—Å—Ç–≤–æ–≤–∞—Ç—å –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è —Ü–µ–ª–µ–π.

### –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–æ–≤

–ü–æ–Ω–∏–º–∞–Ω–∏–µ –≥—Ä–∞–Ω–∏—Ü –∞–≥–µ–Ω—Ç–æ–≤ –ø–æ–º–æ–≥–∞–µ—Ç –≤—ã–±—Ä–∞—Ç—å –ø–æ–¥—Ö–æ–¥—è—â–∏–µ —Ç–∏–ø—ã –∞–≥–µ–Ω—Ç–æ–≤ –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤:

- **üî¨ –ü—Ä–æ—Å—Ç—ã–µ —Ä–µ—Ñ–ª–µ–∫—Å–Ω—ã–µ –∞–≥–µ–Ω—Ç—ã**: –°–∏—Å—Ç–µ–º—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–∞–≤–∏–ª, —Ä–µ–∞–≥–∏—Ä—É—é—â–∏–µ –Ω–∞ –Ω–µ–ø–æ—Å—Ä–µ–¥—Å—Ç–≤–µ–Ω–Ω—ã–µ –≤–æ—Å–ø—Ä–∏—è—Ç–∏—è (—Ç–µ—Ä–º–æ—Å—Ç–∞—Ç—ã, –±–∞–∑–æ–≤–∞—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è)
- **üì± –ê–≥–µ–Ω—Ç—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–æ–¥–µ–ª–µ–π**: –°–∏—Å—Ç–µ–º—ã, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–µ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∏ –ø–∞–º—è—Ç—å (—Ä–æ–±–æ—Ç—ã-–ø—ã–ª–µ—Å–æ—Å—ã, –Ω–∞–≤–∏–≥–∞—Ü–∏–æ–Ω–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã)
- **‚öñÔ∏è –¶–µ–ª–µ–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∞–≥–µ–Ω—Ç—ã**: –°–∏—Å—Ç–µ–º—ã, –∫–æ—Ç–æ—Ä—ã–µ –ø–ª–∞–Ω–∏—Ä—É—é—Ç –∏ –≤—ã–ø–æ–ª–Ω—è—é—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è —Ü–µ–ª–µ–π (–ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∏ –º–∞—Ä—à—Ä—É—Ç–æ–≤, —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è –∑–∞–¥–∞—á)
- **üß† –û–±—É—á–∞—é—â–∏–µ—Å—è –∞–≥–µ–Ω—Ç—ã**: –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ –≤—Ä–µ–º–µ–Ω–µ–º —É–ª—É—á—à–∞—é—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (—Å–∏—Å—Ç–µ–º—ã —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π, –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–º–æ—â–Ω–∏–∫–∏)

### –û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ AI-–∞–≥–µ–Ω—Ç–æ–≤

AI-–∞–≥–µ–Ω—Ç—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—ã—Ö –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤, –∫–æ—Ç–æ—Ä—ã–µ –¥–µ–ª–∞—é—Ç –∏—Ö –∏–¥–µ–∞–ª—å–Ω—ã–º–∏ –¥–ª—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π –Ω–∞ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–∏:

**–û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è –∞–≤—Ç–æ–Ω–æ–º–∏—è**: –ê–≥–µ–Ω—Ç—ã –æ–±–µ—Å–ø–µ—á–∏–≤–∞—é—Ç –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–¥–∞—á –±–µ–∑ –ø–æ—Å—Ç–æ—è–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç—Ä–æ–ª—è —á–µ–ª–æ–≤–µ–∫–∞, —á—Ç–æ –¥–µ–ª–∞–µ—Ç –∏—Ö –∏–¥–µ–∞–ª—å–Ω—ã–º–∏ –¥–ª—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏. –û–Ω–∏ —Ç—Ä–µ–±—É—é—Ç –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –Ω–∞–¥–∑–æ—Ä–∞, —Å–æ—Ö—Ä–∞–Ω—è—è –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞—Ç—å –∏—Ö –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞—Ö —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–º–∏ —Ä–µ—Å—É—Ä—Å–∞–º–∏ —Å —É–º–µ–Ω—å—à–µ–Ω–Ω—ã–º–∏ —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–æ–Ω–Ω—ã–º–∏ –∑–∞—Ç—Ä–∞—Ç–∞–º–∏.

**–ì–∏–±–∫–æ—Å—Ç—å —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è**: –≠—Ç–∏ —Å–∏—Å—Ç–µ–º—ã –æ–±–µ—Å–ø–µ—á–∏–≤–∞—é—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –ò–ò –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ –±–µ–∑ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É, –ø–æ–≤—ã—à–∞—é—Ç –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å –∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –±–ª–∞–≥–æ–¥–∞—Ä—è –ª–æ–∫–∞–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ, –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã –¥–ª—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π, —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏, –∏ –ø–æ–¥—Ö–æ–¥—è—Ç –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Å—Ä–µ–¥ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –Ω–∞ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–∏.

**–≠–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∞—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å**: –ê–≥–µ–Ω—Ç–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –æ–±–ª–∞—á–Ω—ã–º–∏ —Ä–µ—à–µ–Ω–∏—è–º–∏, —Å —É–º–µ–Ω—å—à–µ–Ω–Ω—ã–º–∏ —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–æ–Ω–Ω—ã–º–∏ –∑–∞—Ç—Ä–∞—Ç–∞–º–∏ –∏ —Å–Ω–∏–∂–µ–Ω–Ω–æ–π –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—å—é –≤ –ø—Ä–æ–ø—É—Å–∫–Ω–æ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –¥–ª—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π –Ω–∞ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–∏.

## –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –º–∞–ª—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π

### –û—Å–Ω–æ–≤—ã SLM (–º–∞–ª—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π)

–ú–∞–ª–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å (SLM) ‚Äî —ç—Ç–æ —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è –º–æ–∂–µ—Ç –±—ã—Ç—å —Ä–∞–∑–º–µ—â–µ–Ω–∞ –Ω–∞ –æ–±—ã—á–Ω–æ–º –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å—Å–∫–æ–º —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ –∏ –≤—ã–ø–æ–ª–Ω—è—Ç—å –≤—ã–≤–æ–¥ —Å –∑–∞–¥–µ—Ä–∂–∫–æ–π, –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –Ω–∏–∑–∫–æ–π –¥–ª—è –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø—Ä–∏ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–∏ –∑–∞–ø—Ä–æ—Å–æ–≤ –∞–≥–µ–Ω—Ç–∞ –æ–¥–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –ù–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ SLM –æ–±—ã—á–Ω–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç —Å–æ–±–æ–π –º–æ–¥–µ–ª–∏ —Å –º–µ–Ω–µ–µ —á–µ–º 10 –º–∏–ª–ª–∏–∞—Ä–¥–∞–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.

**–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è —Ñ–æ—Ä–º–∞—Ç–æ–≤**: SLM –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—É—é –ø–æ–¥–¥–µ—Ä–∂–∫—É —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —É—Ä–æ–≤–Ω–µ–π –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏—è, —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –º–µ–∂–¥—É –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞–º–∏, –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –Ω–∞ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–∏. –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –º–æ–≥—É—Ç –ø–æ–ª—É—á–∏—Ç—å —É–ª—É—á—à–µ–Ω–Ω—É—é –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å –±–ª–∞–≥–æ–¥–∞—Ä—è –ª–æ–∫–∞–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏ –ø–æ–¥–¥–µ—Ä–∂–∫–µ WebGPU –¥–ª—è —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –≤ –±—Ä–∞—É–∑–µ—Ä–µ.

**–ö–æ–ª–ª–µ–∫—Ü–∏–∏ —É—Ä–æ–≤–Ω–µ–π –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏—è**: –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã SLM –≤–∫–ª—é—á–∞—é—Ç Q4_K_M –¥–ª—è —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∫–æ–º–ø—Ä–µ—Å—Å–∏–∏ –≤ –º–æ–±–∏–ª—å–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è—Ö, —Å–µ—Ä–∏—é Q5_K_S –¥–ª—è —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –Ω–∞ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–∏ —Å –∞–∫—Ü–µ–Ω—Ç–æ–º –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ, Q8_0 –¥–ª—è –ø–æ—á—Ç–∏ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏ –Ω–∞ –º–æ—â–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞—Ö –ø–µ—Ä–∏—Ñ–µ—Ä–∏–∏ –∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã, —Ç–∞–∫–∏–µ –∫–∞–∫ Q2_K –¥–ª—è —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ —Å —É–ª—å—Ç—Ä–∞–Ω–∏–∑–∫–∏–º–∏ —Ä–µ—Å—É—Ä—Å–∞–º–∏.

### GGUF (General GGML Universal Format) –¥–ª—è —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è SLM

GGUF —Å–ª—É–∂–∏—Ç –æ—Å–Ω–æ–≤–Ω—ã–º —Ñ–æ—Ä–º–∞—Ç–æ–º –¥–ª—è —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–Ω—ã—Ö SLM –Ω–∞ CPU –∏ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞—Ö –ø–µ—Ä–∏—Ñ–µ—Ä–∏–∏, —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –¥–ª—è –∞–≥–µ–Ω—Ç–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π:

**–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤**: –§–æ—Ä–º–∞—Ç –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –æ–±—à–∏—Ä–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Å–∏–∏ –∏ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è SLM —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –≤—ã–∑–æ–≤–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤, –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞ –∏ –º–Ω–æ–≥–æ–∫—Ä–∞—Ç–Ω—ã—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤. –°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –º–µ–∂–¥—É –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞–º–∏ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞—Ö –ø–µ—Ä–∏—Ñ–µ—Ä–∏–∏.

**–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏**: GGUF –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ –¥–ª—è —Ä–∞–±–æ—á–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –∞–≥–µ–Ω—Ç–æ–≤, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –¥–∏–Ω–∞–º–∏—á–µ—Å–∫—É—é –∑–∞–≥—Ä—É–∑–∫—É –º–æ–¥–µ–ª–µ–π –¥–ª—è –º–Ω–æ–≥–æ–∞–≥–µ–Ω—Ç–Ω—ã—Ö —Å–∏—Å—Ç–µ–º –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã–≤–æ–¥ –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π –∞–≥–µ–Ω—Ç–æ–≤ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏.

### –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–ª—è –ø–µ—Ä–∏—Ñ–µ—Ä–∏–∏ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∏ SLM

#### –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è Llama.cpp –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤

Llama.cpp –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –ø–µ—Ä–µ–¥–æ–≤—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏ –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏—è, —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–ª—è —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –∞–≥–µ–Ω—Ç–Ω—ã—Ö SLM:

**–ö–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏–µ, —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ–µ –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤**: –§—Ä–µ–π–º–≤–æ—Ä–∫ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç Q4_0 (–æ–ø—Ç–∏–º–∞–ª—å–Ω–æ –¥–ª—è –º–æ–±–∏–ª—å–Ω–æ–≥–æ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤ —Å —É–º–µ–Ω—å—à–µ–Ω–∏–µ–º —Ä–∞–∑–º–µ—Ä–∞ –Ω–∞ 75%), Q5_1 (—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ-–∫–æ–º–ø—Ä–µ—Å—Å–∏—è –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–∏) –∏ Q8_0 (–ø–æ—á—Ç–∏ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∞–≥–µ–Ω—Ç–Ω—ã—Ö —Å–∏—Å—Ç–µ–º). –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –ø–æ–∑–≤–æ–ª—è—é—Ç —Å–æ–∑–¥–∞–≤–∞—Ç—å —É–ª—å—Ç—Ä–∞–∫–æ–º–ø—Ä–µ—Å—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∞–≥–µ–Ω—Ç—ã –¥–ª—è —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–∏.

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏**: –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–ª—è CPU –≤—ã–≤–æ–¥ —Å —É—Å–∫–æ—Ä–µ–Ω–∏–µ–º SIMD –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–æ–≤ —Å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ø–∞–º—è—Ç–∏. –°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –º–µ–∂–¥—É –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞–º–∏ –Ω–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞—Ö x86, ARM –∏ Apple Silicon –ø–æ–∑–≤–æ–ª—è–µ—Ç —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤.

#### –§—Ä–µ–π–º–≤–æ—Ä–∫ Apple MLX –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤ SLM

Apple MLX –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–∞—Ç–∏–≤–Ω—É—é –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é, —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–Ω—É—é –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ SLM –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞—Ö Apple Silicon:

**–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–æ–≤ –¥–ª—è Apple Silicon**: –§—Ä–µ–π–º–≤–æ—Ä–∫ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –ø–∞–º—è—Ç–∏ —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π Metal Performance Shaders, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é —Å–º–µ—à–∞–Ω–Ω—É—é —Ç–æ—á–Ω–æ—Å—Ç—å –¥–ª—è –≤—ã–≤–æ–¥–∞ –∞–≥–µ–Ω—Ç–æ–≤ –∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –ø—Ä–æ–ø—É—Å–∫–Ω—É—é —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –ø–∞–º—è—Ç–∏ –¥–ª—è –º–Ω–æ–≥–æ–∞–≥–µ–Ω—Ç–Ω—ã—Ö —Å–∏—Å—Ç–µ–º. –ê–≥–µ–Ω—Ç—ã SLM –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—é—Ç –∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω–∞ —á–∏–ø–∞—Ö —Å–µ—Ä–∏–∏ M.

**–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏**: –ü–æ–¥–¥–µ—Ä–∂–∫–∞ API –¥–ª—è Python –∏ Swift —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏, —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–º–∏ –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤ –∏ –±–µ—Å—à–æ–≤–Ω–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º–∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ Apple –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—é—Ç –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–µ —Å—Ä–µ–¥—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –∞–≥–µ–Ω—Ç–æ–≤.

#### ONNX Runtime –¥–ª—è –∫—Ä–æ—Å—Å–ø–ª–∞—Ç—Ñ–æ—Ä–º–µ–Ω–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤ SLM

ONNX Runtime –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –¥–≤–∏–∂–æ–∫ –≤—ã–≤–æ–¥–∞, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª—è–µ—Ç –∞–≥–µ–Ω—Ç–∞–º SLM —Ä–∞–±–æ—Ç–∞—Ç—å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –Ω–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∞–ø–ø–∞—Ä–∞—Ç–Ω—ã—Ö –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞—Ö –∏ –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Å–∏—Å—Ç–µ–º–∞—Ö:

**–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–µ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ**: ONNX Runtime –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–æ–≤ SLM –Ω–∞ –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞—Ö Windows, Linux, macOS, iOS –∏ Android. –≠—Ç–∞ –∫—Ä–æ—Å—Å–ø–ª–∞—Ç—Ñ–æ—Ä–º–µ–Ω–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –ø–æ–∑–≤–æ–ª—è–µ—Ç —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞–º –ø–∏—Å–∞—Ç—å –æ–¥–∏–Ω —Ä–∞–∑ –∏ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞—Ç—å –≤–µ–∑–¥–µ, –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —Å–Ω–∏–∂–∞—è –∑–∞—Ç—Ä–∞—Ç—ã –Ω–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫—É –∏ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ –¥–ª—è –º–Ω–æ–≥–æ–ø–ª–∞—Ç—Ñ–æ—Ä–º–µ–Ω–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π.

**–û–ø—Ü–∏–∏ –∞–ø–ø–∞—Ä–∞—Ç–Ω–æ–≥–æ —É—Å–∫–æ—Ä–µ–Ω–∏—è**: –§—Ä–µ–π–º–≤–æ—Ä–∫ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è, –≤–∫–ª—é—á–∞—è CPU (Intel, AMD, ARM), GPU (NVIDIA CUDA, AMD ROCm) –∏ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —É—Å–∫–æ—Ä–∏—Ç–µ–ª–∏ (Intel VPU, Qualcomm NPU). –ê–≥–µ–Ω—Ç—ã SLM –º–æ–≥—É—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª—É—á—à–µ–µ –¥–æ—Å—Ç—É–ø–Ω–æ–µ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ –∫–æ–¥–µ.

**–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å–∏—Å—Ç–µ–º**: ONNX Runtime –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç —Ñ—É–Ω–∫—Ü–∏–∏ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è, –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–ª—è —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤ –≤ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å–∏—Å—Ç–µ–º–∞—Ö, –≤–∫–ª—é—á–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –≥—Ä–∞—Ñ–æ–≤ –¥–ª—è –±–æ–ª–µ–µ –±—ã—Å—Ç—Ä–æ–≥–æ –≤—ã–≤–æ–¥–∞, —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç—å—é –¥–ª—è —Å—Ä–µ–¥ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–º–∏ —Ä–µ—Å—É—Ä—Å–∞–º–∏ –∏ –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏. –§—Ä–µ–π–º–≤–æ—Ä–∫ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç API –¥–ª—è Python –∏ C++ –¥–ª—è –≥–∏–±–∫–æ–π –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏.

## SLM –ø—Ä–æ—Ç–∏–≤ LLM –≤ –∞–≥–µ–Ω—Ç–Ω—ã—Ö —Å–∏—Å—Ç–µ–º–∞—Ö: –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ

### –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ SLM –≤ –∞–≥–µ–Ω—Ç–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è—Ö

**–û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å**: SLM –æ–±–µ—Å–ø–µ—á–∏–≤–∞—é—Ç —Å–Ω–∏–∂–µ–Ω–∏–µ –∑–∞—Ç—Ä–∞—Ç –Ω–∞ 10-30√ó –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å LLM –¥–ª—è –∑–∞–¥–∞—á –∞–≥–µ–Ω—Ç–æ–≤, –ø–æ–∑–≤–æ–ª—è—è –º–∞—Å—à—Ç–∞–±–Ω—ã–µ –∞–≥–µ–Ω—Ç–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏. –û–Ω–∏ –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –±–æ–ª–µ–µ –±—ã—Å—Ç—Ä–æ–µ –≤—Ä–µ–º—è –≤—ã–≤–æ–¥–∞ –±–ª–∞–≥–æ–¥–∞—Ä—è —É–º–µ–Ω—å—à–µ–Ω–Ω–æ–π –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–æ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏, —á—Ç–æ –¥–µ–ª–∞–µ—Ç –∏—Ö –∏–¥–µ–∞–ª—å–Ω—ã–º–∏ –¥–ª—è –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã—Ö –∞–≥–µ–Ω—Ç–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π.

**–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –Ω–∞ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–∏**: SLM –ø–æ–∑–≤–æ–ª—è—é—Ç –≤—ã–ø–æ–ª–Ω—è—Ç—å –∑–∞–¥–∞—á–∏ –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ –±–µ–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞, –ø–æ–≤—ã—à–∞—é—Ç –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å –±–ª–∞–≥–æ–¥–∞—Ä—è –ª–æ–∫–∞–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ –∞–≥–µ–Ω—Ç–æ–≤ –∏ –æ–±–µ—Å–ø–µ—á–∏–≤–∞—é—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫—É –¥–ª—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π, —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏, –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Å—Ä–µ–¥ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –Ω–∞ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–∏.

**–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è, —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–∞—è –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤**: SLM –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–Ω–æ —Å–ø—Ä–∞–≤–ª—è—é—Ç—Å—è —Å –≤—ã–∑–æ–≤–æ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤, –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞ –∏ —Ä—É—Ç–∏–Ω–Ω—ã–º–∏ —Ä–∞–±–æ—á–∏–º–∏ –ø—Ä–æ—Ü–µ—Å—Å–∞–º–∏ –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ—Å—Ç–∞–≤–ª—è—é—Ç 70-80% —Ç–∏–ø–∏—á–Ω—ã—Ö –∑–∞–¥–∞—á –∞–≥–µ–Ω—Ç–æ–≤.

### –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å SLM –ø—Ä–æ—Ç–∏–≤ LLM –≤ –∞–≥–µ–Ω—Ç–Ω—ã—Ö —Å–∏—Å—Ç–µ–º–∞—Ö

**–ò–¥–µ–∞–ª—å–Ω–æ –¥–ª—è SLM**:
- **–ü–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –∑–∞–¥–∞—á–∏ –∞–≥–µ–Ω—Ç–æ–≤**: –í–≤–æ–¥ –¥–∞–Ω–Ω—ã—Ö, –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ —Ñ–æ—Ä–º, —Ä—É—Ç–∏–Ω–Ω—ã–µ –≤—ã–∑–æ–≤—ã API
- **–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤**: –ó–∞–ø—Ä–æ—Å—ã –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö, –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å —Ñ–∞–π–ª–∞–º–∏, –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ —Å —Å–∏—Å—Ç–µ–º–æ–π
- **–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–∞–±–æ—á–∏–µ –ø—Ä–æ—Ü–µ—Å—Å—ã**: –°–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∑–∞—Ä–∞–Ω–µ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–º –ø—Ä–æ—Ü–µ—Å—Å–∞–º –∞–≥–µ–Ω—Ç–æ–≤
- **–ê–≥–µ–Ω—Ç—ã, —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–ª—è –æ–±–ª–∞—Å—Ç–∏**: –û–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ –∫–ª–∏–µ–Ω—Ç–æ–≤, –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ, –±–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑
- **–õ–æ–∫–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞**: –û–ø–µ—Ä–∞—Ü–∏–∏ –∞–≥–µ–Ω—Ç–æ–≤, —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ –∫ –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç–∏

**–õ—É—á—à–µ –¥–ª—è LLM**:
- **–°–ª–æ–∂–Ω–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ**: –ù–æ–≤–æ–µ —Ä–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º, —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–æ–µ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
- **–û—Ç–∫—Ä—ã—Ç—ã–µ —Ä–∞–∑–≥–æ–≤–æ—Ä—ã**: –û–±—â–∏–π —á–∞—Ç, —Ç–≤–æ—Ä—á–µ—Å–∫–∏–µ –æ–±—Å—É–∂–¥–µ–Ω–∏—è
- **–ó–∞–¥–∞—á–∏ —Å —à–∏—Ä–æ–∫–∏–º–∏ –∑–Ω–∞–Ω–∏—è–º–∏**: –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è, —Ç—Ä–µ–±—É—é—â–∏–µ –æ–±—à–∏—Ä–Ω—ã—Ö –æ–±—â–∏—Ö –∑–Ω–∞–Ω–∏–π
- **–ù–æ–≤—ã–µ —Å–∏—Ç—É–∞—Ü–∏–∏**: –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ –Ω–æ–≤—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –∞–≥–µ–Ω—Ç–æ–≤

### –ì–∏–±—Ä–∏–¥–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∞–≥–µ–Ω—Ç–æ–≤

–û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ–¥—Ö–æ–¥ —Å–æ—á–µ—Ç–∞–µ—Ç SLM –∏ LLM –≤ –≥–µ—Ç–µ—Ä–æ–≥–µ–Ω–Ω—ã—Ö –∞–≥–µ–Ω—Ç–Ω—ã—Ö —Å–∏—Å—Ç–µ–º–∞—Ö:

**–£–º–Ω–∞—è –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–æ–≤**:
1. **SLM –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–π**: –û–±—Ä–∞–±–æ—Ç–∫–∞ 70-80% —Ä—É—Ç–∏–Ω–Ω—ã—Ö –∑–∞–¥–∞—á –∞–≥–µ–Ω—Ç–æ–≤ –ª–æ–∫–∞–ª—å–Ω–æ
2. **LLM –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏**: –ü–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –Ω–∞ –æ–±–ª–∞—á–Ω—ã–µ –±–æ–ª—å—à–∏–µ –º–æ–¥–µ–ª–∏
3. **–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ SLM**: –†–∞–∑–Ω—ã–µ –º–∞–ª—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –æ–±–ª–∞—Å—Ç–µ–π –∞–≥–µ–Ω—Ç–æ–≤
4. **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞—Ç—Ä–∞—Ç**: –ú–∏–Ω–∏–º–∏–∑–∞—Ü–∏—è –¥–æ—Ä–æ–≥–æ—Å—Ç–æ—è—â–∏—Ö –≤—ã–∑–æ–≤–æ–≤ LLM —á–µ—Ä–µ–∑ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—É—é –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—é

## –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤ SLM

### Foundry Local: –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–π runtime –¥–ª—è AI –Ω–∞ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–∏

Foundry Local (https://github.com/microsoft/foundry-local) —è–≤–ª—è–µ—Ç—Å—è —Ñ–ª–∞–≥–º–∞–Ω—Å–∫–∏–º —Ä–µ—à–µ–Ω–∏–µ–º Microsoft –¥–ª—è —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –º–∞–ª—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –≤ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å—Ä–µ–¥–∞—Ö –ø–µ—Ä–∏—Ñ–µ—Ä–∏–∏. –û–Ω–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –ø–æ–ª–Ω–æ–µ runtime-–æ–∫—Ä—É–∂–µ–Ω–∏–µ, —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ SLM —Å —Ñ—É–Ω–∫—Ü–∏—è–º–∏ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è –∏ –±–µ—Å—à–æ–≤–Ω—ã–º–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏.

**–û—Å–Ω–æ–≤–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∏ —Ñ—É–Ω–∫—Ü–∏–∏**:
- **–°–æ–≤–º–µ—Å—Ç–∏–º—ã–π API OpenAI**: –ü–æ–ª–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å SDK OpenAI –∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è–º–∏ Agent Framework
- **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è**: –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –≤—ã–±–æ—Ä –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –º–æ–¥–µ–ª–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ—Å—Ç—É–ø–Ω–æ–≥–æ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è (CUDA GPU, Qualcomm NPU, CPU)
- **–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª—è–º–∏**: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∑–∞–≥—Ä—É–∑–∫–∞, –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∂–∏–∑–Ω–µ–Ω–Ω—ã–º —Ü–∏–∫–ª–æ–º –º–æ–¥–µ–ª–µ–π SLM
- **–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Å–µ—Ä–≤–∏—Å–æ–≤**: –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Å–µ—Ä–≤–∏—Å–æ–≤ –±–µ–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–æ–≤ –∞–≥–µ–Ω—Ç–æ–≤
- **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ä–µ—Å—É—Ä—Å–æ–≤**: –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç—å—é –∏ —ç–Ω–µ—Ä–≥–æ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –¥–ª—è —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –Ω–∞ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–∏

#### –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞

**–ö—Ä–æ—Å—Å–ø–ª–∞—Ç—Ñ–æ—Ä–º–µ–Ω–Ω–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞**:
```bash
# Windows (recommended)
winget install Microsoft.FoundryLocal

# macOS
brew tap microsoft/foundrylocal
brew install foundrylocal

# Linux (manual installation)
wget https://github.com/microsoft/foundry-local/releases/latest/download/foundry-local-linux.tar.gz
tar -xzf foundry-local-linux.tar.gz
sudo mv foundry-local /usr/local/bin/
```

**–ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –∞–≥–µ–Ω—Ç–æ–≤**:
```bash
# Start service with automatic model loading
foundry model run phi-4-mini

# Verify service status and endpoint
foundry service status

# List available models
foundry model ls

# Test API endpoint
curl http://localhost:<port>/v1/models
```

#### –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Agent Framework

**–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è SDK Foundry Local**:
```python
from foundry_local import FoundryLocalManager
from microsoft_agent_framework import Agent, Config
import openai

# Initialize Foundry Local with automatic service management
manager = FoundryLocalManager("phi-4-mini")

# Configure OpenAI client for local inference
client = openai.OpenAI(
    base_url=manager.endpoint,
    api_key=manager.api_key  # Auto-generated for local usage
)

# Create agent with Foundry Local backend
agent_config = Config(
    name="production-agent",
    model_provider="foundry-local",
    model_id=manager.get_model_info("phi-4-mini").id,
    endpoint=manager.endpoint,
    api_key=manager.api_key
)

agent = Agent(config=agent_config)
```

**–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–µ–π –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è**:
```python
# Foundry Local automatically selects optimal model variant
models_by_use_case = {
    "lightweight_routing": "qwen2.5-0.5b",      # 500MB, ultra-fast
    "general_conversation": "phi-4-mini",       # 2.4GB, balanced
    "complex_reasoning": "phi-4",               # 7GB, high-capability
    "code_assistance": "qwen2.5-coder-0.5b"    # 500MB, code-optimized
}

# Foundry Local handles hardware detection and quantization
for use_case, model_alias in models_by_use_case.items():
    manager = FoundryLocalManager(model_alias)
    print(f"{use_case}: {manager.get_model_info(model_alias).variant_selected}")
    # Output examples:
    # lightweight_routing: qwen2.5-0.5b-instruct-q4_k_m.gguf (CPU optimized)
    # general_conversation: phi-4-mini-instruct-cuda-q5_k_m.gguf (GPU accelerated)
```

#### –®–∞–±–ª–æ–Ω—ã —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –≤ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ

**–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–¥–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞**:
```python
import asyncio
from foundry_local import FoundryLocalManager
from microsoft_agent_framework import Agent, Config, Tool

class ProductionAgentService:
    def __init__(self, model_alias="phi-4-mini"):
        self.foundry = FoundryLocalManager(model_alias)
        self.agent = self._create_agent()
        
    def _create_agent(self):
        config = Config(
            name="production-customer-service",
            model_provider="foundry-local",
            model_id=self.foundry.get_model_info().id,
            endpoint=self.foundry.endpoint,
            api_key=self.foundry.api_key,
            max_tokens=512,
            temperature=0.1,
            timeout=30.0
        )
        
        agent = Agent(config=config)
        
        # Add production tools
        @agent.tool
        def lookup_customer(customer_id: str) -> dict:
            """Look up customer information from local database."""
            return self.local_db.get_customer(customer_id)
            
        @agent.tool
        def create_ticket(issue: str, priority: str = "medium") -> str:
            """Create a support ticket."""
            ticket_id = self.ticketing_system.create(issue, priority)
            return f"Created ticket {ticket_id}"
            
        return agent
    
    async def process_request(self, user_input: str) -> str:
        """Process user request with error handling and monitoring."""
        try:
            response = await self.agent.chat_async(user_input)
            self.log_interaction(user_input, response, "success")
            return response
        except Exception as e:
            self.log_interaction(user_input, str(e), "error")
            return "I'm experiencing technical difficulties. Please try again."
    
    def health_check(self) -> dict:
        """Check service health for monitoring."""
        return {
            "foundry_status": self.foundry.health_check(),
            "model_loaded": self.foundry.is_model_loaded(),
            "endpoint": self.foundry.endpoint,
            "memory_usage": self.foundry.get_memory_usage()
        }

# Production usage
service = ProductionAgentService("phi-4-mini")
response = await service.process_request("I need help with my order #12345")
```

**–û—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏—è –º–Ω–æ–≥–æ–∞–≥–µ–Ω—Ç–Ω–æ–≥–æ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞**:
```python
from foundry_local import FoundryLocalManager
from microsoft_agent_framework import AgentOrchestrator, Agent, Config

class MultiAgentProductionSystem:
    def __init__(self):
        self.agents = self._initialize_agents()
        self.orchestrator = AgentOrchestrator(list(self.agents.values()))
        
    def _initialize_agents(self):
        agents = {}
        
        # Lightweight routing agent
        routing_foundry = FoundryLocalManager("qwen2.5-0.5b")
        agents["router"] = Agent(Config(
            name="request-router",
            model_provider="foundry-local",
            endpoint=routing_foundry.endpoint,
            api_key=routing_foundry.api_key,
            role="Route user requests to appropriate specialized agents"
        ))
        
        # Customer service agent
        service_foundry = FoundryLocalManager("phi-4-mini")
        agents["customer_service"] = Agent(Config(
            name="customer-service",
            model_provider="foundry-local",
            endpoint=service_foundry.endpoint,
            api_key=service_foundry.api_key,
            role="Handle customer service inquiries and support requests"
        ))
        
        # Technical support agent
        tech_foundry = FoundryLocalManager("qwen2.5-coder-0.5b")
        agents["technical"] = Agent(Config(
            name="technical-support",
            model_provider="foundry-local",
            endpoint=tech_foundry.endpoint,
            api_key=tech_foundry.api_key,
            role="Provide technical assistance and troubleshooting"
        ))
        
        return agents
    
    async def process_request(self, user_input: str) -> str:
        """Route and process user requests through appropriate agents."""
        # Route request to appropriate agent
        routing_result = await self.agents["router"].chat_async(
            f"Classify this request and route to customer_service or technical: {user_input}"
        )
        
        # Determine target agent based on routing
        target_agent = "customer_service" if "customer" in routing_result.lower() else "technical"
        
        # Process with specialized agent
        response = await self.agents[target_agent].chat_async(user_input)
        
        return response

# Production deployment
system = MultiAgentProductionSystem()
response = await system.process_request("My application keeps crashing")
```

#### –ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

**–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å–æ—Å—Ç–æ—è–Ω–∏—è –∏ –Ω–∞–±–ª—é–¥–∞–µ–º–æ—Å—Ç—å**:
```python
from foundry_local import FoundryLocalManager
import asyncio
import logging

class FoundryMonitoringService:
    def __init__(self):
        self.managers = {}
        self.metrics = []
        
    def add_model(self, alias: str) -> FoundryLocalManager:
        """Add a model to monitoring."""
        manager = FoundryLocalManager(alias)
        self.managers[alias] = manager
        return manager
    
    async def collect_metrics(self):
        """Collect performance metrics from all Foundry Local instances."""
        metrics = {
            "timestamp": time.time(),
            "models": {}
        }
        
        for alias, manager in self.managers.items():
            try:
                model_metrics = {
                    "status": "healthy" if manager.health_check() else "unhealthy",
                    "memory_usage": manager.get_memory_usage(),
                    "inference_count": manager.get_inference_count(),
                    "average_latency": manager.get_average_latency(),
                    "error_rate": manager.get_error_rate()
                }
                metrics["models"][alias] = model_metrics
            except Exception as e:
                logging.error(f"Failed to collect metrics for {alias}: {e}")
                metrics["models"][alias] = {"status": "error", "error": str(e)}
        
        self.metrics.append(metrics)
        return metrics
    
    def get_health_status(self) -> dict:
        """Get overall system health status."""
        healthy_models = 0
        total_models = len(self.managers)
        
        for alias, manager in self.managers.items():
            if manager.health_check():
                healthy_models += 1
        
        return {
            "overall_status": "healthy" if healthy_models == total_models else "degraded",
            "healthy_models": healthy_models,
            "total_models": total_models,
            "health_percentage": (healthy_models / total_models) * 100 if total_models > 0 else 0
        }

# Production monitoring setup
monitor = FoundryMonitoringService()
monitor.add_model("phi-4-mini")
monitor.add_model("qwen2.5-0.5b")

# Continuous monitoring
async def monitoring_loop():
    while True:
        metrics = await monitor.collect_metrics()
        health = monitor.get_health_status()
        
        if health["health_percentage"] < 100:
            logging.warning(f"System health degraded: {health}")
        
        await asyncio.sleep(30)  # Collect metrics every 30 seconds
```

**–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–∞–º–∏ –∏ –∞–≤—Ç–æ-–º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ**:
```python
class FoundryResourceManager:
    def __init__(self):
        self.model_instances = {}
        self.resource_limits = {
            "max_memory_gb": 8,
            "max_concurrent_models": 3,
            "cpu_threshold": 80
        }
    
    def auto_scale_models(self, demand_metrics: dict):
        """Automatically scale models based on demand."""
        current_memory = self.get_total_memory_usage()
        
        # Scale down if memory usage is high
        if current_memory > self.resource_limits["max_memory_gb"] * 0.8:
            self.scale_down_idle_models()
        
        # Scale up if demand is high and resources allow
        for model_alias, demand in demand_metrics.items():
            if demand > 0.8 and len(self.model_instances) < self.resource_limits["max_concurrent_models"]:
                self.load_model_instance(model_alias)
    
    def load_model_instance(self, alias: str) -> FoundryLocalManager:
        """Load a new model instance if resources allow."""
        if alias not in self.model_instances:
            try:
                manager = FoundryLocalManager(alias)
                self.model_instances[alias] = manager
                logging.info(f"Loaded model instance: {alias}")
                return manager
            except Exception as e:
                logging.error(f"Failed to load model {alias}: {e}")
                return None
        return self.model_instances[alias]
    
    def scale_down_idle_models(self):
        """Remove idle model instances to free resources."""
        idle_models = []
        
        for alias, manager in self.model_instances.items():
            if manager.get_idle_time() > 300:  # 5 minutes idle
                idle_models.append(alias)
        
        for alias in idle_models:
            self.model_instances[alias].shutdown()
            del self.model_instances[alias]
            logging.info(f"Scaled down idle model: {alias}")
```

#### –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è

**–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π**:
```python
# Advanced Foundry Local configuration for production
from foundry_local import FoundryLocalManager, ModelConfig

# Custom configuration for specific use cases
config = ModelConfig(
    alias="phi-4-mini",
    quantization="Q5_K_M",  # Specific quantization level
    context_length=4096,    # Extended context for complex agents
    batch_size=1,          # Optimized for single-user agents
    threads=4,             # CPU thread optimization
    gpu_layers=32,         # GPU acceleration layers
    memory_lock=True,      # Lock model in memory for consistent performance
    numa=True              # NUMA optimization for multi-socket systems
)

manager = FoundryLocalManager(config=config)
```

**–ö–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ –¥–ª—è —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –≤ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ**:

‚úÖ **–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–∞**:
- –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –ø—Å–µ–≤–¥–æ–Ω–∏–º—ã –º–æ–¥–µ–ª–µ–π –¥–ª—è —Å–ª—É—á–∞–µ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
- –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è —Ä–µ—Å—É—Ä—Å–æ–≤ –∏ –ø–æ—Ä–æ–≥–∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
- –í–∫–ª—é—á–∏—Ç–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è –∏ —Å–±–æ—Ä –º–µ—Ç—Ä–∏–∫
- –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ –∏ —Ä–µ–∑–µ—Ä–≤–∏—Ä–æ–≤–∞–Ω–∏–µ

‚úÖ **–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏**:
- –í–∫–ª—é—á–∏—Ç–µ –¥–æ—Å—Ç—É–ø –∫ API —Ç–æ–ª—å–∫–æ –ª–æ–∫–∞–ª—å–Ω–æ (–±–µ–∑ –≤–Ω–µ—à–Ω–µ–≥–æ –¥–æ—Å—Ç—É–ø–∞)
- –ù–∞—Å—Ç—Ä–æ–π—Ç–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–ª—é—á–∞–º–∏ API
- –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –≤–µ–¥–µ–Ω–∏–µ –∂—É—Ä–Ω–∞–ª–∞ –∞—É–¥–∏—Ç–∞ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π –∞–≥–µ–Ω—Ç–æ–≤
- –†–µ–∞–ª–∏–∑—É–π—Ç–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

‚úÖ **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏**:
- –¢–µ—Å—Ç–∏—Ä—É–π—Ç–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –ø–æ–¥ –æ–∂–∏–¥–∞–µ–º–æ–π –Ω–∞–≥—Ä—É–∑–∫–æ–π
- –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ —É—Ä–æ–≤–Ω–∏ –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏—è
- –ù–∞—Å—Ç—Ä–æ–π—Ç–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –ø—Ä–æ–≥—Ä–µ–≤–∞ –º–æ–¥–µ–ª–µ–π
- –ú–æ–Ω–∏—Ç–æ—Ä—å—Ç–µ —à–∞–±–ª–æ–Ω—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏ –∏ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞

‚úÖ **–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏**:
- –¢–µ—Å—Ç–∏—Ä—É–π—Ç–µ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é —Å —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–æ–º –∞–≥–µ–Ω—Ç–æ–≤
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Ä–∞–±–æ—Ç—ã –≤ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–º —Ä–µ–∂–∏–º–µ
- –¢–µ—Å—Ç–∏—Ä—É–π—Ç–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏ —Ä–µ–∑–µ—Ä–≤–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–∫–≤–æ–∑–Ω—ã–µ —Ä–∞–±–æ—á–∏–µ –ø—Ä–æ—Ü–µ—Å—Å—ã –∞–≥–µ–Ω—Ç–æ–≤

### Ollama: —É–ø—Ä–æ—â–µ–Ω–Ω–æ–µ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –∞–≥–µ–Ω—Ç–æ–≤ SLM

### Ollama: —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –∞–≥–µ–Ω—Ç–æ–≤ SLM, –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –Ω–∞ —Å–æ–æ–±—â–µ—Å—Ç–≤–æ

Ollama –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –ø–æ–¥—Ö–æ–¥ –∫ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—é –∞–≥–µ–Ω—Ç–æ–≤ SLM, –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ —Å–æ–æ–±—â–µ—Å—Ç–≤–æ, —Å –∞–∫—Ü–µ–Ω—Ç–æ–º –Ω–∞ –ø—Ä–æ—Å—Ç–æ—Ç—É, –æ–±—à–∏—Ä–Ω—É—é —ç–∫–æ—Å–∏—Å—Ç–µ–º—É –º–æ–¥–µ–ª–µ–π –∏ —É–¥–æ–±–Ω—ã–µ –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ —Ä–∞–±–æ—á–∏–µ –ø—Ä–æ—Ü–µ—Å—Å—ã. –í —Ç–æ –≤—Ä–µ–º—è –∫–∞–∫ Foundry Local —Å–æ—Å—Ä–µ–¥–æ—Ç–æ—á–µ–Ω –Ω–∞ —Ñ—É–Ω–∫—Ü–∏—è—Ö –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è, Ollama –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç –≤ –±—ã—Å—Ç—Ä–æ–º –ø—Ä–æ—Ç–æ—Ç–∏–ø–∏—Ä–æ–≤–∞–Ω–∏–∏, –¥–æ—Å—Ç—É–ø–µ –∫ –º–æ–¥–µ–ª—è–º —Å–æ–æ–±—â–µ—Å—Ç–≤–∞ –∏ —É–ø—Ä–æ—â–µ–Ω–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏—è—Ö —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è.

**–û—Å–Ω–æ–≤–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∏ —Ñ—É–Ω–∫—Ü–∏–∏**:
- **–°–æ–≤–º–µ—Å—Ç–∏–º—ã–π API OpenAI**: –ü–æ–ª–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å REST API –¥–ª—è –±–µ—Å—à–æ–≤–Ω–æ–π –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–æ–º –∞–≥–µ–Ω—Ç–æ–≤
- **–û–±—à–∏—Ä–Ω–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –º–æ–¥–µ–ª–µ–π**: –î–æ—Å—Ç—É–ø –∫ —Å–æ—Ç–Ω—è–º –º–æ–¥–µ–ª–µ–π, —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ—Å—Ç–≤–æ–º –∏ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
- **–ü—Ä–æ—Å—Ç–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª—è–º–∏**: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –æ–¥–Ω–æ–π –∫–æ–º–∞–Ω–¥–æ–π
- **–ö—Ä–æ—Å—Å–ø–ª–∞—Ç—Ñ–æ—Ä–º–µ–Ω–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞**: –ù–∞—Ç–∏–≤–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ Windows, macOS –∏ Linux
- **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ä–µ—Å—É—Ä—Å–æ–≤**: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏–µ –∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è

#### –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞

**–ö—Ä–æ—Å—Å–ø–ª–∞—Ç—Ñ–æ—Ä–º–µ–Ω–Ω–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞**:
```bash
# Windows
winget install Ollama.Ollama

# macOS
brew install ollama

# Linux
curl -fsSL https://ollama.com/install.sh | sh

# Docker deployment
docker run -d -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama
```

**–ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –∞–≥–µ–Ω—Ç–æ–≤**:
```bash
# Start Ollama service
ollama serve

# Pull and run models for agent development
ollama pull phi3.5:3.8b-mini-instruct-q4_K_M    # Microsoft Phi-3.5 Mini
ollama pull qwen2.5:0.5b-instruct-q4_K_M        # Qwen2.5 0.5B
ollama pull llama3.2:1b-instruct-q4_K_M         # Llama 3.2 1B

# Test model availability
ollama list

# Test API endpoint
curl http://localhost:11434/api/generate -d '{
  "model": "phi3.5:3.8b-mini-instruct-q4_K_M",
  "prompt": "Hello, how can I help you today?"
}'
```

#### –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–æ–º –∞–≥–µ–Ω—Ç–æ–≤

**Ollama —Å Microsoft Agent Framework**:
```python
from microsoft_agent_framework import Agent, Config
import openai
import requests
import json

class OllamaManager:
    def __init__(self, model_name: str, base_url: str = "http://localhost:11434"):
        self.model_name = model_name
        self.base_url = base_url
        self.api_url = f"{base_url}/api"
        self.openai_url = f"{base_url}/v1"
        
    def ensure_model_available(self) -> bool:
        """Ensure the model is pulled and available."""
        try:
            response = requests.post(f"{self.api_url}/pull", 
                json={"name": self.model_name})
            return response.status_code == 200
        except Exception as e:
            print(f"Failed to pull model {self.model_name}: {e}")
            return False
    
    def get_openai_client(self) -> openai.OpenAI:
        """Get OpenAI-compatible client for Ollama."""
        return openai.OpenAI(
            base_url=self.openai_url,
            api_key="ollama",  # Ollama doesn't require real API key
        )
    
    def health_check(self) -> bool:
        """Check if Ollama service is running."""
        try:
            response = requests.get(f"{self.base_url}/api/tags")
            return response.status_code == 200
        except:
            return False

# Initialize Ollama for agent development
ollama_manager = OllamaManager("phi3.5:3.8b-mini-instruct-q4_K_M")
ollama_manager.ensure_model_available()

# Configure agent with Ollama backend
agent_config = Config(
    name="ollama-agent",
    model_provider="ollama",
    model_id="phi3.5:3.8b-mini-instruct-q4_K_M",
    endpoint=ollama_manager.openai_url,
    api_key="ollama"
)

agent = Agent(config=agent_config)
```

**–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–Ω–æ–≥–æ–∞–≥–µ–Ω—Ç–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã —Å Ollama**:
```python
class OllamaMultiModelManager:
    def __init__(self):
        self.models = {
            "lightweight": "qwen2.5:0.5b-instruct-q4_K_M",      # 350MB
            "balanced": "phi3.5:3.8b-mini-instruct-q4_K_M",     # 2.3GB  
            "capable": "llama3.2:3b-instruct-q4_K_M",           # 1.9GB
            "coding": "codellama:7b-code-q4_K_M"                # 4.1GB
        }
        self.base_url = "http://localhost:11434"
        self.clients = {}
        self._initialize_models()
    
    def _initialize_models(self):
        """Pull all required models and create clients."""
        for category, model_name in self.models.items():
            # Pull model if not available
            self._pull_model(model_name)
            
            # Create OpenAI client for each model
            self.clients[category] = openai.OpenAI(
                base_url=f"{self.base_url}/v1",
                api_key="ollama"
            )
    
    def _pull_model(self, model_name: str):
        """Pull model if not already available."""
        try:
            response = requests.post(f"{self.base_url}/api/pull", 
                json={"name": model_name})
            if response.status_code == 200:
                print(f"Model {model_name} ready")
        except Exception as e:
            print(f"Failed to pull {model_name}: {e}")
    
    def get_agent_for_task(self, task_type: str) -> Agent:
        """Get appropriate agent based on task complexity."""
        model_category = self._classify_task(task_type)
        model_name = self.models[model_category]
        
        config = Config(
            name=f"ollama-{model_category}-agent",
            model_provider="ollama",
            model_id=model_name,
            endpoint=f"{self.base_url}/v1",
            api_key="ollama"
        )
        
        return Agent(config=config)
    
    def _classify_task(self, task_type: str) -> str:
        """Classify task to appropriate model category."""
        if any(keyword in task_type.lower() for keyword in ["simple", "route", "classify"]):
            return "lightweight"
        elif any(keyword in task_type.lower() for keyword in ["code", "programming", "debug"]):
            return "coding"
        elif any(keyword in task_type.lower() for keyword in ["complex", "analysis", "research"]):
            return "capable"
        else:
            return "balanced"

# Usage example
manager = OllamaMultiModelManager()

# Get appropriate agents for different tasks
routing_agent = manager.get_agent_for_task("simple routing")
coding_agent = manager.get_agent_for_task("code debugging")
analysis_agent = manager.get_agent_for_task("complex analysis")
```

#### –®–∞–±–ª–æ–Ω—ã —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –≤ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ

**–ü—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã–π —Å–µ—Ä–≤–∏—Å —Å Ollama**:
```python
import asyncio
import logging
from typing import Dict, Optional
from microsoft_agent_framework import Agent, Config
import requests
import openai

class OllamaProductionService:
    def __init__(self, models_config: Dict[str, str]):
        self.models_config = models_config
        self.base_url = "http://localhost:11434"
        self.agents = {}
        self.metrics = {
            "requests_processed": 0,
            "errors": 0,
            "model_usage": {model: 0 for model in models_config.keys()}
        }
        self._initialize_production_agents()
    
    def _initialize_production_agents(self):
        """Initialize production agents with health checks."""
        for agent_type, model_name in self.models_config.items():
            try:
                # Ensure model is available
                self._ensure_model_ready(model_name)
                
                # Create production agent
                config = Config(
                    name=f"production-{agent_type}",
                    model_provider="ollama",
                    model_id=model_name,
                    endpoint=f"{self.base_url}/v1",
                    api_key="ollama",
                    max_tokens=512,
                    temperature=0.1,
                    timeout=30.0
                )
                
                agent = Agent(config=config)
                
                # Add production tools based on agent type
                self._add_production_tools(agent, agent_type)
                
                self.agents[agent_type] = agent
                logging.info(f"Initialized {agent_type} agent with model {model_name}")
                
            except Exception as e:
                logging.error(f"Failed to initialize {agent_type} agent: {e}")
    
    def _ensure_model_ready(self, model_name: str):
        """Ensure model is pulled and ready for use."""
        try:
            # Check if model exists
            response = requests.get(f"{self.base_url}/api/tags")
            models = response.json().get('models', [])
            
            model_exists = any(model['name'] == model_name for model in models)
            
            if not model_exists:
                logging.info(f"Pulling model {model_name}...")
                pull_response = requests.post(f"{self.base_url}/api/pull", 
                    json={"name": model_name})
                
                if pull_response.status_code != 200:
                    raise Exception(f"Failed to pull model {model_name}")
                    
        except Exception as e:
            raise Exception(f"Model setup failed for {model_name}: {e}")
    
    def _add_production_tools(self, agent: Agent, agent_type: str):
        """Add tools based on agent type."""
        if agent_type == "customer_service":
            @agent.tool
            def lookup_customer(customer_id: str) -> dict:
                """Look up customer information."""
                # Simulate database lookup
                return {"customer_id": customer_id, "status": "active", "tier": "premium"}
            
            @agent.tool
            def create_support_ticket(issue: str, priority: str = "medium") -> str:
                """Create a support ticket."""
                ticket_id = f"TICK-{hash(issue) % 10000:04d}"
                return f"Created ticket {ticket_id} with priority {priority}"
        
        elif agent_type == "technical_support":
            @agent.tool
            def run_diagnostics(system_info: str) -> dict:
                """Run system diagnostics."""
                return {"status": "healthy", "issues": [], "recommendations": []}
            
            @agent.tool
            def access_knowledge_base(query: str) -> str:
                """Search technical knowledge base."""
                return f"Knowledge base results for: {query}"
    
    async def process_request(self, request: str, agent_type: str = "customer_service") -> dict:
        """Process user request with monitoring and error handling."""
        start_time = time.time()
        
        try:
            if agent_type not in self.agents:
                raise ValueError(f"Agent type {agent_type} not available")
            
            agent = self.agents[agent_type]
            response = await agent.chat_async(request)
            
            # Update metrics
            self.metrics["requests_processed"] += 1
            self.metrics["model_usage"][agent_type] += 1
            
            processing_time = time.time() - start_time
            
            self._log_interaction(request, response, "success", processing_time, agent_type)
            
            return {
                "response": response,
                "status": "success",
                "processing_time": processing_time,
                "agent_type": agent_type
            }
            
        except Exception as e:
            self.metrics["errors"] += 1
            processing_time = time.time() - start_time
            
            self._log_interaction(request, str(e), "error", processing_time, agent_type)
            
            return {
                "response": "I'm experiencing technical difficulties. Please try again.",
                "status": "error",
                "error": str(e),
                "processing_time": processing_time
            }
    
    def _log_interaction(self, request: str, response: str, status: str, 
                        processing_time: float, agent_type: str):
        """Log interaction for monitoring and analysis."""
        logging.info(f"Agent: {agent_type}, Status: {status}, Time: {processing_time:.2f}s")
        
        # In production, this would write to a proper logging system
        log_entry = {
            "timestamp": time.time(),
            "agent_type": agent_type,
            "request_length": len(request),
            "response_length": len(response),
            "status": status,
            "processing_time": processing_time
        }
    
    def get_health_status(self) -> dict:
        """Get service health status."""
        try:
            # Check Ollama service health
            response = requests.get(f"{self.base_url}/api/tags", timeout=5)
            ollama_healthy = response.status_code == 200
            
            # Check model availability
            available_models = []
            if ollama_healthy:
                models = response.json().get('models', [])
                available_models = [model['name'] for model in models]
            
            return {
                "service_status": "healthy" if ollama_healthy else "unhealthy",
                "ollama_endpoint": self.base_url,
                "available_models": available_models,
                "active_agents": list(self.agents.keys()),
                "metrics": self.metrics,
                "timestamp": time.time()
            }
            
        except Exception as e:
            return {
                "service_status": "error",
                "error": str(e),
                "timestamp": time.time()
            }

# Production deployment example
production_models = {
    "customer_service": "phi3.5:3.8b-mini-instruct-q4_K_M",
    "technical_support": "llama3.2:3b-instruct-q4_K_M",
    "routing": "qwen2.5:0.5b-instruct-q4_K_M"
}

service = OllamaProductionService(production_models)

# Process requests
result = await service.process_request(
    "I need help with my account settings", 
    "customer_service"
)
print(result)
```

#### –ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

**–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –Ω–∞–±–ª—é–¥–∞–µ–º–æ—Å—Ç—å Ollama**:
```python
import time
import asyncio
import requests
from typing import Dict, List

class OllamaMonitoringService:
    def __init__(self, base_url: str = "http://localhost:11434"):
        self.base_url = base_url
        self.metrics_history = []
        self.alert_thresholds = {
            "response_time_ms": 2000,
            "error_rate_percent": 5,
            "memory_usage_percent": 85
        }
    
    async def collect_metrics(self) -> dict:
        """Collect comprehensive metrics from Ollama service."""
        metrics = {
            "timestamp": time.time(),
            "service_status": "unknown",
            "models": {},
            "performance": {},
            "resources": {}
        }
        
        try:
            # Check service health
            health_response = requests.get(f"{self.base_url}/api/tags", timeout=5)
            metrics["service_status"] = "healthy" if health_response.status_code == 200 else "unhealthy"
            
            if metrics["service_status"] == "healthy":
                # Get model information
                models_data = health_response.json().get('models', [])
                for model in models_data:
                    model_name = model['name']
                    metrics["models"][model_name] = {
                        "size_gb": model.get('size', 0) / (1024**3),
                        "modified": model.get('modified_at', ''),
                        "digest": model.get('digest', '')[:12]  # Short digest
                    }
                
                # Test inference performance
                start_time = time.time()
                test_response = requests.post(f"{self.base_url}/api/generate", 
                    json={
                        "model": list(metrics["models"].keys())[0] if metrics["models"] else "",
                        "prompt": "Hello",
                        "stream": False
                    }, timeout=10)
                
                if test_response.status_code == 200:
                    inference_time = (time.time() - start_time) * 1000
                    metrics["performance"] = {
                        "inference_time_ms": inference_time,
                        "tokens_per_second": self._calculate_tokens_per_second(test_response.json()),
                        "last_successful_inference": time.time()
                    }
            
        except Exception as e:
            metrics["service_status"] = "error"
            metrics["error"] = str(e)
        
        self.metrics_history.append(metrics)
        
        # Keep only last 100 metrics entries
        if len(self.metrics_history) > 100:
            self.metrics_history = self.metrics_history[-100:]
        
        return metrics
    
    def _calculate_tokens_per_second(self, response_data: dict) -> float:
        """Calculate approximate tokens per second from response."""
        try:
            # Estimate tokens (rough approximation)
            response_text = response_data.get('response', '')
            estimated_tokens = len(response_text.split())
            
            # Get timing info if available
            eval_duration = response_data.get('eval_duration', 0)
            if eval_duration > 0:
                # Convert nanoseconds to seconds
                duration_seconds = eval_duration / 1e9
                return estimated_tokens / duration_seconds if duration_seconds > 0 else 0
        except:
            pass
        return 0
    
    def check_alerts(self, current_metrics: dict) -> List[dict]:
        """Check current metrics against alert thresholds."""
        alerts = []
        
        # Check response time
        if current_metrics.get('performance', {}).get('inference_time_ms', 0) > self.alert_thresholds['response_time_ms']:
            alerts.append({
                "type": "performance",
                "message": f"High response time: {current_metrics['performance']['inference_time_ms']:.0f}ms",
                "severity": "warning"
            })
        
        # Check service status
        if current_metrics.get('service_status') != 'healthy':
            alerts.append({
                "type": "availability",
                "message": f"Service unhealthy: {current_metrics.get('error', 'Unknown error')}",
                "severity": "critical"
            })
        
        return alerts
    
    def get_performance_summary(self, minutes: int = 60) -> dict:
        """Get performance summary for the last N minutes."""
        cutoff_time = time.time() - (minutes * 60)
        recent_metrics = [m for m in self.metrics_history if m['timestamp'] > cutoff_time]
        
        if not recent_metrics:
            return {"error": "No recent metrics available"}
        
        # Calculate averages
        response_times = [m.get('performance', {}).get('inference_time_ms', 0) 
                         for m in recent_metrics if m.get('performance')]
        
        healthy_checks = sum(1 for m in recent_metrics if m.get('service_status') == 'healthy')
        uptime_percent = (healthy_checks / len(recent_metrics)) * 100 if recent_metrics else 0
        
        return {
            "period_minutes": minutes,
            "total_checks": len(recent_metrics),
            "uptime_percent": uptime_percent,
            "avg_response_time_ms": sum(response_times) / len(response_times) if response_times else 0,
            "max_response_time_ms": max(response_times) if response_times else 0,
            "min_response_time_ms": min(response_times) if response_times else 0
        }

# Production monitoring setup
monitor = OllamaMonitoringService()

async def monitoring_loop():
    """Continuous monitoring loop."""
    while True:
        try:
            metrics = await monitor.collect_metrics()
            alerts = monitor.check_alerts(metrics)
            
            if alerts:
                for alert in alerts:
                    logging.warning(f"ALERT: {alert['message']} (Severity: {alert['severity']})")
            
            # Log performance summary every 10 minutes
            if int(time.time()) % 600 == 0:  # Every 10 minutes
                summary = monitor.get_performance_summary(10)
                logging.info(f"Performance Summary: {summary}")
            
        except Exception as e:
            logging.error(f"Monitoring error: {e}")
        
        await asyncio.sleep(30)  # Check every 30 seconds

# Start monitoring
# asyncio.create_task(monitoring_loop())
```

#### –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è

**–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–º–∏ –º–æ–¥–µ–ª—è–º–∏ —Å Ollama**:
```python
class OllamaModelManager:
    def __init__(self, base_url: str = "http://localhost:11434"):
        self.base_url = base_url
        self.model_catalog = {
            # Lightweight models for fast responses
            "ultra_light": [
                "qwen2.5:0.5b-instruct-q4_K_M",
                "tinyllama:1.1b-chat-q4_K_M"
            ],
            # Balanced models for general use
            "balanced": [
                "phi3.5:3.8b-mini-instruct-q4_K_M",
                "llama3.2:3b-instruct-q4_K_M"
            ],
            # Specialized models for specific tasks
            "code_specialist": [
                "codellama:7b-code-q4_K_M",
                "codegemma:7b-code-q4_K_M"
            ],
            # High capability models
            "high_capability": [
                "llama3.1:8b-instruct-q4_K_M",
                "qwen2.5:7b-instruct-q4_K_M"
            ]
        }
    
    def setup_production_models(self, categories: List[str]) -> dict:
        """Set up models for production use."""
        setup_results = {}
        
        for category in categories:
            if category not in self.model_catalog:
                setup_results[category] = {"status": "error", "message": "Unknown category"}
                continue
            
            models = self.model_catalog[category]
            category_results = []
            
            for model in models:
                try:
                    # Pull model
                    response = requests.post(f"{self.base_url}/api/pull", 
                        json={"name": model})
                    
                    if response.status_code == 200:
                        category_results.append({"model": model, "status": "ready"})
                    else:
                        category_results.append({"model": model, "status": "failed"})
                        
                except Exception as e:
                    category_results.append({"model": model, "status": "error", "error": str(e)})
            
            setup_results[category] = category_results
        
        return setup_results
    
    def optimize_for_hardware(self) -> dict:
        """Recommend optimal models based on available hardware."""
        # This would typically check actual hardware specs
        # For demo purposes, we'll simulate hardware detection
        
        recommendations = {
            "low_resource": {
                "models": ["qwen2.5:0.5b-instruct-q4_K_M"],
                "max_concurrent": 1,
                "memory_usage": "< 1GB"
            },
            "medium_resource": {
                "models": ["phi3.5:3.8b-mini-instruct-q4_K_M", "llama3.2:3b-instruct-q4_K_M"],
                "max_concurrent": 2,
                "memory_usage": "2-4GB"
            },
            "high_resource": {
                "models": ["llama3.1:8b-instruct-q4_K_M", "codellama:7b-code-q4_K_M"],
                "max_concurrent": 3,
                "memory_usage": "6-12GB"
            }
        }
        
        return recommendations

# Production model setup
model_manager = OllamaModelManager()
setup_results = model_manager.setup_production_models(["balanced", "ultra_light"])
print(f"Model setup results: {setup_results}")
```

**–ö–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ –¥–ª—è —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –≤ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ —Å Ollama**:

‚úÖ **–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–∞**:
- –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ —Å–µ—Ä–≤–∏—Å Ollama —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π –≤ —Å–∏—Å—Ç–µ–º—É
- –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤
- –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Å–∫—Ä–∏–ø—Ç—ã –∑–∞–ø—É—Å–∫–∞ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–µ—Ä–≤–∏—Å–æ–º
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∑–∞–≥—Ä—É–∑–∫—É –º–æ–¥–µ–ª–µ–π –∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å API

‚úÖ **–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª—è–º–∏**:
- –ó–∞–≥—Ä—É–∑–∏—Ç–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –º–æ–¥–µ–ª–∏ –∏ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –∏—Ö —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å
- –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø—Ä–æ—Ü–µ–¥—É—Ä—ã –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∏ —Ä–æ—Ç–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π
- –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é —Ö—Ä–∞–Ω–µ–Ω–∏—è
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–µ–π –ø–æ–¥ –æ–∂–∏–¥–∞–µ–º–æ–π –Ω–∞–≥—Ä—É–∑–∫–æ–π

‚úÖ **–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏**:
- –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø—Ä–∞–≤–∏–ª–∞ –±—Ä–∞–Ω–¥–º–∞—É—ç—Ä–∞ –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞
- –ù–∞—Å—Ç—Ä–æ–π—Ç–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–æ—Å—Ç—É–ø–æ–º –∫ API –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏
- –†–µ–∞–ª–∏–∑—É–π—Ç–µ –≤–µ–¥–µ–Ω–∏–µ –∂—É—Ä–Ω–∞–ª–∞ –∞—É–¥–∏—Ç–∞ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤
- –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ Microsoft Agent Framework  
- –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π —Ä–∞–±–æ—Ç—ã –≤ –æ—Ñ—Ñ–ª–∞–π–Ω-—Ä–µ–∂–∏–º–µ  
- –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –æ—Ç–∫–∞–∑–æ—É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫  
- –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—á–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –∞–≥–µ–Ω—Ç–æ–≤ –æ—Ç –Ω–∞—á–∞–ª–∞ –¥–æ –∫–æ–Ω—Ü–∞  

**–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å Foundry Local**:

| –§—É–Ω–∫—Ü–∏—è | Foundry Local | Ollama |
|---------|---------------|--------|
| **–¶–µ–ª–µ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ** | –ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–µ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–æ | –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –∏ —Å–æ–æ–±—â–µ—Å—Ç–≤–æ |
| **–≠–∫–æ—Å–∏—Å—Ç–µ–º–∞ –º–æ–¥–µ–ª–µ–π** | –û—Ç–æ–±—Ä–∞–Ω–Ω—ã–µ Microsoft | –û–±—à–∏—Ä–Ω–æ–µ —Å–æ–æ–±—â–µ—Å—Ç–≤–æ |
| **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è** | –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è (CUDA/NPU/CPU) | –†—É—á–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ |
| **–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏** | –í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥, –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å | –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã —Å–æ–æ–±—â–µ—Å—Ç–≤–∞ |
| **–°–ª–æ–∂–Ω–æ—Å—Ç—å —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è** | –ü—Ä–æ—Å—Ç–∞—è (—É—Å—Ç–∞–Ω–æ–≤–∫–∞ —á–µ—Ä–µ–∑ winget) | –ü—Ä–æ—Å—Ç–∞—è (—É—Å—Ç–∞–Ω–æ–≤–∫–∞ —á–µ—Ä–µ–∑ curl) |
| **–°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å API** | OpenAI + —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è | –°—Ç–∞–Ω–¥–∞—Ä—Ç OpenAI |
| **–ü–æ–¥–¥–µ—Ä–∂–∫–∞** | –û—Ñ–∏—Ü–∏–∞–ª—å–Ω–∞—è Microsoft | –£–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —Å–æ–æ–±—â–µ—Å—Ç–≤–æ–º |
| **–õ—É—á—à–µ –≤—Å–µ–≥–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è** | –ü—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã–µ –∞–≥–µ–Ω—Ç—ã | –ü—Ä–æ—Ç–æ—Ç–∏–ø–∏—Ä–æ–≤–∞–Ω–∏–µ, –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è |

**–ö–æ–≥–¥–∞ –≤—ã–±—Ä–∞—Ç—å Ollama**:  
- **–†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –∏ –ø—Ä–æ—Ç–æ—Ç–∏–ø–∏—Ä–æ–≤–∞–Ω–∏–µ**: –ë—ã—Å—Ç—Ä–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π  
- **–ú–æ–¥–µ–ª–∏ —Å–æ–æ–±—â–µ—Å—Ç–≤–∞**: –î–æ—Å—Ç—É–ø –∫ –ø–æ—Å–ª–µ–¥–Ω–∏–º –º–æ–¥–µ–ª—è–º, —Å–æ–∑–¥–∞–Ω–Ω—ã–º —Å–æ–æ–±—â–µ—Å—Ç–≤–æ–º  
- **–û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ**: –û–±—É—á–µ–Ω–∏–µ –∏ –ø—Ä–µ–ø–æ–¥–∞–≤–∞–Ω–∏–µ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ AI-–∞–≥–µ–Ω—Ç–æ–≤  
- **–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –ø—Ä–æ–µ–∫—Ç—ã**: –ê–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è —Å –¥–æ—Å—Ç—É–ø–æ–º –∫ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–º –º–æ–¥–µ–ª—è–º  
- **–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –º–æ–¥–µ–ª–∏**: –°–æ–∑–¥–∞–Ω–∏–µ –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π  

### VLLM: –í—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ–µ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å-–∞–≥–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ SLM  

VLLM (–∏–Ω—Ñ–µ—Ä–µ–Ω—Å –æ—á–µ–Ω—å –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π) –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –≤—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω—ã–π, —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π —Å —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è –ø–∞–º—è—Ç–∏ –º–µ—Ö–∞–Ω–∏–∑–º –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞, —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–ª—è –º–∞—Å—à—Ç–∞–±–Ω—ã—Ö –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–π SLM. –í —Ç–æ –≤—Ä–µ–º—è –∫–∞–∫ Foundry Local –¥–µ–ª–∞–µ—Ç –∞–∫—Ü–µ–Ω—Ç –Ω–∞ –ø—Ä–æ—Å—Ç–æ—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è, –∞ Ollama ‚Äî –Ω–∞ –º–æ–¥–µ–ª—è—Ö —Å–æ–æ–±—â–µ—Å—Ç–≤–∞, VLLM –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç –≤ —Å—Ü–µ–Ω–∞—Ä–∏—è—Ö –≤—ã—Å–æ–∫–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, —Ç—Ä–µ–±—É—é—â–∏—Ö –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–ø—É—Å–∫–Ω–æ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ä–µ—Å—É—Ä—Å–æ–≤.

**–û—Å–Ω–æ–≤–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∏ —Ñ—É–Ω–∫—Ü–∏–∏**:  
- **PagedAttention**: –†–µ–≤–æ–ª—é—Ü–∏–æ–Ω–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç—å—é –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –≤–Ω–∏–º–∞–Ω–∏—è  
- **–î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –ø–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞**: –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–∞—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–ø—É—Å–∫–Ω–æ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏  
- **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è GPU**: –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —è–¥—Ä–∞ CUDA –∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞ —Ç–µ–Ω–∑–æ—Ä–æ–≤  
- **–°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å OpenAI**: –ü–æ–ª–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å API –¥–ª—è –±–µ—Å—à–æ–≤–Ω–æ–π –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏  
- **–°–ø–µ–∫—É–ª—è—Ç–∏–≤–Ω–æ–µ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ**: –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –º–µ—Ç–æ–¥—ã —É—Å–∫–æ—Ä–µ–Ω–∏—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞  
- **–ü–æ–¥–¥–µ—Ä–∂–∫–∞ –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏—è**: INT4, INT8 –∏ FP16 –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏  

#### –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞  

**–í–∞—Ä–∏–∞–Ω—Ç—ã —É—Å—Ç–∞–Ω–æ–≤–∫–∏**:  
```bash
# Standard installation
pip install vllm

# With additional dependencies for agent frameworks
pip install vllm[agent] openai

# Docker deployment for production
docker pull vllm/vllm-openai:latest

# From source for latest features
git clone https://github.com/vllm-project/vllm.git
cd vllm
pip install -e .
```
  
**–ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –∞–≥–µ–Ω—Ç–æ–≤**:  
```bash
# Start VLLM server with SLM model
python -m vllm.entrypoints.openai.api_server \
    --model microsoft/Phi-3.5-mini-instruct \
    --trust-remote-code \
    --max-model-len 4096 \
    --gpu-memory-utilization 0.8

# Alternative: Start with Qwen2.5 for lightweight agents
python -m vllm.entrypoints.openai.api_server \
    --model Qwen/Qwen2.5-0.5B-Instruct \
    --trust-remote-code \
    --max-model-len 2048 \
    --tensor-parallel-size 1

# Test API endpoint
curl http://localhost:8000/v1/models

# Test chat completion
curl http://localhost:8000/v1/chat/completions \
    -H "Content-Type: application/json" \
    -d '{
        "model": "microsoft/Phi-3.5-mini-instruct",
        "messages": [{"role": "user", "content": "Hello!"}]
    }'
```
  

#### –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Agent Framework  

**VLLM —Å Microsoft Agent Framework**:  
```python
from microsoft_agent_framework import Agent, Config
import openai
import subprocess
import time
import requests
from typing import Optional, Dict, Any

class VLLMManager:
    def __init__(self, model_name: str, 
                 host: str = "localhost", 
                 port: int = 8000,
                 gpu_memory_utilization: float = 0.8,
                 max_model_len: int = 4096):
        self.model_name = model_name
        self.host = host
        self.port = port
        self.base_url = f"http://{host}:{port}"
        self.gpu_memory_utilization = gpu_memory_utilization
        self.max_model_len = max_model_len
        self.process = None
        self.client = None
        
    def start_server(self) -> bool:
        """Start VLLM server with optimized settings for agents."""
        try:
            cmd = [
                "python", "-m", "vllm.entrypoints.openai.api_server",
                "--model", self.model_name,
                "--host", self.host,
                "--port", str(self.port),
                "--gpu-memory-utilization", str(self.gpu_memory_utilization),
                "--max-model-len", str(self.max_model_len),
                "--trust-remote-code",
                "--disable-log-requests",  # Reduce logging for agents
                "--served-model-name", self.get_served_model_name()
            ]
            
            self.process = subprocess.Popen(cmd, 
                stdout=subprocess.PIPE, 
                stderr=subprocess.PIPE)
            
            # Wait for server to start
            max_retries = 30
            for _ in range(max_retries):
                if self.health_check():
                    self.client = openai.OpenAI(base_url=f"{self.base_url}/v1")
                    return True
                time.sleep(2)
                
            return False
            
        except Exception as e:
            print(f"Failed to start VLLM server: {e}")
            return False
    
    def get_served_model_name(self) -> str:
        """Get a clean model name for serving."""
        return self.model_name.replace("/", "--")
    
    def health_check(self) -> bool:
        """Check if VLLM server is healthy."""
        try:
            response = requests.get(f"{self.base_url}/health", timeout=5)
            return response.status_code == 200
        except:
            return False
    
    def get_openai_client(self) -> openai.OpenAI:
        """Get OpenAI-compatible client for VLLM."""
        if not self.client:
            self.client = openai.OpenAI(base_url=f"{self.base_url}/v1")
        return self.client
    
    def get_model_info(self) -> Dict[str, Any]:
        """Get model information and statistics."""
        try:
            response = requests.get(f"{self.base_url}/v1/models")
            if response.status_code == 200:
                return response.json()
        except:
            pass
        return {}
    
    def shutdown(self):
        """Shutdown VLLM server."""
        if self.process:
            self.process.terminate()
            self.process.wait()

# Initialize VLLM for high-performance agents
vllm_manager = VLLMManager("microsoft/Phi-3.5-mini-instruct")
if vllm_manager.start_server():
    print("VLLM server started successfully")
    
    # Configure agent with VLLM backend
    agent_config = Config(
        name="vllm-performance-agent",
        model_provider="vllm",
        model_id=vllm_manager.get_served_model_name(),
        endpoint=f"{vllm_manager.base_url}/v1",
        api_key="none"  # VLLM doesn't require API key
    )
    
    agent = Agent(config=agent_config)
else:
    print("Failed to start VLLM server")
```
  
**–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ–≥–æ –≤—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞**:  
```python
import asyncio
from concurrent.futures import ThreadPoolExecutor
from microsoft_agent_framework import Agent, Config
import openai

class VLLMHighThroughputManager:
    def __init__(self):
        self.model_configs = {
            "lightweight": {
                "model": "Qwen/Qwen2.5-0.5B-Instruct",
                "port": 8000,
                "max_model_len": 2048,
                "gpu_memory_utilization": 0.3
            },
            "balanced": {
                "model": "microsoft/Phi-3.5-mini-instruct",
                "port": 8001,
                "max_model_len": 4096,
                "gpu_memory_utilization": 0.5
            },
            "capable": {
                "model": "meta-llama/Llama-3.2-3B-Instruct",
                "port": 8002,
                "max_model_len": 8192,
                "gpu_memory_utilization": 0.7
            }
        }
        self.managers = {}
        self.agents = {}
        self.client_pool = {}
        
    async def initialize_all_models(self):
        """Initialize all VLLM models in parallel."""
        initialization_tasks = []
        
        for category, config in self.model_configs.items():
            task = self._initialize_model(category, config)
            initialization_tasks.append(task)
        
        results = await asyncio.gather(*initialization_tasks, return_exceptions=True)
        
        successful_inits = 0
        for i, result in enumerate(results):
            category = list(self.model_configs.keys())[i]
            if isinstance(result, Exception):
                print(f"Failed to initialize {category}: {result}")
            else:
                successful_inits += 1
                print(f"Successfully initialized {category} model")
        
        return successful_inits
    
    async def _initialize_model(self, category: str, config: Dict[str, Any]):
        """Initialize a single VLLM model instance."""
        manager = VLLMManager(
            model_name=config["model"],
            port=config["port"],
            max_model_len=config["max_model_len"],
            gpu_memory_utilization=config["gpu_memory_utilization"]
        )
        
        # Start server in thread to avoid blocking
        loop = asyncio.get_event_loop()
        with ThreadPoolExecutor() as executor:
            success = await loop.run_in_executor(executor, manager.start_server)
        
        if success:
            self.managers[category] = manager
            
            # Create agent
            agent_config = Config(
                name=f"vllm-{category}-agent",
                model_provider="vllm",
                model_id=manager.get_served_model_name(),
                endpoint=f"{manager.base_url}/v1",
                api_key="none"
            )
            
            self.agents[category] = Agent(config=agent_config)
            
            # Create client pool for high throughput
            self.client_pool[category] = [
                openai.OpenAI(base_url=f"{manager.base_url}/v1")
                for _ in range(5)  # 5 clients per model for parallelism
            ]
            
            return True
        else:
            raise Exception(f"Failed to start VLLM server for {category}")
    
    def get_optimal_agent(self, request_complexity: str, current_load: Dict[str, int]) -> str:
        """Select optimal agent based on request complexity and current load."""
        complexity_mapping = {
            "simple": "lightweight",
            "moderate": "balanced", 
            "complex": "capable"
        }
        
        preferred_category = complexity_mapping.get(request_complexity, "balanced")
        
        # Check if preferred agent is available and not overloaded
        if (preferred_category in self.agents and 
            current_load.get(preferred_category, 0) < 10):  # Max 10 concurrent per agent
            return preferred_category
        
        # Fallback to least loaded available agent
        available_agents = [(cat, load) for cat, load in current_load.items() 
                          if cat in self.agents and load < 10]
        
        if available_agents:
            return min(available_agents, key=lambda x: x[1])[0]
        
        return "balanced"  # Default fallback
    
    async def process_batch_requests(self, requests: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Process multiple requests in parallel for maximum throughput."""
        current_load = {cat: 0 for cat in self.agents.keys()}
        tasks = []
        
        for request in requests:
            # Determine optimal agent
            complexity = request.get("complexity", "moderate")
            agent_category = self.get_optimal_agent(complexity, current_load)
            current_load[agent_category] += 1
            
            # Create processing task
            task = self._process_single_request(request, agent_category)
            tasks.append(task)
        
        # Process all requests in parallel
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Format results
        formatted_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                formatted_results.append({
                    "request_id": requests[i].get("id", i),
                    "status": "error",
                    "error": str(result)
                })
            else:
                formatted_results.append(result)
        
        return formatted_results
    
    async def _process_single_request(self, request: Dict[str, Any], agent_category: str) -> Dict[str, Any]:
        """Process a single request with the specified agent."""
        start_time = time.time()
        
        try:
            agent = self.agents[agent_category]
            response = await agent.chat_async(request["message"])
            
            processing_time = time.time() - start_time
            
            return {
                "request_id": request.get("id"),
                "status": "success",
                "response": response,
                "agent_used": agent_category,
                "processing_time": processing_time
            }
            
        except Exception as e:
            return {
                "request_id": request.get("id"),
                "status": "error",
                "error": str(e),
                "agent_used": agent_category,
                "processing_time": time.time() - start_time
            }

# High-throughput usage example
throughput_manager = VLLMHighThroughputManager()

# Initialize all models
initialized_count = await throughput_manager.initialize_all_models()
print(f"Initialized {initialized_count} models")

# Process batch requests
batch_requests = [
    {"id": 1, "message": "Simple question", "complexity": "simple"},
    {"id": 2, "message": "Complex analysis needed", "complexity": "complex"},
    {"id": 3, "message": "Moderate difficulty task", "complexity": "moderate"}
]

results = await throughput_manager.process_batch_requests(batch_requests)
for result in results:
    print(f"Request {result['request_id']}: {result['status']} in {result.get('processing_time', 0):.2f}s")
```
  

#### –®–∞–±–ª–æ–Ω—ã —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –≤ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ  

**–ü—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω–∞—è —Å–ª—É–∂–±–∞ VLLM –¥–ª—è –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–π**:  
```python
import asyncio
import logging
import time
from typing import Dict, List, Optional
from dataclasses import dataclass
from microsoft_agent_framework import Agent, Config
import uvicorn
from fastapi import FastAPI, HTTPException, BackgroundTasks
from pydantic import BaseModel

@dataclass
class VLLMServerConfig:
    model_name: str
    port: int
    gpu_memory_utilization: float
    max_model_len: int
    tensor_parallel_size: int = 1
    quantization: Optional[str] = None

class AgentRequest(BaseModel):
    message: str
    agent_type: str = "general"
    priority: str = "normal"
    timeout: int = 30

class VLLMProductionService:
    def __init__(self, server_configs: Dict[str, VLLMServerConfig]):
        self.server_configs = server_configs
        self.managers = {}
        self.agents = {}
        self.metrics = {
            "requests_processed": 0,
            "requests_failed": 0,
            "total_processing_time": 0,
            "agent_usage": {name: 0 for name in server_configs.keys()},
            "throughput_per_minute": 0
        }
        self.request_queue = asyncio.Queue(maxsize=1000)
        self.processing_workers = []
        self.app = FastAPI(title="VLLM Agent Service")
        self._setup_routes()
        
    async def initialize_production_environment(self):
        """Initialize all VLLM servers for production."""
        logging.info("Initializing VLLM production environment...")
        
        initialization_tasks = []
        for name, config in self.server_configs.items():
            task = self._initialize_server(name, config)
            initialization_tasks.append(task)
        
        results = await asyncio.gather(*initialization_tasks, return_exceptions=True)
        
        successful_servers = 0
        for i, result in enumerate(results):
            server_name = list(self.server_configs.keys())[i]
            if isinstance(result, Exception):
                logging.error(f"Failed to initialize {server_name}: {result}")
            else:
                successful_servers += 1
                logging.info(f"Successfully initialized {server_name}")
        
        if successful_servers == 0:
            raise Exception("No VLLM servers could be initialized")
        
        # Start processing workers
        self.processing_workers = [
            asyncio.create_task(self._processing_worker(i))
            for i in range(min(4, successful_servers))  # 4 workers max
        ]
        
        logging.info(f"Production environment ready with {successful_servers} servers")
        return successful_servers
    
    async def _initialize_server(self, name: str, config: VLLMServerConfig):
        """Initialize a single VLLM server."""
        manager = VLLMManager(
            model_name=config.model_name,
            port=config.port,
            gpu_memory_utilization=config.gpu_memory_utilization,
            max_model_len=config.max_model_len
        )
        
        # Add quantization if specified
        if config.quantization:
            # This would be added to the manager's start command
            pass
        
        success = manager.start_server()
        if success:
            self.managers[name] = manager
            
            # Create production agent
            agent_config = Config(
                name=f"vllm-production-{name}",
                model_provider="vllm",
                model_id=manager.get_served_model_name(),
                endpoint=f"{manager.base_url}/v1",
                api_key="none",
                timeout=30.0
            )
            
            agent = Agent(config=agent_config)
            
            # Add production tools
            self._add_production_tools(agent, name)
            
            self.agents[name] = agent
            return True
        else:
            raise Exception(f"Failed to start VLLM server for {name}")
    
    def _add_production_tools(self, agent: Agent, server_type: str):
        """Add production tools based on server type."""
        if server_type == "customer_service":
            @agent.tool
            def escalate_to_human(issue: str, customer_id: str) -> str:
                """Escalate complex issues to human agents."""
                return f"Escalated issue for customer {customer_id}: {issue}"
            
            @agent.tool
            def lookup_order_status(order_id: str) -> dict:
                """Look up order status from production database."""
                # Production database lookup
                return {"order_id": order_id, "status": "shipped", "eta": "2 days"}
        
        elif server_type == "technical_support":
            @agent.tool
            def run_system_diagnostics(system_id: str) -> dict:
                """Run comprehensive system diagnostics."""
                return {"system_id": system_id, "status": "healthy", "issues": []}
            
            @agent.tool
            def create_incident_report(description: str, severity: str) -> str:
                """Create incident report in production system."""
                incident_id = f"INC-{hash(description) % 100000:05d}"
                return f"Created incident {incident_id} with severity {severity}"
    
    def _setup_routes(self):
        """Set up FastAPI routes for production service."""
        @self.app.post("/chat")
        async def chat_endpoint(request: AgentRequest, background_tasks: BackgroundTasks):
            try:
                # Add request to queue
                await self.request_queue.put({
                    "request": request,
                    "timestamp": time.time(),
                    "future": asyncio.Future()
                })
                
                # Wait for processing (with timeout)
                result = await asyncio.wait_for(
                    self._wait_for_result(request),
                    timeout=request.timeout
                )
                
                return result
                
            except asyncio.TimeoutError:
                raise HTTPException(status_code=408, detail="Request timeout")
            except Exception as e:
                raise HTTPException(status_code=500, detail=str(e))
        
        @self.app.get("/health")
        async def health_endpoint():
            return await self.get_health_status()
        
        @self.app.get("/metrics")
        async def metrics_endpoint():
            return self.get_production_metrics()
    
    async def _processing_worker(self, worker_id: int):
        """Background worker for processing agent requests."""
        logging.info(f"Starting processing worker {worker_id}")
        
        while True:
            try:
                # Get request from queue
                queue_item = await self.request_queue.get()
                request_data = queue_item["request"]
                request_future = queue_item["future"]
                
                # Select appropriate agent
                agent_name = self._select_agent(request_data.agent_type)
                
                if agent_name not in self.agents:
                    request_future.set_exception(Exception(f"Agent {agent_name} not available"))
                    continue
                
                # Process request
                start_time = time.time()
                try:
                    agent = self.agents[agent_name]
                    response = await agent.chat_async(request_data.message)
                    
                    processing_time = time.time() - start_time
                    
                    # Update metrics
                    self.metrics["requests_processed"] += 1
                    self.metrics["total_processing_time"] += processing_time
                    self.metrics["agent_usage"][agent_name] += 1
                    
                    result = {
                        "response": response,
                        "agent_used": agent_name,
                        "processing_time": processing_time,
                        "worker_id": worker_id
                    }
                    
                    request_future.set_result(result)
                    
                except Exception as e:
                    self.metrics["requests_failed"] += 1
                    request_future.set_exception(e)
                
                finally:
                    self.request_queue.task_done()
                    
            except Exception as e:
                logging.error(f"Worker {worker_id} error: {e}")
                await asyncio.sleep(1)
    
    def _select_agent(self, agent_type: str) -> str:
        """Select appropriate agent based on request type."""
        agent_mapping = {
            "customer_service": "customer_service",
            "technical": "technical_support",
            "general": "general_purpose"
        }
        
        return agent_mapping.get(agent_type, "general_purpose")
    
    async def _wait_for_result(self, request: AgentRequest):
        """Wait for request processing to complete."""
        # This is simplified - in production you'd track futures properly
        await asyncio.sleep(0.1)  # Placeholder
        return {"response": "Processed", "status": "success"}
    
    async def get_health_status(self) -> dict:
        """Get comprehensive health status of all services."""
        health_status = {
            "overall_status": "healthy",
            "servers": {},
            "queue_size": self.request_queue.qsize(),
            "active_workers": len([w for w in self.processing_workers if not w.done()]),
            "timestamp": time.time()
        }
        
        unhealthy_servers = 0
        for name, manager in self.managers.items():
            try:
                is_healthy = manager.health_check()
                health_status["servers"][name] = {
                    "status": "healthy" if is_healthy else "unhealthy",
                    "endpoint": manager.base_url,
                    "model": manager.model_name
                }
                if not is_healthy:
                    unhealthy_servers += 1
            except Exception as e:
                health_status["servers"][name] = {
                    "status": "error",
                    "error": str(e)
                }
                unhealthy_servers += 1
        
        if unhealthy_servers > 0:
            health_status["overall_status"] = "degraded" if unhealthy_servers < len(self.managers) else "unhealthy"
        
        return health_status
    
    def get_production_metrics(self) -> dict:
        """Get production performance metrics."""
        total_requests = self.metrics["requests_processed"] + self.metrics["requests_failed"]
        avg_processing_time = (
            self.metrics["total_processing_time"] / self.metrics["requests_processed"]
            if self.metrics["requests_processed"] > 0 else 0
        )
        
        success_rate = (
            self.metrics["requests_processed"] / total_requests * 100
            if total_requests > 0 else 0
        )
        
        return {
            "total_requests": total_requests,
            "successful_requests": self.metrics["requests_processed"],
            "failed_requests": self.metrics["requests_failed"],
            "success_rate_percent": success_rate,
            "average_processing_time_seconds": avg_processing_time,
            "agent_usage_distribution": self.metrics["agent_usage"],
            "queue_size": self.request_queue.qsize()
        }
    
    async def start_production_server(self, host: str = "0.0.0.0", port: int = 8080):
        """Start the production FastAPI server."""
        config = uvicorn.Config(
            self.app,
            host=host,
            port=port,
            log_level="info",
            workers=1  # Single worker for simplicity
        )
        server = uvicorn.Server(config)
        await server.serve()

# Production deployment example
production_configs = {
    "customer_service": VLLMServerConfig(
        model_name="microsoft/Phi-3.5-mini-instruct",
        port=8000,
        gpu_memory_utilization=0.4,
        max_model_len=4096
    ),
    "technical_support": VLLMServerConfig(
        model_name="meta-llama/Llama-3.2-3B-Instruct",
        port=8001,
        gpu_memory_utilization=0.6,
        max_model_len=8192
    ),
    "general_purpose": VLLMServerConfig(
        model_name="Qwen/Qwen2.5-1.5B-Instruct",
        port=8002,
        gpu_memory_utilization=0.3,
        max_model_len=2048
    )
}

production_service = VLLMProductionService(production_configs)

# Initialize and start production service
# await production_service.initialize_production_environment()
# await production_service.start_production_server()
```
  

#### –ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥  

**–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ VLLM**:  
```python
import psutil
import nvidia_ml_py3 as nvml
from dataclasses import dataclass
from typing import List, Dict, Optional
import json
import asyncio

@dataclass
class PerformanceMetrics:
    timestamp: float
    requests_per_second: float
    average_latency_ms: float
    gpu_utilization_percent: float
    gpu_memory_used_gb: float
    cpu_utilization_percent: float
    memory_used_gb: float
    queue_length: int
    active_requests: int

class VLLMAdvancedMonitoring:
    def __init__(self, vllm_managers: Dict[str, VLLMManager]):
        self.managers = vllm_managers
        self.metrics_history = []
        self.alert_thresholds = {
            "gpu_utilization_max": 95,
            "gpu_memory_max_gb": 10,
            "latency_max_ms": 3000,
            "queue_length_max": 50,
            "error_rate_max_percent": 10
        }
        
        # Initialize NVIDIA ML for GPU monitoring
        try:
            nvml.nvmlInit()
            self.gpu_monitoring_available = True
            self.gpu_count = nvml.nvmlDeviceGetCount()
        except:
            self.gpu_monitoring_available = False
            self.gpu_count = 0
    
    async def collect_comprehensive_metrics(self) -> Dict[str, PerformanceMetrics]:
        """Collect detailed performance metrics for all VLLM instances."""
        all_metrics = {}
        
        for name, manager in self.managers.items():
            try:
                metrics = await self._collect_single_instance_metrics(name, manager)
                all_metrics[name] = metrics
            except Exception as e:
                logging.error(f"Failed to collect metrics for {name}: {e}")
                # Create error metrics
                all_metrics[name] = PerformanceMetrics(
                    timestamp=time.time(),
                    requests_per_second=0,
                    average_latency_ms=0,
                    gpu_utilization_percent=0,
                    gpu_memory_used_gb=0,
                    cpu_utilization_percent=0,
                    memory_used_gb=0,
                    queue_length=0,
                    active_requests=0
                )
        
        return all_metrics
    
    async def _collect_single_instance_metrics(self, name: str, manager: VLLMManager) -> PerformanceMetrics:
        """Collect metrics for a single VLLM instance."""
        timestamp = time.time()
        
        # Get VLLM-specific metrics via API
        vllm_stats = await self._get_vllm_stats(manager)
        
        # Get system metrics
        cpu_percent = psutil.cpu_percent(interval=0.1)
        memory_info = psutil.virtual_memory()
        memory_used_gb = memory_info.used / (1024**3)
        
        # Get GPU metrics if available
        gpu_utilization = 0
        gpu_memory_used = 0
        
        if self.gpu_monitoring_available and self.gpu_count > 0:
            try:
                # Assuming first GPU for simplicity
                handle = nvml.nvmlDeviceGetHandleByIndex(0)
                gpu_util = nvml.nvmlDeviceGetUtilizationRates(handle)
                gpu_utilization = gpu_util.gpu
                
                gpu_mem = nvml.nvmlDeviceGetMemoryInfo(handle)
                gpu_memory_used = gpu_mem.used / (1024**3)
                
            except Exception as e:
                logging.warning(f"GPU monitoring failed: {e}")
        
        return PerformanceMetrics(
            timestamp=timestamp,
            requests_per_second=vllm_stats.get("requests_per_second", 0),
            average_latency_ms=vllm_stats.get("average_latency_ms", 0),
            gpu_utilization_percent=gpu_utilization,
            gpu_memory_used_gb=gpu_memory_used,
            cpu_utilization_percent=cpu_percent,
            memory_used_gb=memory_used_gb,
            queue_length=vllm_stats.get("queue_length", 0),
            active_requests=vllm_stats.get("active_requests", 0)
        )
    
    async def _get_vllm_stats(self, manager: VLLMManager) -> dict:
        """Get VLLM-specific statistics via API calls."""
        try:
            # Test inference to measure latency
            start_time = time.time()
            client = manager.get_openai_client()
            
            response = await asyncio.wait_for(
                asyncio.to_thread(
                    client.chat.completions.create,
                    model=manager.get_served_model_name(),
                    messages=[{"role": "user", "content": "ping"}],
                    max_tokens=1
                ),
                timeout=5.0
            )
            
            latency_ms = (time.time() - start_time) * 1000
            
            return {
                "average_latency_ms": latency_ms,
                "requests_per_second": 1000 / latency_ms if latency_ms > 0 else 0,
                "queue_length": 0,  # Would need to be exposed by VLLM
                "active_requests": 1  # Approximation
            }
            
        except Exception as e:
            logging.warning(f"Failed to get VLLM stats: {e}")
            return {
                "average_latency_ms": 0,
                "requests_per_second": 0,
                "queue_length": 0,
                "active_requests": 0
            }
    
    def generate_performance_report(self, time_window_minutes: int = 60) -> dict:
        """Generate comprehensive performance report."""
        cutoff_time = time.time() - (time_window_minutes * 60)
        recent_metrics = [
            metrics for metrics in self.metrics_history
            if any(m.timestamp > cutoff_time for m in metrics.values())
        ]
        
        if not recent_metrics:
            return {"error": "No recent metrics available"}
        
        report = {
            "time_window_minutes": time_window_minutes,
            "total_samples": len(recent_metrics),
            "instances": {}
        }
        
        # Analyze each instance
        for instance_name in self.managers.keys():
            instance_metrics = [
                metrics[instance_name] for metrics in recent_metrics
                if instance_name in metrics
            ]
            
            if instance_metrics:
                report["instances"][instance_name] = {
                    "avg_latency_ms": sum(m.average_latency_ms for m in instance_metrics) / len(instance_metrics),
                    "max_latency_ms": max(m.average_latency_ms for m in instance_metrics),
                    "avg_gpu_utilization": sum(m.gpu_utilization_percent for m in instance_metrics) / len(instance_metrics),
                    "avg_requests_per_second": sum(m.requests_per_second for m in instance_metrics) / len(instance_metrics),
                    "max_queue_length": max(m.queue_length for m in instance_metrics),
                    "availability_percent": (len(instance_metrics) / len(recent_metrics)) * 100
                }
        
        return report
    
    async def auto_scaling_recommendations(self) -> List[dict]:
        """Generate auto-scaling recommendations based on performance metrics."""
        recommendations = []
        
        if not self.metrics_history:
            return recommendations
        
        latest_metrics = self.metrics_history[-1]
        
        for instance_name, metrics in latest_metrics.items():
            # High latency recommendation
            if metrics.average_latency_ms > self.alert_thresholds["latency_max_ms"]:
                recommendations.append({
                    "instance": instance_name,
                    "type": "scale_up",
                    "reason": f"High latency: {metrics.average_latency_ms:.0f}ms",
                    "suggestion": "Consider adding tensor parallelism or increasing GPU memory"
                })
            
            # High GPU utilization recommendation
            if metrics.gpu_utilization_percent > self.alert_thresholds["gpu_utilization_max"]:
                recommendations.append({
                    "instance": instance_name,
                    "type": "scale_out",
                    "reason": f"High GPU utilization: {metrics.gpu_utilization_percent:.1f}%",
                    "suggestion": "Consider adding additional GPU instances"
                })
            
            # Low utilization recommendation
            if (metrics.gpu_utilization_percent < 20 and 
                metrics.requests_per_second < 1):
                recommendations.append({
                    "instance": instance_name,
                    "type": "scale_down",
                    "reason": f"Low utilization: {metrics.gpu_utilization_percent:.1f}% GPU, {metrics.requests_per_second:.1f} RPS",
                    "suggestion": "Consider consolidating workloads or reducing resources"
                })
        
        return recommendations

# Advanced monitoring setup
monitoring = VLLMAdvancedMonitoring({
    "customer_service": vllm_manager,
    # Add other managers as needed
})

async def advanced_monitoring_loop():
    """Advanced monitoring with auto-scaling recommendations."""
    while True:
        try:
            # Collect metrics
            metrics = await monitoring.collect_comprehensive_metrics()
            monitoring.metrics_history.append(metrics)
            
            # Keep only last 1000 entries
            if len(monitoring.metrics_history) > 1000:
                monitoring.metrics_history = monitoring.metrics_history[-1000:]
            
            # Generate recommendations every 5 minutes
            if len(monitoring.metrics_history) % 10 == 0:  # Every 10th collection (5 minutes if collecting every 30s)
                recommendations = await monitoring.auto_scaling_recommendations()
                
                if recommendations:
                    logging.info(f"Auto-scaling recommendations: {recommendations}")
            
            # Generate performance report every hour
            if len(monitoring.metrics_history) % 120 == 0:  # Every 120th collection (1 hour)
                report = monitoring.generate_performance_report(60)
                logging.info(f"Performance report: {json.dumps(report, indent=2)}")
            
        except Exception as e:
            logging.error(f"Advanced monitoring error: {e}")
        
        await asyncio.sleep(30)  # Collect metrics every 30 seconds

# Start advanced monitoring
# asyncio.create_task(advanced_monitoring_loop())
```
  

#### –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è  

**–®–∞–±–ª–æ–Ω—ã –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ VLLM –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞**:  
```python
from enum import Enum
from typing import Dict, Any

class DeploymentScenario(Enum):
    DEVELOPMENT = "development"
    STAGING = "staging"
    PRODUCTION_LOW = "production_low"
    PRODUCTION_HIGH = "production_high"
    ENTERPRISE = "enterprise"

class VLLMConfigTemplates:
    """Production-ready VLLM configuration templates."""
    
    @staticmethod
    def get_config_template(scenario: DeploymentScenario) -> Dict[str, Any]:
        """Get optimized configuration for deployment scenario."""
        
        templates = {
            DeploymentScenario.DEVELOPMENT: {
                "gpu_memory_utilization": 0.6,
                "max_model_len": 2048,
                "tensor_parallel_size": 1,
                "pipeline_parallel_size": 1,
                "quantization": None,
                "enable_prefix_caching": False,
                "max_num_seqs": 32,
                "max_num_batched_tokens": 2048
            },
            
            DeploymentScenario.STAGING: {
                "gpu_memory_utilization": 0.8,
                "max_model_len": 4096,
                "tensor_parallel_size": 1,
                "pipeline_parallel_size": 1,
                "quantization": "awq",
                "enable_prefix_caching": True,
                "max_num_seqs": 64,
                "max_num_batched_tokens": 4096
            },
            
            DeploymentScenario.PRODUCTION_LOW: {
                "gpu_memory_utilization": 0.85,
                "max_model_len": 4096,
                "tensor_parallel_size": 1,
                "pipeline_parallel_size": 1,
                "quantization": "awq",
                "enable_prefix_caching": True,
                "max_num_seqs": 128,
                "max_num_batched_tokens": 8192,
                "enable_chunked_prefill": True
            },
            
            DeploymentScenario.PRODUCTION_HIGH: {
                "gpu_memory_utilization": 0.9,
                "max_model_len": 8192,
                "tensor_parallel_size": 2,
                "pipeline_parallel_size": 1,
                "quantization": "awq",
                "enable_prefix_caching": True,
                "max_num_seqs": 256,
                "max_num_batched_tokens": 16384,
                "enable_chunked_prefill": True,
                "speculative_model": "small_draft_model"
            },
            
            DeploymentScenario.ENTERPRISE: {
                "gpu_memory_utilization": 0.95,
                "max_model_len": 16384,
                "tensor_parallel_size": 4,
                "pipeline_parallel_size": 2,
                "quantization": "awq",
                "enable_prefix_caching": True,
                "max_num_seqs": 512,
                "max_num_batched_tokens": 32768,
                "enable_chunked_prefill": True,
                "speculative_model": "optimized_draft_model",
                "guided_decoding_backend": "outlines"
            }
        }
        
        return templates[scenario]
    
    @staticmethod
    def generate_vllm_command(model_name: str, 
                             scenario: DeploymentScenario,
                             port: int = 8000,
                             host: str = "0.0.0.0") -> List[str]:
        """Generate optimized VLLM command for deployment scenario."""
        
        config = VLLMConfigTemplates.get_config_template(scenario)
        
        cmd = [
            "python", "-m", "vllm.entrypoints.openai.api_server",
            "--model", model_name,
            "--host", host,
            "--port", str(port),
            "--gpu-memory-utilization", str(config["gpu_memory_utilization"]),
            "--max-model-len", str(config["max_model_len"]),
            "--tensor-parallel-size", str(config["tensor_parallel_size"]),
            "--max-num-seqs", str(config["max_num_seqs"]),
            "--max-num-batched-tokens", str(config["max_num_batched_tokens"]),
            "--trust-remote-code",
            "--disable-log-requests"
        ]
        
        # Add optional parameters
        if config.get("quantization"):
            cmd.extend(["--quantization", config["quantization"]])
        
        if config.get("enable_prefix_caching"):
            cmd.append("--enable-prefix-caching")
        
        if config.get("enable_chunked_prefill"):
            cmd.append("--enable-chunked-prefill")
        
        if config.get("pipeline_parallel_size", 1) > 1:
            cmd.extend(["--pipeline-parallel-size", str(config["pipeline_parallel_size"])])
        
        if config.get("speculative_model"):
            cmd.extend(["--speculative-model", config["speculative_model"]])
        
        return cmd

# Usage examples
dev_cmd = VLLMConfigTemplates.generate_vllm_command(
    "microsoft/Phi-3.5-mini-instruct",
    DeploymentScenario.DEVELOPMENT,
    port=8000
)

prod_cmd = VLLMConfigTemplates.generate_vllm_command(
    "microsoft/Phi-3.5-mini-instruct",
    DeploymentScenario.PRODUCTION_HIGH,
    port=8001
)

print(f"Development command: {' '.join(dev_cmd)}")
print(f"Production command: {' '.join(prod_cmd)}")
```
  
**–ö–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ –¥–ª—è —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è VLLM –≤ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ**:  

‚úÖ **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è**:  
- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞ —Ç–µ–Ω–∑–æ—Ä–æ–≤ –¥–ª—è –º–Ω–æ–≥–æ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–Ω—ã—Ö —Å–∏—Å—Ç–µ–º  
- –í–∫–ª—é—á–µ–Ω–∏–µ –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏—è (AWQ/GPTQ) –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏  
- –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏ GPU (85-95%)  
- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Ä–∞–∑–º–µ—Ä–æ–≤ –ø–∞–∫–µ—Ç–æ–≤ –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–Ω–æ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏  

‚úÖ **–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏**:  
- –í–∫–ª—é—á–µ–Ω–∏–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤ –¥–ª—è –ø–æ–≤—Ç–æ—Ä—è—é—â–∏—Ö—Å—è –∑–∞–ø—Ä–æ—Å–æ–≤  
- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π  
- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å–ø–µ–∫—É–ª—è—Ç–∏–≤–Ω–æ–≥–æ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞  
- –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è max_num_seqs –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è  

‚úÖ **–ü—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏**:  
- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –∏ —Å–±–æ—Ä–∞ –º–µ—Ç—Ä–∏–∫  
- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞ –∏ –æ—Ç–∫–∞–∑–æ—É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏  
- –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –æ—á–µ—Ä–µ–¥–µ–π –∑–∞–ø—Ä–æ—Å–æ–≤ –∏ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –Ω–∞–≥—Ä—É–∑–∫–∏  
- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –æ–ø–æ–≤–µ—â–µ–Ω–∏–π  

‚úÖ **–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –∏ –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å**:  
- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—Ä–∞–≤–∏–ª –±—Ä–∞–Ω–¥–º–∞—É—ç—Ä–∞ –∏ –∫–æ–Ω—Ç—Ä–æ–ª—è –¥–æ—Å—Ç—É–ø–∞  
- –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è —Å–∫–æ—Ä–æ—Å—Ç–∏ API –∏ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏  
- –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Ä–∞–±–æ—Ç—ã –∏ –æ—á–∏—Å—Ç–∫–∏  
- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –ø–æ—Å–ª–µ —Å–±–æ–µ–≤  

‚úÖ **–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏**:  
- –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å Microsoft Agent Framework  
- –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –≤—ã—Å–æ–∫–æ–π –ø—Ä–æ–ø—É—Å–∫–Ω–æ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏  
- –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ—Ü–µ–¥—É—Ä –æ—Ç–∫–∞–∑–æ—É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏ –∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è  
- –û—Ü–µ–Ω–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø–æ–¥ –Ω–∞–≥—Ä—É–∑–∫–æ–π  

**–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –¥—Ä—É–≥–∏–º–∏ —Ä–µ—à–µ–Ω–∏—è–º–∏**:

| –§—É–Ω–∫—Ü–∏—è | VLLM | Foundry Local | Ollama |
|---------|------|---------------|--------|
| **–¶–µ–ª–µ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ** | –í—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ–µ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–æ | –ü—Ä–æ—Å—Ç–æ—Ç–∞ –¥–ª—è –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–π | –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –∏ —Å–æ–æ–±—â–µ—Å—Ç–≤–æ |
| **–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å** | –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ–ø—É—Å–∫–Ω–∞—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å | –°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è | –•–æ—Ä–æ—à–∞—è |
| **–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–∞–º—è—Ç–∏** | –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è PagedAttention | –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è | –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è |
| **–°–ª–æ–∂–Ω–æ—Å—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏** | –í—ã—Å–æ–∫–∞—è (–º–Ω–æ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤) | –ù–∏–∑–∫–∞—è (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è) | –ù–∏–∑–∫–∞—è (–ø—Ä–æ—Å—Ç–∞—è) |
| **–ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å** | –û—Ç–ª–∏—á–Ω–∞—è (–ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º —Ç–µ–Ω–∑–æ—Ä–æ–≤/–∫–æ–Ω–≤–µ–π–µ—Ä–æ–≤) | –•–æ—Ä–æ—à–∞—è | –û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–∞—è |
| **–ö–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏–µ** | –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–µ (AWQ, GPTQ, FP8) | –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ | –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ GGUF |
| **–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏** | –¢—Ä–µ–±—É–µ—Ç—Å—è –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è | –í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ | –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã —Å–æ–æ–±—â–µ—Å—Ç–≤–∞ |
| **–õ—É—á—à–µ –≤—Å–µ–≥–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è** | –í—ã—Å–æ–∫–æ–º–∞—Å—à—Ç–∞–±–Ω—ã–µ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã–µ –∞–≥–µ–Ω—Ç—ã | –ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–µ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–æ | –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ |

**–ö–æ–≥–¥–∞ –≤—ã–±—Ä–∞—Ç—å VLLM**:  
- **–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –≤—ã—Å–æ–∫–æ–π –ø—Ä–æ–ø—É—Å–∫–Ω–æ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏**: –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ—Ç–µ–Ω –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ —Å–µ–∫—É–Ω–¥—É  
- **–ú–∞—Å—à—Ç–∞–±–Ω—ã–µ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è**: –ú–Ω–æ–≥–æ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–Ω—ã–µ, –º–Ω–æ–≥–æ—Å–µ—Ä–≤–µ—Ä–Ω—ã–µ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è  
- **–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å**: –û—Ç–≤–µ—Ç—ã –∑–∞ –¥–æ–ª–∏ —Å–µ–∫—É–Ω–¥—ã –≤ –º–∞—Å—à—Ç–∞–±–∞—Ö  
- **–ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è**: –ù–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –≤ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–º –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏–∏ –∏ –ø–∞–∫–µ—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏  
- **–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —Ä–µ—Å—É—Ä—Å–æ–≤**: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –¥–æ—Ä–æ–≥–æ—Å—Ç–æ—è—â–µ–≥–æ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è GPU  

## –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ SLM-–∞–≥–µ–Ω—Ç–æ–≤ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –º–∏—Ä–µ  

### SLM-–∞–≥–µ–Ω—Ç—ã –¥–ª—è –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è –∫–ª–∏–µ–Ω—Ç–æ–≤  
- **–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ SLM**: –ü–æ–∏—Å–∫ —É—á–µ—Ç–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π, —Å–±—Ä–æ—Å –ø–∞—Ä–æ–ª–µ–π, –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–∫–∞–∑–æ–≤  
- **–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –ø–æ —Å—Ç–æ–∏–º–æ—Å—Ç–∏**: –°–Ω–∏–∂–µ–Ω–∏–µ –∑–∞—Ç—Ä–∞—Ç –Ω–∞ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å –≤ 10 —Ä–∞–∑ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å LLM-–∞–≥–µ–Ω—Ç–∞–º–∏  
- **–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å**: –ë—ã—Å—Ç—Ä—ã–µ –æ—Ç–≤–µ—Ç—ã —Å –ø–æ—Å—Ç–æ—è–Ω–Ω—ã–º –∫–∞—á–µ—Å—Ç–≤–æ–º –¥–ª—è —Ä—É—Ç–∏–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤  

### SLM-–∞–≥–µ–Ω—Ç—ã –¥–ª—è –±–∏–∑–Ω–µ—Å-–ø—Ä–æ—Ü–µ—Å—Å–æ–≤  
- **–ê–≥–µ–Ω—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—á–µ—Ç–æ–≤**: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö, –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è –Ω–∞ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ  
- **–ê–≥–µ–Ω—Ç—ã —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç–æ–π**: –ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è, –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–æ–≤  
- **–ê–≥–µ–Ω—Ç—ã –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è**: –ö–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—è –≤—Å—Ç—Ä–µ—á, —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–∞–ª–µ–Ω–¥–∞—Ä—è–º–∏, –æ—Ç–ø—Ä–∞–≤–∫–∞ –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏–π  

### –ü–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ —Ü–∏—Ñ—Ä–æ–≤—ã–µ –ø–æ–º–æ—â–Ω–∏–∫–∏ SLM  
- **–ê–≥–µ–Ω—Ç—ã —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∑–∞–¥–∞—á–∞–º–∏**: –°–æ–∑–¥–∞–Ω–∏–µ, –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ, –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è —Å–ø–∏—Å–∫–æ–≤ –¥–µ–ª  
- **–ê–≥–µ–Ω—Ç—ã —Å–±–æ—Ä–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏**: –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —Ç–µ–º, –ª–æ–∫–∞–ª—å–Ω–æ–µ —Ä–µ–∑—é–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤  
- **–ê–≥–µ–Ω—Ç—ã –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏**: –°–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –ø–∏—Å–µ–º, —Å–æ–æ–±—â–µ–Ω–∏–π, –ø–æ—Å—Ç–æ–≤ –≤ —Å–æ—Ü—Å–µ—Ç—è—Ö  

### SLM-–∞–≥–µ–Ω—Ç—ã –¥–ª—è —Ç–æ—Ä–≥–æ–≤–ª–∏ –∏ —Ñ–∏–Ω–∞–Ω—Å–æ–≤  
- **–ê–≥–µ–Ω—Ç—ã –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Ä—ã–Ω–∫–∞**: –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ —Ü–µ–Ω, –≤—ã—è–≤–ª–µ–Ω–∏–µ —Ç—Ä–µ–Ω–¥–æ–≤ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏  
- **–ê–≥–µ–Ω—Ç—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–æ–≤**: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –µ–∂–µ–¥–Ω–µ–≤–Ω—ã—Ö/–µ–∂–µ–Ω–µ–¥–µ–ª—å–Ω—ã—Ö —Å–≤–æ–¥–æ–∫  
- **–ê–≥–µ–Ω—Ç—ã –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–æ–≤**: –ê–Ω–∞–ª–∏–∑ –ø–æ–∑–∏—Ü–∏–π –ø–æ—Ä—Ç—Ñ–µ–ª—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ª–æ–∫–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö  

### SLM-–∞–≥–µ–Ω—Ç—ã –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –∑–¥—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è  
- **–ê–≥–µ–Ω—Ç—ã –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤**: –ö–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—è –≤—Å—Ç—Ä–µ—á, –æ—Ç–ø—Ä–∞–≤–∫–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏–π  
- **–ê–≥–µ–Ω—Ç—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏**: –õ–æ–∫–∞–ª—å–Ω–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö —Å–≤–æ–¥–æ–∫, –æ—Ç—á–µ—Ç–æ–≤  
- **–ê–≥–µ–Ω—Ç—ã —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ä–µ—Ü–µ–ø—Ç–∞–º–∏**: –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –∑–∞–∫–∞–∑–æ–≤, –ø—Ä–æ–≤–µ—Ä–∫–∞ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π  

## Microsoft Agent Framework: –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –≥–æ—Ç–æ–≤—ã—Ö –∫ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤—É –∞–≥–µ–Ω—Ç–æ–≤  

### –û–±–∑–æ—Ä –∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞  

Microsoft Agent Framework –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –∫–æ–º–ø–ª–µ–∫—Å–Ω—É—é –ø–ª–∞—Ç—Ñ–æ—Ä–º—É –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è, —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è AI-–∞–≥–µ–Ω—Ç–∞–º–∏, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –∫–∞–∫ –≤ –æ–±–ª–∞–∫–µ, —Ç–∞–∫ –∏ –≤ –æ—Ñ—Ñ–ª–∞–π–Ω-—Ä–µ–∂–∏–º–µ. –§—Ä–µ–π–º–≤–æ—Ä–∫ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–∞–ª—ã–º–∏ —è–∑—ã–∫–æ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ –∏ —Å—Ü–µ–Ω–∞—Ä–∏—è–º–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –Ω–∞ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–∏, —á—Ç–æ –¥–µ–ª–∞–µ—Ç –µ–≥–æ –∏–¥–µ–∞–ª—å–Ω—ã–º –¥–ª—è –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã—Ö –ø–æ —Ä–µ—Å—É—Ä—Å–∞–º —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–π.

**–û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞**:  
- **–°—Ä–µ–¥–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–∞**: –õ–µ–≥–∫–æ–≤–µ—Å–Ω–∞—è —Å—Ä–µ–¥–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –¥–ª—è –ø–µ—Ä–∏—Ñ–µ—Ä–∏–π–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤  
- **–°–∏—Å—Ç–µ–º–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤**: –†–∞—Å—à–∏—Ä—è–µ–º–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –ø–ª–∞–≥–∏–Ω–æ–≤ –¥–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –≤–Ω–µ—à–Ω–∏—Ö —Å–µ—Ä–≤–∏—Å–æ–≤ –∏ API  
- **–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º**: –ü–æ—Å—Ç–æ—è–Ω–Ω–∞—è –ø–∞–º—è—Ç—å –∞–≥–µ–Ω—Ç–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –º–µ–∂–¥—É —Å–µ—Å—Å–∏—è–º–∏  
- **–°–ª–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏**: –í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –¥–ª—è –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è  
- **–î–≤–∏–∂–æ–∫ –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏–∏**: –ö–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∞–≥–µ–Ω—Ç–æ–≤ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–∞–±–æ—á–∏–º–∏ –ø—Ä–æ—Ü–µ—Å—Å–∞–º–∏  

### –û—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –Ω–∞ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–∏  

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º –æ—Ñ—Ñ–ª–∞–π–Ω**: Microsoft Agent Framework —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω —Å —É—á–µ—Ç–æ–º –ø—Ä–∏–Ω—Ü–∏–ø–æ–≤ –æ—Ñ—Ñ–ª–∞–π–Ω-—Ä–∞–±–æ—Ç—ã, –ø–æ–∑–≤–æ–ª—è—è –∞–≥–µ–Ω—Ç–∞–º —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞—Ç—å –±–µ–∑ –ø–æ—Å—Ç–æ—è–Ω–Ω–æ–≥–æ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É. –≠—Ç–æ –≤–∫–ª—é—á–∞–µ—Ç –ª–æ–∫–∞–ª—å–Ω—ã–π –∏–Ω—Ñ–µ—Ä–µ–Ω—Å –º–æ–¥–µ–ª–µ–π, –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π, –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –≤ –æ—Ñ—Ñ–ª–∞–π–Ω-—Ä–µ–∂–∏–º–µ –∏ –ø–ª–∞–≤–Ω—É—é –¥–µ–≥—Ä–∞–¥–∞—Ü–∏—é –ø—Ä–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –æ–±–ª–∞—á–Ω—ã—Ö —Å–µ—Ä–≤–∏—Å–æ–≤.

**–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ä–µ—Å—É—Ä—Å–æ–≤**: –§—Ä–µ–π–º–≤–æ—Ä–∫ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–∞–º–∏ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –ø–∞–º—è—Ç–∏ –¥–ª—è SLM, –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π –Ω–∞–≥—Ä—É–∑–∫–∏ CPU/GPU –¥–ª—è –ø–µ—Ä–∏—Ñ–µ—Ä–∏–π–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤, –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–º –≤—ã–±–æ—Ä–æ–º –º–æ–¥–µ–ª–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤ –∏ —ç–Ω–µ—Ä–≥–æ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–º–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –¥–ª—è –º–æ–±–∏–ª—å–Ω—ã—Ö —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–π.

**–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –∏ –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å**: –§—É–Ω–∫—Ü–∏–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è –≤–∫–ª—é—á–∞—é—Ç –ª–æ–∫–∞–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç–∏, –∑–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–∞–Ω–∞–ª—ã —Å–≤—è–∑–∏ –∞–≥–µ–Ω—Ç–æ–≤, –∫–æ–Ω—Ç—Ä–æ–ª—å –¥–æ—Å—Ç—É–ø–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–æ–ª–µ–π –¥–ª—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –∞–≥–µ–Ω—Ç–æ–≤ –∏ –≤–µ–¥–µ–Ω–∏–µ –∂—É—Ä–Ω–∞–ª–∞ –∞—É–¥–∏—Ç–∞ –¥–ª—è —Å–æ–±–ª—é–¥–µ–Ω–∏—è —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π.

### –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Foundry Local  

Microsoft Agent Framework –±–µ—Å—à–æ–≤–Ω–æ –∏–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç—Å—è —Å Foundry Local, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—è –ø–æ–ª–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –¥–ª—è –ø–µ—Ä–∏—Ñ–µ—Ä–∏–π–Ω–æ–≥–æ AI:  

**–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π**: –§—Ä–µ–π–º–≤–æ—Ä–∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç –∏ –ø–æ–¥–∫–ª—é—á–∞–µ—Ç—Å—è –∫ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞–º Foundry Local, –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ SLM –∏ –≤—ã–±–∏—Ä–∞–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –∞–≥–µ–Ω—Ç–æ–≤ –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è.

**–î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π**: –ê–≥–µ–Ω—Ç—ã –º–æ–≥—É—Ç –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –∑–∞–≥—Ä—É–∂–∞—Ç—å —Ä–∞–∑–ª–∏—á–Ω—ã–µ SLM –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –∑–∞–¥–∞—á, —Å–æ–∑–¥–∞–≤–∞—è —Å–∏—Å—Ç–µ–º—ã –∞–≥–µ–Ω—Ç–æ–≤ —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –º–æ–¥–µ–ª—è–º–∏, –≥–¥–µ —Ä–∞–∑–Ω—ã–µ –º–æ–¥–µ–ª–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç —Ä–∞–∑–Ω—ã–µ —Ç–∏–ø—ã –∑–∞–ø—Ä–æ—Å–æ–≤, –∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.

**–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏**: –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ö–∞–Ω–∏–∑–º—ã –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è —Å–æ–∫—Ä–∞—â–∞—é—Ç –≤—Ä–µ–º—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π, –ø—É–ª —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç –≤—ã–∑–æ–≤—ã API –∫ Foundry Local, –∞ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–∞—è –ø–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —É–ª—É—á—à–∞–µ—Ç –ø—Ä–æ–ø—É—Å–∫–Ω—É—é —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∞–≥–µ–Ω—Ç–æ–≤.

### –°–æ–∑–¥–∞–Ω–∏–µ –∞–≥–µ–Ω—Ç–æ–≤ —Å Microsoft Agent Framework  

#### –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–∞  

```python
from microsoft_agent_framework import Agent, Tool, Config
from foundry_local import FoundryLocalManager

# Configure agent with Foundry Local integration
config = Config(
    name="customer-service-agent",
    model_provider="foundry-local",
    model_alias="phi-4-mini",
    max_tokens=512,
    temperature=0.1,
    offline_mode=True
)

# Initialize Foundry Local connection
foundry = FoundryLocalManager("phi-4-mini")

# Create agent instance
agent = Agent(
    config=config,
    model_endpoint=foundry.endpoint,
    api_key=foundry.api_key
)
```
  
#### –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –ø–µ—Ä–∏—Ñ–µ—Ä–∏–π–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤  

```python
# Define tools for offline operation
@agent.tool
def lookup_customer_info(customer_id: str) -> dict:
    """Look up customer information from local database."""
    # Local database query - works offline
    return local_db.get_customer(customer_id)

@agent.tool
def create_support_ticket(issue: str, priority: str) -> str:
    """Create a support ticket in local system."""
    # Local ticket creation with sync when online
    ticket_id = local_system.create_ticket(issue, priority)
    return f"Ticket {ticket_id} created successfully"

@agent.tool
def schedule_callback(customer_id: str, preferred_time: str) -> str:
    """Schedule a callback for the customer."""
    # Local scheduling with calendar integration
    return local_calendar.schedule(customer_id, preferred_time)
```
  
#### –û—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∞–≥–µ–Ω—Ç–æ–≤  

```python
from microsoft_agent_framework import AgentOrchestrator

# Create specialized agents for different domains
scheduling_agent = Agent(
    config=Config(
        name="scheduling-agent",
        model_alias="qwen2.5-0.5b",  # Lightweight for simple tasks
        specialized_for="scheduling"
    )
)

technical_support_agent = Agent(
    config=Config(
        name="technical-agent",
        model_alias="phi-4-mini",  # More capable for complex issues
        specialized_for="technical_support"
    )
)

# Orchestrate multiple agents
orchestrator = AgentOrchestrator([
    scheduling_agent,
    technical_support_agent
])

# Route requests based on intent
result = orchestrator.process_request(
    "I need to schedule a callback for a technical issue",
    routing_strategy="intent-based"
)
```
  

### –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —à–∞–±–ª–æ–Ω—ã —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –Ω–∞ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–∏  

#### –ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∞–≥–µ–Ω—Ç–æ–≤  

**–ö–ª–∞—Å—Ç–µ—Ä—ã –ª–æ–∫–∞–ª—å–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤**: –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö SLM-–∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–π–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞—Ö, –∫–∞–∂–¥—ã–π –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –∑–∞–¥–∞—á. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ª–µ–≥–∫–æ–≤–µ—Å–Ω—ã–µ –º–æ–¥–µ–ª–∏, —Ç–∞–∫–∏–µ –∫–∞–∫ Qwen2.5-0.5B, –¥–ª—è –ø—Ä–æ—Å—Ç–æ–≥–æ –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏ –∏ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è, —Å—Ä–µ–¥–Ω–∏–µ –º–æ–¥–µ–ª–∏, —Ç–∞–∫–∏–µ –∫–∞–∫ Phi-4-Mini, –¥–ª—è –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è –∫–ª–∏–µ–Ω—Ç–æ–≤ –∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏, –∏ –±–æ–ª–µ–µ –∫—Ä—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π, –µ—Å–ª–∏ –ø–æ–∑–≤–æ–ª—è—é—Ç —Ä–µ—Å—É—Ä—Å—ã.

**–ö–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—è –ø–µ—Ä–∏—Ñ–µ—Ä–∏–∏ –∏ –æ–±–ª–∞–∫–∞**: –†–µ–∞–ª–∏–∑—É–π—Ç–µ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–µ —Å—Ö–µ–º—ã —ç—Å–∫–∞–ª–∞—Ü–∏–∏, –ø—Ä–∏ –∫–æ—Ç–æ—Ä—ã—Ö –ª–æ–∫–∞–ª—å–Ω—ã–µ –∞–≥–µ–Ω—Ç—ã –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç —Ä—É—Ç–∏–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏, –æ–±–ª–∞—á–Ω—ã–µ –∞–≥–µ–Ω—Ç—ã –æ–±–µ—Å–ø–µ—á–∏–≤–∞—é—Ç —Å–ª–æ–∂–Ω—ã–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è, –∞ –ø–ª–∞–≤–Ω–∞—è –ø–µ—Ä–µ–¥–∞—á–∞ –º–µ–∂–¥—É –ø–µ—Ä–∏—Ñ–µ—Ä–∏–π–Ω–æ–π –∏ –æ–±–ª–∞—á–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ—Å—Ç—å.

#### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è  

**–†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –Ω–∞ –æ–¥–Ω–æ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ**:  
```yaml
deployment:
  type: single-device
  hardware: edge-device
  models:
    - alias: "phi-4-mini"
      primary: true
      tasks: ["conversation", "reasoning"]
    - alias: "qwen2.5-0.5b"
      secondary: true
      tasks: ["routing", "classification"]
  agents:
    - name: "primary-agent"
      model: "phi-4-mini"
      tools: ["database", "calendar", "email"]
```
  
**–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–µ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –Ω–∞ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–∏**:  
```yaml
deployment:
  type: distributed-edge
  nodes:
    - id: "edge-1"
      agents: ["customer-service", "scheduling"]
      models: ["phi-4-mini"]
    - id: "edge-2"
      agents: ["technical-support", "documentation"]
      models: ["qwen2.5-coder-0.5b"]
  coordination:
    load_balancing: true
    failover: automatic
```
  

### –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è –ø–µ—Ä–∏—Ñ–µ—Ä–∏–π–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤  

#### –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–µ–π  

**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–¥–∞—á**: Microsoft Agent Framework –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ –≤—ã–±–∏—Ä–∞—Ç—å –º–æ–¥–µ–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∑–∞–¥–∞—á –∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π:  

- **–ü—Ä–æ—Å—Ç—ã–µ –∑–∞–¥–∞—á–∏** (–≤–æ–ø—Ä–æ—Å—ã –∏ –æ—Ç–≤–µ—Ç—ã, –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è): Qwen2.5-0.5B (500MB, <100–º—Å –æ—Ç–≤–µ—Ç–∞)  
- **–£–º–µ—Ä–µ–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏** (–æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ –∫–ª–∏–µ–Ω—Ç–æ–≤, –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ): Phi-4-Mini (2.4GB, 200-500–º—Å –æ—Ç–≤–µ—Ç–∞)  
- **–°–ª–æ–∂–Ω—ã–µ –∑–∞–¥–∞—á–∏** (—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑, –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ): Phi-4 (7GB, 1-3—Å –æ—Ç–≤–µ—Ç–∞ –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ —Ä–µ—Å—É—Ä—Å–æ–≤)  

**–î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π**: –ê–≥–µ–Ω—Ç—ã –º–æ–≥—É—Ç –ø–µ—Ä–µ–∫–ª—é—á–∞—Ç—å—Å—è –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—É—â–µ–π –Ω–∞–≥—Ä—É–∑–∫–∏ —Å–∏—Å—Ç–µ–º—ã, –æ—Ü–µ–Ω–∫–∏ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∑–∞–¥–∞—á, —É—Ä–æ–≤–Ω—è –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è.

#### –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç—å—é –∏ —Ä–µ—Å—É—Ä—Å–∞–º–∏  

```python
# Configure resource constraints for edge deployment
resource_config = ResourceConfig(
    max_memory_usage="4GB",
    max_concurrent_agents=3,
    model_cache_size="2GB",
    auto_unload_idle_models=True,
    power_management=True
)

agent = Agent(
    config=config,
    resource_limits=resource_config
)
```
  

### –®–∞–±–ª–æ–Ω—ã –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –¥–ª—è –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–π  

#### –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ  

**–õ–æ–∫–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö**: –í—Å—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∞–≥–µ–Ω—Ç–∞–º–∏ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –ª–æ–∫–∞–ª—å–Ω–æ, —á—Ç–æ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ –ø–æ–∫–∏–¥–∞—é—Ç –ø–µ—Ä–∏—Ñ–µ—Ä–∏–π–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ. –≠—Ç–æ –≤–∫–ª—é—á–∞–µ—Ç –∑–∞—â–∏—Ç—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∫–ª–∏–µ–Ω—Ç–æ–≤, —Å–æ–±–ª—é–¥–µ–Ω–∏–µ HIPAA –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤ –∑–¥—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è, –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –±–∞–Ω–∫–æ–≤—Å–∫–∏—Ö –∞–≥–µ–Ω—Ç–æ–≤ –∏ —Å–æ–±–ª—é–¥–µ–Ω–∏–µ GDPR –¥–ª—è –µ–≤—Ä–æ–ø–µ–π—Å–∫–∏—Ö —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–π.

**–ö–æ–Ω—Ç—Ä–æ–ª—å –¥–æ—Å—Ç—É–ø–∞**: –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è–º–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–æ–ª–µ–π –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ—Ç, –∫ –∫–∞–∫–∏–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º –º–æ–≥—É—Ç –æ–±—Ä–∞—â–∞—Ç—å—Å—è –∞–≥–µ–Ω—Ç—ã, –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å –∞–≥–µ–Ω—Ç–∞–º–∏ –∏ –≤–µ–¥–µ–Ω–∏–µ –∂—É—Ä–Ω–∞–ª–∞ –≤—Å–µ—Ö –¥–µ–π—Å—Ç–≤–∏–π –∏ —Ä–µ—à–µ–Ω–∏–π –∞–≥–µ–Ω—Ç–æ–≤.

#### –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –Ω–∞–±–ª—é–¥–∞–µ–º–æ—Å—Ç—å  

```python
from microsoft_agent_framework import AgentMonitor

# Set up monitoring for edge agents
monitor = AgentMonitor(
    metrics=["response_time", "success_rate", "resource_usage"],
    alerts=[
        {"metric": "response_time", "threshold": "2s", "action": "scale_down_model"},
        {"metric": "memory_usage", "threshold": "80%", "action": "unload_idle_agents"}
    ],
    local_storage=True  # Store metrics locally for offline operation
)

agent.add_monitor(monitor)
```
  

### –ü—Ä–∏–º–µ—Ä—ã —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –º–∏—Ä–µ  

#### –°–∏—Å—Ç–µ–º–∞ –∞–≥–µ–Ω—Ç–æ–≤ –¥–ª—è —Ä–æ–∑–Ω–∏—á–Ω–æ–π —Ç–æ—Ä–≥–æ–≤–ª–∏  

```python
# Retail kiosk agent for in-store customer assistance
retail_agent = Agent(
    config=Config(
        name="retail-assistant",
        model_alias="phi-4-mini",
        context="You are a helpful retail assistant in an electronics store."
    )
)

@retail_agent.tool
def check_inventory(product_sku: str) -> dict:
    """Check local inventory for a product."""
    return local_inventory.lookup(product_sku)

@retail_agent.tool
def find_alternatives(product_category: str) -> list:
    """Find alternative products in the same category."""
    return local_catalog.find_similar(product_category)

@retail_agent.tool
def create_price_quote(items: list) -> dict:
    """Generate a price quote for multiple items."""
    return pricing_engine.calculate_quote(items)
```
  
#### –ê–≥–µ–Ω—Ç –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –∑–¥—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è  

```python
# HIPAA-compliant patient support agent
healthcare_agent = Agent(
    config=Config(
        name="patient-support",
        model_alias="phi-4-mini",
        privacy_mode=True,  # Enhanced privacy for healthcare
        compliance=["HIPAA"]
    )
)

@healthcare_agent.tool
def check_appointment_availability(provider_id: str, date_range: str) -> list:
    """Check appointment slots with healthcare provider."""
    return local_scheduling.get_availability(provider_id, date_range)

@healthcare_agent.tool
def access_patient_portal(patient_id: str, auth_token: str) -> dict:
    """Secure access to patient information."""
    if security.validate_token(auth_token):
        return patient_portal.get_summary(patient_id)
    return {"error": "Authentication failed"}
```
  

### –õ—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏ –¥–ª—è Microsoft Agent Framework  

#### –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ  

1. **–ù–∞—á–∏–Ω–∞–π—Ç–µ —Å –ø—Ä–æ—Å—Ç–æ–≥–æ**: –ù–∞—á–Ω–∏—Ç–µ —Å —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ —Å –æ–¥–Ω–∏–º –∞–≥–µ–Ω—Ç–æ–º, –ø—Ä–µ–∂–¥–µ —á–µ–º —Å–æ–∑–¥–∞–≤–∞—Ç—å —Å–ª–æ–∂–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –∞–≥–µ–Ω—Ç–∞–º–∏  
2. **–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏**: –í—ã–±–∏—Ä–∞–π—Ç–µ —Å–∞–º—É—é –º–∞–ª–µ–Ω—å–∫—É—é –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –≤–∞—à–∏–º —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º –∫ —Ç–æ—á–Ω–æ—Å—Ç–∏  
3. **–î–∏–∑–∞–π–Ω –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤**: –°–æ–∑–¥–∞–≤–∞–π—Ç–µ —É–∑–∫–æ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã —Å –æ–¥–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–µ–π, –∞ –Ω–µ —Å–ª–æ–∂–Ω—ã–µ –º–Ω–æ–≥–æ—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ  
4. **–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫**: –†–µ–∞–ª–∏–∑—É–π—Ç–µ –ø–ª–∞–≤–Ω—É—é –¥–µ–≥—Ä–∞–¥–∞—Ü–∏—é –¥–ª—è –æ—Ñ—Ñ–ª–∞–π–Ω-—Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –∏ –æ—Ç–∫–∞–∑–æ–≤ –º–æ–¥–µ–ª–µ–π  
5. **–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ**: –¢–µ—Å—Ç–∏—Ä—É–π—Ç–µ –∞–≥–µ–Ω—Ç–æ–≤ –≤ —É—Å–ª–æ–≤–∏—è—Ö –æ—Ñ—Ñ–ª–∞–π–Ω-—Ä–∞–±–æ—Ç—ã –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤  

#### –õ—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è  

1. **–ü–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ–µ –≤–Ω–µ–¥—Ä–µ–Ω–∏–µ**: –°–Ω–∞—á–∞–ª–∞ —Ä–∞–∑–≤–µ—Ä–Ω–∏—Ç–µ –¥–ª—è –Ω–µ–±–æ–ª—å—à–æ–π –≥—Ä—É–ø–ø—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ —Å–ª–µ–¥–∏—Ç–µ –∑–∞ –º–µ—Ç—Ä–∏–∫–∞–º–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏  
2. **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Ä–µ—Å—É—Ä—Å–æ–≤**: –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –æ–ø–æ–≤–µ—â–µ–Ω–∏—è –¥–ª—è –ø–æ—Ä–æ–≥–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –ø–∞–º—è—Ç–∏, CPU –∏ –≤—Ä–µ–º–µ–Ω–∏ –æ—Ç–≤–µ—Ç–∞  
3. **–†–µ–∑–µ—Ä–≤–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏**: –í—Å–µ–≥–¥–∞ –∏–º–µ–π—Ç–µ –ø–ª–∞–Ω—ã —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–∞ —Å–ª—É—á–∞–π –æ—Ç–∫–∞–∑–æ–≤ –º–æ–¥–µ–ª–µ–π –∏–ª–∏ –∏—Å—á–µ—Ä–ø–∞–Ω–∏—è —Ä–µ—Å—É—Ä—Å–æ–≤  
4. **–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –ø—Ä–µ–∂–¥–µ –≤—Å–µ–≥–æ**: –†–µ–∞–ª–∏–∑—É–π—Ç–µ –º–µ—Ä—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ —Å —Å–∞–º–æ–≥–æ –Ω–∞—á–∞–ª–∞, –∞ –Ω–µ –≤ –∫–∞—á–µ—Å—Ç–≤–µ –ø–æ—Å–ª–µ–¥—É—é—â–µ–π –¥–æ—Ä–∞–±–æ—Ç–∫–∏  
5. **–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è**: –í–µ–¥–∏—Ç–µ —á–µ—Ç–∫—É—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –∞–≥–µ–Ω—Ç–æ–≤  

### –ë—É–¥—É—â–∞—è –¥–æ—Ä–æ–∂–Ω–∞—è –∫–∞—Ä—Ç–∞ –∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è  

Microsoft Agent Framework –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç —Ä–∞–∑–≤–∏–≤–∞—Ç—å—Å—è —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π SLM, —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º–∏ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –Ω–∞ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–∏, –ª—É—á—à–∏–º —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º —Ä–µ—Å—É—Ä—Å–∞–º–∏ –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã—Ö —Å—Ä–µ–¥ –∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π —ç–∫–æ—Å–∏—Å—Ç–µ–º–æ–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤.

**–ü—Ä–µ–¥—Å—Ç–æ—è—â–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏**:  
- **AutoML –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∞–≥–µ–Ω—Ç–æ–≤**: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ SLM –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –∑–∞–¥–∞—á –∞–≥–µ–Ω—Ç–æ–≤  
- **–°–µ—Ç–µ–≤–æ–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–π–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤**: –ö–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—è –º–µ–∂–¥—É –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è–º–∏ –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–∏  
- **–†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è —Ç–µ–ª–µ–º–µ—Ç—Ä–∏—è**: –£–ª—É—á—à–µ–Ω–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∞–≥–µ–Ω—Ç–æ–≤  
- **–í–∏–∑—É–∞–ª—å–Ω—ã–π –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä –∞–≥–µ–Ω—Ç–æ–≤**: –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –∞–≥–µ–Ω—Ç–æ–≤ —Å –Ω–∏–∑–∫–∏–º/–Ω—É–ª–µ–≤—ã–º –∫–æ–¥–æ–º  

## –õ—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏ –¥–ª—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ SLM-–∞–≥–µ–Ω—Ç–æ–≤  

### –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –≤—ã–±–æ—Ä—É SLM –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤  

–ü—Ä–∏ –≤—ã–±–æ—Ä–µ SLM –¥–ª—è —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤ —É—á–∏—Ç—ã–≤–∞–π—Ç–µ —Å–ª–µ–¥—É—é—â–∏–µ —Ñ–∞–∫—Ç–æ—Ä—ã:  

**–†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏**: –í—ã–±–∏—Ä–∞–π—Ç–µ —Å–≤–µ—Ä—Ö–∫–æ–º–ø–∞–∫—Ç–Ω—ã–µ –º–æ–¥–µ–ª–∏, —Ç–∞–∫–∏–µ –∫–∞–∫ Q2_K, –¥–ª—è —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã—Ö –º–æ–±–∏–ª—å–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π –∞–≥–µ–Ω—Ç–æ–≤, —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏, —Ç–∞–∫–∏–µ
**–í—ã–±–æ—Ä —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞ –¥–ª—è —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤**: –í—ã–±–∏—Ä–∞–π—Ç–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ü–µ–ª–µ–≤–æ–≥–æ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è –∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –∫ –∞–≥–µ–Ω—Ç—É. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ Llama.cpp –¥–ª—è —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–≤, Apple MLX –¥–ª—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ Apple Silicon –∏ ONNX –¥–ª—è –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ —Ä–∞–∑–Ω—ã—Ö –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞—Ö.

## –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ SLM-–∞–≥–µ–Ω—Ç–æ–≤ –∏ –ø—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### –°—Ü–µ–Ω–∞—Ä–∏–∏ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –º–∏—Ä–µ

**–ú–æ–±–∏–ª—å–Ω—ã–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤**: –§–æ—Ä–º–∞—Ç—ã Q4_K –æ—Ç–ª–∏—á–Ω–æ –ø–æ–¥—Ö–æ–¥—è—Ç –¥–ª—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ —Å–º–∞—Ä—Ç—Ñ–æ–Ω–∞—Ö –±–ª–∞–≥–æ–¥–∞—Ä—è –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–º—É –æ–±—ä–µ–º—É –ø–∞–º—è—Ç–∏, –≤ —Ç–æ –≤—Ä–µ–º—è –∫–∞–∫ Q8_0 –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–ª—è —Å–∏—Å—Ç–µ–º –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –ø–ª–∞–Ω—à–µ—Ç–∞—Ö. –§–æ—Ä–º–∞—Ç—ã Q5_K –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–ª—è –º–æ–±–∏–ª—å–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤ –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏.

**–ù–∞—Å—Ç–æ–ª—å–Ω—ã–µ –∏ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–π–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤**: Q5_K –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–ª—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –Ω–∞—Å—Ç–æ–ª—å–Ω—ã—Ö –∫–æ–º–ø—å—é—Ç–µ—Ä–∞—Ö, Q8_0 –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —Ä–∞–±–æ—á–∏—Ö —Å—Ç–∞–Ω—Ü–∏–π, –∞ Q4_K –ø–æ–∑–≤–æ–ª—è–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –Ω–∞ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–π–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞—Ö.

**–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ –∞–≥–µ–Ω—Ç—ã**: –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏—è –ø–æ–∑–≤–æ–ª—è—é—Ç –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç—å –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–≥–µ–Ω—Ç–æ–≤ —Å —É–ª—å—Ç—Ä–∞–Ω–∏–∑–∫–æ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é –¥–ª—è –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π –∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏, —Ç—Ä–µ–±—É—é—â–∏—Ö —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã—Ö –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π —Ä–µ—Å—É—Ä—Å–æ–≤.

### –≠—Ç–∞–ª–æ–Ω–Ω—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ SLM-–∞–≥–µ–Ω—Ç–æ–≤

**–°–∫–æ—Ä–æ—Å—Ç—å –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤**: Q4_K –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —Å–∞–º—ã–µ –±—ã—Å—Ç—Ä—ã–µ –≤—Ä–µ–º–µ–Ω–∞ –æ—Ç–∫–ª–∏–∫–∞ –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –º–æ–±–∏–ª—å–Ω—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞—Ö, Q5_K –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è –æ–±—â–∏—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π –∞–≥–µ–Ω—Ç–æ–≤, Q8_0 –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á –∞–≥–µ–Ω—Ç–æ–≤, –∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –¥–æ—Å—Ç–∏–≥–∞—é—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–ø—É—Å–∫–Ω–æ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –¥–ª—è —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤.

**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –ø–∞–º—è—Ç–∏ –∞–≥–µ–Ω—Ç–æ–≤**: –£—Ä–æ–≤–Ω–∏ –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏—è –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤ –≤–∞—Ä—å–∏—Ä—É—é—Ç—Å—è –æ—Ç Q2_K (–º–µ–Ω–µ–µ 500 –ú–ë –¥–ª—è –Ω–µ–±–æ–ª—å—à–∏—Ö –º–æ–¥–µ–ª–µ–π –∞–≥–µ–Ω—Ç–æ–≤) –¥–æ Q8_0 (–ø—Ä–∏–º–µ—Ä–Ω–æ 50% –æ—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞), –∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–æ—Å—Ç–∏–≥–∞—é—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –∫–æ–º–ø—Ä–µ—Å—Å–∏–∏ –¥–ª—è —Å—Ä–µ–¥ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–º–∏ —Ä–µ—Å—É—Ä—Å–∞–º–∏.

## –ü—Ä–æ–±–ª–µ–º—ã –∏ —Å–æ–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è SLM-–∞–≥–µ–Ω—Ç–æ–≤

### –ö–æ–º–ø—Ä–æ–º–∏—Å—Å—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤ —Å–∏—Å—Ç–µ–º–∞—Ö –∞–≥–µ–Ω—Ç–æ–≤

–†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ SLM-–∞–≥–µ–Ω—Ç–æ–≤ —Ç—Ä–µ–±—É–µ—Ç —Ç—â–∞—Ç–µ–ª—å–Ω–æ–≥–æ —É—á–µ—Ç–∞ –∫–æ–º–ø—Ä–æ–º–∏—Å—Å–æ–≤ –º–µ–∂–¥—É —Ä–∞–∑–º–µ—Ä–æ–º –º–æ–¥–µ–ª–∏, —Å–∫–æ—Ä–æ—Å—Ç—å—é –æ—Ç–∫–ª–∏–∫–∞ –∞–≥–µ–Ω—Ç–∞ –∏ –∫–∞—á–µ—Å—Ç–≤–æ–º –≤—ã–≤–æ–¥–∞. –í —Ç–æ –≤—Ä–µ–º—è –∫–∞–∫ Q4_K –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω—É—é —Å–∫–æ—Ä–æ—Å—Ç—å –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –¥–ª—è –º–æ–±–∏–ª—å–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤, Q8_0 –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á –∞–≥–µ–Ω—Ç–æ–≤. Q5_K –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –∑–æ–ª–æ—Ç—É—é —Å–µ—Ä–µ–¥–∏–Ω—É, –ø–æ–¥—Ö–æ–¥—è—â—É—é –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ –æ–±—â–∏—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π –∞–≥–µ–Ω—Ç–æ–≤.

### –°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è –¥–ª—è SLM-–∞–≥–µ–Ω—Ç–æ–≤

–†–∞–∑–ª–∏—á–Ω—ã–µ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–π–Ω—ã–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ –∏–º–µ—é—Ç —Ä–∞–∑–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –¥–ª—è —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è SLM-–∞–≥–µ–Ω—Ç–æ–≤. Q4_K —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ –±–∞–∑–æ–≤—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞—Ö –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤, Q5_K —Ç—Ä–µ–±—É–µ—Ç —É–º–µ—Ä–µ–Ω–Ω—ã—Ö –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤ –¥–ª—è —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∞–≥–µ–Ω—Ç–æ–≤, –∞ Q8_0 –≤—ã–∏–≥—Ä—ã–≤–∞–µ—Ç –æ—Ç –≤—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –∞–≥–µ–Ω—Ç–æ–≤.

### –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –∏ –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å –≤ —Å–∏—Å—Ç–µ–º–∞—Ö SLM-–∞–≥–µ–Ω—Ç–æ–≤

–•–æ—Ç—è SLM-–∞–≥–µ–Ω—Ç—ã –ø–æ–∑–≤–æ–ª—è—é—Ç –ª–æ–∫–∞–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç–∏, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –≤–Ω–µ–¥—Ä—è—Ç—å –Ω–∞–¥–ª–µ–∂–∞—â–∏–µ –º–µ—Ä—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –¥–ª—è –∑–∞—â–∏—Ç—ã –º–æ–¥–µ–ª–µ–π –∞–≥–µ–Ω—Ç–æ–≤ –∏ –¥–∞–Ω–Ω—ã—Ö –≤ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–π–Ω—ã—Ö —Å—Ä–µ–¥–∞—Ö. –≠—Ç–æ –æ—Å–æ–±–µ–Ω–Ω–æ –≤–∞–∂–Ω–æ –ø—Ä–∏ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–∏ —Ñ–æ—Ä–º–∞—Ç–æ–≤ –∞–≥–µ–Ω—Ç–æ–≤ —Å –≤—ã—Å–æ–∫–æ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é –≤ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã—Ö —Å—Ä–µ–¥–∞—Ö –∏–ª–∏ —Å–∂–∞—Ç—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ –∞–≥–µ–Ω—Ç–æ–≤ –≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è—Ö, —Ä–∞–±–æ—Ç–∞—é—â–∏—Ö —Å –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏.

## –ë—É–¥—É—â–∏–µ —Ç–µ–Ω–¥–µ–Ω—Ü–∏–∏ –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ SLM-–∞–≥–µ–Ω—Ç–æ–≤

–õ–∞–Ω–¥—à–∞—Ñ—Ç SLM-–∞–≥–µ–Ω—Ç–æ–≤ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç —Ä–∞–∑–≤–∏–≤–∞—Ç—å—Å—è –±–ª–∞–≥–æ–¥–∞—Ä—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è–º –≤ –º–µ—Ç–æ–¥–∞—Ö –∫–æ–º–ø—Ä–µ—Å—Å–∏–∏, –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è—Ö —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –Ω–∞ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–∏. –ë—É–¥—É—â–∏–µ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –≤–∫–ª—é—á–∞—é—Ç –±–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏—è –¥–ª—è –º–æ–¥–µ–ª–µ–π –∞–≥–µ–Ω—Ç–æ–≤, —É–ª—É—á—à–µ–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã –∫–æ–º–ø—Ä–µ—Å—Å–∏–∏ –¥–ª—è —Ä–∞–±–æ—á–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –∞–≥–µ–Ω—Ç–æ–≤ –∏ –ª—É—á—à—É—é –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é —Å –∞–ø–ø–∞—Ä–∞—Ç–Ω—ã–º–∏ —É—Å–∫–æ—Ä–∏—Ç–µ–ª—è–º–∏ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–π–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞–≥–µ–Ω—Ç–æ–≤.

**–ü—Ä–æ–≥–Ω–æ–∑—ã —Ä—ã–Ω–∫–∞ –¥–ª—è SLM-–∞–≥–µ–Ω—Ç–æ–≤**: –°–æ–≥–ª–∞—Å–Ω–æ –Ω–µ–¥–∞–≤–Ω–∏–º –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è–º, –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–≥–µ–Ω—Ç–æ–≤ –º–æ–∂–µ—Ç —É—Å—Ç—Ä–∞–Ω–∏—Ç—å 40‚Äì60% –ø–æ–≤—Ç–æ—Ä—è—é—â–∏—Ö—Å—è –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã—Ö –∑–∞–¥–∞—á –≤ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã—Ö —Ä–∞–±–æ—á–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–∞—Ö –∫ 2027 –≥–æ–¥—É, –ø—Ä–∏—á–µ–º SLM –±—É–¥—É—Ç –ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å –≤ —ç—Ç–æ–π —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –±–ª–∞–≥–æ–¥–∞—Ä—è —Å–≤–æ–µ–π —ç–∫–æ–Ω–æ–º–∏—á–Ω–æ—Å—Ç–∏ –∏ –≥–∏–±–∫–æ—Å—Ç–∏ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è.

**–¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ —Ç–µ–Ω–¥–µ–Ω—Ü–∏–∏ –≤ SLM-–∞–≥–µ–Ω—Ç–∞—Ö**:
- **–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ SLM-–∞–≥–µ–Ω—Ç—ã**: –ú–æ–¥–µ–ª–∏, –æ–±—É—á–µ–Ω–Ω—ã–µ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –∑–∞–¥–∞—á –∞–≥–µ–Ω—Ç–æ–≤ –∏ –æ—Ç—Ä–∞—Å–ª–µ–π
- **–ü–µ—Ä–∏—Ñ–µ—Ä–∏–π–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤**: –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞—Ö —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å—é –∏ —Å–Ω–∏–∂–µ–Ω–Ω–æ–π –∑–∞–¥–µ—Ä–∂–∫–æ–π
- **–û—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–æ–≤**: –õ—É—á—à–∞—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—è –º–µ–∂–¥—É –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ SLM-–∞–≥–µ–Ω—Ç–∞–º–∏ —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–π –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–µ–π –∏ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π –Ω–∞–≥—Ä—É–∑–∫–∏
- **–î–µ–º–æ–∫—Ä–∞—Ç–∏–∑–∞—Ü–∏—è**: –ì–∏–±–∫–æ—Å—Ç—å SLM –ø–æ–∑–≤–æ–ª—è–µ—Ç –±–æ–ª–µ–µ —à–∏—Ä–æ–∫–æ–µ —É—á–∞—Å—Ç–∏–µ –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ –∞–≥–µ–Ω—Ç–æ–≤ —Å—Ä–µ–¥–∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π

## –ù–∞—á–∞–ª–æ —Ä–∞–±–æ—Ç—ã —Å SLM-–∞–≥–µ–Ω—Ç–∞–º–∏

### –®–∞–≥ 1: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ä–µ–¥—ã Microsoft Agent Framework

**–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏**:
```bash
# Install Microsoft Agent Framework
pip install microsoft-agent-framework

# Install Foundry Local SDK for edge deployment
pip install foundry-local-sdk

# Install additional dependencies for edge agents
pip install openai asyncio
```

**–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ Foundry Local**:
```bash
# Start Foundry Local service
foundry service start

# Load default model for agent development
foundry model run phi-4-mini
```

### –®–∞–≥ 2: –í—ã–±–µ—Ä–∏—Ç–µ SLM –¥–ª—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π –∞–≥–µ–Ω—Ç–æ–≤
–ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –¥–ª—è Microsoft Agent Framework:
- **Microsoft Phi-4 Mini (3.8B)**: –û—Ç–ª–∏—á–Ω–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –æ–±—â–∏—Ö –∑–∞–¥–∞—á –∞–≥–µ–Ω—Ç–æ–≤ —Å —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é
- **Qwen2.5-0.5B (0.5B)**: –£–ª—å—Ç—Ä–∞—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤ –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏ –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
- **Qwen2.5-Coder-0.5B (0.5B)**: –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è –∑–∞–¥–∞—á –∞–≥–µ–Ω—Ç–æ–≤, —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å –∫–æ–¥–æ–º
- **Phi-4 (7B)**: –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –ø–µ—Ä–∏—Ñ–µ—Ä–∏–π–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ —Ä–µ—Å—É—Ä—Å–æ–≤

### –®–∞–≥ 3: –°–æ–∑–¥–∞–π—Ç–µ —Å–≤–æ–µ–≥–æ –ø–µ—Ä–≤–æ–≥–æ –∞–≥–µ–Ω—Ç–∞ —Å Microsoft Agent Framework

**–ë–∞–∑–æ–≤–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –∞–≥–µ–Ω—Ç–∞**:
```python
from microsoft_agent_framework import Agent, Config
from foundry_local import FoundryLocalManager

# Initialize Foundry Local connection
foundry = FoundryLocalManager("phi-4-mini")

# Create agent configuration
config = Config(
    name="my-first-agent",
    model_provider="foundry-local",
    model_alias="phi-4-mini",
    offline_mode=True
)

# Create and configure agent
agent = Agent(
    config=config,
    model_endpoint=foundry.endpoint,
    api_key=foundry.api_key
)

# Define a simple tool
@agent.tool
def get_current_time() -> str:
    """Get the current time."""
    from datetime import datetime
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

# Test the agent
response = agent.chat("What time is it?")
print(response)
```

### –®–∞–≥ 4: –û–ø—Ä–µ–¥–µ–ª–∏—Ç–µ –æ–±–ª–∞—Å—Ç—å –∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∞–≥–µ–Ω—Ç–∞
–ù–∞—á–Ω–∏—Ç–µ —Å —Å—Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö, —á–µ—Ç–∫–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π –∞–≥–µ–Ω—Ç–æ–≤, –∏—Å–ø–æ–ª—å–∑—É—è Microsoft Agent Framework:
- **–ê–≥–µ–Ω—Ç—ã –æ–¥–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏**: –û–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ –∫–ª–∏–µ–Ω—Ç–æ–≤ –ò–õ–ò –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ò–õ–ò –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
- **–ß–µ—Ç–∫–∏–µ —Ü–µ–ª–∏ –∞–≥–µ–Ω—Ç–∞**: –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ, –∏–∑–º–µ—Ä–∏–º—ã–µ —Ü–µ–ª–∏ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∞–≥–µ–Ω—Ç–∞
- **–û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤**: –ú–∞–∫—Å–∏–º—É–º 3-5 –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –∞–≥–µ–Ω—Ç–∞
- **–û–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ –≥—Ä–∞–Ω–∏—Ü—ã –∞–≥–µ–Ω—Ç–∞**: –ß–µ—Ç–∫–∏–µ –ø—É—Ç–∏ —ç—Å–∫–∞–ª–∞—Ü–∏–∏ –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤
- **–î–∏–∑–∞–π–Ω —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º –Ω–∞ –ø–µ—Ä–∏—Ñ–µ—Ä–∏—é**: –û—Ä–∏–µ–Ω—Ç–∏—Ä—É–π—Ç–µ—Å—å –Ω–∞ –æ—Ñ–ª–∞–π–Ω-—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –∏ –ª–æ–∫–∞–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É

### –®–∞–≥ 5: –†–µ–∞–ª–∏–∑—É–π—Ç–µ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –Ω–∞ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–∏ —Å Microsoft Agent Framework

**–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Ä–µ—Å—É—Ä—Å–æ–≤**:
```python
from microsoft_agent_framework import ResourceConfig

# Configure for edge deployment
resource_config = ResourceConfig(
    max_memory_usage="2GB",
    max_concurrent_agents=2,
    model_cache_size="1GB",
    auto_unload_idle_models=True,
    power_management=True
)

agent = Agent(
    config=config,
    resource_limits=resource_config
)
```

**–†–∞–∑–≤–µ—Ä–Ω–∏—Ç–µ –º–µ—Ä—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –¥–ª—è –ø–µ—Ä–∏—Ñ–µ—Ä–∏–π–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤**:
- **–õ–æ–∫–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –≤–≤–æ–¥–∞**: –ü—Ä–æ–≤–µ—Ä—è–π—Ç–µ –∑–∞–ø—Ä–æ—Å—ã –±–µ–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –æ–±–ª–∞–∫–∞
- **–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –≤—ã–≤–æ–¥–∞ –æ—Ñ–ª–∞–π–Ω**: –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –æ—Ç–≤–µ—Ç—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º –∫–∞—á–µ—Å—Ç–≤–∞ –ª–æ–∫–∞–ª—å–Ω–æ
- **–ö–æ–Ω—Ç—Ä–æ–ª—å –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –Ω–∞ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–∏**: –í–Ω–µ–¥—Ä—è–π—Ç–µ –º–µ—Ä—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –±–µ–∑ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É
- **–õ–æ–∫–∞–ª—å–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥**: –û—Ç—Å–ª–µ–∂–∏–≤–∞–π—Ç–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏ –æ—Ç–º–µ—á–∞–π—Ç–µ –ø—Ä–æ–±–ª–µ–º—ã —Å –ø–æ–º–æ—â—å—é —Ç–µ–ª–µ–º–µ—Ç—Ä–∏–∏ –Ω–∞ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–∏

### –®–∞–≥ 6: –ò–∑–º–µ—Ä—è–π—Ç–µ –∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–π—Ç–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–µ—Ä–∏—Ñ–µ—Ä–∏–π–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤
- **–£—Ä–æ–≤–Ω–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∑–∞–¥–∞—á –∞–≥–µ–Ω—Ç–∞**: –û—Ç—Å–ª–µ–∂–∏–≤–∞–π—Ç–µ —É—Å–ø–µ—à–Ω–æ—Å—Ç—å –≤ –æ—Ñ–ª–∞–π–Ω-—Å—Ü–µ–Ω–∞—Ä–∏—è—Ö
- **–í—Ä–µ–º—è –æ—Ç–∫–ª–∏–∫–∞ –∞–≥–µ–Ω—Ç–∞**: –û–±–µ—Å–ø–µ—á—å—Ç–µ –≤—Ä–µ–º—è –æ—Ç–∫–ª–∏–∫–∞ –º–µ–Ω–µ–µ —Å–µ–∫—É–Ω–¥—ã –¥–ª—è —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –Ω–∞ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–∏
- **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤**: –û—Ç—Å–ª–µ–∂–∏–≤–∞–π—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏, –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ –∏ –±–∞—Ç–∞—Ä–µ–∏ –Ω–∞ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–π–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞—Ö
- **–≠–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∞—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å**: –°—Ä–∞–≤–Ω–∏—Ç–µ –∑–∞—Ç—Ä–∞—Ç—ã –Ω–∞ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –Ω–∞ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–∏ —Å –æ–±–ª–∞—á–Ω—ã–º–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞–º–∏
- **–ù–∞–¥–µ–∂–Ω–æ—Å—Ç—å –æ—Ñ–ª–∞–π–Ω**: –ò–∑–º–µ—Ä—è–π—Ç–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞–≥–µ–Ω—Ç–∞ –≤–æ –≤—Ä–µ–º—è —Å–µ—Ç–µ–≤—ã—Ö —Å–±–æ–µ–≤

## –û—Å–Ω–æ–≤–Ω—ã–µ –≤—ã–≤–æ–¥—ã –¥–ª—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ SLM-–∞–≥–µ–Ω—Ç–æ–≤

1. **SLM –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤**: –î–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ –∑–∞–¥–∞—á –∞–≥–µ–Ω—Ç–æ–≤ –Ω–µ–±–æ–ª—å—à–∏–µ –º–æ–¥–µ–ª–∏ —Ä–∞–±–æ—Ç–∞—é—Ç —Ç–∞–∫ –∂–µ —Ö–æ—Ä–æ—à–æ, –∫–∞–∫ –∏ –±–æ–ª—å—à–∏–µ, –ø—Ä–µ–¥–ª–∞–≥–∞—è –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞
2. **–≠–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∞—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∞–≥–µ–Ω—Ç–æ–≤**: –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ SLM-–∞–≥–µ–Ω—Ç–æ–≤ –≤ 10-30 —Ä–∞–∑ –¥–µ—à–µ–≤–ª–µ, —á—Ç–æ –¥–µ–ª–∞–µ—Ç –∏—Ö —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏ –≤—ã–≥–æ–¥–Ω—ã–º–∏ –¥–ª—è —à–∏—Ä–æ–∫–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
3. **–°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞–±–æ—Ç–∞–µ—Ç –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤**: –¢–æ–Ω–∫–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ SLM —á–∞—Å—Ç–æ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—è—Ç —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–µ LLM –≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è—Ö –∞–≥–µ–Ω—Ç–æ–≤
4. **–ì–∏–±—Ä–∏–¥–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∞–≥–µ–Ω—Ç–æ–≤**: –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ SLM –¥–ª—è —Ä—É—Ç–∏–Ω–Ω—ã—Ö –∑–∞–¥–∞—á –∞–≥–µ–Ω—Ç–æ–≤, LLM –¥–ª—è —Å–ª–æ–∂–Ω–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
5. **Microsoft Agent Framework –ø–æ–∑–≤–æ–ª—è–µ—Ç —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –≤ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ**: –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è, —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–µ—Ä–∏—Ñ–µ—Ä–∏–π–Ω—ã–º–∏ –∞–≥–µ–Ω—Ç–∞–º–∏
6. **–ü—Ä–∏–Ω—Ü–∏–ø—ã –¥–∏–∑–∞–π–Ω–∞ —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º –Ω–∞ –ø–µ—Ä–∏—Ñ–µ—Ä–∏—é**: –ê–≥–µ–Ω—Ç—ã —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é —Ä–∞–±–æ—Ç—ã –æ—Ñ–ª–∞–π–Ω –∏ –ª–æ–∫–∞–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ–±–µ—Å–ø–µ—á–∏–≤–∞—é—Ç –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å –∏ –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å
7. **–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è Foundry Local**: –ë–µ—Å—à–æ–≤–Ω–æ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –º–µ–∂–¥—É Microsoft Agent Framework –∏ –ª–æ–∫–∞–ª—å–Ω—ã–º –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ–º –º–æ–¥–µ–ª–µ–π
8. **–ë—É–¥—É—â–µ–µ –∑–∞ SLM-–∞–≥–µ–Ω—Ç–∞–º–∏**: –ú–∞–ª—ã–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ —Å –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞–º–∏ ‚Äî –±—É–¥—É—â–µ–µ –∞–≥–µ–Ω—Ç–Ω–æ–≥–æ –ò–ò, –æ–±–µ—Å–ø–µ—á–∏–≤–∞—é—â–µ–µ –¥–µ–º–æ–∫—Ä–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –∞–≥–µ–Ω—Ç–æ–≤

## –°—Å—ã–ª–∫–∏ –∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞

### –û—Å–Ω–æ–≤–Ω—ã–µ –Ω–∞—É—á–Ω—ã–µ —Å—Ç–∞—Ç—å–∏ –∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏

#### –ò–ò-–∞–≥–µ–Ω—Ç—ã –∏ –∞–≥–µ–Ω—Ç–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã
- **"Language Agents as Optimizable Graphs"** (2024) - –§—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –∞–≥–µ–Ω—Ç–æ–≤ –∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
  - –ê–≤—Ç–æ—Ä—ã: Wenyue Hua, Lishan Yang –∏ –¥—Ä.
  - –°—Å—ã–ª–∫–∞: https://arxiv.org/abs/2402.16823
  - –û—Å–Ω–æ–≤–Ω—ã–µ –≤—ã–≤–æ–¥—ã: –î–∏–∑–∞–π–Ω –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≥—Ä–∞—Ñ–æ–≤ –∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏

- **"The Rise and Potential of Large Language Model Based Agents"** (2023)
  - –ê–≤—Ç–æ—Ä—ã: Zhiheng Xi, Wenxiang Chen –∏ –¥—Ä.
  - –°—Å—ã–ª–∫–∞: https://arxiv.org/abs/2309.07864
  - –û—Å–Ω–æ–≤–Ω—ã–µ –≤—ã–≤–æ–¥—ã: –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –æ–±–∑–æ—Ä –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ LLM

- **"Cognitive Architectures for Language Agents"** (2024)
  - –ê–≤—Ç–æ—Ä—ã: Theodore Sumers, Shunyu Yao –∏ –¥—Ä.
  - –°—Å—ã–ª–∫–∞: https://arxiv.org/abs/2309.02427
  - –û—Å–Ω–æ–≤–Ω—ã–µ –≤—ã–≤–æ–¥—ã: –ö–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã–µ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∏ –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤

#### –ú–∞–ª—ã–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
- **"Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone"** (2024)
  - –ê–≤—Ç–æ—Ä—ã: –ö–æ–º–∞–Ω–¥–∞ Microsoft Research
  - –°—Å—ã–ª–∫–∞: https://arxiv.org/abs/2404.14219
  - –û—Å–Ω–æ–≤–Ω—ã–µ –≤—ã–≤–æ–¥—ã: –ü—Ä–∏–Ω—Ü–∏–ø—ã –¥–∏–∑–∞–π–Ω–∞ SLM –∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –Ω–∞ –º–æ–±–∏–ª—å–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞—Ö

- **"Qwen2.5 Technical Report"** (2024)
  - –ê–≤—Ç–æ—Ä—ã: –ö–æ–º–∞–Ω–¥–∞ Alibaba Cloud
  - –°—Å—ã–ª–∫–∞: https://arxiv.org/abs/2407.10671
  - –û—Å–Ω–æ–≤–Ω—ã–µ –≤—ã–≤–æ–¥—ã: –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è SLM –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

- **"TinyLlama: An Open-Source Small Language Model"** (2024)
  - –ê–≤—Ç–æ—Ä—ã: Peiyuan Zhang, Guangtao Zeng –∏ –¥—Ä.
  - –°—Å—ã–ª–∫–∞: https://arxiv.org/abs/2401.02385
  - –û—Å–Ω–æ–≤–Ω—ã–µ –≤—ã–≤–æ–¥—ã: –î–∏–∑–∞–π–Ω —É–ª—å—Ç—Ä–∞–∫–æ–º–ø–∞–∫—Ç–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è

### –û—Ñ–∏—Ü–∏–∞–ª—å–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –∏ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∏

#### Microsoft Agent Framework
- **–û—Ñ–∏—Ü–∏–∞–ª—å–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è**: https://docs.microsoft.com/en-us/azure/ai-services/agents/
- **–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π GitHub**: https://github.com/microsoft/agent-framework

#### Foundry Local
- **–û—Å–Ω–æ–≤–Ω–æ–π —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π**: https://github.com/microsoft/foundry-local
- **–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è**: https://github.com/microsoft/foundry-local/blob/main/docs/README.md


#### VLLM
- **–û—Å–Ω–æ–≤–Ω–æ–π —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π**: https://github.com/vllm-project/vllm
- **–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è**: https://docs.vllm.ai/


#### Ollama
- **–û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π —Å–∞–π—Ç**: https://ollama.ai/
- **–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π GitHub**: https://github.com/ollama/ollama

### –§—Ä–µ–π–º–≤–æ—Ä–∫–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π

#### Llama.cpp
- **–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π**: https://github.com/ggml-org/llama.cpp


#### Microsoft Olive
- **–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è**: https://microsoft.github.io/Olive/
- **–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π GitHub**: https://github.com/microsoft/Olive

#### OpenVINO
- **–û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π —Å–∞–π—Ç**: https://docs.openvino.ai/

#### Apple MLX
- **–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π**: https://github.com/ml-explore/mlx

### –û—Ç—á–µ—Ç—ã –æ—Ç—Ä–∞—Å–ª–∏ –∏ –∞–Ω–∞–ª–∏–∑ —Ä—ã–Ω–∫–∞

#### –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —Ä—ã–Ω–∫–∞ –ò–ò-–∞–≥–µ–Ω—Ç–æ–≤
- **"The State of AI Agents 2025"** - McKinsey Global Institute
  - –°—Å—ã–ª–∫–∞: https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/ai-agents-2025
  - –û—Å–Ω–æ–≤–Ω—ã–µ –≤—ã–≤–æ–¥—ã: –¢–µ–Ω–¥–µ–Ω—Ü–∏–∏ —Ä—ã–Ω–∫–∞ –∏ –º–æ–¥–µ–ª–∏ –≤–Ω–µ–¥—Ä–µ–Ω–∏—è –≤ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–π —Å—Ä–µ–¥–µ

#### –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —ç—Ç–∞–ª–æ–Ω–Ω—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏

- **"Edge AI Inference Benchmarks"** - MLPerf
  - –°—Å—ã–ª–∫–∞: https://mlcommons.org/en/inference-edge/
  - –û—Å–Ω–æ–≤–Ω—ã–µ –≤—ã–≤–æ–¥—ã: –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –Ω–∞ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–∏

### –°—Ç–∞–Ω–¥–∞—Ä—Ç—ã –∏ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏

#### –§–æ—Ä–º–∞—Ç—ã –º–æ–¥–µ–ª–µ–π –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã
- **ONNX (Open Neural Network Exchange)**: https://onnx.ai/
  - –ö—Ä–æ—Å—Å–ø–ª–∞—Ç—Ñ–æ—Ä–º–µ–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –º–æ–¥–µ–ª–∏ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
- **GGUF Specification**: https://github.com/ggerganov/ggml/blob/master/docs/gguf.md
  - –§–æ—Ä–º–∞—Ç –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–∞ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞—Ö
- **OpenAI API Specification**: https://platform.openai.com/docs/api-reference
  - –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç API –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π

#### –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ
- **NIST AI Risk Management Framework**: https://www.nist.gov/itl/ai-risk-management-framework
- **ISO/IEC 23053:2022 - AI Systems**: –§—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –ò–ò-—Å–∏—Å—Ç–µ–º –∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
- **IEEE Standards for AI**: https://standards.ieee.org/industry-connections/ai/

–ü–µ—Ä–µ—Ö–æ–¥ –∫ –∞–≥–µ–Ω—Ç–∞–º –Ω–∞ –æ—Å–Ω–æ–≤–µ SLM –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –≤ –ø–æ–¥—Ö–æ–¥–µ –∫ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—é –ò–ò. Microsoft Agent Framework, –≤ —Å–æ—á–µ—Ç–∞–Ω–∏–∏ —Å –ª–æ–∫–∞–ª—å–Ω—ã–º–∏ –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞–º–∏ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–º–∏ –º–∞–ª—ã–º–∏ —è–∑—ã–∫–æ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –ø–æ–ª–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≥–æ—Ç–æ–≤—ã—Ö –∫ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤—É –∞–≥–µ–Ω—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ —Ä–∞–±–æ—Ç–∞—é—Ç –≤ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–π–Ω—ã—Ö —Å—Ä–µ–¥–∞—Ö. –°–æ—Å—Ä–µ–¥–æ—Ç–æ—á–∏–≤ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–π –ø–æ–ª–µ–∑–Ω–æ—Å—Ç–∏, —ç—Ç–æ—Ç —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫ –¥–µ–ª–∞–µ—Ç –∞–≥–µ–Ω—Ç–æ–≤ –ò–ò –±–æ–ª–µ–µ –¥–æ—Å—Ç—É–ø–Ω—ã–º–∏, —ç–∫–æ–Ω–æ–º–∏—á–Ω—ã–º–∏ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–º–∏ –¥–ª—è —Ä–µ–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π –≤ –ª—é–±–æ–π –æ—Ç—Ä–∞—Å–ª–∏ –∏ —Å—Ä–µ–¥–µ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–π–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π.

–ü–æ –º–µ—Ä–µ –ø—Ä–æ–¥–≤–∏–∂–µ–Ω–∏—è –∫ 2025 –≥–æ–¥—É —Å–æ—á–µ—Ç–∞–Ω–∏–µ –≤—Å–µ –±–æ–ª–µ–µ —Å–ø–æ—Å–æ–±–Ω—ã—Ö –º–∞–ª—ã—Ö –º–æ–¥–µ–ª–µ–π, —Å–ª–æ–∂–Ω—ã—Ö —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–æ–≤ –∞–≥–µ–Ω—Ç–æ–≤, —Ç–∞–∫–∏—Ö –∫–∞–∫ Microsoft Agent Framework, –∏ –Ω–∞–¥–µ–∂–Ω—ã—Ö –ø–ª–∞—Ç—Ñ–æ—Ä–º —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –Ω–∞ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–∏ –æ—Ç–∫—Ä–æ–µ—Ç –Ω–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –¥–ª—è –∞–≤—Ç–æ–Ω–æ–º–Ω—ã—Ö —Å–∏—Å—Ç–µ–º, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∞ –ø–µ—Ä–∏—Ñ–µ—Ä–∏–π–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞—Ö, —Å–æ—Ö—Ä–∞–Ω—è—è –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å, —Å–Ω–∏–∂–∞—è –∑–∞—Ç—Ä–∞—Ç—ã –∏ –æ–±–µ—Å–ø–µ—á–∏–≤–∞—è –∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –æ–ø—ã—Ç.

**–°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏ –¥–ª—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏**:
1. **–ò–∑—É—á–∏—Ç–µ –≤—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–π**: –£–∑–Ω–∞–π—Ç–µ, –∫–∞–∫ SLM –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤—ã–≤–æ–¥—ã
2. **–û—Å–≤–æ–π—Ç–µ –ø—Ä–æ—Ç–æ–∫–æ–ª –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –º–æ–¥–µ–ª–∏ (MCP)**: –ü–æ–π–º–∏—Ç–µ —Å–ª–æ–∂–Ω—ã–µ —à–∞–±–ª–æ–Ω—ã –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏ –∞–≥–µ–Ω—Ç–æ–≤
3. **–°–æ–∑–¥–∞–≤–∞–π—Ç–µ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤**: –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ Microsoft Agent Framework –¥–ª—è —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è
4. **–û–ø—Ç–∏–º–∏–∑–∏—Ä—É–π—Ç–µ –¥–ª—è –ø–µ—Ä–∏—Ñ–µ—Ä–∏–∏**: –ü—Ä–∏–º–µ–Ω—è–π—Ç–µ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –º–µ—Ç–æ–¥—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è —Å—Ä–µ–¥ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–º–∏ —Ä–µ—Å—É—Ä—Å–∞–º–∏


## ‚û°Ô∏è –ß—Ç–æ –¥–∞–ª—å—à–µ

- [02: –í—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–π –≤ –º–∞–ª—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö (SLM)](./02.FunctionCalling.md)

---

**–û—Ç–∫–∞–∑ –æ—Ç –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏**:  
–≠—Ç–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –±—ã–ª –ø–µ—Ä–µ–≤–µ–¥–µ–Ω —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Å–µ—Ä–≤–∏—Å–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞ [Co-op Translator](https://github.com/Azure/co-op-translator). –ù–µ—Å–º–æ—Ç—Ä—è –Ω–∞ –Ω–∞—à–∏ —É—Å–∏–ª–∏—è –æ–±–µ—Å–ø–µ—á–∏—Ç—å —Ç–æ—á–Ω–æ—Å—Ç—å, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø–µ—Ä–µ–≤–æ–¥—ã –º–æ–≥—É—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –æ—à–∏–±–∫–∏ –∏–ª–∏ –Ω–µ—Ç–æ—á–Ω–æ—Å—Ç–∏. –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –Ω–∞ –µ–≥–æ —Ä–æ–¥–Ω–æ–º —è–∑—ã–∫–µ —Å–ª–µ–¥—É–µ—Ç —Å—á–∏—Ç–∞—Ç—å –∞–≤—Ç–æ—Ä–∏—Ç–µ—Ç–Ω—ã–º –∏—Å—Ç–æ—á–Ω–∏–∫–æ–º. –î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥ —á–µ–ª–æ–≤–µ–∫–æ–º. –ú—ã –Ω–µ –Ω–µ—Å–µ–º –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ –∑–∞ –ª—é–±—ã–µ –Ω–µ–¥–æ—Ä–∞–∑—É–º–µ–Ω–∏—è –∏–ª–∏ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏, –≤–æ–∑–Ω–∏–∫–∞—é—â–∏–µ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –¥–∞–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞.